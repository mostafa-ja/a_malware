{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPWkgR96I0Nn+sR1tex5BgT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/a_malware/blob/main/PGD_Max.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install androguard\n",
        "!pip install captum\n",
        "\n",
        "import androguard\n",
        "import captum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdWcbQsbDh0u",
        "outputId": "97dc21ca-b46a-4ad4-f20c-b99bdc4db850"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting androguard\n",
            "  Downloading androguard-3.3.5-py3-none-any.whl (922 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.4/922.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asn1crypto>=0.24.0 (from androguard)\n",
            "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from androguard) (8.1.7)\n",
            "Collecting colorama (from androguard)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from androguard) (0.18.3)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from androguard) (7.34.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from androguard) (4.9.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from androguard) (3.7.1)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.10/dist-packages (from androguard) (3.2)\n",
            "Requirement already satisfied: pydot>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from androguard) (1.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from androguard) (2.16.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->androguard)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (3.0.39)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (4.8.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot>=1.4.1->androguard) (3.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (2.8.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->androguard) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->androguard) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->androguard) (0.2.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->androguard) (1.16.0)\n",
            "Installing collected packages: asn1crypto, jedi, colorama, androguard\n",
            "Successfully installed androguard-3.3.5 asn1crypto-1.5.1 colorama-0.4.6 jedi-0.19.1\n",
            "Collecting captum\n",
            "  Downloading captum-0.6.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from captum) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from captum) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from captum) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->captum) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->captum) (1.3.0)\n",
            "Installing collected packages: captum\n",
            "Successfully installed captum-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eRx10YoAiFg",
        "outputId": "f9d8218a-aa80-4ada-e1f1-18a4b4eb13b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Cloning into 'malware_detection'...\n",
            "remote: Enumerating objects: 16028, done.\u001b[K\n",
            "remote: Counting objects: 100% (2180/2180), done.\u001b[K\n",
            "remote: Compressing objects: 100% (163/163), done.\u001b[K\n",
            "remote: Total 16028 (delta 2017), reused 2165 (delta 2003), pack-reused 13848\u001b[K\n",
            "Receiving objects: 100% (16028/16028), 249.84 MiB | 16.67 MiB/s, done.\n",
            "Resolving deltas: 100% (12947/12947), done.\n",
            "Updating files: 100% (141/141), done.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import os.path as path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import os\n",
        "import gdown\n",
        "from functools import partial\n",
        "import random\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "!git clone https://github.com/mostafa-ja/malware_detection.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# our sharable address : https://drive.google.com/file/d/1-MPYbRTFn_zH3rybfAYihHuIjq2XSiI5/view?usp=sharing\n",
        "download_link = 'https://drive.google.com/uc?id=1Rro-6k4D8y5t7wX8L8dRd4SPCKAKGZXl'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "nBAlbafmmMfq",
        "outputId": "9a95ff94-b66f-4666-f6db-4beabe43c068"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Rro-6k4D8y5t7wX8L8dRd4SPCKAKGZXl\n",
            "To: /content/archive.zip\n",
            "100%|██████████| 71.3M/71.3M [00:01<00:00, 40.7MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/archive.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://drive.google.com/uc?id=1--gjFTkAJUW74RXWE4anJ5wssV7K_VAo'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "LWrVkcPVjjzg",
        "outputId": "018c7786-f651-4935-803d-1c57288c68a4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1--gjFTkAJUW74RXWE4anJ5wssV7K_VAo\n",
            "To: /content/train_dataset.pt\n",
            "100%|██████████| 97.4M/97.4M [00:01<00:00, 63.8MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/train_dataset.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://drive.google.com/uc?id=1-2NnBk3YKauGTGK8DfQHBxrLrYyTxNsp'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "P3KZMz42m4c1",
        "outputId": "274c780f-6cee-4021-b9fd-7be28d48734a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-2NnBk3YKauGTGK8DfQHBxrLrYyTxNsp\n",
            "To: /content/validation_dataset.pt\n",
            "100%|██████████| 32.5M/32.5M [00:00<00:00, 95.5MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/validation_dataset.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://drive.google.com/uc?id=1-4PhQGYHpMXrCcxcgMadgPPA4S-9yluX'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "9vo-g1RHm46G",
        "outputId": "918fda12-235b-43f8-dc72-f45b82e1e7f2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-4PhQGYHpMXrCcxcgMadgPPA4S-9yluX\n",
            "To: /content/test_dataset.pt\n",
            "100%|██████████| 32.5M/32.5M [00:00<00:00, 82.2MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/test_dataset.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/archive.zip"
      ],
      "metadata": {
        "id": "sZsmPn-7pXNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/content/naive_data /content/malware_detection/datasets/\n",
        "!cp /content/train_dataset.pt /content/malware_detection/datasets\n",
        "!cp /content/validation_dataset.pt /content/malware_detection/datasets\n",
        "!cp /content/test_dataset.pt /content/malware_detection/datasets"
      ],
      "metadata": {
        "id": "ml8RC85unN-m"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_list = os.listdir('/content/malware_detection/datasets/naive_data')\n",
        "len(file_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buq6_Gzz_JbQ",
        "outputId": "93dd65be-c78f-442e-e1b6-292a2e045f4d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5995"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "\n",
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, samples):\n",
        "        self.samples = [(torch.tensor(data, dtype=torch.float32), label) for data, label in samples]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.samples[index]"
      ],
      "metadata": {
        "id": "a4E-Kgs2AoJG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MalwareDetectionDNN(nn.Module):\n",
        "    def __init__(self, input_size, n_classes, device='cpu', name='DNN', dense_hidden_units=[200, 200], dropout=0.6, smooth=False):\n",
        "        \"\"\"\n",
        "        Construct malware detector\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        @param input_size: Integer, the dimentionality number of input vector\n",
        "        @param n_classes: Integer, the number of classes, n=2\n",
        "        @param device: String, 'cpu' or 'cuda'\n",
        "        @param name: String, model name\n",
        "        \"\"\"\n",
        "        super(MalwareDetectionDNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.n_classes = n_classes\n",
        "        self.name = name\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.smooth = smooth\n",
        "        self.dense_hidden_units = dense_hidden_units\n",
        "\n",
        "        self.dense_layers = []\n",
        "        if len(self.dense_hidden_units) >= 1:\n",
        "            self.dense_layers.append(nn.Linear(self.input_size, self.dense_hidden_units[0]))\n",
        "        else:\n",
        "            raise ValueError(\"Expect at least one hidden layer.\")\n",
        "        for i in range(len(self.dense_hidden_units[0:-1])):\n",
        "            self.dense_layers.append(nn.Linear(self.dense_hidden_units[i],  # start from idx=1\n",
        "                                               self.dense_hidden_units[i + 1]))\n",
        "        self.dense_layers.append(nn.Linear(self.dense_hidden_units[-1], self.n_classes))\n",
        "\n",
        "        # registration\n",
        "        for idx_i, dense_layer in enumerate(self.dense_layers):\n",
        "            self.add_module('nn_model_layer_{}'.format(idx_i), dense_layer)\n",
        "\n",
        "        if self.smooth:\n",
        "            self.activation_func = F.selu  # partial(F.elu, alpha=self.alpha_)\n",
        "        else:\n",
        "            self.activation_func = F.relu\n",
        "\n",
        "        self.model_save_path = path.join('/content/malware_detection/save/drebin/md_dnn'+ '_' + self.name,'model.pth')\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Go through the neural network\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        @param x: 2D tensor, feature representation\n",
        "        \"\"\"\n",
        "        for dense_layer in self.dense_layers[:-1]:\n",
        "            x = self.activation_func(dense_layer(x))\n",
        "\n",
        "        latent_representation = F.dropout(x, self.dropout, training=self.training)\n",
        "        logits = self.dense_layers[-1](latent_representation)\n",
        "        return logits\n",
        "\n",
        "    def customize_loss(self, logits, gt_labels, representation = None, mini_batch_idx=None):\n",
        "        return F.cross_entropy(logits, gt_labels)\n",
        "\n",
        "    # for predict pertubed malicious and create a y_true same size for theam\n",
        "    def inference_batch_wise(self, x):\n",
        "        \"\"\"\n",
        "        support malware samples solely\n",
        "        \"\"\"\n",
        "        assert isinstance(x, torch.Tensor)\n",
        "        logit = self.forward(x)\n",
        "        return torch.softmax(logit, dim=-1).detach().cpu().numpy(), np.ones((logit.size()[0],))\n",
        "\n",
        "    def inference(self, test_data_producer):\n",
        "        confidences = []\n",
        "        gt_labels = []\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            for x, y in test_data_producer: # for large dataset we have to consider test dataset with batches\n",
        "                x, y = x.double().to(device), y.long().to(device)\n",
        "                logits = self.forward(x)\n",
        "                confidences.append(F.softmax(logits, dim=-1))\n",
        "                gt_labels.append(y)\n",
        "        confidences = torch.vstack(confidences) #[[1,2,3],[4,5,6]] > below each other\n",
        "        gt_labels = torch.cat(gt_labels, dim=0) #[[1,2,3],[4,5,6]] > [1,2,3,4,5,6]\n",
        "        return confidences, gt_labels\n",
        "\n",
        "\n",
        "    def predict(self, test_data_producer, indicator_masking=True):\n",
        "        \"\"\"\n",
        "        predict labels and conduct evaluation\n",
        "\n",
        "        Parameters\n",
        "        --------\n",
        "        @param test_data_producer, torch.DataLoader\n",
        "        \"\"\"\n",
        "        # evaluation\n",
        "        confidence, y_true = self.inference(test_data_producer)\n",
        "        y_pred = confidence.argmax(1).cpu().numpy()\n",
        "        y_true = y_true.cpu().numpy()\n",
        "        from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, balanced_accuracy_score\n",
        "        accuracy = accuracy_score(y_true, y_pred)\n",
        "        b_accuracy = balanced_accuracy_score(y_true, y_pred)\n",
        "        print(\"The accuracy on the test dataset is {:.5f}%\".format(accuracy * 100))\n",
        "        print(\"The balanced accuracy on the test dataset is {:.5f}%\".format(b_accuracy * 100))\n",
        "\n",
        "\n",
        "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "        fpr = fp / float(tn + fp)\n",
        "        fnr = fn / float(tp + fn)\n",
        "        f1 = f1_score(y_true, y_pred, average='binary')\n",
        "\n",
        "        print(\"Other evaluation metrics we may need:\")\n",
        "        print(\"False Negative Rate (FNR) is {:.5f}%, False Positive Rate (FPR) is {:.5f}%, F1 score is {:.5f}%\".format(fnr * 100, fpr * 100, f1 * 100))\n",
        "\n"
      ],
      "metadata": {
        "id": "IBNqn_OEAuV-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/malware_detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRRx7oWaDnGY",
        "outputId": "23ffd3ee-7650-42e6-98bb-c60264898411"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/malware_detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Projected gradient descent (ascent)."
      ],
      "metadata": {
        "id": "-45R7q66ygAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from core.droidfeature import InverseDroidFeature\n",
        "\n",
        "inverse_feature = InverseDroidFeature()\n",
        "\n",
        "# manipulation_x : removable features\n",
        "manipulation_x = inverse_feature.get_manipulation()\n",
        "manipulation_x = torch.LongTensor(manipulation_x).to(device)\n",
        "\n",
        "# index of vocab which are interdependent\n",
        "omega = inverse_feature.get_interdependent_apis()\n",
        "omega = torch.sum(F.one_hot(torch.tensor(omega), num_classes=len(inverse_feature.vocab)),dim=0).to(device)\n",
        "\n",
        "# a list of vocab length : if the type of feature is api , index of that feature will be true\n",
        "api_flag = inverse_feature.get_api_flag()"
      ],
      "metadata": {
        "id": "sY7SRwnGYixM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_x0(x, rounding_threshold=0.5, is_sample=False):\n",
        "    \"\"\"\n",
        "    Helper function to randomly initialize the the inner maximizer algos\n",
        "    randomize such that the functionality is preserved.\n",
        "    :param x: training sample\n",
        "    :param is_sample: flag to sample randomly from feasible area or return just x\n",
        "    :return: randomly sampled feasible version of x\n",
        "    \"\"\"\n",
        "    if is_sample:\n",
        "        rand_x = round_x(torch.rand(x.size()), alpha=rounding_threshold)\n",
        "        if x.is_cuda:\n",
        "            rand_x = rand_x.cuda()\n",
        "        return (rand_x.byte() | x.byte()).double()\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "\n",
        "def round_x(x, alpha=0.5):\n",
        "    \"\"\"\n",
        "    rounds x by thresholding it according to alpha which can be a scalar or vector\n",
        "    :param x:\n",
        "    :param alpha: threshold parameter\n",
        "    :return: a double tensor of 0s and 1s.\n",
        "    \"\"\"\n",
        "    return (x >= alpha).double()"
      ],
      "metadata": {
        "id": "Ye0d01eYuWZv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PGD():\n",
        "    \"\"\"\n",
        "    Projected gradient descent (ascent).\n",
        "\n",
        "    Parameters\n",
        "    ---------\n",
        "    @param norm, 'l2' or 'linf'\n",
        "    @param use_random, Boolean,  whether use random start point\n",
        "    @param rounding_threshold, float, a threshold for rounding real scalars\n",
        "    @param is_attacker, Boolean, play the role of attacker (note: the defender conducts adversarial training)\n",
        "    @param oblivion, Boolean, whether know the adversary indicator or not\n",
        "    @param kappa, attack confidence\n",
        "    @param manipulation_x, manipulations\n",
        "    @param omega, the indices of interdependent apis corresponding to each api\n",
        "    @param device, 'cpu' or 'cuda'\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, norm, use_random=False, rounding_threshold=0.5,\n",
        "                 is_attacker=True, manipulation_x=None, omega=None,api_flag=None, device=None):\n",
        "        super(PGD, self).__init__()\n",
        "        assert norm == 'l1' or norm == 'l2' or norm == 'linf', \"Expect 'l1', 'l2' or 'linf'.\"\n",
        "        self.norm = norm\n",
        "        self.use_random = use_random\n",
        "        self.round_threshold = rounding_threshold\n",
        "        self.is_attacker = is_attacker\n",
        "        self.lambda_ = 1.\n",
        "        self.omeag = omega\n",
        "        self.manipulation_x = manipulation_x\n",
        "        self.api_flag = api_flag\n",
        "        self.device = device\n",
        "    def _perturb(self, model, x, label=None,\n",
        "                 steps=10,\n",
        "                 step_length=1.,\n",
        "                 lambda_=1.,\n",
        "                 ):\n",
        "        \"\"\"\n",
        "        perturb node feature vectors\n",
        "\n",
        "        Parameters\n",
        "        -----------\n",
        "        @param model, a victim model\n",
        "        @param x: torch.FloatTensor, node feature vectors (each represents the occurrences of apis in a graph) with shape [batch_size, vocab_dim]\n",
        "        @param label: torch.LongTensor, ground truth labels\n",
        "        @param steps: Integer, maximum number of iterations\n",
        "        @param step_length: float, the step length in each iteration\n",
        "        @param lambda_, float, penalty factor\n",
        "        \"\"\"\n",
        "        adv_x = x\n",
        "        self.lambda_ = lambda_\n",
        "        model.eval()\n",
        "        loss_natural = 0.\n",
        "        for t in range(steps):\n",
        "            if t == 0 and self.use_random:\n",
        "                adv_x = get_x0(adv_x, rounding_threshold=self.round_threshold, is_sample=True)\n",
        "            var_adv_x = torch.autograd.Variable(adv_x, requires_grad=True)\n",
        "            loss, done = self.get_loss(model, var_adv_x, label, self.lambda_)\n",
        "            if t == 0:\n",
        "                loss_natural = loss\n",
        "            grad = torch.autograd.grad(torch.mean(loss), var_adv_x)[0].detach().data\n",
        "            perturbation = self.get_perturbation(grad, x, adv_x)\n",
        "            adv_x = torch.clamp(adv_x + perturbation * step_length, min=0., max=1.)\n",
        "        # round\n",
        "        if self.norm == 'linf' and (not hasattr(model, 'is_detector_enabled')):\n",
        "            round_threshold = torch.rand(x.size()).to(self.device)\n",
        "        else:\n",
        "            round_threshold = self.round_threshold\n",
        "        adv_x = round_x(adv_x, round_threshold)\n",
        "        loss_adv, _1 = self.get_loss(model, adv_x, label, self.lambda_)\n",
        "        replace_flag = (loss_adv < loss_natural).unsqueeze(1).expand_as(adv_x)\n",
        "        adv_x[replace_flag] = x[replace_flag]\n",
        "        return adv_x\n",
        "\n",
        "    def perturb(self, model, x, label=None,\n",
        "                steps=10,\n",
        "                step_length=1.,\n",
        "                min_lambda_=1e-5,\n",
        "                max_lambda_=1e5,\n",
        "                base=10.,\n",
        "                verbose=False):\n",
        "        \"\"\"\n",
        "        enhance attack\n",
        "        \"\"\"\n",
        "        model.eval()\n",
        "        if hasattr(model, 'is_detector_enabled'):\n",
        "            self.lambda_ = min_lambda_\n",
        "        else:\n",
        "            self.lambda_ = max_lambda_\n",
        "\n",
        "        adv_x = x.detach().clone().to(torch.double)\n",
        "        while self.lambda_ <= max_lambda_:\n",
        "            with torch.no_grad():\n",
        "                _, done = self.get_loss(model, adv_x, label, self.lambda_)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            pert_x = self._perturb(model, adv_x[~done], label[~done],\n",
        "                                   steps,\n",
        "                                   step_length,\n",
        "                                   lambda_=self.lambda_\n",
        "                                   )\n",
        "            adv_x[~done] = pert_x\n",
        "            self.lambda_ *= base\n",
        "        with torch.no_grad():\n",
        "            _, done = self.get_loss(model, adv_x, label, self.lambda_)\n",
        "            print(f\"pgd {self.norm}: attack effectiveness {done.sum().item() / done.size()[0] * 100:.3f}%.\")\n",
        "        return adv_x\n",
        "\n",
        "    def get_perturbation(self, gradients, features, adv_features):\n",
        "        # look for allowable position, because only '1--> -' and '0 --> +' are permitted\n",
        "        # api insertion\n",
        "        pos_insertion = (adv_features <= 0.5) * 1 * (adv_features >= 0.)\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "        # grad4insertion = (gradients > 0) * gradients\n",
        "        # api removal\n",
        "        pos_removal = (adv_features > 0.5) * 1\n",
        "        grad4removal = (gradients < 0) * (pos_removal & self.manipulation_x) * gradients\n",
        "        if self.is_attacker:\n",
        "            # cope with the interdependent apis\n",
        "            checking_nonexist_api = (pos_removal ^ self.omega) & self.omega\n",
        "            grad4removal[:, self.api_flag] += torch.sum(gradients * checking_nonexist_api, dim=-1, keepdim=True)\n",
        "        gradients = grad4removal + grad4insertion\n",
        "\n",
        "        # norm\n",
        "        if self.norm == 'linf':\n",
        "            perturbation = torch.sign(gradients)\n",
        "        elif self.norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = torch.minimum(\n",
        "                torch.tensor(1., dtype=features.dtype, device=features.device),\n",
        "                gradients / l2norm\n",
        "            )\n",
        "            perturbation = torch.where(torch.isnan(perturbation), 0., perturbation)\n",
        "            perturbation = torch.where(torch.isinf(perturbation), 1., perturbation)\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # add the extra perturbation owing to the interdependent apis\n",
        "        if self.norm == 'linf' and self.is_attacker:\n",
        "            perturbation += torch.any(perturbation[:, self.api_flag] < 0, dim=-1,\n",
        "                                      keepdim=True) * checking_nonexist_api\n",
        "        if self.norm == 'l2' and self.is_attacker:\n",
        "            min_val = torch.amin(perturbation, dim=-1, keepdim=True).clamp_(max=0.)\n",
        "            perturbation += (torch.any(perturbation[:, self.api_flag] < 0, dim=-1,\n",
        "                                       keepdim=True) * torch.abs(min_val) * checking_nonexist_api)\n",
        "        return perturbation\n",
        "\n",
        "    def get_loss(self, model, adv_x, label, lambda_=None):\n",
        "        if hasattr(model, 'is_detector_enabled'):\n",
        "            logits_f, prob_g = model.forward(adv_x)\n",
        "        else:\n",
        "            logits_f = model.forward(adv_x)\n",
        "\n",
        "        ce = F.cross_entropy(logits_f, label, reduction='none')\n",
        "        y_pred = logits_f.argmax(1)\n",
        "        if hasattr(model, 'is_detector_enabled') and (not self.oblivion):\n",
        "            assert lambda_ is not None\n",
        "            tau = model.get_tau_sample_wise(y_pred)\n",
        "            if self.is_attacker:\n",
        "                loss_no_reduction = ce + lambda_ * (torch.clamp(tau - prob_g,\n",
        "                                                                max=self.kappa)\n",
        "                                                    )\n",
        "            else:\n",
        "                loss_no_reduction = ce + lambda_ * (tau - prob_g)\n",
        "            done = (y_pred != label) & (prob_g <= tau)\n",
        "        else:\n",
        "            loss_no_reduction = ce\n",
        "            done = y_pred != label\n",
        "        return loss_no_reduction, done"
      ],
      "metadata": {
        "id": "Wd8Q6mNduaya"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PGDl1():\n",
        "    \"\"\"\n",
        "    Projected gradient descent (ascent) with gradients 'normalized' using l1 norm.\n",
        "    By comparing BCA, the api removal is leveraged\n",
        "\n",
        "    Parameters\n",
        "    ---------\n",
        "    @param is_attacker, Boolean, play the role of attacker (note: the defender conducts adversarial training)\n",
        "    @param oblivion, Boolean, whether know the adversary indicator or not\n",
        "    @param kappa, attack confidence\n",
        "    @param manipulation_x, manipulations\n",
        "    @param omega, the indices of interdependent apis corresponding to each api\n",
        "    @param device, 'cpu' or 'cuda'\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, is_attacker=True, oblivion=False, kappa=1., manipulation_x=None, omega=None, api_flag=None, device=None):\n",
        "        super(PGDl1, self).__init__()\n",
        "        self.is_attacker = is_attacker\n",
        "        self.lambda_ = 1.\n",
        "        self.omeag = omega\n",
        "        self.manipulation_x = manipulation_x\n",
        "        self.api_flag = api_flag\n",
        "        self.device = device\n",
        "\n",
        "    def _perturb(self, model, x,  label=None,\n",
        "                 steps=10,\n",
        "                 lambda_=1.):\n",
        "        \"\"\"\n",
        "        perturb node feature vectors\n",
        "\n",
        "        Parameters\n",
        "        -----------\n",
        "        @param model, a victim model\n",
        "        @param x: torch.FloatTensor, node feature vectors (each represents the occurrences of apis in a graph) with shape [batch_size, number_of_graphs, vocab_dim]\n",
        "        @param label: torch.LongTensor, ground truth labels\n",
        "        @param steps: Integer, maximum number of perturbations\n",
        "        @param lambda_, float, penalty factor\n",
        "        \"\"\"\n",
        "        adv_x = x\n",
        "        worst_x = x.detach().clone()\n",
        "        self.lambda_ = lambda_\n",
        "        self.padding_mask = torch.sum(adv_x, dim=-1, keepdim=True) > 1  # we set a graph contains two apis at least\n",
        "        model.eval()\n",
        "        for t in range(steps):\n",
        "            var_adv_x = torch.autograd.Variable(adv_x, requires_grad=True)\n",
        "            loss, done = self.get_loss(model, var_adv_x, label, self.lambda_)\n",
        "            worst_x[done] = adv_x[done]\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            grad = torch.autograd.grad(torch.mean(loss), var_adv_x)[0]\n",
        "            perturbation, direction = self.get_perturbation(grad, x, adv_x)\n",
        "            # stop perturbing the examples that are successful to evade the victim\n",
        "            perturbation[done] = 0.\n",
        "            adv_x = torch.clamp(adv_x + perturbation * direction, min=0., max=1.)\n",
        "        done = self.get_scores(model, adv_x, label)\n",
        "        worst_x[done] = adv_x[done]\n",
        "        return worst_x\n",
        "\n",
        "    def perturb(self, model, x, label=None,\n",
        "                steps=10,\n",
        "                min_lambda_=1e-5,\n",
        "                max_lambda_=1e5,\n",
        "                base=10.,\n",
        "                verbose=True):\n",
        "        \"\"\"\n",
        "        enhance attack\n",
        "        \"\"\"\n",
        "        model.eval()\n",
        "        if hasattr(model, 'is_detector_enabled'):\n",
        "            self.lambda_ = min_lambda_\n",
        "        else:\n",
        "            self.lambda_ = max_lambda_\n",
        "        adv_x = x.detach().clone().to(torch.double)\n",
        "        while self.lambda_ <= max_lambda_:\n",
        "            _, done = self.get_loss(model, adv_x, label, self.lambda_)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            pert_x = self._perturb(model, adv_x[~done], label[~done],\n",
        "                                   steps,\n",
        "                                   lambda_=self.lambda_\n",
        "                                   )\n",
        "            adv_x[~done] = pert_x\n",
        "            self.lambda_ *= base\n",
        "            #if not self.check_lambda(model):\n",
        "                #break\n",
        "        with torch.no_grad():\n",
        "            _, done = self.get_loss(model, adv_x, label, self.lambda_)\n",
        "            if verbose:\n",
        "                print(f\"pgd l1: attack effectiveness {done.sum().item() / done.size()[0] * 100:.3f}%.\")\n",
        "        return adv_x\n",
        "\n",
        "    def get_perturbation(self, gradients, features, adv_features):\n",
        "        # 1. mask paddings\n",
        "        gradients = gradients * self.padding_mask\n",
        "\n",
        "        # 2. look for allowable position, because only '1--> -' and '0 --> +' are permitted\n",
        "        #    2.1 api insertion\n",
        "        pos_insertion = (adv_features <= 0.5) * 1\n",
        "        grad4insertion = (gradients > 0) * pos_insertion * gradients\n",
        "        #    2.2 api removal\n",
        "        pos_removal = (adv_features > 0.5) * 1\n",
        "        grad4removal = (gradients <= 0) * (pos_removal & self.manipulation_x) * gradients\n",
        "        if self.is_attacker:\n",
        "            #     2.2.1 cope with the interdependent apis\n",
        "            checking_nonexist_api = (pos_removal ^ self.omega) & self.omega\n",
        "            grad4removal[:, self.api_flag] += torch.sum(gradients * checking_nonexist_api, dim=-1, keepdim=True)\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "\n",
        "        # 3. remove duplications\n",
        "        un_mod = torch.abs(features - adv_features) <= 1e-6\n",
        "        gradients = gradients * un_mod\n",
        "\n",
        "        # 4. look for important position\n",
        "        absolute_grad = torch.abs(gradients).reshape(features.shape[0], -1)\n",
        "        _, position = torch.max(absolute_grad, dim=-1)\n",
        "        perturbations = F.one_hot(position, num_classes=absolute_grad.shape[-1]).double()\n",
        "        perturbations = perturbations.reshape(features.shape)\n",
        "        directions = torch.sign(gradients) * (perturbations > 1e-6)\n",
        "\n",
        "        # 5. tailor the interdependent apis\n",
        "        if self.is_attacker:\n",
        "            perturbations += (torch.any(directions[:, self.api_flag] < 0, dim=-1, keepdim=True)) * checking_nonexist_api\n",
        "            directions += perturbations * self.omega\n",
        "        return perturbations, directions\n",
        "\n",
        "\n",
        "    def get_loss(self, model, adv_x, label, lambda_=None):\n",
        "        if hasattr(model, 'is_detector_enabled'):\n",
        "            logits_f, prob_g = model.forward(adv_x)\n",
        "        else:\n",
        "            logits_f = model.forward(adv_x)\n",
        "\n",
        "        ce = F.cross_entropy(logits_f, label, reduction='none')\n",
        "        y_pred = logits_f.argmax(1)\n",
        "        if hasattr(model, 'is_detector_enabled') and (not self.oblivion):\n",
        "            assert lambda_ is not None\n",
        "            tau = model.get_tau_sample_wise(y_pred)\n",
        "            if self.is_attacker:\n",
        "                loss_no_reduction = ce + lambda_ * (torch.clamp(tau - prob_g,\n",
        "                                                                max=self.kappa)\n",
        "                                                    )\n",
        "            else:\n",
        "                loss_no_reduction = ce + lambda_ * (tau - prob_g)\n",
        "            done = (y_pred != label) & (prob_g <= tau)\n",
        "        else:\n",
        "            loss_no_reduction = ce\n",
        "            done = y_pred != label\n",
        "        return loss_no_reduction, done\n",
        "\n",
        "    def get_scores(self, model, pertb_x, label, lmda=1.):\n",
        "        if hasattr(model, 'is_detector_enabled'):\n",
        "            logits_f, prob_g = model.forward(pertb_x)\n",
        "        else:\n",
        "            logits_f = model.forward(pertb_x)\n",
        "        y_pred = logits_f.argmax(1)\n",
        "        if hasattr(model, 'is_detector_enabled') and (not self.oblivion):\n",
        "            tau = model.get_tau_sample_wise(y_pred)\n",
        "            done = (y_pred != label) & (prob_g <= tau)\n",
        "        else:\n",
        "            done = y_pred != label\n",
        "        return done"
      ],
      "metadata": {
        "id": "q-FgY4O2hy2g"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DQzXOfTmAUtp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torch.load('/content/malware_detection/datasets/train_dataset.pt')\n",
        "train_Loader = data.DataLoader(train_dataset, batch_size=128, shuffle=False)\n",
        "validation_dataset = torch.load('/content/malware_detection/datasets/validation_dataset.pt')\n",
        "validation_Loader = data.DataLoader(validation_dataset, batch_size=10000, shuffle=False)\n",
        "test_dataset = torch.load('/content/malware_detection/datasets/test_dataset.pt')\n",
        "test_Loader = data.DataLoader(test_dataset, batch_size=10000, shuffle=False)"
      ],
      "metadata": {
        "id": "MRAX7j_qywXf"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('/content/malware_detection/dataset/drebin/data.vocab', 'rb') as file:\n",
        "    loaded_data = pickle.load(file)\n",
        "\n",
        "print('number of vocabs : ',len(loaded_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngwMMct9nohS",
        "outputId": "c5bd4ffb-09c2-4c76-b55a-088bddd132ed"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of vocabs :  6693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples,labels = next(iter(test_Loader))\n",
        "x,label = samples[0:5].double(),labels[0:5].long()"
      ],
      "metadata": {
        "id": "Aunmabl3Xb6d"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "from functools import partial\n",
        "\n",
        "# A normal function\n",
        "def f(a, b, c, x):\n",
        "    return 1000*a + 100*b + 10*c + x\n",
        "\n",
        "# A partial function that calls f with\n",
        "# a as 3, b as 1 and c as 4.\n",
        "g = partial(f, 3, 1, 4)\n",
        "\n",
        "# Calling g()\n",
        "print(g(5))\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "XAgKob_UFdxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MalwareDetectionDNN(6693,2)\n",
        "model = model.double().to(device)\n",
        "\n",
        "pgdlinf = PGD(norm='linf', use_random=False,is_attacker=False,manipulation_x=manipulation_x, omega=omega,api_flag=api_flag,device=device)\n",
        "pgdlinf.perturb = partial(pgdlinf.perturb, steps=50, step_length=0.02)\n",
        "\n",
        "pgdl2 = PGD(norm='l2', use_random=False, is_attacker=False,manipulation_x=manipulation_x, omega=omega,api_flag=api_flag, device=device)\n",
        "pgdl2.perturb = partial(pgdl2.perturb, steps=50, step_length=0.5)\n",
        "\n",
        "pgdl1 = PGDl1(is_attacker=False,manipulation_x=manipulation_x, omega=omega,api_flag=api_flag,device=device)\n",
        "pgdl1.perturb = partial(pgdl1.perturb, steps=50)\n"
      ],
      "metadata": {
        "id": "tHO333FtBO55"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pgdlinf.perturb(model,x.to(device),label.to(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIiiATuQC1LD",
        "outputId": "d7925597-e52f-49f1-a96b-7ab24f686943"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pgd linf: attack effectiveness 100.000%.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
              "        [1., 1., 1.,  ..., 1., 0., 0.],\n",
              "        [1., 1., 1.,  ..., 1., 0., 1.],\n",
              "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
              "        [0., 1., 1.,  ..., 0., 1., 1.]], device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Max():\n",
        "    \"\"\"\n",
        "    max attack: select results from several attacks iteratively\n",
        "\n",
        "    Parameters\n",
        "    --------\n",
        "    @param attack_list: List, a list of instantiated attack object\n",
        "    @param varepsilon: Float, a scaler for justifying the convergence\n",
        "    \"\"\"\n",
        "    def __init__(self, attack_list, varepsilon=1e-20,is_attacker=True, oblivion=False, kappa=1., manipulation_x=None, omega=None, device=None):\n",
        "        super(Max, self).__init__()\n",
        "        assert len(attack_list) > 0, 'Expect one attack at least.'\n",
        "        self.attack_list = attack_list\n",
        "        self.varepsilon = varepsilon\n",
        "        self.device = device\n",
        "\n",
        "    def perturb(self, model, x, label=None, steps_max=5, min_lambda_=1e-5, max_lambda_=1e5, verbose=False):\n",
        "        \"\"\"\n",
        "        perturb node features\n",
        "\n",
        "        Parameters\n",
        "        -----------\n",
        "        @param model, a victim model\n",
        "        @param x: torch.FloatTensor, feature vectors with shape [batch_size, vocab_dim]\n",
        "        @param label: torch.LongTensor, ground truth labels\n",
        "        @param steps_max: Integer, maximum number of iterations\n",
        "        @param min_lambda_: float, balance the importance of adversary detector, if it exists\n",
        "        @param max_lambda_: float, balance the importance of adversary detector, if it exists\n",
        "        @param verbose: Boolean, print verbose log\n",
        "        \"\"\"\n",
        "        if x is None or x.shape[0] <= 0:\n",
        "            return []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            loss, done = self.get_scores(model, x, label) #shape:[samples],[samples]\n",
        "        pre_loss = loss\n",
        "        n, red_n = x.size()[0], x.size()[1:] #samples,features\n",
        "        red_ind = list(range(2, len(x.size()) + 1)) #2\n",
        "        adv_x = x.detach().clone()\n",
        "        stop_flag = torch.zeros(n, dtype=torch.bool, device=self.device) #[samples]\n",
        "        for t in range(steps_max):\n",
        "            num_sample_red = n - torch.sum(stop_flag)\n",
        "            if num_sample_red <= 0:\n",
        "                break\n",
        "\n",
        "            red_label = label[~stop_flag]\n",
        "            pertbx = []\n",
        "            for attack in self.attack_list:\n",
        "                assert 'perturb' in type(attack).__dict__.keys()\n",
        "                if t > 0 and 'use_random' in attack.__dict__.keys():\n",
        "                    attack.use_random = False\n",
        "                if 'Orthogonal' in type(attack).__name__:\n",
        "                    pertbx.append(attack.perturb(model=model, x=adv_x[~stop_flag], label=red_label))\n",
        "                else:\n",
        "                    pertbx.append(attack.perturb(model=model, x=adv_x[~stop_flag], label=red_label,\n",
        "                                                 min_lambda_=1e-5,\n",
        "                                                 max_lambda_=1e5,\n",
        "                                                 ))\n",
        "            # here pertbx.shape = a list of (number of attacks  ,(num_sample_red,features))\n",
        "            pertbx = torch.vstack(pertbx)\n",
        "            # here pertbx.shape = a tensor (num_sample_red*number of attacks samples, features)\n",
        "            with torch.no_grad():\n",
        "                red_label_ext = torch.cat([red_label] * len(self.attack_list)) #(labels*number of attacks )\n",
        "                loss, done = self.get_scores(model, pertbx, red_label_ext) #(labels*number of attacks )\n",
        "                loss = loss.reshape(len(self.attack_list), num_sample_red).permute(1, 0) #(num_sample_red,number of attacks) IMPORTANT: NOT(number of attacks, samples)\n",
        "                done = done.reshape(len(self.attack_list), num_sample_red).permute(1, 0) #(num_sample_red,number of attacks)\n",
        "                success_flag = torch.any(done, dim=-1) #(num_sample_red)\n",
        "                # for a sample, if there is at least one successful attack, we will select the one with maximum loss;\n",
        "                # while if no attacks evade the victim successful, all perturbed examples are reminded for selection\n",
        "                done[~torch.any(done, dim=-1)] = 1 #loss.shape=done.shape=(samples,number of attacks)\n",
        "                loss = (loss * done.to(torch.float)) + torch.min(loss) * (~done).to(torch.float) #(num_sample_red,number of attacks)\n",
        "                pertbx = pertbx.reshape(len(self.attack_list), num_sample_red, *red_n).permute([1, 0, *red_ind])#(num_sample_red,attacks,features)\n",
        "                _, indices = loss.max(dim=-1) # ans:(samples), max loss among attacks which worked, and max loss among all attacks for sample , none of them worked\n",
        "                adv_x[~stop_flag] = pertbx[torch.arange(num_sample_red), indices]\n",
        "                a_loss = loss[torch.arange(num_sample_red), indices]\n",
        "                pre_stop_flag = stop_flag.clone()\n",
        "                stop_flag[~stop_flag] = (torch.abs(pre_loss[~stop_flag] - a_loss) < self.varepsilon) | success_flag\n",
        "                pre_loss[~pre_stop_flag] = a_loss\n",
        "        if verbose:\n",
        "            with torch.no_grad():\n",
        "                _, done = self.get_scores(model, adv_x, label)\n",
        "                print(f\"max: attack effectiveness {done.sum().item() / x.size()[0] * 100}%.\")\n",
        "        return adv_x\n",
        "\n",
        "    def get_scores(self, model, pertb_x, label):\n",
        "        if hasattr(model, 'is_detector_enabled'):\n",
        "            logits_f, prob_g = model.forward(pertb_x)\n",
        "        else:\n",
        "            logits_f = model.forward(pertb_x)\n",
        "        ce = F.cross_entropy(logits_f, label, reduction='none')\n",
        "        y_pred = logits_f.argmax(1)\n",
        "        if hasattr(model, 'is_detector_enabled') and (not self.oblivion):\n",
        "            tau = model.get_tau_sample_wise(y_pred)\n",
        "            loss_no_reduction = -prob_g\n",
        "            done = (y_pred != label) & (prob_g <= tau)\n",
        "        else:\n",
        "            loss_no_reduction = ce\n",
        "            done = y_pred != label\n",
        "        return loss_no_reduction, done"
      ],
      "metadata": {
        "id": "P00GaglimTRy"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack = Max(attack_list=[pgdlinf, pgdl2, pgdl1],varepsilon=1e-9,is_attacker=False,device=device)\n",
        "attack.perturb(model,x.to(device),label.to(device),steps_max=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqZT2OCgoMI4",
        "outputId": "ea1523e7-6347-450a-ca2a-05e5a0e55e0e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pgd linf: attack effectiveness 100.000%.\n",
            "pgd l2: attack effectiveness 100.000%.\n",
            "pgd l1: attack effectiveness 100.000%.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
              "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
              "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
              "        [0., 0., 1.,  ..., 0., 1., 0.]], device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PGDAdvTraining(object):\n",
        "    \"\"\"adversarial training incorporating pgd attack\n",
        "\n",
        "    Parameters\n",
        "    -------\n",
        "    @param model, Object,  a model to be protected, e.g., MalwareDetector\n",
        "    @attack_model: Object, adversary's model for generating adversarial malware on the feature space\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, attack=None, attack_param=None):\n",
        "        self.model = model\n",
        "        self.attack = attack\n",
        "        self.attack_param = attack_param\n",
        "\n",
        "        self.name = self.model.name\n",
        "        self.model_save_path =  path.join('/content/malware_detection/save/md_at_pgd' + '_' + 'train','model.pth')\n",
        "\n",
        "    def fit(self, train_data_producer, validation_data_producer=None, adv_epochs=45,beta=0.001,lr=0.005,weight_decay=0, verbose=True):\n",
        "        \"\"\"\n",
        "        Applying adversarial train to enhance the malware detector.\n",
        "\n",
        "        Parameters\n",
        "        -------\n",
        "        @param train_data_producer: Object, an dataloader object for producing a batch of training data\n",
        "        @param validation_data_producer: Object, an dataloader object for producing validation dataset\n",
        "        @param epochs: Integer, epochs for adversarial training\n",
        "        @param adv_epochs: Integer, epochs for adversarial training\n",
        "        @param beta: Float, penalty factor for adversarial loss\n",
        "        @param lr: Float, learning rate of Adam optimizer\n",
        "        @param weight_decay: Float, penalty factor, default value 5e-4\n",
        "        @param verbose: Boolean, whether to show verbose info\n",
        "        \"\"\"\n",
        "        optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "        total_time = 0.\n",
        "        nbatches = len(train_data_producer)\n",
        "        best_acc_val = 0.\n",
        "        acc_val_adv_be = 0.\n",
        "        best_epoch = 0\n",
        "        for i in range(adv_epochs):\n",
        "            losses, accuracies = [], []\n",
        "            for idx_batch, (x_batch, y_batch) in enumerate(train_data_producer):\n",
        "                x_batch, y_batch = x_batch.double().to(device), y_batch.long().to(device)\n",
        "                batch_size = x_batch.shape[0]\n",
        "                # make data\n",
        "                mal_x_batch, ben_x_batch, mal_y_batch, ben_y_batch = x_batch[y_batch == 1], x_batch[y_batch == 0], y_batch[y_batch == 1], y_batch[y_batch == 0]\n",
        "                start_time = time.time()\n",
        "                self.model.eval()\n",
        "                pertb_mal_x = self.attack.perturb(self.model, mal_x_batch, mal_y_batch,**self.attack_param)\n",
        "                total_time += time.time() - start_time\n",
        "                x_batch = torch.cat([ben_x_batch, pertb_mal_x], dim=0)\n",
        "                y_batch = torch.cat([ben_y_batch, mal_y_batch])\n",
        "                start_time = time.time()\n",
        "                self.model.train()\n",
        "                optimizer.zero_grad()\n",
        "                logits = self.model.forward(x_batch)\n",
        "                loss_train = self.model.customize_loss(logits,y_batch)\n",
        "\n",
        "                loss_train.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                total_time += time.time() - start_time\n",
        "                mins, secs = int(total_time / 60), int(total_time % 60)\n",
        "                acc_train = (logits.argmax(1) == y_batch).sum().item()\n",
        "                acc_train /= x_batch.size()[0]\n",
        "                accuracies.append(acc_train)\n",
        "                losses.append(loss_train.item())\n",
        "                if verbose:\n",
        "                    print(f'Mini batch: {i * nbatches + idx_batch + 1}/{adv_epochs * nbatches} | training time in {mins:.0f} minutes, {secs} seconds.')\n",
        "                    print(f'Training loss (batch level): {losses[-1]:.4f} | Train accuracy: {acc_train * 100:.2f}%.')\n",
        "            if verbose:\n",
        "                print(f'Training loss (epoch level): {np.mean(losses):.4f} | Train accuracy: {np.mean(accuracies) * 100:.2f}')\n",
        "\n",
        "            # select model\n",
        "            self.model.eval()\n",
        "            # long-time to train (save the model temporally in case of interruption)\n",
        "            self.save_to_disk(i + 1, optimizer, self.model_save_path + '.tmp')\n",
        "\n",
        "            res_val = []\n",
        "            avg_acc_val = []\n",
        "            for x_val, y_val in validation_data_producer:\n",
        "                x_val, y_val = x_val.double().to(device), y_val.long().to(device)\n",
        "                logits = self.model.forward(x_val)\n",
        "                acc_val = (logits.argmax(1) == y_val).sum().item()\n",
        "                acc_val /= x_val.size()[0]\n",
        "                avg_acc_val.append(acc_val)\n",
        "\n",
        "                mal_x_batch, mal_y_batch = x_val[y_val == 1], y_val[y_val == 1]\n",
        "                pertb_mal_x = self.attack.perturb(self.model, mal_x_batch, mal_y_batch,**self.attack_param)\n",
        "                y_cent_batch, x_density_batch = self.model.inference_batch_wise(pertb_mal_x)\n",
        "                y_pred = np.argmax(y_cent_batch, axis=-1)\n",
        "                res_val.append(y_pred == 1.)\n",
        "            assert len(res_val) > 0\n",
        "            res_val = np.concatenate(res_val)\n",
        "            acc_val_adv = np.sum(res_val).astype(float) / res_val.shape[0]\n",
        "            acc_val = (np.mean(avg_acc_val) + acc_val_adv) / 2.\n",
        "            # Owing to we look for a new threshold after each epoch, this hinders the convergence of training.\n",
        "            # We save the model's parameters at last several epochs as a well-trained model may be obtained.\n",
        "            if acc_val >= best_acc_val:\n",
        "                best_acc_val = acc_val\n",
        "                acc_val_adv_be = acc_val_adv\n",
        "                best_epoch = i + 1\n",
        "                self.save_to_disk(best_epoch, optimizer, self.model_save_path)\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"\\tVal accuracy {acc_val * 100:.4}% with accuracy {acc_val_adv * 100:.4}% under attack.\")\n",
        "                print(f\"\\tModel select at epoch {best_epoch} with validation accuracy {best_acc_val * 100:.4}% and accuracy {acc_val_adv_be * 100:.4}% under attack.\")\n",
        "                if hasattr(self.model, 'tau'):\n",
        "                    print(f'The threshold is {self.model.tau}.')\n",
        "\n",
        "    #we define here not in model definition, beacause we need attack.pertube()\n",
        "    #also we must not use \"with no grad\" because we need grad for pertubation\n",
        "    def adv_predict(self, test_data_producer):\n",
        "      res_test = []\n",
        "      for x, y in test_data_producer:\n",
        "          x, y = x.double().to(device), y.long().to(device)\n",
        "\n",
        "          mal_x_batch, mal_y_batch = x[y == 1], y[y == 1]\n",
        "          pertb_mal_x = self.attack.perturb(self.model, mal_x_batch, mal_y_batch,**self.attack_param)\n",
        "          y_cent_batch, x_density_batch = self.model.inference_batch_wise(pertb_mal_x)\n",
        "          y_pred = np.argmax(y_cent_batch, axis=-1)\n",
        "          res_test.append(y_pred == 1.)\n",
        "      assert len(res_test) > 0\n",
        "      res_test = np.concatenate(res_test)\n",
        "      acc_val_adv = np.sum(res_test).astype(float) / res_test.shape[0]\n",
        "      print(f\"\\tadversarial accuracy  {acc_val_adv * 100:.4}% under attack.\")\n",
        "\n",
        "\n",
        "    def load(self):\n",
        "        assert path.exists(self.model_save_path), 'train model first'\n",
        "        ckpt = torch.load(self.model_save_path)\n",
        "        self.model.load_state_dict(ckpt['model'])\n",
        "\n",
        "    def save_to_disk(self, epoch, optimizer, save_path=None):\n",
        "        if not path.exists(save_path):\n",
        "            os.makedirs(path.dirname(save_path), exist_ok = True)\n",
        "        torch.save({'model': self.model.state_dict(),\n",
        "                    'epoch': epoch,\n",
        "                    'optimizer_state_dict': optimizer.state_dict()\n",
        "                    },\n",
        "                   save_path)"
      ],
      "metadata": {
        "id": "4eqeD6NWvqhF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxAdvTraining(object):\n",
        "    \"\"\"adversarial training incorporating mixture of attacks\n",
        "\n",
        "    Parameters\n",
        "    -------\n",
        "    @param model, Object,  a model to be protected, e.g., MalwareDetector\n",
        "    @attack_model: Object, adversary's model for generating adversarial malware on the feature space\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, attack=None, attack_param=None):\n",
        "        self.model = model\n",
        "        if attack is not None:\n",
        "            #assert isinstance(attack, (Max, StepwiseMax))\n",
        "            if 'is_attacker' in attack.__dict__.keys():\n",
        "                assert not attack.is_attacker\n",
        "        self.attack = attack\n",
        "        self.attack_param = attack_param\n",
        "\n",
        "        self.name = self.model.name\n",
        "        self.model_save_path =  path.join('/content/malware_detection/save/md_at_ma' + '_' + 'train','model.pth')\n",
        "\n",
        "    def fit(self, train_data_producer, validation_data_producer=None, adv_epochs=50,\n",
        "            beta=0.01,\n",
        "            lr=0.001,\n",
        "            under_sampling_ratio=1.,\n",
        "            weight_decay=0, verbose=True):\n",
        "        \"\"\"\n",
        "        Applying adversarial train to enhance the malware detector.\n",
        "\n",
        "        Parameters\n",
        "        -------\n",
        "        @param train_data_producer: Object, an dataloader object for producing a batch of training data\n",
        "        @param validation_data_producer: Object, an dataloader object for producing validation dataset\n",
        "        @param epochs: Integer, epochs for adversarial training\n",
        "        @param adv_epochs: Integer, epochs for adversarial training\n",
        "        @param beta: Float, penalty factor for adversarial loss\n",
        "        @param lr: Float, learning rate of Adam optimizer\n",
        "        @param under_sampling_ratio: [0,1], under-sampling a portion of malware examples for adversarial training\n",
        "        @param weight_decay: Float, penalty factor, default value 5e-4\n",
        "        @param verbose: Boolean, whether to show verbose info\n",
        "        \"\"\"\n",
        "        optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "        total_time = 0.\n",
        "        nbatches = len(train_data_producer)\n",
        "        print(\"Max adversarial training is starting ...\")\n",
        "        best_acc_val = 0.\n",
        "        acc_val_adv_be = 0.\n",
        "        best_epoch = 0\n",
        "        for i in range(adv_epochs):\n",
        "            random.seed(0)\n",
        "            losses, accuracies = [], []\n",
        "            for idx_batch, (x_batch, y_batch) in enumerate(train_data_producer):\n",
        "                x_batch, y_batch = x_batch.double().to(device), y_batch.long().to(device)\n",
        "                batch_size = x_batch.shape[0]\n",
        "                # make data\n",
        "                mal_x_batch, ben_x_batch, mal_y_batch, ben_y_batch = x_batch[y_batch == 1], x_batch[y_batch == 0], y_batch[y_batch == 1], y_batch[y_batch == 0]\n",
        "                if 0. < under_sampling_ratio < 1.:\n",
        "                    n_mal = mal_x_batch.shape[0]\n",
        "                    n_mal_sampling = int(under_sampling_ratio * n_mal) if int(under_sampling_ratio * n_mal) > 1 else 1\n",
        "                    idx_sampling = random.sample(range(n_mal), n_mal_sampling)\n",
        "                    mal_x_batch, mal_y_batch = mal_x_batch[idx_sampling], mal_y_batch[idx_sampling]\n",
        "\n",
        "                start_time = time.time()\n",
        "                self.model.eval()\n",
        "                pertb_mal_x = self.attack.perturb(self.model, mal_x_batch, mal_y_batch,**self.attack_param)\n",
        "                pertb_mal_x = round_x(pertb_mal_x, 0.5)\n",
        "                total_time += time.time() - start_time\n",
        "                x_batch = torch.cat([x_batch, pertb_mal_x], dim=0)\n",
        "                y_batch = torch.cat([y_batch, mal_y_batch])\n",
        "                start_time = time.time()\n",
        "                self.model.train()\n",
        "                optimizer.zero_grad()\n",
        "                logits = self.model.forward(x_batch)\n",
        "                loss_train = self.model.customize_loss(logits[:batch_size],y_batch[:batch_size])\n",
        "                loss_train += beta * self.model.customize_loss(logits[batch_size:],y_batch[batch_size:])\n",
        "\n",
        "                loss_train.backward()\n",
        "                optimizer.step()\n",
        "                total_time += time.time() - start_time\n",
        "                mins, secs = int(total_time / 60), int(total_time % 60)\n",
        "                acc_train = (logits.argmax(1) == y_batch).sum().item()\n",
        "                acc_train /= x_batch.size()[0]\n",
        "                accuracies.append(acc_train)\n",
        "                losses.append(loss_train.item())\n",
        "                if verbose:\n",
        "                    print(f'Mini batch: {i * nbatches + idx_batch + 1}/{adv_epochs * nbatches} | training time in {mins:.0f} minutes, {secs} seconds.')\n",
        "                    print(f'Training loss (batch level): {losses[-1]:.4f} | Train accuracy: {acc_train * 100:.2f}%.')\n",
        "            if verbose:\n",
        "                print(f'Training loss (epoch level): {np.mean(losses):.4f} | Train accuracy: {np.mean(accuracies) * 100:.2f}')\n",
        "\n",
        "            # select model\n",
        "            self.model.eval()\n",
        "            # long-time to train (save the model temporally in case of interruption)\n",
        "            self.save_to_disk(i + 1, optimizer, self.model_save_path + '.tmp')\n",
        "            self.attack.is_attacker = True\n",
        "            res_val = []\n",
        "            avg_acc_val = []\n",
        "            for x_val, y_val in validation_data_producer:\n",
        "                x_val, y_val = x_val.double().to(device), y_val.long().to(device)\n",
        "                logits = self.model.forward(x_val)\n",
        "                acc_val = (logits.argmax(1) == y_val).sum().item()\n",
        "                acc_val /= x_val.size()[0]\n",
        "                avg_acc_val.append(acc_val)\n",
        "\n",
        "                mal_x_batch, mal_y_batch = x_val[y_val == 1], y_val[y_val == 1]\n",
        "\n",
        "                pertb_mal_x = self.attack.perturb(self.model, mal_x_batch, mal_y_batch,\n",
        "                                                  **self.attack_param\n",
        "                                                  )\n",
        "                pertb_mal_x = round_x(pertb_mal_x, 0.5)\n",
        "                y_cent_batch, x_density_batch = self.model.inference_batch_wise(pertb_mal_x)\n",
        "                y_pred = np.argmax(y_cent_batch, axis=-1)\n",
        "                res_val.append(y_pred == 1.)\n",
        "            assert len(res_val) > 0\n",
        "            res_val = np.concatenate(res_val)\n",
        "            acc_val_adv = np.sum(res_val).astype(float) / res_val.shape[0]\n",
        "            acc_val = (np.mean(avg_acc_val) + acc_val_adv) / 2.\n",
        "            # Owing to we look for a new threshold after each epoch, this hinders the convergence of training.\n",
        "            # We save the model's parameters at last several epochs as a well-trained model may be obtained.\n",
        "            if acc_val >= best_acc_val:\n",
        "                best_acc_val = acc_val\n",
        "                acc_val_adv_be = acc_val_adv\n",
        "                best_epoch = i + 1\n",
        "                self.save_to_disk(best_epoch, optimizer, self.model_save_path)\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"\\tVal accuracy {acc_val * 100:.4}% with accuracy {acc_val_adv * 100:.4}% under attack.\")\n",
        "                print(f\"\\tModel select at epoch {best_epoch} with validation accuracy {best_acc_val * 100:.4}% and accuracy {acc_val_adv_be * 100:.4}% under attack.\")\n",
        "                if hasattr(self.model, 'tau'):\n",
        "                    print(\n",
        "                        f'The threshold is {self.model.tau}.'\n",
        "                    )\n",
        "            self.attack.is_attacker = False\n",
        "\n",
        "    def load(self):\n",
        "        assert path.exists(self.model_save_path), 'train model first'\n",
        "        ckpt = torch.load(self.model_save_path)\n",
        "        # self.model.tau = ckpt['tau']\n",
        "        # self.model.md_nn_model.load_state_dict(ckpt['md_model'])\n",
        "        # self.model.load_state_dict(ckpt['amd_model'])\n",
        "        self.model.load_state_dict(ckpt['model'])\n",
        "\n",
        "    def save_to_disk(self, epoch, optimizer, save_path=None):\n",
        "        if not path.exists(save_path):\n",
        "            os.makedirs(path.dirname(save_path), exist_ok = True)\n",
        "        # torch.save({'tau': self.model.tau,\n",
        "        #             'md_model': self.model.md_nn_model.state_dict(),\n",
        "        #             'amd_model': self.model.state_dict(),\n",
        "        #             'epoch': epoch,\n",
        "        #             'optimizer_state_dict': optimizer.state_dict()\n",
        "        #             },\n",
        "        #            save_path)\n",
        "        torch.save({'model': self.model.state_dict(),\n",
        "                    'epoch': epoch,\n",
        "                    'optimizer_state_dict': optimizer.state_dict()\n",
        "                    },\n",
        "                   save_path)"
      ],
      "metadata": {
        "id": "ep4KRO56n0nb"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack = Max(attack_list=[pgdlinf, pgdl2, pgdl1],varepsilon=1e-9,is_attacker=False,device=device)\n",
        "attack_param = {\n",
        "            'steps_max': 1,  # steps for max attack\n",
        "            'verbose': True\n",
        "              }\n",
        "max_adv_training_model = MaxAdvTraining(model, attack, attack_param)\n",
        "\n",
        "max_adv_training_model.fit(train_Loader,\n",
        "                          validation_Loader,\n",
        "                          adv_epochs=50,\n",
        "                          beta=0.01,\n",
        "                          lr=0.001,\n",
        "                          under_sampling_ratio=1.,\n",
        "                          weight_decay=0.\n",
        "                          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RptuASbsmQly",
        "outputId": "3439aa12-c491-4466-b05f-07731703d247"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "pgd l1: attack effectiveness 53.968%.\n",
            "max: attack effectiveness 76.19047619047619%.\n",
            "Mini batch: 650/1450 | training time in 7 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0406 | Train accuracy: 76.96%.\n",
            "pgd linf: attack effectiveness 12.308%.\n",
            "pgd l2: attack effectiveness 50.769%.\n",
            "pgd l1: attack effectiveness 56.923%.\n",
            "max: attack effectiveness 70.76923076923077%.\n",
            "Mini batch: 651/1450 | training time in 7 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0311 | Train accuracy: 78.76%.\n",
            "pgd linf: attack effectiveness 10.606%.\n",
            "pgd l2: attack effectiveness 40.909%.\n",
            "pgd l1: attack effectiveness 50.000%.\n",
            "max: attack effectiveness 53.03030303030303%.\n",
            "Mini batch: 652/1450 | training time in 7 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0611 | Train accuracy: 80.41%.\n",
            "pgd linf: attack effectiveness 13.846%.\n",
            "pgd l2: attack effectiveness 27.692%.\n",
            "pgd l1: attack effectiveness 46.154%.\n",
            "max: attack effectiveness 47.69230769230769%.\n",
            "Mini batch: 653/1450 | training time in 7 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0411 | Train accuracy: 84.46%.\n",
            "pgd linf: attack effectiveness 21.127%.\n",
            "pgd l2: attack effectiveness 45.070%.\n",
            "pgd l1: attack effectiveness 59.155%.\n",
            "max: attack effectiveness 60.56338028169014%.\n",
            "Mini batch: 654/1450 | training time in 7 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0217 | Train accuracy: 81.41%.\n",
            "pgd linf: attack effectiveness 9.375%.\n",
            "pgd l2: attack effectiveness 25.000%.\n",
            "pgd l1: attack effectiveness 42.188%.\n",
            "max: attack effectiveness 42.1875%.\n",
            "Mini batch: 655/1450 | training time in 7 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0194 | Train accuracy: 87.50%.\n",
            "pgd linf: attack effectiveness 22.388%.\n",
            "pgd l2: attack effectiveness 16.418%.\n",
            "pgd l1: attack effectiveness 47.761%.\n",
            "max: attack effectiveness 49.25373134328358%.\n",
            "Mini batch: 656/1450 | training time in 7 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0299 | Train accuracy: 83.59%.\n",
            "pgd linf: attack effectiveness 21.875%.\n",
            "pgd l2: attack effectiveness 18.750%.\n",
            "pgd l1: attack effectiveness 56.250%.\n",
            "max: attack effectiveness 56.25%.\n",
            "Mini batch: 657/1450 | training time in 7 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0194 | Train accuracy: 82.81%.\n",
            "pgd linf: attack effectiveness 33.784%.\n",
            "pgd l2: attack effectiveness 45.946%.\n",
            "pgd l1: attack effectiveness 55.405%.\n",
            "max: attack effectiveness 56.75675675675676%.\n",
            "Mini batch: 658/1450 | training time in 7 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0296 | Train accuracy: 79.70%.\n",
            "pgd linf: attack effectiveness 27.536%.\n",
            "pgd l2: attack effectiveness 34.783%.\n",
            "pgd l1: attack effectiveness 53.623%.\n",
            "max: attack effectiveness 53.62318840579711%.\n",
            "Mini batch: 659/1450 | training time in 7 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0180 | Train accuracy: 81.73%.\n",
            "pgd linf: attack effectiveness 22.667%.\n",
            "pgd l2: attack effectiveness 25.333%.\n",
            "pgd l1: attack effectiveness 54.667%.\n",
            "max: attack effectiveness 54.666666666666664%.\n",
            "Mini batch: 660/1450 | training time in 7 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0230 | Train accuracy: 82.27%.\n",
            "pgd linf: attack effectiveness 19.118%.\n",
            "pgd l2: attack effectiveness 10.294%.\n",
            "pgd l1: attack effectiveness 50.000%.\n",
            "max: attack effectiveness 50.0%.\n",
            "Mini batch: 661/1450 | training time in 7 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0127 | Train accuracy: 85.20%.\n",
            "pgd linf: attack effectiveness 20.339%.\n",
            "pgd l2: attack effectiveness 32.203%.\n",
            "pgd l1: attack effectiveness 49.153%.\n",
            "max: attack effectiveness 49.152542372881356%.\n",
            "Mini batch: 662/1450 | training time in 7 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0294 | Train accuracy: 85.56%.\n",
            "pgd linf: attack effectiveness 12.000%.\n",
            "pgd l2: attack effectiveness 18.667%.\n",
            "pgd l1: attack effectiveness 53.333%.\n",
            "max: attack effectiveness 54.666666666666664%.\n",
            "Mini batch: 663/1450 | training time in 7 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0146 | Train accuracy: 79.80%.\n",
            "pgd linf: attack effectiveness 5.797%.\n",
            "pgd l2: attack effectiveness 11.594%.\n",
            "pgd l1: attack effectiveness 55.072%.\n",
            "max: attack effectiveness 57.971014492753625%.\n",
            "Mini batch: 664/1450 | training time in 7 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0287 | Train accuracy: 81.22%.\n",
            "pgd linf: attack effectiveness 4.688%.\n",
            "pgd l2: attack effectiveness 9.375%.\n",
            "pgd l1: attack effectiveness 42.188%.\n",
            "max: attack effectiveness 42.1875%.\n",
            "Mini batch: 665/1450 | training time in 7 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0194 | Train accuracy: 88.02%.\n",
            "pgd linf: attack effectiveness 3.226%.\n",
            "pgd l2: attack effectiveness 8.065%.\n",
            "pgd l1: attack effectiveness 43.548%.\n",
            "max: attack effectiveness 43.54838709677419%.\n",
            "Mini batch: 666/1450 | training time in 7 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0172 | Train accuracy: 88.42%.\n",
            "pgd linf: attack effectiveness 16.667%.\n",
            "pgd l2: attack effectiveness 16.667%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 667/1450 | training time in 7 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0167 | Train accuracy: 89.47%.\n",
            "Training loss (epoch level): 0.0267 | Train accuracy: 82.67\n",
            "pgd linf: attack effectiveness 9.319%.\n",
            "pgd l2: attack effectiveness 18.100%.\n",
            "pgd l1: attack effectiveness 61.470%.\n",
            "max: attack effectiveness 61.648745519713266%.\n",
            "\tVal accuracy 67.42% with accuracy 38.35% under attack.\n",
            "\tModel select at epoch 23 with validation accuracy 67.42% and accuracy 38.35% under attack.\n",
            "pgd linf: attack effectiveness 9.091%.\n",
            "pgd l2: attack effectiveness 16.667%.\n",
            "pgd l1: attack effectiveness 46.970%.\n",
            "max: attack effectiveness 46.96969696969697%.\n",
            "Mini batch: 668/1450 | training time in 7 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0241 | Train accuracy: 86.08%.\n",
            "pgd linf: attack effectiveness 3.175%.\n",
            "pgd l2: attack effectiveness 6.349%.\n",
            "pgd l1: attack effectiveness 55.556%.\n",
            "max: attack effectiveness 55.55555555555556%.\n",
            "Mini batch: 669/1450 | training time in 7 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0315 | Train accuracy: 82.72%.\n",
            "pgd linf: attack effectiveness 7.576%.\n",
            "pgd l2: attack effectiveness 15.152%.\n",
            "pgd l1: attack effectiveness 46.970%.\n",
            "max: attack effectiveness 46.96969696969697%.\n",
            "Mini batch: 670/1450 | training time in 7 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0798 | Train accuracy: 85.57%.\n",
            "pgd linf: attack effectiveness 10.000%.\n",
            "pgd l2: attack effectiveness 7.143%.\n",
            "pgd l1: attack effectiveness 54.286%.\n",
            "max: attack effectiveness 54.285714285714285%.\n",
            "Mini batch: 671/1450 | training time in 7 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0112 | Train accuracy: 86.36%.\n",
            "pgd linf: attack effectiveness 22.535%.\n",
            "pgd l2: attack effectiveness 11.268%.\n",
            "pgd l1: attack effectiveness 53.521%.\n",
            "max: attack effectiveness 53.52112676056338%.\n",
            "Mini batch: 672/1450 | training time in 7 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0296 | Train accuracy: 84.42%.\n",
            "pgd linf: attack effectiveness 19.737%.\n",
            "pgd l2: attack effectiveness 32.895%.\n",
            "pgd l1: attack effectiveness 59.211%.\n",
            "max: attack effectiveness 59.210526315789465%.\n",
            "Mini batch: 673/1450 | training time in 7 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0203 | Train accuracy: 82.35%.\n",
            "pgd linf: attack effectiveness 3.279%.\n",
            "pgd l2: attack effectiveness 16.393%.\n",
            "pgd l1: attack effectiveness 54.098%.\n",
            "max: attack effectiveness 54.09836065573771%.\n",
            "Mini batch: 674/1450 | training time in 7 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0130 | Train accuracy: 85.71%.\n",
            "pgd linf: attack effectiveness 20.290%.\n",
            "pgd l2: attack effectiveness 36.232%.\n",
            "pgd l1: attack effectiveness 59.420%.\n",
            "max: attack effectiveness 60.86956521739131%.\n",
            "Mini batch: 675/1450 | training time in 7 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0305 | Train accuracy: 79.70%.\n",
            "pgd linf: attack effectiveness 14.516%.\n",
            "pgd l2: attack effectiveness 33.871%.\n",
            "pgd l1: attack effectiveness 50.000%.\n",
            "max: attack effectiveness 53.2258064516129%.\n",
            "Mini batch: 676/1450 | training time in 7 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0155 | Train accuracy: 85.26%.\n",
            "pgd linf: attack effectiveness 26.667%.\n",
            "pgd l2: attack effectiveness 50.000%.\n",
            "pgd l1: attack effectiveness 68.333%.\n",
            "max: attack effectiveness 76.66666666666667%.\n",
            "Mini batch: 677/1450 | training time in 7 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0303 | Train accuracy: 81.91%.\n",
            "pgd linf: attack effectiveness 14.815%.\n",
            "pgd l2: attack effectiveness 40.741%.\n",
            "pgd l1: attack effectiveness 53.704%.\n",
            "max: attack effectiveness 64.81481481481481%.\n",
            "Mini batch: 678/1450 | training time in 7 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0177 | Train accuracy: 83.52%.\n",
            "pgd linf: attack effectiveness 17.460%.\n",
            "pgd l2: attack effectiveness 36.508%.\n",
            "pgd l1: attack effectiveness 61.905%.\n",
            "max: attack effectiveness 69.84126984126983%.\n",
            "Mini batch: 679/1450 | training time in 7 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0226 | Train accuracy: 78.53%.\n",
            "pgd linf: attack effectiveness 12.308%.\n",
            "pgd l2: attack effectiveness 26.154%.\n",
            "pgd l1: attack effectiveness 66.154%.\n",
            "max: attack effectiveness 69.23076923076923%.\n",
            "Mini batch: 680/1450 | training time in 7 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0177 | Train accuracy: 80.83%.\n",
            "pgd linf: attack effectiveness 10.606%.\n",
            "pgd l2: attack effectiveness 22.727%.\n",
            "pgd l1: attack effectiveness 50.000%.\n",
            "max: attack effectiveness 50.0%.\n",
            "Mini batch: 681/1450 | training time in 7 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0449 | Train accuracy: 83.51%.\n",
            "pgd linf: attack effectiveness 6.154%.\n",
            "pgd l2: attack effectiveness 29.231%.\n",
            "pgd l1: attack effectiveness 47.692%.\n",
            "max: attack effectiveness 47.69230769230769%.\n",
            "Mini batch: 682/1450 | training time in 7 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0412 | Train accuracy: 85.49%.\n",
            "pgd linf: attack effectiveness 7.042%.\n",
            "pgd l2: attack effectiveness 38.028%.\n",
            "pgd l1: attack effectiveness 57.746%.\n",
            "max: attack effectiveness 57.74647887323944%.\n",
            "Mini batch: 683/1450 | training time in 7 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0256 | Train accuracy: 80.90%.\n",
            "pgd linf: attack effectiveness 14.062%.\n",
            "pgd l2: attack effectiveness 21.875%.\n",
            "pgd l1: attack effectiveness 42.188%.\n",
            "max: attack effectiveness 42.1875%.\n",
            "Mini batch: 684/1450 | training time in 7 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0196 | Train accuracy: 89.58%.\n",
            "pgd linf: attack effectiveness 10.448%.\n",
            "pgd l2: attack effectiveness 38.806%.\n",
            "pgd l1: attack effectiveness 47.761%.\n",
            "max: attack effectiveness 50.74626865671642%.\n",
            "Mini batch: 685/1450 | training time in 7 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0259 | Train accuracy: 83.08%.\n",
            "pgd linf: attack effectiveness 18.750%.\n",
            "pgd l2: attack effectiveness 60.938%.\n",
            "pgd l1: attack effectiveness 54.688%.\n",
            "max: attack effectiveness 73.4375%.\n",
            "Mini batch: 686/1450 | training time in 7 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0299 | Train accuracy: 77.60%.\n",
            "pgd linf: attack effectiveness 24.324%.\n",
            "pgd l2: attack effectiveness 67.568%.\n",
            "pgd l1: attack effectiveness 54.054%.\n",
            "max: attack effectiveness 72.97297297297297%.\n",
            "Mini batch: 687/1450 | training time in 7 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0433 | Train accuracy: 73.76%.\n",
            "pgd linf: attack effectiveness 18.841%.\n",
            "pgd l2: attack effectiveness 76.812%.\n",
            "pgd l1: attack effectiveness 44.928%.\n",
            "max: attack effectiveness 81.15942028985508%.\n",
            "Mini batch: 688/1450 | training time in 7 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0328 | Train accuracy: 73.60%.\n",
            "pgd linf: attack effectiveness 20.000%.\n",
            "pgd l2: attack effectiveness 72.000%.\n",
            "pgd l1: attack effectiveness 50.667%.\n",
            "max: attack effectiveness 77.33333333333333%.\n",
            "Mini batch: 689/1450 | training time in 7 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0422 | Train accuracy: 72.91%.\n",
            "pgd linf: attack effectiveness 16.176%.\n",
            "pgd l2: attack effectiveness 60.294%.\n",
            "pgd l1: attack effectiveness 48.529%.\n",
            "max: attack effectiveness 63.23529411764706%.\n",
            "Mini batch: 690/1450 | training time in 7 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0297 | Train accuracy: 78.57%.\n",
            "pgd linf: attack effectiveness 13.559%.\n",
            "pgd l2: attack effectiveness 54.237%.\n",
            "pgd l1: attack effectiveness 52.542%.\n",
            "max: attack effectiveness 57.6271186440678%.\n",
            "Mini batch: 691/1450 | training time in 7 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0494 | Train accuracy: 80.75%.\n",
            "pgd linf: attack effectiveness 14.667%.\n",
            "pgd l2: attack effectiveness 48.000%.\n",
            "pgd l1: attack effectiveness 48.000%.\n",
            "max: attack effectiveness 54.666666666666664%.\n",
            "Mini batch: 692/1450 | training time in 7 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0282 | Train accuracy: 79.80%.\n",
            "pgd linf: attack effectiveness 10.145%.\n",
            "pgd l2: attack effectiveness 40.580%.\n",
            "pgd l1: attack effectiveness 52.174%.\n",
            "max: attack effectiveness 55.072463768115945%.\n",
            "Mini batch: 693/1450 | training time in 7 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0287 | Train accuracy: 82.74%.\n",
            "pgd linf: attack effectiveness 9.375%.\n",
            "pgd l2: attack effectiveness 31.250%.\n",
            "pgd l1: attack effectiveness 42.188%.\n",
            "max: attack effectiveness 42.1875%.\n",
            "Mini batch: 694/1450 | training time in 7 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0230 | Train accuracy: 86.98%.\n",
            "pgd linf: attack effectiveness 6.452%.\n",
            "pgd l2: attack effectiveness 27.419%.\n",
            "pgd l1: attack effectiveness 43.548%.\n",
            "max: attack effectiveness 43.54838709677419%.\n",
            "Mini batch: 695/1450 | training time in 7 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0229 | Train accuracy: 87.89%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 696/1450 | training time in 7 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0180 | Train accuracy: 89.47%.\n",
            "Training loss (epoch level): 0.0293 | Train accuracy: 82.40\n",
            "pgd linf: attack effectiveness 15.591%.\n",
            "pgd l2: attack effectiveness 34.588%.\n",
            "pgd l1: attack effectiveness 60.036%.\n",
            "max: attack effectiveness 60.0358422939068%.\n",
            "\tVal accuracy 68.27% with accuracy 39.96% under attack.\n",
            "\tModel select at epoch 24 with validation accuracy 68.27% and accuracy 39.96% under attack.\n",
            "pgd linf: attack effectiveness 12.121%.\n",
            "pgd l2: attack effectiveness 34.848%.\n",
            "pgd l1: attack effectiveness 48.485%.\n",
            "max: attack effectiveness 48.484848484848484%.\n",
            "Mini batch: 697/1450 | training time in 7 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0490 | Train accuracy: 85.57%.\n",
            "pgd linf: attack effectiveness 14.286%.\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "pgd l1: attack effectiveness 55.556%.\n",
            "max: attack effectiveness 55.55555555555556%.\n",
            "Mini batch: 698/1450 | training time in 7 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0467 | Train accuracy: 82.72%.\n",
            "pgd linf: attack effectiveness 16.667%.\n",
            "pgd l2: attack effectiveness 28.788%.\n",
            "pgd l1: attack effectiveness 46.970%.\n",
            "max: attack effectiveness 46.96969696969697%.\n",
            "Mini batch: 699/1450 | training time in 7 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0646 | Train accuracy: 85.05%.\n",
            "pgd linf: attack effectiveness 7.143%.\n",
            "pgd l2: attack effectiveness 30.000%.\n",
            "pgd l1: attack effectiveness 52.857%.\n",
            "max: attack effectiveness 52.85714285714286%.\n",
            "Mini batch: 700/1450 | training time in 7 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0199 | Train accuracy: 81.31%.\n",
            "pgd linf: attack effectiveness 19.718%.\n",
            "pgd l2: attack effectiveness 43.662%.\n",
            "pgd l1: attack effectiveness 54.930%.\n",
            "max: attack effectiveness 56.33802816901409%.\n",
            "Mini batch: 701/1450 | training time in 7 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0284 | Train accuracy: 77.89%.\n",
            "pgd linf: attack effectiveness 15.789%.\n",
            "pgd l2: attack effectiveness 42.105%.\n",
            "pgd l1: attack effectiveness 55.263%.\n",
            "max: attack effectiveness 57.89473684210527%.\n",
            "Mini batch: 702/1450 | training time in 7 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0230 | Train accuracy: 81.86%.\n",
            "pgd linf: attack effectiveness 11.475%.\n",
            "pgd l2: attack effectiveness 37.705%.\n",
            "pgd l1: attack effectiveness 52.459%.\n",
            "max: attack effectiveness 52.459016393442624%.\n",
            "Mini batch: 703/1450 | training time in 7 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0298 | Train accuracy: 84.13%.\n",
            "pgd linf: attack effectiveness 14.493%.\n",
            "pgd l2: attack effectiveness 31.884%.\n",
            "pgd l1: attack effectiveness 52.174%.\n",
            "max: attack effectiveness 52.17391304347826%.\n",
            "Mini batch: 704/1450 | training time in 7 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0295 | Train accuracy: 84.26%.\n",
            "pgd linf: attack effectiveness 17.742%.\n",
            "pgd l2: attack effectiveness 38.710%.\n",
            "pgd l1: attack effectiveness 46.774%.\n",
            "max: attack effectiveness 53.2258064516129%.\n",
            "Mini batch: 705/1450 | training time in 7 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0259 | Train accuracy: 86.32%.\n",
            "pgd linf: attack effectiveness 15.000%.\n",
            "pgd l2: attack effectiveness 45.000%.\n",
            "pgd l1: attack effectiveness 63.333%.\n",
            "max: attack effectiveness 66.66666666666666%.\n",
            "Mini batch: 706/1450 | training time in 7 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0401 | Train accuracy: 82.45%.\n",
            "pgd linf: attack effectiveness 12.963%.\n",
            "pgd l2: attack effectiveness 40.741%.\n",
            "pgd l1: attack effectiveness 42.593%.\n",
            "max: attack effectiveness 55.55555555555556%.\n",
            "Mini batch: 707/1450 | training time in 7 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0230 | Train accuracy: 85.71%.\n",
            "pgd linf: attack effectiveness 19.048%.\n",
            "pgd l2: attack effectiveness 53.968%.\n",
            "pgd l1: attack effectiveness 63.492%.\n",
            "max: attack effectiveness 68.25396825396825%.\n",
            "Mini batch: 708/1450 | training time in 7 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0313 | Train accuracy: 79.58%.\n",
            "pgd linf: attack effectiveness 20.000%.\n",
            "pgd l2: attack effectiveness 40.000%.\n",
            "pgd l1: attack effectiveness 61.538%.\n",
            "max: attack effectiveness 63.07692307692307%.\n",
            "Mini batch: 709/1450 | training time in 7 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0202 | Train accuracy: 81.87%.\n",
            "pgd linf: attack effectiveness 16.667%.\n",
            "pgd l2: attack effectiveness 50.000%.\n",
            "pgd l1: attack effectiveness 50.000%.\n",
            "max: attack effectiveness 57.57575757575758%.\n",
            "Mini batch: 710/1450 | training time in 7 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0278 | Train accuracy: 82.99%.\n",
            "pgd linf: attack effectiveness 20.000%.\n",
            "pgd l2: attack effectiveness 33.846%.\n",
            "pgd l1: attack effectiveness 50.769%.\n",
            "max: attack effectiveness 52.307692307692314%.\n",
            "Mini batch: 711/1450 | training time in 7 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0568 | Train accuracy: 84.97%.\n",
            "pgd linf: attack effectiveness 22.535%.\n",
            "pgd l2: attack effectiveness 49.296%.\n",
            "pgd l1: attack effectiveness 64.789%.\n",
            "max: attack effectiveness 66.19718309859155%.\n",
            "Mini batch: 712/1450 | training time in 7 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0299 | Train accuracy: 78.39%.\n",
            "pgd linf: attack effectiveness 14.062%.\n",
            "pgd l2: attack effectiveness 43.750%.\n",
            "pgd l1: attack effectiveness 45.312%.\n",
            "max: attack effectiveness 54.6875%.\n",
            "Mini batch: 713/1450 | training time in 7 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0240 | Train accuracy: 82.29%.\n",
            "pgd linf: attack effectiveness 23.881%.\n",
            "pgd l2: attack effectiveness 40.299%.\n",
            "pgd l1: attack effectiveness 49.254%.\n",
            "max: attack effectiveness 58.2089552238806%.\n",
            "Mini batch: 714/1450 | training time in 7 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0230 | Train accuracy: 83.59%.\n",
            "pgd linf: attack effectiveness 20.312%.\n",
            "pgd l2: attack effectiveness 45.312%.\n",
            "pgd l1: attack effectiveness 60.938%.\n",
            "max: attack effectiveness 67.1875%.\n",
            "Mini batch: 715/1450 | training time in 7 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0240 | Train accuracy: 83.33%.\n",
            "pgd linf: attack effectiveness 32.432%.\n",
            "pgd l2: attack effectiveness 41.892%.\n",
            "pgd l1: attack effectiveness 58.108%.\n",
            "max: attack effectiveness 60.810810810810814%.\n",
            "Mini batch: 716/1450 | training time in 7 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0386 | Train accuracy: 79.70%.\n",
            "pgd linf: attack effectiveness 15.942%.\n",
            "pgd l2: attack effectiveness 40.580%.\n",
            "pgd l1: attack effectiveness 50.725%.\n",
            "max: attack effectiveness 53.62318840579711%.\n",
            "Mini batch: 717/1450 | training time in 7 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0199 | Train accuracy: 83.25%.\n",
            "pgd linf: attack effectiveness 20.000%.\n",
            "pgd l2: attack effectiveness 41.333%.\n",
            "pgd l1: attack effectiveness 53.333%.\n",
            "max: attack effectiveness 54.666666666666664%.\n",
            "Mini batch: 718/1450 | training time in 7 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0256 | Train accuracy: 81.77%.\n",
            "pgd linf: attack effectiveness 13.235%.\n",
            "pgd l2: attack effectiveness 42.647%.\n",
            "pgd l1: attack effectiveness 51.471%.\n",
            "max: attack effectiveness 51.470588235294116%.\n",
            "Mini batch: 719/1450 | training time in 7 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0195 | Train accuracy: 83.16%.\n",
            "pgd linf: attack effectiveness 15.254%.\n",
            "pgd l2: attack effectiveness 42.373%.\n",
            "pgd l1: attack effectiveness 55.932%.\n",
            "max: attack effectiveness 57.6271186440678%.\n",
            "Mini batch: 720/1450 | training time in 7 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0425 | Train accuracy: 82.89%.\n",
            "pgd linf: attack effectiveness 17.333%.\n",
            "pgd l2: attack effectiveness 49.333%.\n",
            "pgd l1: attack effectiveness 57.333%.\n",
            "max: attack effectiveness 57.333333333333336%.\n",
            "Mini batch: 721/1450 | training time in 7 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0163 | Train accuracy: 79.80%.\n",
            "pgd linf: attack effectiveness 18.841%.\n",
            "pgd l2: attack effectiveness 24.638%.\n",
            "pgd l1: attack effectiveness 57.971%.\n",
            "max: attack effectiveness 69.56521739130434%.\n",
            "Mini batch: 722/1450 | training time in 7 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0208 | Train accuracy: 79.70%.\n",
            "pgd linf: attack effectiveness 9.375%.\n",
            "pgd l2: attack effectiveness 28.125%.\n",
            "pgd l1: attack effectiveness 43.750%.\n",
            "max: attack effectiveness 54.6875%.\n",
            "Mini batch: 723/1450 | training time in 7 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0219 | Train accuracy: 83.85%.\n",
            "pgd linf: attack effectiveness 1.613%.\n",
            "pgd l2: attack effectiveness 27.419%.\n",
            "pgd l1: attack effectiveness 46.774%.\n",
            "max: attack effectiveness 59.67741935483871%.\n",
            "Mini batch: 724/1450 | training time in 7 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0197 | Train accuracy: 82.11%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 16.667%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 725/1450 | training time in 7 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0099 | Train accuracy: 94.74%.\n",
            "Training loss (epoch level): 0.0294 | Train accuracy: 82.94\n",
            "pgd linf: attack effectiveness 11.111%.\n",
            "pgd l2: attack effectiveness 26.523%.\n",
            "pgd l1: attack effectiveness 63.620%.\n",
            "max: attack effectiveness 70.43010752688173%.\n",
            "\tVal accuracy 63.08% with accuracy 29.57% under attack.\n",
            "\tModel select at epoch 24 with validation accuracy 68.27% and accuracy 39.96% under attack.\n",
            "pgd linf: attack effectiveness 15.152%.\n",
            "pgd l2: attack effectiveness 24.242%.\n",
            "pgd l1: attack effectiveness 48.485%.\n",
            "max: attack effectiveness 54.54545454545454%.\n",
            "Mini batch: 726/1450 | training time in 7 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0271 | Train accuracy: 82.47%.\n",
            "pgd linf: attack effectiveness 4.762%.\n",
            "pgd l2: attack effectiveness 44.444%.\n",
            "pgd l1: attack effectiveness 55.556%.\n",
            "max: attack effectiveness 65.07936507936508%.\n",
            "Mini batch: 727/1450 | training time in 7 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0333 | Train accuracy: 80.63%.\n",
            "pgd linf: attack effectiveness 6.061%.\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "pgd l1: attack effectiveness 46.970%.\n",
            "max: attack effectiveness 48.484848484848484%.\n",
            "Mini batch: 728/1450 | training time in 7 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0653 | Train accuracy: 84.02%.\n",
            "pgd linf: attack effectiveness 5.714%.\n",
            "pgd l2: attack effectiveness 27.143%.\n",
            "pgd l1: attack effectiveness 50.000%.\n",
            "max: attack effectiveness 52.85714285714286%.\n",
            "Mini batch: 729/1450 | training time in 7 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0221 | Train accuracy: 83.33%.\n",
            "pgd linf: attack effectiveness 12.676%.\n",
            "pgd l2: attack effectiveness 38.028%.\n",
            "pgd l1: attack effectiveness 53.521%.\n",
            "max: attack effectiveness 54.929577464788736%.\n",
            "Mini batch: 730/1450 | training time in 7 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0233 | Train accuracy: 80.90%.\n",
            "pgd linf: attack effectiveness 13.158%.\n",
            "pgd l2: attack effectiveness 32.895%.\n",
            "pgd l1: attack effectiveness 52.632%.\n",
            "max: attack effectiveness 52.63157894736842%.\n",
            "Mini batch: 731/1450 | training time in 7 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0253 | Train accuracy: 81.37%.\n",
            "pgd linf: attack effectiveness 6.557%.\n",
            "pgd l2: attack effectiveness 29.508%.\n",
            "pgd l1: attack effectiveness 49.180%.\n",
            "max: attack effectiveness 49.18032786885246%.\n",
            "Mini batch: 732/1450 | training time in 7 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0171 | Train accuracy: 85.19%.\n",
            "pgd linf: attack effectiveness 13.043%.\n",
            "pgd l2: attack effectiveness 30.435%.\n",
            "pgd l1: attack effectiveness 47.826%.\n",
            "max: attack effectiveness 50.72463768115942%.\n",
            "Mini batch: 733/1450 | training time in 8 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0365 | Train accuracy: 82.74%.\n",
            "pgd linf: attack effectiveness 3.226%.\n",
            "pgd l2: attack effectiveness 14.516%.\n",
            "pgd l1: attack effectiveness 43.548%.\n",
            "max: attack effectiveness 43.54838709677419%.\n",
            "Mini batch: 734/1450 | training time in 8 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0156 | Train accuracy: 86.84%.\n",
            "pgd linf: attack effectiveness 10.000%.\n",
            "pgd l2: attack effectiveness 31.667%.\n",
            "pgd l1: attack effectiveness 58.333%.\n",
            "max: attack effectiveness 58.333333333333336%.\n",
            "Mini batch: 735/1450 | training time in 8 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0322 | Train accuracy: 83.51%.\n",
            "pgd linf: attack effectiveness 9.259%.\n",
            "pgd l2: attack effectiveness 27.778%.\n",
            "pgd l1: attack effectiveness 40.741%.\n",
            "max: attack effectiveness 40.74074074074074%.\n",
            "Mini batch: 736/1450 | training time in 8 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0157 | Train accuracy: 89.56%.\n",
            "pgd linf: attack effectiveness 4.762%.\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "pgd l1: attack effectiveness 52.381%.\n",
            "max: attack effectiveness 52.38095238095239%.\n",
            "Mini batch: 737/1450 | training time in 8 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0171 | Train accuracy: 84.29%.\n",
            "pgd linf: attack effectiveness 7.692%.\n",
            "pgd l2: attack effectiveness 16.923%.\n",
            "pgd l1: attack effectiveness 56.923%.\n",
            "max: attack effectiveness 56.92307692307692%.\n",
            "Mini batch: 738/1450 | training time in 8 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0123 | Train accuracy: 84.97%.\n",
            "pgd linf: attack effectiveness 7.576%.\n",
            "pgd l2: attack effectiveness 24.242%.\n",
            "pgd l1: attack effectiveness 48.485%.\n",
            "max: attack effectiveness 48.484848484848484%.\n",
            "Mini batch: 739/1450 | training time in 8 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0215 | Train accuracy: 83.51%.\n",
            "pgd linf: attack effectiveness 6.154%.\n",
            "pgd l2: attack effectiveness 13.846%.\n",
            "pgd l1: attack effectiveness 44.615%.\n",
            "max: attack effectiveness 44.61538461538462%.\n",
            "Mini batch: 740/1450 | training time in 8 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0164 | Train accuracy: 87.05%.\n",
            "pgd linf: attack effectiveness 5.634%.\n",
            "pgd l2: attack effectiveness 11.268%.\n",
            "pgd l1: attack effectiveness 53.521%.\n",
            "max: attack effectiveness 53.52112676056338%.\n",
            "Mini batch: 741/1450 | training time in 8 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0204 | Train accuracy: 83.92%.\n",
            "pgd linf: attack effectiveness 6.250%.\n",
            "pgd l2: attack effectiveness 9.375%.\n",
            "pgd l1: attack effectiveness 40.625%.\n",
            "max: attack effectiveness 40.625%.\n",
            "Mini batch: 742/1450 | training time in 8 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0170 | Train accuracy: 87.50%.\n",
            "pgd linf: attack effectiveness 10.448%.\n",
            "pgd l2: attack effectiveness 5.970%.\n",
            "pgd l1: attack effectiveness 44.776%.\n",
            "max: attack effectiveness 44.776119402985074%.\n",
            "Mini batch: 743/1450 | training time in 8 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0153 | Train accuracy: 88.21%.\n",
            "pgd linf: attack effectiveness 10.938%.\n",
            "pgd l2: attack effectiveness 26.562%.\n",
            "pgd l1: attack effectiveness 50.000%.\n",
            "max: attack effectiveness 51.5625%.\n",
            "Mini batch: 744/1450 | training time in 8 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0156 | Train accuracy: 84.90%.\n",
            "pgd linf: attack effectiveness 20.270%.\n",
            "pgd l2: attack effectiveness 12.162%.\n",
            "pgd l1: attack effectiveness 54.054%.\n",
            "max: attack effectiveness 55.4054054054054%.\n",
            "Mini batch: 745/1450 | training time in 8 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0360 | Train accuracy: 84.16%.\n",
            "pgd linf: attack effectiveness 13.043%.\n",
            "pgd l2: attack effectiveness 34.783%.\n",
            "pgd l1: attack effectiveness 46.377%.\n",
            "max: attack effectiveness 47.82608695652174%.\n",
            "Mini batch: 746/1450 | training time in 8 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0138 | Train accuracy: 84.77%.\n",
            "pgd linf: attack effectiveness 13.333%.\n",
            "pgd l2: attack effectiveness 17.333%.\n",
            "pgd l1: attack effectiveness 52.000%.\n",
            "max: attack effectiveness 53.333333333333336%.\n",
            "Mini batch: 747/1450 | training time in 8 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0180 | Train accuracy: 81.28%.\n",
            "pgd linf: attack effectiveness 10.294%.\n",
            "pgd l2: attack effectiveness 29.412%.\n",
            "pgd l1: attack effectiveness 48.529%.\n",
            "max: attack effectiveness 48.529411764705884%.\n",
            "Mini batch: 748/1450 | training time in 8 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0129 | Train accuracy: 87.24%.\n",
            "pgd linf: attack effectiveness 8.475%.\n",
            "pgd l2: attack effectiveness 25.424%.\n",
            "pgd l1: attack effectiveness 52.542%.\n",
            "max: attack effectiveness 54.23728813559322%.\n",
            "Mini batch: 749/1450 | training time in 8 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0409 | Train accuracy: 85.56%.\n",
            "pgd linf: attack effectiveness 4.000%.\n",
            "pgd l2: attack effectiveness 10.667%.\n",
            "pgd l1: attack effectiveness 53.333%.\n",
            "max: attack effectiveness 53.333333333333336%.\n",
            "Mini batch: 750/1450 | training time in 8 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0092 | Train accuracy: 86.21%.\n",
            "pgd linf: attack effectiveness 7.246%.\n",
            "pgd l2: attack effectiveness 30.435%.\n",
            "pgd l1: attack effectiveness 55.072%.\n",
            "max: attack effectiveness 55.072463768115945%.\n",
            "Mini batch: 751/1450 | training time in 8 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0167 | Train accuracy: 81.73%.\n",
            "pgd linf: attack effectiveness 4.688%.\n",
            "pgd l2: attack effectiveness 17.188%.\n",
            "pgd l1: attack effectiveness 45.312%.\n",
            "max: attack effectiveness 46.875%.\n",
            "Mini batch: 752/1450 | training time in 8 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0416 | Train accuracy: 86.98%.\n",
            "pgd linf: attack effectiveness 9.677%.\n",
            "pgd l2: attack effectiveness 29.032%.\n",
            "pgd l1: attack effectiveness 43.548%.\n",
            "max: attack effectiveness 45.16129032258064%.\n",
            "Mini batch: 753/1450 | training time in 8 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0160 | Train accuracy: 85.26%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 50.0%.\n",
            "Mini batch: 754/1450 | training time in 8 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0119 | Train accuracy: 89.47%.\n",
            "Training loss (epoch level): 0.0230 | Train accuracy: 84.74\n",
            "pgd linf: attack effectiveness 8.781%.\n",
            "pgd l2: attack effectiveness 38.710%.\n",
            "pgd l1: attack effectiveness 61.111%.\n",
            "max: attack effectiveness 62.18637992831542%.\n",
            "\tVal accuracy 67.07% with accuracy 37.81% under attack.\n",
            "\tModel select at epoch 24 with validation accuracy 68.27% and accuracy 39.96% under attack.\n",
            "pgd linf: attack effectiveness 4.545%.\n",
            "pgd l2: attack effectiveness 37.879%.\n",
            "pgd l1: attack effectiveness 46.970%.\n",
            "max: attack effectiveness 54.54545454545454%.\n",
            "Mini batch: 755/1450 | training time in 8 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0278 | Train accuracy: 85.05%.\n",
            "pgd linf: attack effectiveness 6.349%.\n",
            "pgd l2: attack effectiveness 34.921%.\n",
            "pgd l1: attack effectiveness 53.968%.\n",
            "max: attack effectiveness 55.55555555555556%.\n",
            "Mini batch: 756/1450 | training time in 8 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0333 | Train accuracy: 82.72%.\n",
            "pgd linf: attack effectiveness 4.545%.\n",
            "pgd l2: attack effectiveness 27.273%.\n",
            "pgd l1: attack effectiveness 45.455%.\n",
            "max: attack effectiveness 45.45454545454545%.\n",
            "Mini batch: 757/1450 | training time in 8 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0202 | Train accuracy: 85.57%.\n",
            "pgd linf: attack effectiveness 8.571%.\n",
            "pgd l2: attack effectiveness 25.714%.\n",
            "pgd l1: attack effectiveness 52.857%.\n",
            "max: attack effectiveness 52.85714285714286%.\n",
            "Mini batch: 758/1450 | training time in 8 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0177 | Train accuracy: 86.36%.\n",
            "pgd linf: attack effectiveness 14.085%.\n",
            "pgd l2: attack effectiveness 38.028%.\n",
            "pgd l1: attack effectiveness 59.155%.\n",
            "max: attack effectiveness 59.154929577464785%.\n",
            "Mini batch: 759/1450 | training time in 8 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0197 | Train accuracy: 80.90%.\n",
            "pgd linf: attack effectiveness 14.474%.\n",
            "pgd l2: attack effectiveness 10.526%.\n",
            "pgd l1: attack effectiveness 55.263%.\n",
            "max: attack effectiveness 55.26315789473685%.\n",
            "Mini batch: 760/1450 | training time in 8 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0178 | Train accuracy: 81.37%.\n",
            "pgd linf: attack effectiveness 8.197%.\n",
            "pgd l2: attack effectiveness 13.115%.\n",
            "pgd l1: attack effectiveness 50.820%.\n",
            "max: attack effectiveness 50.81967213114754%.\n",
            "Mini batch: 761/1450 | training time in 8 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0196 | Train accuracy: 84.66%.\n",
            "pgd linf: attack effectiveness 8.696%.\n",
            "pgd l2: attack effectiveness 26.087%.\n",
            "pgd l1: attack effectiveness 52.174%.\n",
            "max: attack effectiveness 52.17391304347826%.\n",
            "Mini batch: 762/1450 | training time in 8 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0223 | Train accuracy: 83.76%.\n",
            "pgd linf: attack effectiveness 16.129%.\n",
            "pgd l2: attack effectiveness 12.903%.\n",
            "pgd l1: attack effectiveness 45.161%.\n",
            "max: attack effectiveness 45.16129032258064%.\n",
            "Mini batch: 763/1450 | training time in 8 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0155 | Train accuracy: 86.32%.\n",
            "pgd linf: attack effectiveness 16.667%.\n",
            "pgd l2: attack effectiveness 23.333%.\n",
            "pgd l1: attack effectiveness 60.000%.\n",
            "max: attack effectiveness 60.0%.\n",
            "Mini batch: 764/1450 | training time in 8 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0212 | Train accuracy: 83.51%.\n",
            "pgd linf: attack effectiveness 7.407%.\n",
            "pgd l2: attack effectiveness 14.815%.\n",
            "pgd l1: attack effectiveness 42.593%.\n",
            "max: attack effectiveness 42.592592592592595%.\n",
            "Mini batch: 765/1450 | training time in 8 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0135 | Train accuracy: 90.11%.\n",
            "pgd linf: attack effectiveness 3.175%.\n",
            "pgd l2: attack effectiveness 28.571%.\n",
            "pgd l1: attack effectiveness 57.143%.\n",
            "max: attack effectiveness 57.14285714285714%.\n",
            "Mini batch: 766/1450 | training time in 8 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0257 | Train accuracy: 82.72%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 27.692%.\n",
            "pgd l1: attack effectiveness 55.385%.\n",
            "max: attack effectiveness 55.38461538461539%.\n",
            "Mini batch: 767/1450 | training time in 8 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0153 | Train accuracy: 82.90%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 31.818%.\n",
            "pgd l1: attack effectiveness 50.000%.\n",
            "max: attack effectiveness 50.0%.\n",
            "Mini batch: 768/1450 | training time in 8 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0479 | Train accuracy: 84.02%.\n",
            "pgd linf: attack effectiveness 6.154%.\n",
            "pgd l2: attack effectiveness 29.231%.\n",
            "pgd l1: attack effectiveness 47.692%.\n",
            "max: attack effectiveness 47.69230769230769%.\n",
            "Mini batch: 769/1450 | training time in 8 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0151 | Train accuracy: 86.53%.\n",
            "pgd linf: attack effectiveness 8.451%.\n",
            "pgd l2: attack effectiveness 35.211%.\n",
            "pgd l1: attack effectiveness 59.155%.\n",
            "max: attack effectiveness 59.154929577464785%.\n",
            "Mini batch: 770/1450 | training time in 8 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0179 | Train accuracy: 82.41%.\n",
            "pgd linf: attack effectiveness 9.375%.\n",
            "pgd l2: attack effectiveness 28.125%.\n",
            "pgd l1: attack effectiveness 42.188%.\n",
            "max: attack effectiveness 42.1875%.\n",
            "Mini batch: 771/1450 | training time in 8 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0201 | Train accuracy: 86.98%.\n",
            "pgd linf: attack effectiveness 20.896%.\n",
            "pgd l2: attack effectiveness 29.851%.\n",
            "pgd l1: attack effectiveness 47.761%.\n",
            "max: attack effectiveness 47.76119402985074%.\n",
            "Mini batch: 772/1450 | training time in 8 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0319 | Train accuracy: 85.64%.\n",
            "pgd linf: attack effectiveness 15.625%.\n",
            "pgd l2: attack effectiveness 37.500%.\n",
            "pgd l1: attack effectiveness 54.688%.\n",
            "max: attack effectiveness 54.6875%.\n",
            "Mini batch: 773/1450 | training time in 8 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0271 | Train accuracy: 83.85%.\n",
            "pgd linf: attack effectiveness 24.324%.\n",
            "pgd l2: attack effectiveness 33.784%.\n",
            "pgd l1: attack effectiveness 54.054%.\n",
            "max: attack effectiveness 54.054054054054056%.\n",
            "Mini batch: 774/1450 | training time in 8 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0417 | Train accuracy: 82.18%.\n",
            "pgd linf: attack effectiveness 11.594%.\n",
            "pgd l2: attack effectiveness 34.783%.\n",
            "pgd l1: attack effectiveness 44.928%.\n",
            "max: attack effectiveness 44.927536231884055%.\n",
            "Mini batch: 775/1450 | training time in 8 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0264 | Train accuracy: 84.77%.\n",
            "pgd linf: attack effectiveness 21.333%.\n",
            "pgd l2: attack effectiveness 38.667%.\n",
            "pgd l1: attack effectiveness 52.000%.\n",
            "max: attack effectiveness 52.0%.\n",
            "Mini batch: 776/1450 | training time in 8 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0259 | Train accuracy: 83.25%.\n",
            "pgd linf: attack effectiveness 22.059%.\n",
            "pgd l2: attack effectiveness 38.235%.\n",
            "pgd l1: attack effectiveness 50.000%.\n",
            "max: attack effectiveness 50.0%.\n",
            "Mini batch: 777/1450 | training time in 8 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0227 | Train accuracy: 83.16%.\n",
            "pgd linf: attack effectiveness 20.339%.\n",
            "pgd l2: attack effectiveness 33.898%.\n",
            "pgd l1: attack effectiveness 52.542%.\n",
            "max: attack effectiveness 52.54237288135594%.\n",
            "Mini batch: 778/1450 | training time in 8 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0380 | Train accuracy: 85.03%.\n",
            "pgd linf: attack effectiveness 28.000%.\n",
            "pgd l2: attack effectiveness 38.667%.\n",
            "pgd l1: attack effectiveness 50.667%.\n",
            "max: attack effectiveness 50.66666666666667%.\n",
            "Mini batch: 779/1450 | training time in 8 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0172 | Train accuracy: 82.27%.\n",
            "pgd linf: attack effectiveness 11.594%.\n",
            "pgd l2: attack effectiveness 37.681%.\n",
            "pgd l1: attack effectiveness 55.072%.\n",
            "max: attack effectiveness 55.072463768115945%.\n",
            "Mini batch: 780/1450 | training time in 8 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0233 | Train accuracy: 84.26%.\n",
            "pgd linf: attack effectiveness 15.625%.\n",
            "pgd l2: attack effectiveness 21.875%.\n",
            "pgd l1: attack effectiveness 43.750%.\n",
            "max: attack effectiveness 43.75%.\n",
            "Mini batch: 781/1450 | training time in 8 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0204 | Train accuracy: 86.98%.\n",
            "pgd linf: attack effectiveness 8.065%.\n",
            "pgd l2: attack effectiveness 22.581%.\n",
            "pgd l1: attack effectiveness 43.548%.\n",
            "max: attack effectiveness 43.54838709677419%.\n",
            "Mini batch: 782/1450 | training time in 8 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0189 | Train accuracy: 86.32%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 783/1450 | training time in 8 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0067 | Train accuracy: 89.47%.\n",
            "Training loss (epoch level): 0.0231 | Train accuracy: 84.59\n",
            "pgd linf: attack effectiveness 8.781%.\n",
            "pgd l2: attack effectiveness 31.004%.\n",
            "pgd l1: attack effectiveness 61.111%.\n",
            "max: attack effectiveness 61.111111111111114%.\n",
            "\tVal accuracy 67.53% with accuracy 38.89% under attack.\n",
            "\tModel select at epoch 24 with validation accuracy 68.27% and accuracy 39.96% under attack.\n",
            "pgd linf: attack effectiveness 10.606%.\n",
            "pgd l2: attack effectiveness 25.758%.\n",
            "pgd l1: attack effectiveness 48.485%.\n",
            "max: attack effectiveness 48.484848484848484%.\n",
            "Mini batch: 784/1450 | training time in 8 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0352 | Train accuracy: 84.02%.\n",
            "pgd linf: attack effectiveness 3.175%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 55.556%.\n",
            "max: attack effectiveness 55.55555555555556%.\n",
            "Mini batch: 785/1450 | training time in 8 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0176 | Train accuracy: 85.34%.\n",
            "pgd linf: attack effectiveness 12.121%.\n",
            "pgd l2: attack effectiveness 19.697%.\n",
            "pgd l1: attack effectiveness 45.455%.\n",
            "max: attack effectiveness 45.45454545454545%.\n",
            "Mini batch: 786/1450 | training time in 8 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0203 | Train accuracy: 87.11%.\n",
            "pgd linf: attack effectiveness 2.857%.\n",
            "pgd l2: attack effectiveness 2.857%.\n",
            "pgd l1: attack effectiveness 55.714%.\n",
            "max: attack effectiveness 55.714285714285715%.\n",
            "Mini batch: 787/1450 | training time in 8 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0224 | Train accuracy: 81.82%.\n",
            "pgd linf: attack effectiveness 11.268%.\n",
            "pgd l2: attack effectiveness 9.859%.\n",
            "pgd l1: attack effectiveness 60.563%.\n",
            "max: attack effectiveness 60.56338028169014%.\n",
            "Mini batch: 788/1450 | training time in 8 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0151 | Train accuracy: 81.91%.\n",
            "pgd linf: attack effectiveness 6.579%.\n",
            "pgd l2: attack effectiveness 18.421%.\n",
            "pgd l1: attack effectiveness 56.579%.\n",
            "max: attack effectiveness 56.57894736842105%.\n",
            "Mini batch: 789/1450 | training time in 8 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0148 | Train accuracy: 82.35%.\n",
            "pgd linf: attack effectiveness 6.557%.\n",
            "pgd l2: attack effectiveness 16.393%.\n",
            "pgd l1: attack effectiveness 55.738%.\n",
            "max: attack effectiveness 55.73770491803278%.\n",
            "Mini batch: 790/1450 | training time in 8 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0146 | Train accuracy: 84.13%.\n",
            "pgd linf: attack effectiveness 13.043%.\n",
            "pgd l2: attack effectiveness 18.841%.\n",
            "pgd l1: attack effectiveness 56.522%.\n",
            "max: attack effectiveness 56.52173913043478%.\n",
            "Mini batch: 791/1450 | training time in 8 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0208 | Train accuracy: 83.76%.\n",
            "pgd linf: attack effectiveness 24.194%.\n",
            "pgd l2: attack effectiveness 14.516%.\n",
            "pgd l1: attack effectiveness 48.387%.\n",
            "max: attack effectiveness 50.0%.\n",
            "Mini batch: 792/1450 | training time in 8 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0214 | Train accuracy: 86.84%.\n",
            "pgd linf: attack effectiveness 36.667%.\n",
            "pgd l2: attack effectiveness 18.333%.\n",
            "pgd l1: attack effectiveness 65.000%.\n",
            "max: attack effectiveness 65.0%.\n",
            "Mini batch: 793/1450 | training time in 8 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0329 | Train accuracy: 81.91%.\n",
            "pgd linf: attack effectiveness 24.074%.\n",
            "pgd l2: attack effectiveness 12.963%.\n",
            "pgd l1: attack effectiveness 46.296%.\n",
            "max: attack effectiveness 46.2962962962963%.\n",
            "Mini batch: 794/1450 | training time in 8 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0191 | Train accuracy: 88.46%.\n",
            "pgd linf: attack effectiveness 6.349%.\n",
            "pgd l2: attack effectiveness 9.524%.\n",
            "pgd l1: attack effectiveness 57.143%.\n",
            "max: attack effectiveness 57.14285714285714%.\n",
            "Mini batch: 795/1450 | training time in 8 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0278 | Train accuracy: 84.29%.\n",
            "pgd linf: attack effectiveness 3.077%.\n",
            "pgd l2: attack effectiveness 7.692%.\n",
            "pgd l1: attack effectiveness 58.462%.\n",
            "max: attack effectiveness 58.46153846153847%.\n",
            "Mini batch: 796/1450 | training time in 8 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0090 | Train accuracy: 84.97%.\n",
            "pgd linf: attack effectiveness 4.545%.\n",
            "pgd l2: attack effectiveness 13.636%.\n",
            "pgd l1: attack effectiveness 50.000%.\n",
            "max: attack effectiveness 50.0%.\n",
            "Mini batch: 797/1450 | training time in 8 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0458 | Train accuracy: 85.05%.\n",
            "pgd linf: attack effectiveness 7.692%.\n",
            "pgd l2: attack effectiveness 20.000%.\n",
            "pgd l1: attack effectiveness 46.154%.\n",
            "max: attack effectiveness 46.15384615384615%.\n",
            "Mini batch: 798/1450 | training time in 8 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0152 | Train accuracy: 87.56%.\n",
            "pgd linf: attack effectiveness 11.268%.\n",
            "pgd l2: attack effectiveness 16.901%.\n",
            "pgd l1: attack effectiveness 56.338%.\n",
            "max: attack effectiveness 57.74647887323944%.\n",
            "Mini batch: 799/1450 | training time in 8 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0171 | Train accuracy: 81.91%.\n",
            "pgd linf: attack effectiveness 10.938%.\n",
            "pgd l2: attack effectiveness 26.562%.\n",
            "pgd l1: attack effectiveness 42.188%.\n",
            "max: attack effectiveness 42.1875%.\n",
            "Mini batch: 800/1450 | training time in 8 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0126 | Train accuracy: 89.06%.\n",
            "pgd linf: attack effectiveness 7.463%.\n",
            "pgd l2: attack effectiveness 34.328%.\n",
            "pgd l1: attack effectiveness 44.776%.\n",
            "max: attack effectiveness 49.25373134328358%.\n",
            "Mini batch: 801/1450 | training time in 8 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0234 | Train accuracy: 86.67%.\n",
            "pgd linf: attack effectiveness 10.938%.\n",
            "pgd l2: attack effectiveness 39.062%.\n",
            "pgd l1: attack effectiveness 54.688%.\n",
            "max: attack effectiveness 56.25%.\n",
            "Mini batch: 802/1450 | training time in 8 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0694 | Train accuracy: 83.33%.\n",
            "pgd linf: attack effectiveness 21.622%.\n",
            "pgd l2: attack effectiveness 40.541%.\n",
            "pgd l1: attack effectiveness 58.108%.\n",
            "max: attack effectiveness 59.45945945945946%.\n",
            "Mini batch: 803/1450 | training time in 8 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0326 | Train accuracy: 81.19%.\n",
            "pgd linf: attack effectiveness 17.391%.\n",
            "pgd l2: attack effectiveness 34.783%.\n",
            "pgd l1: attack effectiveness 47.826%.\n",
            "max: attack effectiveness 49.275362318840585%.\n",
            "Mini batch: 804/1450 | training time in 8 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0300 | Train accuracy: 84.26%.\n",
            "pgd linf: attack effectiveness 20.000%.\n",
            "pgd l2: attack effectiveness 42.667%.\n",
            "pgd l1: attack effectiveness 52.000%.\n",
            "max: attack effectiveness 53.333333333333336%.\n",
            "Mini batch: 805/1450 | training time in 8 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0274 | Train accuracy: 80.30%.\n",
            "pgd linf: attack effectiveness 38.235%.\n",
            "pgd l2: attack effectiveness 41.176%.\n",
            "pgd l1: attack effectiveness 51.471%.\n",
            "max: attack effectiveness 51.470588235294116%.\n",
            "Mini batch: 806/1450 | training time in 8 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0404 | Train accuracy: 83.16%.\n",
            "pgd linf: attack effectiveness 37.288%.\n",
            "pgd l2: attack effectiveness 49.153%.\n",
            "pgd l1: attack effectiveness 62.712%.\n",
            "max: attack effectiveness 62.71186440677966%.\n",
            "Mini batch: 807/1450 | training time in 8 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0847 | Train accuracy: 81.82%.\n",
            "pgd linf: attack effectiveness 42.667%.\n",
            "pgd l2: attack effectiveness 52.000%.\n",
            "pgd l1: attack effectiveness 60.000%.\n",
            "max: attack effectiveness 61.33333333333333%.\n",
            "Mini batch: 808/1450 | training time in 8 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0530 | Train accuracy: 79.31%.\n",
            "pgd linf: attack effectiveness 34.783%.\n",
            "pgd l2: attack effectiveness 55.072%.\n",
            "pgd l1: attack effectiveness 57.971%.\n",
            "max: attack effectiveness 63.76811594202898%.\n",
            "Mini batch: 809/1450 | training time in 8 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0673 | Train accuracy: 78.68%.\n",
            "pgd linf: attack effectiveness 29.688%.\n",
            "pgd l2: attack effectiveness 37.500%.\n",
            "pgd l1: attack effectiveness 43.750%.\n",
            "max: attack effectiveness 46.875%.\n",
            "Mini batch: 810/1450 | training time in 8 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0413 | Train accuracy: 85.94%.\n",
            "pgd linf: attack effectiveness 35.484%.\n",
            "pgd l2: attack effectiveness 37.097%.\n",
            "pgd l1: attack effectiveness 43.548%.\n",
            "max: attack effectiveness 45.16129032258064%.\n",
            "Mini batch: 811/1450 | training time in 8 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0343 | Train accuracy: 84.74%.\n",
            "pgd linf: attack effectiveness 16.667%.\n",
            "pgd l2: attack effectiveness 16.667%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 812/1450 | training time in 8 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0303 | Train accuracy: 89.47%.\n",
            "Training loss (epoch level): 0.0309 | Train accuracy: 84.12\n",
            "pgd linf: attack effectiveness 12.186%.\n",
            "pgd l2: attack effectiveness 39.785%.\n",
            "pgd l1: attack effectiveness 62.007%.\n",
            "max: attack effectiveness 62.365591397849464%.\n",
            "\tVal accuracy 66.9% with accuracy 37.63% under attack.\n",
            "\tModel select at epoch 24 with validation accuracy 68.27% and accuracy 39.96% under attack.\n",
            "pgd linf: attack effectiveness 9.091%.\n",
            "pgd l2: attack effectiveness 37.879%.\n",
            "pgd l1: attack effectiveness 48.485%.\n",
            "max: attack effectiveness 51.515151515151516%.\n",
            "Mini batch: 813/1450 | training time in 8 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0532 | Train accuracy: 84.54%.\n",
            "pgd linf: attack effectiveness 4.762%.\n",
            "pgd l2: attack effectiveness 36.508%.\n",
            "pgd l1: attack effectiveness 52.381%.\n",
            "max: attack effectiveness 53.96825396825397%.\n",
            "Mini batch: 814/1450 | training time in 8 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0251 | Train accuracy: 84.82%.\n",
            "pgd linf: attack effectiveness 6.061%.\n",
            "pgd l2: attack effectiveness 28.788%.\n",
            "pgd l1: attack effectiveness 45.455%.\n",
            "max: attack effectiveness 45.45454545454545%.\n",
            "Mini batch: 815/1450 | training time in 8 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0246 | Train accuracy: 85.05%.\n",
            "pgd linf: attack effectiveness 2.857%.\n",
            "pgd l2: attack effectiveness 24.286%.\n",
            "pgd l1: attack effectiveness 55.714%.\n",
            "max: attack effectiveness 55.714285714285715%.\n",
            "Mini batch: 816/1450 | training time in 8 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0276 | Train accuracy: 83.33%.\n",
            "pgd linf: attack effectiveness 5.634%.\n",
            "pgd l2: attack effectiveness 33.803%.\n",
            "pgd l1: attack effectiveness 57.746%.\n",
            "max: attack effectiveness 57.74647887323944%.\n",
            "Mini batch: 817/1450 | training time in 8 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0204 | Train accuracy: 80.40%.\n",
            "pgd linf: attack effectiveness 9.211%.\n",
            "pgd l2: attack effectiveness 30.263%.\n",
            "pgd l1: attack effectiveness 60.526%.\n",
            "max: attack effectiveness 60.526315789473685%.\n",
            "Mini batch: 818/1450 | training time in 8 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0194 | Train accuracy: 81.37%.\n",
            "pgd linf: attack effectiveness 4.918%.\n",
            "pgd l2: attack effectiveness 26.230%.\n",
            "pgd l1: attack effectiveness 55.738%.\n",
            "max: attack effectiveness 55.73770491803278%.\n",
            "Mini batch: 819/1450 | training time in 8 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0150 | Train accuracy: 84.13%.\n",
            "pgd linf: attack effectiveness 10.145%.\n",
            "pgd l2: attack effectiveness 20.290%.\n",
            "pgd l1: attack effectiveness 50.725%.\n",
            "max: attack effectiveness 50.72463768115942%.\n",
            "Mini batch: 820/1450 | training time in 8 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0174 | Train accuracy: 85.28%.\n",
            "pgd linf: attack effectiveness 8.065%.\n",
            "pgd l2: attack effectiveness 32.258%.\n",
            "pgd l1: attack effectiveness 50.000%.\n",
            "max: attack effectiveness 51.61290322580645%.\n",
            "Mini batch: 821/1450 | training time in 8 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0147 | Train accuracy: 84.74%.\n",
            "pgd linf: attack effectiveness 8.333%.\n",
            "pgd l2: attack effectiveness 15.000%.\n",
            "pgd l1: attack effectiveness 65.000%.\n",
            "max: attack effectiveness 65.0%.\n",
            "Mini batch: 822/1450 | training time in 8 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0228 | Train accuracy: 81.38%.\n",
            "pgd linf: attack effectiveness 5.556%.\n",
            "pgd l2: attack effectiveness 12.963%.\n",
            "pgd l1: attack effectiveness 48.148%.\n",
            "max: attack effectiveness 48.148148148148145%.\n",
            "Mini batch: 823/1450 | training time in 8 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0122 | Train accuracy: 90.66%.\n",
            "pgd linf: attack effectiveness 11.111%.\n",
            "pgd l2: attack effectiveness 7.937%.\n",
            "pgd l1: attack effectiveness 57.143%.\n",
            "max: attack effectiveness 57.14285714285714%.\n",
            "Mini batch: 824/1450 | training time in 9 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0141 | Train accuracy: 83.77%.\n",
            "pgd linf: attack effectiveness 13.846%.\n",
            "pgd l2: attack effectiveness 33.846%.\n",
            "pgd l1: attack effectiveness 60.000%.\n",
            "max: attack effectiveness 60.0%.\n",
            "Mini batch: 825/1450 | training time in 9 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0107 | Train accuracy: 82.38%.\n",
            "pgd linf: attack effectiveness 13.636%.\n",
            "pgd l2: attack effectiveness 16.667%.\n",
            "pgd l1: attack effectiveness 48.485%.\n",
            "max: attack effectiveness 48.484848484848484%.\n",
            "Mini batch: 826/1450 | training time in 9 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0221 | Train accuracy: 86.08%.\n",
            "pgd linf: attack effectiveness 13.846%.\n",
            "pgd l2: attack effectiveness 16.923%.\n",
            "pgd l1: attack effectiveness 46.154%.\n",
            "max: attack effectiveness 49.23076923076923%.\n",
            "Mini batch: 827/1450 | training time in 9 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0240 | Train accuracy: 87.05%.\n",
            "pgd linf: attack effectiveness 14.085%.\n",
            "pgd l2: attack effectiveness 18.310%.\n",
            "pgd l1: attack effectiveness 57.746%.\n",
            "max: attack effectiveness 59.154929577464785%.\n",
            "Mini batch: 828/1450 | training time in 9 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0119 | Train accuracy: 84.42%.\n",
            "pgd linf: attack effectiveness 6.250%.\n",
            "pgd l2: attack effectiveness 29.688%.\n",
            "pgd l1: attack effectiveness 45.312%.\n",
            "max: attack effectiveness 46.875%.\n",
            "Mini batch: 829/1450 | training time in 9 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0256 | Train accuracy: 87.50%.\n",
            "pgd linf: attack effectiveness 7.463%.\n",
            "pgd l2: attack effectiveness 19.403%.\n",
            "pgd l1: attack effectiveness 50.746%.\n",
            "max: attack effectiveness 52.23880597014925%.\n",
            "Mini batch: 830/1450 | training time in 9 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0204 | Train accuracy: 85.13%.\n",
            "pgd linf: attack effectiveness 12.500%.\n",
            "pgd l2: attack effectiveness 29.688%.\n",
            "pgd l1: attack effectiveness 51.562%.\n",
            "max: attack effectiveness 51.5625%.\n",
            "Mini batch: 831/1450 | training time in 9 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0195 | Train accuracy: 83.33%.\n",
            "pgd linf: attack effectiveness 20.270%.\n",
            "pgd l2: attack effectiveness 44.595%.\n",
            "pgd l1: attack effectiveness 60.811%.\n",
            "max: attack effectiveness 62.16216216216216%.\n",
            "Mini batch: 832/1450 | training time in 9 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0315 | Train accuracy: 79.70%.\n",
            "pgd linf: attack effectiveness 13.043%.\n",
            "pgd l2: attack effectiveness 28.986%.\n",
            "pgd l1: attack effectiveness 50.725%.\n",
            "max: attack effectiveness 53.62318840579711%.\n",
            "Mini batch: 833/1450 | training time in 9 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0278 | Train accuracy: 83.25%.\n",
            "pgd linf: attack effectiveness 17.333%.\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "pgd l1: attack effectiveness 54.667%.\n",
            "max: attack effectiveness 58.666666666666664%.\n",
            "Mini batch: 834/1450 | training time in 9 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0311 | Train accuracy: 80.79%.\n",
            "pgd linf: attack effectiveness 10.294%.\n",
            "pgd l2: attack effectiveness 35.294%.\n",
            "pgd l1: attack effectiveness 48.529%.\n",
            "max: attack effectiveness 48.529411764705884%.\n",
            "Mini batch: 835/1450 | training time in 9 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0227 | Train accuracy: 83.67%.\n",
            "pgd linf: attack effectiveness 15.254%.\n",
            "pgd l2: attack effectiveness 33.898%.\n",
            "pgd l1: attack effectiveness 50.847%.\n",
            "max: attack effectiveness 54.23728813559322%.\n",
            "Mini batch: 836/1450 | training time in 9 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0327 | Train accuracy: 82.35%.\n",
            "pgd linf: attack effectiveness 13.333%.\n",
            "pgd l2: attack effectiveness 38.667%.\n",
            "pgd l1: attack effectiveness 53.333%.\n",
            "max: attack effectiveness 54.666666666666664%.\n",
            "Mini batch: 837/1450 | training time in 9 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0198 | Train accuracy: 80.79%.\n",
            "pgd linf: attack effectiveness 11.594%.\n",
            "pgd l2: attack effectiveness 34.783%.\n",
            "pgd l1: attack effectiveness 55.072%.\n",
            "max: attack effectiveness 56.52173913043478%.\n",
            "Mini batch: 838/1450 | training time in 9 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0229 | Train accuracy: 81.73%.\n",
            "pgd linf: attack effectiveness 10.938%.\n",
            "pgd l2: attack effectiveness 18.750%.\n",
            "pgd l1: attack effectiveness 43.750%.\n",
            "max: attack effectiveness 45.3125%.\n",
            "Mini batch: 839/1450 | training time in 9 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0265 | Train accuracy: 86.98%.\n",
            "pgd linf: attack effectiveness 14.516%.\n",
            "pgd l2: attack effectiveness 32.258%.\n",
            "pgd l1: attack effectiveness 46.774%.\n",
            "max: attack effectiveness 50.0%.\n",
            "Mini batch: 840/1450 | training time in 9 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0171 | Train accuracy: 85.79%.\n",
            "pgd linf: attack effectiveness 16.667%.\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 841/1450 | training time in 9 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0121 | Train accuracy: 89.47%.\n",
            "Training loss (epoch level): 0.0222 | Train accuracy: 84.13\n",
            "pgd linf: attack effectiveness 12.545%.\n",
            "pgd l2: attack effectiveness 28.495%.\n",
            "pgd l1: attack effectiveness 61.649%.\n",
            "max: attack effectiveness 65.77060931899642%.\n",
            "\tVal accuracy 64.9% with accuracy 34.23% under attack.\n",
            "\tModel select at epoch 24 with validation accuracy 68.27% and accuracy 39.96% under attack.\n",
            "pgd linf: attack effectiveness 10.606%.\n",
            "pgd l2: attack effectiveness 19.697%.\n",
            "pgd l1: attack effectiveness 48.485%.\n",
            "max: attack effectiveness 50.0%.\n",
            "Mini batch: 842/1450 | training time in 9 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0244 | Train accuracy: 88.14%.\n",
            "pgd linf: attack effectiveness 4.762%.\n",
            "pgd l2: attack effectiveness 41.270%.\n",
            "pgd l1: attack effectiveness 53.968%.\n",
            "max: attack effectiveness 58.730158730158735%.\n",
            "Mini batch: 843/1450 | training time in 9 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0290 | Train accuracy: 80.63%.\n",
            "pgd linf: attack effectiveness 12.121%.\n",
            "pgd l2: attack effectiveness 30.303%.\n",
            "pgd l1: attack effectiveness 45.455%.\n",
            "max: attack effectiveness 45.45454545454545%.\n",
            "Mini batch: 844/1450 | training time in 9 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0198 | Train accuracy: 85.05%.\n",
            "pgd linf: attack effectiveness 10.000%.\n",
            "pgd l2: attack effectiveness 12.857%.\n",
            "pgd l1: attack effectiveness 52.857%.\n",
            "max: attack effectiveness 54.285714285714285%.\n",
            "Mini batch: 845/1450 | training time in 9 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0162 | Train accuracy: 83.33%.\n",
            "pgd linf: attack effectiveness 14.085%.\n",
            "pgd l2: attack effectiveness 39.437%.\n",
            "pgd l1: attack effectiveness 53.521%.\n",
            "max: attack effectiveness 56.33802816901409%.\n",
            "Mini batch: 846/1450 | training time in 9 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0197 | Train accuracy: 81.41%.\n",
            "pgd linf: attack effectiveness 10.526%.\n",
            "pgd l2: attack effectiveness 27.632%.\n",
            "pgd l1: attack effectiveness 56.579%.\n",
            "max: attack effectiveness 56.57894736842105%.\n",
            "Mini batch: 847/1450 | training time in 9 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0178 | Train accuracy: 81.86%.\n",
            "pgd linf: attack effectiveness 11.475%.\n",
            "pgd l2: attack effectiveness 21.311%.\n",
            "pgd l1: attack effectiveness 49.180%.\n",
            "max: attack effectiveness 49.18032786885246%.\n",
            "Mini batch: 848/1450 | training time in 9 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0162 | Train accuracy: 85.71%.\n",
            "pgd linf: attack effectiveness 15.942%.\n",
            "pgd l2: attack effectiveness 18.841%.\n",
            "pgd l1: attack effectiveness 49.275%.\n",
            "max: attack effectiveness 49.275362318840585%.\n",
            "Mini batch: 849/1450 | training time in 9 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0167 | Train accuracy: 86.29%.\n",
            "pgd linf: attack effectiveness 14.516%.\n",
            "pgd l2: attack effectiveness 22.581%.\n",
            "pgd l1: attack effectiveness 46.774%.\n",
            "max: attack effectiveness 46.774193548387096%.\n",
            "Mini batch: 850/1450 | training time in 9 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0121 | Train accuracy: 87.89%.\n",
            "pgd linf: attack effectiveness 20.000%.\n",
            "pgd l2: attack effectiveness 13.333%.\n",
            "pgd l1: attack effectiveness 56.667%.\n",
            "max: attack effectiveness 58.333333333333336%.\n",
            "Mini batch: 851/1450 | training time in 9 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0263 | Train accuracy: 83.51%.\n",
            "pgd linf: attack effectiveness 9.259%.\n",
            "pgd l2: attack effectiveness 5.556%.\n",
            "pgd l1: attack effectiveness 42.593%.\n",
            "max: attack effectiveness 42.592592592592595%.\n",
            "Mini batch: 852/1450 | training time in 9 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0125 | Train accuracy: 91.21%.\n",
            "pgd linf: attack effectiveness 15.873%.\n",
            "pgd l2: attack effectiveness 14.286%.\n",
            "pgd l1: attack effectiveness 57.143%.\n",
            "max: attack effectiveness 57.14285714285714%.\n",
            "Mini batch: 853/1450 | training time in 9 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0161 | Train accuracy: 85.34%.\n",
            "pgd linf: attack effectiveness 12.308%.\n",
            "pgd l2: attack effectiveness 18.462%.\n",
            "pgd l1: attack effectiveness 58.462%.\n",
            "max: attack effectiveness 58.46153846153847%.\n",
            "Mini batch: 854/1450 | training time in 9 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0112 | Train accuracy: 83.42%.\n",
            "pgd linf: attack effectiveness 10.606%.\n",
            "pgd l2: attack effectiveness 21.212%.\n",
            "pgd l1: attack effectiveness 48.485%.\n",
            "max: attack effectiveness 48.484848484848484%.\n",
            "Mini batch: 855/1450 | training time in 9 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0280 | Train accuracy: 84.02%.\n",
            "pgd linf: attack effectiveness 13.846%.\n",
            "pgd l2: attack effectiveness 16.923%.\n",
            "pgd l1: attack effectiveness 47.692%.\n",
            "max: attack effectiveness 49.23076923076923%.\n",
            "Mini batch: 856/1450 | training time in 9 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0133 | Train accuracy: 83.94%.\n",
            "pgd linf: attack effectiveness 12.676%.\n",
            "pgd l2: attack effectiveness 15.493%.\n",
            "pgd l1: attack effectiveness 54.930%.\n",
            "max: attack effectiveness 56.33802816901409%.\n",
            "Mini batch: 857/1450 | training time in 9 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0147 | Train accuracy: 86.93%.\n",
            "pgd linf: attack effectiveness 10.938%.\n",
            "pgd l2: attack effectiveness 17.188%.\n",
            "pgd l1: attack effectiveness 42.188%.\n",
            "max: attack effectiveness 42.1875%.\n",
            "Mini batch: 858/1450 | training time in 9 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0127 | Train accuracy: 86.46%.\n",
            "pgd linf: attack effectiveness 14.925%.\n",
            "pgd l2: attack effectiveness 20.896%.\n",
            "pgd l1: attack effectiveness 43.284%.\n",
            "max: attack effectiveness 46.26865671641791%.\n",
            "Mini batch: 859/1450 | training time in 9 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0139 | Train accuracy: 86.15%.\n",
            "pgd linf: attack effectiveness 12.500%.\n",
            "pgd l2: attack effectiveness 31.250%.\n",
            "pgd l1: attack effectiveness 48.438%.\n",
            "max: attack effectiveness 48.4375%.\n",
            "Mini batch: 860/1450 | training time in 9 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0207 | Train accuracy: 86.46%.\n",
            "pgd linf: attack effectiveness 18.919%.\n",
            "pgd l2: attack effectiveness 12.162%.\n",
            "pgd l1: attack effectiveness 55.405%.\n",
            "max: attack effectiveness 55.4054054054054%.\n",
            "Mini batch: 861/1450 | training time in 9 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0290 | Train accuracy: 83.17%.\n",
            "pgd linf: attack effectiveness 10.145%.\n",
            "pgd l2: attack effectiveness 7.246%.\n",
            "pgd l1: attack effectiveness 47.826%.\n",
            "max: attack effectiveness 47.82608695652174%.\n",
            "Mini batch: 862/1450 | training time in 9 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0387 | Train accuracy: 84.26%.\n",
            "pgd linf: attack effectiveness 12.000%.\n",
            "pgd l2: attack effectiveness 17.333%.\n",
            "pgd l1: attack effectiveness 53.333%.\n",
            "max: attack effectiveness 56.00000000000001%.\n",
            "Mini batch: 863/1450 | training time in 9 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0165 | Train accuracy: 84.24%.\n",
            "pgd linf: attack effectiveness 10.294%.\n",
            "pgd l2: attack effectiveness 33.824%.\n",
            "pgd l1: attack effectiveness 48.529%.\n",
            "max: attack effectiveness 48.529411764705884%.\n",
            "Mini batch: 864/1450 | training time in 9 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0192 | Train accuracy: 83.16%.\n",
            "pgd linf: attack effectiveness 23.729%.\n",
            "pgd l2: attack effectiveness 13.559%.\n",
            "pgd l1: attack effectiveness 52.542%.\n",
            "max: attack effectiveness 54.23728813559322%.\n",
            "Mini batch: 865/1450 | training time in 9 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0298 | Train accuracy: 87.70%.\n",
            "pgd linf: attack effectiveness 30.667%.\n",
            "pgd l2: attack effectiveness 38.667%.\n",
            "pgd l1: attack effectiveness 52.000%.\n",
            "max: attack effectiveness 52.0%.\n",
            "Mini batch: 866/1450 | training time in 9 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0170 | Train accuracy: 82.76%.\n",
            "pgd linf: attack effectiveness 30.435%.\n",
            "pgd l2: attack effectiveness 44.928%.\n",
            "pgd l1: attack effectiveness 55.072%.\n",
            "max: attack effectiveness 55.072463768115945%.\n",
            "Mini batch: 867/1450 | training time in 9 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0219 | Train accuracy: 82.23%.\n",
            "pgd linf: attack effectiveness 20.312%.\n",
            "pgd l2: attack effectiveness 18.750%.\n",
            "pgd l1: attack effectiveness 42.188%.\n",
            "max: attack effectiveness 43.75%.\n",
            "Mini batch: 868/1450 | training time in 9 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0231 | Train accuracy: 86.46%.\n",
            "pgd linf: attack effectiveness 14.516%.\n",
            "pgd l2: attack effectiveness 29.032%.\n",
            "pgd l1: attack effectiveness 43.548%.\n",
            "max: attack effectiveness 43.54838709677419%.\n",
            "Mini batch: 869/1450 | training time in 9 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0175 | Train accuracy: 87.37%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 870/1450 | training time in 9 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0119 | Train accuracy: 89.47%.\n",
            "Training loss (epoch level): 0.0195 | Train accuracy: 85.12\n",
            "pgd linf: attack effectiveness 25.448%.\n",
            "pgd l2: attack effectiveness 48.925%.\n",
            "pgd l1: attack effectiveness 61.290%.\n",
            "max: attack effectiveness 63.620071684587806%.\n",
            "\tVal accuracy 66.44% with accuracy 36.38% under attack.\n",
            "\tModel select at epoch 24 with validation accuracy 68.27% and accuracy 39.96% under attack.\n",
            "pgd linf: attack effectiveness 25.758%.\n",
            "pgd l2: attack effectiveness 43.939%.\n",
            "pgd l1: attack effectiveness 48.485%.\n",
            "max: attack effectiveness 54.54545454545454%.\n",
            "Mini batch: 871/1450 | training time in 9 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0431 | Train accuracy: 82.47%.\n",
            "pgd linf: attack effectiveness 19.048%.\n",
            "pgd l2: attack effectiveness 44.444%.\n",
            "pgd l1: attack effectiveness 53.968%.\n",
            "max: attack effectiveness 58.730158730158735%.\n",
            "Mini batch: 872/1450 | training time in 9 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0251 | Train accuracy: 82.72%.\n",
            "pgd linf: attack effectiveness 18.182%.\n",
            "pgd l2: attack effectiveness 18.182%.\n",
            "pgd l1: attack effectiveness 45.455%.\n",
            "max: attack effectiveness 46.96969696969697%.\n",
            "Mini batch: 873/1450 | training time in 9 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0178 | Train accuracy: 85.57%.\n",
            "pgd linf: attack effectiveness 15.714%.\n",
            "pgd l2: attack effectiveness 24.286%.\n",
            "pgd l1: attack effectiveness 48.571%.\n",
            "max: attack effectiveness 52.85714285714286%.\n",
            "Mini batch: 874/1450 | training time in 9 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0206 | Train accuracy: 83.33%.\n",
            "pgd linf: attack effectiveness 12.676%.\n",
            "pgd l2: attack effectiveness 12.676%.\n",
            "pgd l1: attack effectiveness 50.704%.\n",
            "max: attack effectiveness 52.112676056338024%.\n",
            "Mini batch: 875/1450 | training time in 9 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0197 | Train accuracy: 82.41%.\n",
            "pgd linf: attack effectiveness 14.474%.\n",
            "pgd l2: attack effectiveness 19.737%.\n",
            "pgd l1: attack effectiveness 50.000%.\n",
            "max: attack effectiveness 51.31578947368421%.\n",
            "Mini batch: 876/1450 | training time in 9 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0220 | Train accuracy: 83.33%.\n",
            "pgd linf: attack effectiveness 22.951%.\n",
            "pgd l2: attack effectiveness 8.197%.\n",
            "pgd l1: attack effectiveness 45.902%.\n",
            "max: attack effectiveness 45.90163934426229%.\n",
            "Mini batch: 877/1450 | training time in 9 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0154 | Train accuracy: 88.36%.\n",
            "pgd linf: attack effectiveness 18.841%.\n",
            "pgd l2: attack effectiveness 17.391%.\n",
            "pgd l1: attack effectiveness 43.478%.\n",
            "max: attack effectiveness 43.47826086956522%.\n",
            "Mini batch: 878/1450 | training time in 9 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0235 | Train accuracy: 87.82%.\n",
            "pgd linf: attack effectiveness 14.516%.\n",
            "pgd l2: attack effectiveness 11.290%.\n",
            "pgd l1: attack effectiveness 41.935%.\n",
            "max: attack effectiveness 41.935483870967744%.\n",
            "Mini batch: 879/1450 | training time in 9 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0146 | Train accuracy: 86.32%.\n",
            "pgd linf: attack effectiveness 15.000%.\n",
            "pgd l2: attack effectiveness 16.667%.\n",
            "pgd l1: attack effectiveness 53.333%.\n",
            "max: attack effectiveness 55.00000000000001%.\n",
            "Mini batch: 880/1450 | training time in 9 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0230 | Train accuracy: 85.11%.\n",
            "pgd linf: attack effectiveness 16.667%.\n",
            "pgd l2: attack effectiveness 11.111%.\n",
            "pgd l1: attack effectiveness 42.593%.\n",
            "max: attack effectiveness 42.592592592592595%.\n",
            "Mini batch: 881/1450 | training time in 9 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0116 | Train accuracy: 89.56%.\n",
            "pgd linf: attack effectiveness 25.397%.\n",
            "pgd l2: attack effectiveness 20.635%.\n",
            "pgd l1: attack effectiveness 50.794%.\n",
            "max: attack effectiveness 52.38095238095239%.\n",
            "Mini batch: 882/1450 | training time in 9 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0143 | Train accuracy: 87.43%.\n",
            "pgd linf: attack effectiveness 13.846%.\n",
            "pgd l2: attack effectiveness 29.231%.\n",
            "pgd l1: attack effectiveness 55.385%.\n",
            "max: attack effectiveness 56.92307692307692%.\n",
            "Mini batch: 883/1450 | training time in 9 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0113 | Train accuracy: 85.49%.\n",
            "pgd linf: attack effectiveness 19.697%.\n",
            "pgd l2: attack effectiveness 19.697%.\n",
            "pgd l1: attack effectiveness 48.485%.\n",
            "max: attack effectiveness 48.484848484848484%.\n",
            "Mini batch: 884/1450 | training time in 9 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0475 | Train accuracy: 85.05%.\n",
            "pgd linf: attack effectiveness 20.000%.\n",
            "pgd l2: attack effectiveness 27.692%.\n",
            "pgd l1: attack effectiveness 47.692%.\n",
            "max: attack effectiveness 49.23076923076923%.\n",
            "Mini batch: 885/1450 | training time in 9 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0243 | Train accuracy: 84.46%.\n",
            "pgd linf: attack effectiveness 22.535%.\n",
            "pgd l2: attack effectiveness 30.986%.\n",
            "pgd l1: attack effectiveness 57.746%.\n",
            "max: attack effectiveness 57.74647887323944%.\n",
            "Mini batch: 886/1450 | training time in 9 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0160 | Train accuracy: 82.41%.\n",
            "pgd linf: attack effectiveness 15.625%.\n",
            "pgd l2: attack effectiveness 26.562%.\n",
            "pgd l1: attack effectiveness 42.188%.\n",
            "max: attack effectiveness 43.75%.\n",
            "Mini batch: 887/1450 | training time in 9 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0207 | Train accuracy: 87.50%.\n",
            "pgd linf: attack effectiveness 16.418%.\n",
            "pgd l2: attack effectiveness 31.343%.\n",
            "pgd l1: attack effectiveness 44.776%.\n",
            "max: attack effectiveness 44.776119402985074%.\n",
            "Mini batch: 888/1450 | training time in 9 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0220 | Train accuracy: 84.62%.\n",
            "pgd linf: attack effectiveness 15.625%.\n",
            "pgd l2: attack effectiveness 29.688%.\n",
            "pgd l1: attack effectiveness 51.562%.\n",
            "max: attack effectiveness 51.5625%.\n",
            "Mini batch: 889/1450 | training time in 9 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0254 | Train accuracy: 83.85%.\n",
            "pgd linf: attack effectiveness 25.676%.\n",
            "pgd l2: attack effectiveness 35.135%.\n",
            "pgd l1: attack effectiveness 54.054%.\n",
            "max: attack effectiveness 56.75675675675676%.\n",
            "Mini batch: 890/1450 | training time in 9 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0339 | Train accuracy: 81.68%.\n",
            "pgd linf: attack effectiveness 15.942%.\n",
            "pgd l2: attack effectiveness 15.942%.\n",
            "pgd l1: attack effectiveness 44.928%.\n",
            "max: attack effectiveness 44.927536231884055%.\n",
            "Mini batch: 891/1450 | training time in 9 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0121 | Train accuracy: 85.28%.\n",
            "pgd linf: attack effectiveness 8.000%.\n",
            "pgd l2: attack effectiveness 16.000%.\n",
            "pgd l1: attack effectiveness 52.000%.\n",
            "max: attack effectiveness 54.666666666666664%.\n",
            "Mini batch: 892/1450 | training time in 9 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0159 | Train accuracy: 81.77%.\n",
            "pgd linf: attack effectiveness 11.765%.\n",
            "pgd l2: attack effectiveness 1.471%.\n",
            "pgd l1: attack effectiveness 50.000%.\n",
            "max: attack effectiveness 50.0%.\n",
            "Mini batch: 893/1450 | training time in 9 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0080 | Train accuracy: 87.76%.\n",
            "pgd linf: attack effectiveness 16.949%.\n",
            "pgd l2: attack effectiveness 8.475%.\n",
            "pgd l1: attack effectiveness 50.847%.\n",
            "max: attack effectiveness 50.847457627118644%.\n",
            "Mini batch: 894/1450 | training time in 9 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0310 | Train accuracy: 87.70%.\n",
            "pgd linf: attack effectiveness 6.667%.\n",
            "pgd l2: attack effectiveness 17.333%.\n",
            "pgd l1: attack effectiveness 50.667%.\n",
            "max: attack effectiveness 52.0%.\n",
            "Mini batch: 895/1450 | training time in 9 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0144 | Train accuracy: 83.25%.\n",
            "pgd linf: attack effectiveness 11.594%.\n",
            "pgd l2: attack effectiveness 15.942%.\n",
            "pgd l1: attack effectiveness 53.623%.\n",
            "max: attack effectiveness 53.62318840579711%.\n",
            "Mini batch: 896/1450 | training time in 9 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0167 | Train accuracy: 86.29%.\n",
            "pgd linf: attack effectiveness 3.125%.\n",
            "pgd l2: attack effectiveness 17.188%.\n",
            "pgd l1: attack effectiveness 35.938%.\n",
            "max: attack effectiveness 39.0625%.\n",
            "Mini batch: 897/1450 | training time in 9 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0222 | Train accuracy: 88.54%.\n",
            "pgd linf: attack effectiveness 1.613%.\n",
            "pgd l2: attack effectiveness 12.903%.\n",
            "pgd l1: attack effectiveness 43.548%.\n",
            "max: attack effectiveness 46.774193548387096%.\n",
            "Mini batch: 898/1450 | training time in 9 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0118 | Train accuracy: 86.84%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 899/1450 | training time in 9 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0035 | Train accuracy: 94.74%.\n",
            "Training loss (epoch level): 0.0203 | Train accuracy: 85.58\n",
            "pgd linf: attack effectiveness 14.516%.\n",
            "pgd l2: attack effectiveness 21.685%.\n",
            "pgd l1: attack effectiveness 61.470%.\n",
            "max: attack effectiveness 64.33691756272401%.\n",
            "\tVal accuracy 66.0% with accuracy 35.66% under attack.\n",
            "\tModel select at epoch 24 with validation accuracy 68.27% and accuracy 39.96% under attack.\n",
            "pgd linf: attack effectiveness 15.152%.\n",
            "pgd l2: attack effectiveness 13.636%.\n",
            "pgd l1: attack effectiveness 48.485%.\n",
            "max: attack effectiveness 48.484848484848484%.\n",
            "Mini batch: 900/1450 | training time in 9 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0222 | Train accuracy: 86.08%.\n",
            "pgd linf: attack effectiveness 14.286%.\n",
            "pgd l2: attack effectiveness 34.921%.\n",
            "pgd l1: attack effectiveness 55.556%.\n",
            "max: attack effectiveness 57.14285714285714%.\n",
            "Mini batch: 901/1450 | training time in 9 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0148 | Train accuracy: 84.29%.\n",
            "pgd linf: attack effectiveness 13.636%.\n",
            "pgd l2: attack effectiveness 25.758%.\n",
            "pgd l1: attack effectiveness 45.455%.\n",
            "max: attack effectiveness 45.45454545454545%.\n",
            "Mini batch: 902/1450 | training time in 9 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0148 | Train accuracy: 85.05%.\n",
            "pgd linf: attack effectiveness 7.143%.\n",
            "pgd l2: attack effectiveness 17.143%.\n",
            "pgd l1: attack effectiveness 52.857%.\n",
            "max: attack effectiveness 55.714285714285715%.\n",
            "Mini batch: 903/1450 | training time in 9 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0173 | Train accuracy: 82.83%.\n",
            "pgd linf: attack effectiveness 14.085%.\n",
            "pgd l2: attack effectiveness 8.451%.\n",
            "pgd l1: attack effectiveness 53.521%.\n",
            "max: attack effectiveness 53.52112676056338%.\n",
            "Mini batch: 904/1450 | training time in 9 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0120 | Train accuracy: 86.43%.\n",
            "pgd linf: attack effectiveness 17.105%.\n",
            "pgd l2: attack effectiveness 11.842%.\n",
            "pgd l1: attack effectiveness 55.263%.\n",
            "max: attack effectiveness 55.26315789473685%.\n",
            "Mini batch: 905/1450 | training time in 9 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0138 | Train accuracy: 84.80%.\n",
            "pgd linf: attack effectiveness 14.754%.\n",
            "pgd l2: attack effectiveness 21.311%.\n",
            "pgd l1: attack effectiveness 49.180%.\n",
            "max: attack effectiveness 49.18032786885246%.\n",
            "Mini batch: 906/1450 | training time in 9 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0135 | Train accuracy: 87.83%.\n",
            "pgd linf: attack effectiveness 27.536%.\n",
            "pgd l2: attack effectiveness 10.145%.\n",
            "pgd l1: attack effectiveness 47.826%.\n",
            "max: attack effectiveness 49.275362318840585%.\n",
            "Mini batch: 907/1450 | training time in 9 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0142 | Train accuracy: 85.79%.\n",
            "pgd linf: attack effectiveness 20.968%.\n",
            "pgd l2: attack effectiveness 12.903%.\n",
            "pgd l1: attack effectiveness 38.710%.\n",
            "max: attack effectiveness 41.935483870967744%.\n",
            "Mini batch: 908/1450 | training time in 9 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0139 | Train accuracy: 86.84%.\n",
            "pgd linf: attack effectiveness 23.333%.\n",
            "pgd l2: attack effectiveness 15.000%.\n",
            "pgd l1: attack effectiveness 58.333%.\n",
            "max: attack effectiveness 60.0%.\n",
            "Mini batch: 909/1450 | training time in 9 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0239 | Train accuracy: 85.11%.\n",
            "pgd linf: attack effectiveness 22.222%.\n",
            "pgd l2: attack effectiveness 11.111%.\n",
            "pgd l1: attack effectiveness 38.889%.\n",
            "max: attack effectiveness 38.88888888888889%.\n",
            "Mini batch: 910/1450 | training time in 9 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0155 | Train accuracy: 89.56%.\n",
            "pgd linf: attack effectiveness 26.984%.\n",
            "pgd l2: attack effectiveness 17.460%.\n",
            "pgd l1: attack effectiveness 52.381%.\n",
            "max: attack effectiveness 55.55555555555556%.\n",
            "Mini batch: 911/1450 | training time in 9 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0188 | Train accuracy: 84.29%.\n",
            "pgd linf: attack effectiveness 24.615%.\n",
            "pgd l2: attack effectiveness 7.692%.\n",
            "pgd l1: attack effectiveness 56.923%.\n",
            "max: attack effectiveness 56.92307692307692%.\n",
            "Mini batch: 912/1450 | training time in 9 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0104 | Train accuracy: 84.97%.\n",
            "pgd linf: attack effectiveness 27.273%.\n",
            "pgd l2: attack effectiveness 21.212%.\n",
            "pgd l1: attack effectiveness 48.485%.\n",
            "max: attack effectiveness 50.0%.\n",
            "Mini batch: 913/1450 | training time in 9 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0466 | Train accuracy: 84.54%.\n",
            "pgd linf: attack effectiveness 4.615%.\n",
            "pgd l2: attack effectiveness 6.154%.\n",
            "pgd l1: attack effectiveness 44.615%.\n",
            "max: attack effectiveness 46.15384615384615%.\n",
            "Mini batch: 914/1450 | training time in 10 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0110 | Train accuracy: 87.56%.\n",
            "pgd linf: attack effectiveness 15.493%.\n",
            "pgd l2: attack effectiveness 38.028%.\n",
            "pgd l1: attack effectiveness 54.930%.\n",
            "max: attack effectiveness 54.929577464788736%.\n",
            "Mini batch: 915/1450 | training time in 10 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0193 | Train accuracy: 82.41%.\n",
            "pgd linf: attack effectiveness 15.625%.\n",
            "pgd l2: attack effectiveness 28.125%.\n",
            "pgd l1: attack effectiveness 39.062%.\n",
            "max: attack effectiveness 40.625%.\n",
            "Mini batch: 916/1450 | training time in 10 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0177 | Train accuracy: 86.98%.\n",
            "pgd linf: attack effectiveness 19.403%.\n",
            "pgd l2: attack effectiveness 32.836%.\n",
            "pgd l1: attack effectiveness 40.299%.\n",
            "max: attack effectiveness 43.28358208955223%.\n",
            "Mini batch: 917/1450 | training time in 10 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0209 | Train accuracy: 86.67%.\n",
            "pgd linf: attack effectiveness 23.438%.\n",
            "pgd l2: attack effectiveness 35.938%.\n",
            "pgd l1: attack effectiveness 46.875%.\n",
            "max: attack effectiveness 48.4375%.\n",
            "Mini batch: 918/1450 | training time in 10 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0302 | Train accuracy: 85.42%.\n",
            "pgd linf: attack effectiveness 22.973%.\n",
            "pgd l2: attack effectiveness 48.649%.\n",
            "pgd l1: attack effectiveness 55.405%.\n",
            "max: attack effectiveness 58.108108108108105%.\n",
            "Mini batch: 919/1450 | training time in 10 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0426 | Train accuracy: 79.21%.\n",
            "pgd linf: attack effectiveness 15.942%.\n",
            "pgd l2: attack effectiveness 37.681%.\n",
            "pgd l1: attack effectiveness 44.928%.\n",
            "max: attack effectiveness 46.3768115942029%.\n",
            "Mini batch: 920/1450 | training time in 10 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0249 | Train accuracy: 84.26%.\n",
            "pgd linf: attack effectiveness 26.667%.\n",
            "pgd l2: attack effectiveness 41.333%.\n",
            "pgd l1: attack effectiveness 52.000%.\n",
            "max: attack effectiveness 53.333333333333336%.\n",
            "Mini batch: 921/1450 | training time in 10 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0249 | Train accuracy: 84.73%.\n",
            "pgd linf: attack effectiveness 14.706%.\n",
            "pgd l2: attack effectiveness 39.706%.\n",
            "pgd l1: attack effectiveness 48.529%.\n",
            "max: attack effectiveness 48.529411764705884%.\n",
            "Mini batch: 922/1450 | training time in 10 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0197 | Train accuracy: 85.20%.\n",
            "pgd linf: attack effectiveness 22.034%.\n",
            "pgd l2: attack effectiveness 23.729%.\n",
            "pgd l1: attack effectiveness 49.153%.\n",
            "max: attack effectiveness 50.847457627118644%.\n",
            "Mini batch: 923/1450 | training time in 10 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0341 | Train accuracy: 85.56%.\n",
            "pgd linf: attack effectiveness 13.333%.\n",
            "pgd l2: attack effectiveness 32.000%.\n",
            "pgd l1: attack effectiveness 45.333%.\n",
            "max: attack effectiveness 45.33333333333333%.\n",
            "Mini batch: 924/1450 | training time in 10 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0107 | Train accuracy: 83.74%.\n",
            "pgd linf: attack effectiveness 5.797%.\n",
            "pgd l2: attack effectiveness 10.145%.\n",
            "pgd l1: attack effectiveness 50.725%.\n",
            "max: attack effectiveness 52.17391304347826%.\n",
            "Mini batch: 925/1450 | training time in 10 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0151 | Train accuracy: 84.77%.\n",
            "pgd linf: attack effectiveness 7.812%.\n",
            "pgd l2: attack effectiveness 12.500%.\n",
            "pgd l1: attack effectiveness 35.938%.\n",
            "max: attack effectiveness 35.9375%.\n",
            "Mini batch: 926/1450 | training time in 10 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0248 | Train accuracy: 90.62%.\n",
            "pgd linf: attack effectiveness 11.290%.\n",
            "pgd l2: attack effectiveness 11.290%.\n",
            "pgd l1: attack effectiveness 41.935%.\n",
            "max: attack effectiveness 43.54838709677419%.\n",
            "Mini batch: 927/1450 | training time in 10 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0187 | Train accuracy: 86.32%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 16.667%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 928/1450 | training time in 10 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0102 | Train accuracy: 89.47%.\n",
            "Training loss (epoch level): 0.0199 | Train accuracy: 85.56\n",
            "pgd linf: attack effectiveness 8.602%.\n",
            "pgd l2: attack effectiveness 19.713%.\n",
            "pgd l1: attack effectiveness 59.319%.\n",
            "max: attack effectiveness 60.752688172043015%.\n",
            "\tVal accuracy 67.37% with accuracy 39.25% under attack.\n",
            "\tModel select at epoch 24 with validation accuracy 68.27% and accuracy 39.96% under attack.\n",
            "pgd linf: attack effectiveness 7.576%.\n",
            "pgd l2: attack effectiveness 16.667%.\n",
            "pgd l1: attack effectiveness 46.970%.\n",
            "max: attack effectiveness 46.96969696969697%.\n",
            "Mini batch: 929/1450 | training time in 10 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0212 | Train accuracy: 85.57%.\n",
            "pgd linf: attack effectiveness 4.762%.\n",
            "pgd l2: attack effectiveness 7.937%.\n",
            "pgd l1: attack effectiveness 50.794%.\n",
            "max: attack effectiveness 50.79365079365079%.\n",
            "Mini batch: 930/1450 | training time in 10 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0142 | Train accuracy: 88.48%.\n",
            "pgd linf: attack effectiveness 15.152%.\n",
            "pgd l2: attack effectiveness 13.636%.\n",
            "pgd l1: attack effectiveness 45.455%.\n",
            "max: attack effectiveness 45.45454545454545%.\n",
            "Mini batch: 931/1450 | training time in 10 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0130 | Train accuracy: 85.57%.\n",
            "pgd linf: attack effectiveness 8.571%.\n",
            "pgd l2: attack effectiveness 27.143%.\n",
            "pgd l1: attack effectiveness 52.857%.\n",
            "max: attack effectiveness 52.85714285714286%.\n",
            "Mini batch: 932/1450 | training time in 10 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0142 | Train accuracy: 83.84%.\n",
            "pgd linf: attack effectiveness 16.901%.\n",
            "pgd l2: attack effectiveness 35.211%.\n",
            "pgd l1: attack effectiveness 53.521%.\n",
            "max: attack effectiveness 53.52112676056338%.\n",
            "Mini batch: 933/1450 | training time in 10 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0122 | Train accuracy: 82.91%.\n",
            "pgd linf: attack effectiveness 14.474%.\n",
            "pgd l2: attack effectiveness 22.368%.\n",
            "pgd l1: attack effectiveness 56.579%.\n",
            "max: attack effectiveness 56.57894736842105%.\n",
            "Mini batch: 934/1450 | training time in 10 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0129 | Train accuracy: 80.39%.\n",
            "pgd linf: attack effectiveness 6.557%.\n",
            "pgd l2: attack effectiveness 9.836%.\n",
            "pgd l1: attack effectiveness 49.180%.\n",
            "max: attack effectiveness 49.18032786885246%.\n",
            "Mini batch: 935/1450 | training time in 10 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0148 | Train accuracy: 87.83%.\n",
            "pgd linf: attack effectiveness 17.391%.\n",
            "pgd l2: attack effectiveness 27.536%.\n",
            "pgd l1: attack effectiveness 47.826%.\n",
            "max: attack effectiveness 47.82608695652174%.\n",
            "Mini batch: 936/1450 | training time in 10 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0126 | Train accuracy: 85.79%.\n",
            "pgd linf: attack effectiveness 9.677%.\n",
            "pgd l2: attack effectiveness 11.290%.\n",
            "pgd l1: attack effectiveness 41.935%.\n",
            "max: attack effectiveness 41.935483870967744%.\n",
            "Mini batch: 937/1450 | training time in 10 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0160 | Train accuracy: 88.42%.\n",
            "pgd linf: attack effectiveness 5.000%.\n",
            "pgd l2: attack effectiveness 11.667%.\n",
            "pgd l1: attack effectiveness 58.333%.\n",
            "max: attack effectiveness 58.333333333333336%.\n",
            "Mini batch: 938/1450 | training time in 10 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0214 | Train accuracy: 84.57%.\n",
            "pgd linf: attack effectiveness 5.556%.\n",
            "pgd l2: attack effectiveness 3.704%.\n",
            "pgd l1: attack effectiveness 42.593%.\n",
            "max: attack effectiveness 42.592592592592595%.\n",
            "Mini batch: 939/1450 | training time in 10 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0167 | Train accuracy: 89.01%.\n",
            "pgd linf: attack effectiveness 14.286%.\n",
            "pgd l2: attack effectiveness 11.111%.\n",
            "pgd l1: attack effectiveness 50.794%.\n",
            "max: attack effectiveness 50.79365079365079%.\n",
            "Mini batch: 940/1450 | training time in 10 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0151 | Train accuracy: 84.82%.\n",
            "pgd linf: attack effectiveness 13.846%.\n",
            "pgd l2: attack effectiveness 13.846%.\n",
            "pgd l1: attack effectiveness 56.923%.\n",
            "max: attack effectiveness 56.92307692307692%.\n",
            "Mini batch: 941/1450 | training time in 10 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0104 | Train accuracy: 84.97%.\n",
            "pgd linf: attack effectiveness 12.121%.\n",
            "pgd l2: attack effectiveness 9.091%.\n",
            "pgd l1: attack effectiveness 48.485%.\n",
            "max: attack effectiveness 48.484848484848484%.\n",
            "Mini batch: 942/1450 | training time in 10 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0463 | Train accuracy: 86.08%.\n",
            "pgd linf: attack effectiveness 16.923%.\n",
            "pgd l2: attack effectiveness 4.615%.\n",
            "pgd l1: attack effectiveness 43.077%.\n",
            "max: attack effectiveness 43.07692307692308%.\n",
            "Mini batch: 943/1450 | training time in 10 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0206 | Train accuracy: 88.08%.\n",
            "pgd linf: attack effectiveness 22.535%.\n",
            "pgd l2: attack effectiveness 9.859%.\n",
            "pgd l1: attack effectiveness 53.521%.\n",
            "max: attack effectiveness 53.52112676056338%.\n",
            "Mini batch: 944/1450 | training time in 10 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0126 | Train accuracy: 84.42%.\n",
            "pgd linf: attack effectiveness 18.750%.\n",
            "pgd l2: attack effectiveness 18.750%.\n",
            "pgd l1: attack effectiveness 37.500%.\n",
            "max: attack effectiveness 37.5%.\n",
            "Mini batch: 945/1450 | training time in 10 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0127 | Train accuracy: 89.06%.\n",
            "pgd linf: attack effectiveness 23.881%.\n",
            "pgd l2: attack effectiveness 5.970%.\n",
            "pgd l1: attack effectiveness 43.284%.\n",
            "max: attack effectiveness 46.26865671641791%.\n",
            "Mini batch: 946/1450 | training time in 10 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0105 | Train accuracy: 85.64%.\n",
            "pgd linf: attack effectiveness 15.625%.\n",
            "pgd l2: attack effectiveness 31.250%.\n",
            "pgd l1: attack effectiveness 51.562%.\n",
            "max: attack effectiveness 51.5625%.\n",
            "Mini batch: 947/1450 | training time in 10 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0148 | Train accuracy: 84.38%.\n",
            "pgd linf: attack effectiveness 21.622%.\n",
            "pgd l2: attack effectiveness 45.946%.\n",
            "pgd l1: attack effectiveness 54.054%.\n",
            "max: attack effectiveness 55.4054054054054%.\n",
            "Mini batch: 948/1450 | training time in 10 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0377 | Train accuracy: 80.20%.\n",
            "pgd linf: attack effectiveness 18.841%.\n",
            "pgd l2: attack effectiveness 36.232%.\n",
            "pgd l1: attack effectiveness 47.826%.\n",
            "max: attack effectiveness 47.82608695652174%.\n",
            "Mini batch: 949/1450 | training time in 10 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0335 | Train accuracy: 84.26%.\n",
            "pgd linf: attack effectiveness 25.333%.\n",
            "pgd l2: attack effectiveness 42.667%.\n",
            "pgd l1: attack effectiveness 53.333%.\n",
            "max: attack effectiveness 54.666666666666664%.\n",
            "Mini batch: 950/1450 | training time in 10 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0211 | Train accuracy: 82.27%.\n",
            "pgd linf: attack effectiveness 23.529%.\n",
            "pgd l2: attack effectiveness 38.235%.\n",
            "pgd l1: attack effectiveness 48.529%.\n",
            "max: attack effectiveness 48.529411764705884%.\n",
            "Mini batch: 951/1450 | training time in 10 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0254 | Train accuracy: 84.18%.\n",
            "pgd linf: attack effectiveness 20.339%.\n",
            "pgd l2: attack effectiveness 33.898%.\n",
            "pgd l1: attack effectiveness 52.542%.\n",
            "max: attack effectiveness 52.54237288135594%.\n",
            "Mini batch: 952/1450 | training time in 10 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0392 | Train accuracy: 85.03%.\n",
            "pgd linf: attack effectiveness 26.667%.\n",
            "pgd l2: attack effectiveness 38.667%.\n",
            "pgd l1: attack effectiveness 48.000%.\n",
            "max: attack effectiveness 48.0%.\n",
            "Mini batch: 953/1450 | training time in 10 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0165 | Train accuracy: 82.76%.\n",
            "pgd linf: attack effectiveness 26.087%.\n",
            "pgd l2: attack effectiveness 43.478%.\n",
            "pgd l1: attack effectiveness 55.072%.\n",
            "max: attack effectiveness 56.52173913043478%.\n",
            "Mini batch: 954/1450 | training time in 10 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0163 | Train accuracy: 82.23%.\n",
            "pgd linf: attack effectiveness 10.938%.\n",
            "pgd l2: attack effectiveness 21.875%.\n",
            "pgd l1: attack effectiveness 39.062%.\n",
            "max: attack effectiveness 40.625%.\n",
            "Mini batch: 955/1450 | training time in 10 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0135 | Train accuracy: 88.02%.\n",
            "pgd linf: attack effectiveness 16.129%.\n",
            "pgd l2: attack effectiveness 8.065%.\n",
            "pgd l1: attack effectiveness 40.323%.\n",
            "max: attack effectiveness 40.32258064516129%.\n",
            "Mini batch: 956/1450 | training time in 10 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0106 | Train accuracy: 87.37%.\n",
            "pgd linf: attack effectiveness 16.667%.\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 957/1450 | training time in 10 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0167 | Train accuracy: 89.47%.\n",
            "Training loss (epoch level): 0.0187 | Train accuracy: 85.37\n",
            "pgd linf: attack effectiveness 23.835%.\n",
            "pgd l2: attack effectiveness 41.219%.\n",
            "pgd l1: attack effectiveness 58.244%.\n",
            "max: attack effectiveness 59.85663082437276%.\n",
            "\tVal accuracy 67.82% with accuracy 40.14% under attack.\n",
            "\tModel select at epoch 24 with validation accuracy 68.27% and accuracy 39.96% under attack.\n",
            "pgd linf: attack effectiveness 22.727%.\n",
            "pgd l2: attack effectiveness 31.818%.\n",
            "pgd l1: attack effectiveness 40.909%.\n",
            "max: attack effectiveness 40.909090909090914%.\n",
            "Mini batch: 958/1450 | training time in 10 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0182 | Train accuracy: 87.63%.\n",
            "pgd linf: attack effectiveness 22.222%.\n",
            "pgd l2: attack effectiveness 26.984%.\n",
            "pgd l1: attack effectiveness 50.794%.\n",
            "max: attack effectiveness 50.79365079365079%.\n",
            "Mini batch: 959/1450 | training time in 10 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0242 | Train accuracy: 84.29%.\n",
            "pgd linf: attack effectiveness 16.667%.\n",
            "pgd l2: attack effectiveness 25.758%.\n",
            "pgd l1: attack effectiveness 43.939%.\n",
            "max: attack effectiveness 43.93939393939394%.\n",
            "Mini batch: 960/1450 | training time in 10 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0229 | Train accuracy: 85.57%.\n",
            "pgd linf: attack effectiveness 11.429%.\n",
            "pgd l2: attack effectiveness 24.286%.\n",
            "pgd l1: attack effectiveness 48.571%.\n",
            "max: attack effectiveness 48.57142857142857%.\n",
            "Mini batch: 961/1450 | training time in 10 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0172 | Train accuracy: 85.35%.\n",
            "pgd linf: attack effectiveness 25.352%.\n",
            "pgd l2: attack effectiveness 32.394%.\n",
            "pgd l1: attack effectiveness 50.704%.\n",
            "max: attack effectiveness 50.70422535211267%.\n",
            "Mini batch: 962/1450 | training time in 10 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0198 | Train accuracy: 82.41%.\n",
            "pgd linf: attack effectiveness 13.158%.\n",
            "pgd l2: attack effectiveness 35.526%.\n",
            "pgd l1: attack effectiveness 48.684%.\n",
            "max: attack effectiveness 50.0%.\n",
            "Mini batch: 963/1450 | training time in 10 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0204 | Train accuracy: 82.84%.\n",
            "pgd linf: attack effectiveness 11.475%.\n",
            "pgd l2: attack effectiveness 13.115%.\n",
            "pgd l1: attack effectiveness 45.902%.\n",
            "max: attack effectiveness 45.90163934426229%.\n",
            "Mini batch: 964/1450 | training time in 10 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0122 | Train accuracy: 87.30%.\n",
            "pgd linf: attack effectiveness 10.145%.\n",
            "pgd l2: attack effectiveness 14.493%.\n",
            "pgd l1: attack effectiveness 44.928%.\n",
            "max: attack effectiveness 44.927536231884055%.\n",
            "Mini batch: 965/1450 | training time in 10 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0152 | Train accuracy: 86.80%.\n",
            "pgd linf: attack effectiveness 17.742%.\n",
            "pgd l2: attack effectiveness 22.581%.\n",
            "pgd l1: attack effectiveness 41.935%.\n",
            "max: attack effectiveness 41.935483870967744%.\n",
            "Mini batch: 966/1450 | training time in 10 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0129 | Train accuracy: 87.89%.\n",
            "pgd linf: attack effectiveness 20.000%.\n",
            "pgd l2: attack effectiveness 11.667%.\n",
            "pgd l1: attack effectiveness 53.333%.\n",
            "max: attack effectiveness 53.333333333333336%.\n",
            "Mini batch: 967/1450 | training time in 10 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0178 | Train accuracy: 85.11%.\n",
            "pgd linf: attack effectiveness 16.667%.\n",
            "pgd l2: attack effectiveness 3.704%.\n",
            "pgd l1: attack effectiveness 40.741%.\n",
            "max: attack effectiveness 40.74074074074074%.\n",
            "Mini batch: 968/1450 | training time in 10 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0102 | Train accuracy: 90.11%.\n",
            "pgd linf: attack effectiveness 22.222%.\n",
            "pgd l2: attack effectiveness 28.571%.\n",
            "pgd l1: attack effectiveness 47.619%.\n",
            "max: attack effectiveness 47.61904761904761%.\n",
            "Mini batch: 969/1450 | training time in 10 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0116 | Train accuracy: 86.91%.\n",
            "pgd linf: attack effectiveness 16.923%.\n",
            "pgd l2: attack effectiveness 26.154%.\n",
            "pgd l1: attack effectiveness 52.308%.\n",
            "max: attack effectiveness 52.307692307692314%.\n",
            "Mini batch: 970/1450 | training time in 10 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0129 | Train accuracy: 84.97%.\n",
            "pgd linf: attack effectiveness 16.667%.\n",
            "pgd l2: attack effectiveness 13.636%.\n",
            "pgd l1: attack effectiveness 46.970%.\n",
            "max: attack effectiveness 46.96969696969697%.\n",
            "Mini batch: 971/1450 | training time in 10 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0196 | Train accuracy: 85.05%.\n",
            "pgd linf: attack effectiveness 18.462%.\n",
            "pgd l2: attack effectiveness 4.615%.\n",
            "pgd l1: attack effectiveness 41.538%.\n",
            "max: attack effectiveness 41.53846153846154%.\n",
            "Mini batch: 972/1450 | training time in 10 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0122 | Train accuracy: 88.08%.\n",
            "pgd linf: attack effectiveness 14.085%.\n",
            "pgd l2: attack effectiveness 5.634%.\n",
            "pgd l1: attack effectiveness 50.704%.\n",
            "max: attack effectiveness 50.70422535211267%.\n",
            "Mini batch: 973/1450 | training time in 10 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0133 | Train accuracy: 85.93%.\n",
            "pgd linf: attack effectiveness 10.938%.\n",
            "pgd l2: attack effectiveness 4.688%.\n",
            "pgd l1: attack effectiveness 35.938%.\n",
            "max: attack effectiveness 35.9375%.\n",
            "Mini batch: 974/1450 | training time in 10 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0073 | Train accuracy: 90.62%.\n",
            "pgd linf: attack effectiveness 17.910%.\n",
            "pgd l2: attack effectiveness 4.478%.\n",
            "pgd l1: attack effectiveness 41.791%.\n",
            "max: attack effectiveness 41.7910447761194%.\n",
            "Mini batch: 975/1450 | training time in 10 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0111 | Train accuracy: 88.72%.\n",
            "pgd linf: attack effectiveness 15.625%.\n",
            "pgd l2: attack effectiveness 7.812%.\n",
            "pgd l1: attack effectiveness 46.875%.\n",
            "max: attack effectiveness 46.875%.\n",
            "Mini batch: 976/1450 | training time in 10 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0116 | Train accuracy: 86.46%.\n",
            "pgd linf: attack effectiveness 22.973%.\n",
            "pgd l2: attack effectiveness 17.568%.\n",
            "pgd l1: attack effectiveness 52.703%.\n",
            "max: attack effectiveness 52.702702702702695%.\n",
            "Mini batch: 977/1450 | training time in 10 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0166 | Train accuracy: 82.67%.\n",
            "pgd linf: attack effectiveness 8.696%.\n",
            "pgd l2: attack effectiveness 7.246%.\n",
            "pgd l1: attack effectiveness 42.029%.\n",
            "max: attack effectiveness 42.028985507246375%.\n",
            "Mini batch: 978/1450 | training time in 10 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0098 | Train accuracy: 88.32%.\n",
            "pgd linf: attack effectiveness 10.667%.\n",
            "pgd l2: attack effectiveness 21.333%.\n",
            "pgd l1: attack effectiveness 52.000%.\n",
            "max: attack effectiveness 53.333333333333336%.\n",
            "Mini batch: 979/1450 | training time in 10 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0164 | Train accuracy: 80.79%.\n",
            "pgd linf: attack effectiveness 4.412%.\n",
            "pgd l2: attack effectiveness 7.353%.\n",
            "pgd l1: attack effectiveness 48.529%.\n",
            "max: attack effectiveness 48.529411764705884%.\n",
            "Mini batch: 980/1450 | training time in 10 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0083 | Train accuracy: 87.24%.\n",
            "pgd linf: attack effectiveness 8.475%.\n",
            "pgd l2: attack effectiveness 18.644%.\n",
            "pgd l1: attack effectiveness 52.542%.\n",
            "max: attack effectiveness 52.54237288135594%.\n",
            "Mini batch: 981/1450 | training time in 10 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0217 | Train accuracy: 89.30%.\n",
            "pgd linf: attack effectiveness 10.667%.\n",
            "pgd l2: attack effectiveness 37.333%.\n",
            "pgd l1: attack effectiveness 46.667%.\n",
            "max: attack effectiveness 46.666666666666664%.\n",
            "Mini batch: 982/1450 | training time in 10 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0125 | Train accuracy: 84.73%.\n",
            "pgd linf: attack effectiveness 13.043%.\n",
            "pgd l2: attack effectiveness 5.797%.\n",
            "pgd l1: attack effectiveness 53.623%.\n",
            "max: attack effectiveness 53.62318840579711%.\n",
            "Mini batch: 983/1450 | training time in 10 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0113 | Train accuracy: 84.77%.\n",
            "pgd linf: attack effectiveness 9.375%.\n",
            "pgd l2: attack effectiveness 10.938%.\n",
            "pgd l1: attack effectiveness 42.188%.\n",
            "max: attack effectiveness 42.1875%.\n",
            "Mini batch: 984/1450 | training time in 10 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0336 | Train accuracy: 88.54%.\n",
            "pgd linf: attack effectiveness 8.065%.\n",
            "pgd l2: attack effectiveness 25.806%.\n",
            "pgd l1: attack effectiveness 43.548%.\n",
            "max: attack effectiveness 45.16129032258064%.\n",
            "Mini batch: 985/1450 | training time in 10 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0081 | Train accuracy: 88.95%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 986/1450 | training time in 10 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0151 | Train accuracy: 89.47%.\n",
            "Training loss (epoch level): 0.0153 | Train accuracy: 86.44\n",
            "pgd linf: attack effectiveness 10.932%.\n",
            "pgd l2: attack effectiveness 34.946%.\n",
            "pgd l1: attack effectiveness 60.036%.\n",
            "max: attack effectiveness 60.57347670250897%.\n",
            "\tVal accuracy 67.92% with accuracy 39.43% under attack.\n",
            "\tModel select at epoch 24 with validation accuracy 68.27% and accuracy 39.96% under attack.\n",
            "pgd linf: attack effectiveness 10.606%.\n",
            "pgd l2: attack effectiveness 24.242%.\n",
            "pgd l1: attack effectiveness 48.485%.\n",
            "max: attack effectiveness 48.484848484848484%.\n",
            "Mini batch: 987/1450 | training time in 10 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0181 | Train accuracy: 86.08%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 30.159%.\n",
            "pgd l1: attack effectiveness 52.381%.\n",
            "max: attack effectiveness 52.38095238095239%.\n",
            "Mini batch: 988/1450 | training time in 10 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0116 | Train accuracy: 84.29%.\n",
            "pgd linf: attack effectiveness 6.061%.\n",
            "pgd l2: attack effectiveness 15.152%.\n",
            "pgd l1: attack effectiveness 45.455%.\n",
            "max: attack effectiveness 45.45454545454545%.\n",
            "Mini batch: 989/1450 | training time in 10 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0114 | Train accuracy: 87.63%.\n",
            "pgd linf: attack effectiveness 2.857%.\n",
            "pgd l2: attack effectiveness 12.857%.\n",
            "pgd l1: attack effectiveness 48.571%.\n",
            "max: attack effectiveness 48.57142857142857%.\n",
            "Mini batch: 990/1450 | training time in 10 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0112 | Train accuracy: 85.86%.\n",
            "pgd linf: attack effectiveness 5.634%.\n",
            "pgd l2: attack effectiveness 8.451%.\n",
            "pgd l1: attack effectiveness 50.704%.\n",
            "max: attack effectiveness 50.70422535211267%.\n",
            "Mini batch: 991/1450 | training time in 10 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0095 | Train accuracy: 88.44%.\n",
            "pgd linf: attack effectiveness 6.579%.\n",
            "pgd l2: attack effectiveness 10.526%.\n",
            "pgd l1: attack effectiveness 47.368%.\n",
            "max: attack effectiveness 48.68421052631579%.\n",
            "Mini batch: 992/1450 | training time in 10 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0191 | Train accuracy: 83.82%.\n",
            "pgd linf: attack effectiveness 8.197%.\n",
            "pgd l2: attack effectiveness 1.639%.\n",
            "pgd l1: attack effectiveness 42.623%.\n",
            "max: attack effectiveness 42.62295081967213%.\n",
            "Mini batch: 993/1450 | training time in 10 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0225 | Train accuracy: 89.95%.\n",
            "pgd linf: attack effectiveness 10.145%.\n",
            "pgd l2: attack effectiveness 11.594%.\n",
            "pgd l1: attack effectiveness 43.478%.\n",
            "max: attack effectiveness 43.47826086956522%.\n",
            "Mini batch: 994/1450 | training time in 10 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0144 | Train accuracy: 86.80%.\n",
            "pgd linf: attack effectiveness 12.903%.\n",
            "pgd l2: attack effectiveness 9.677%.\n",
            "pgd l1: attack effectiveness 37.097%.\n",
            "max: attack effectiveness 38.70967741935484%.\n",
            "Mini batch: 995/1450 | training time in 10 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0122 | Train accuracy: 89.47%.\n",
            "pgd linf: attack effectiveness 20.000%.\n",
            "pgd l2: attack effectiveness 10.000%.\n",
            "pgd l1: attack effectiveness 51.667%.\n",
            "max: attack effectiveness 51.66666666666667%.\n",
            "Mini batch: 996/1450 | training time in 10 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0173 | Train accuracy: 87.23%.\n",
            "pgd linf: attack effectiveness 7.407%.\n",
            "pgd l2: attack effectiveness 9.259%.\n",
            "pgd l1: attack effectiveness 40.741%.\n",
            "max: attack effectiveness 40.74074074074074%.\n",
            "Mini batch: 997/1450 | training time in 10 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0130 | Train accuracy: 90.11%.\n",
            "pgd linf: attack effectiveness 20.635%.\n",
            "pgd l2: attack effectiveness 9.524%.\n",
            "pgd l1: attack effectiveness 47.619%.\n",
            "max: attack effectiveness 47.61904761904761%.\n",
            "Mini batch: 998/1450 | training time in 10 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0144 | Train accuracy: 87.96%.\n",
            "pgd linf: attack effectiveness 12.308%.\n",
            "pgd l2: attack effectiveness 7.692%.\n",
            "pgd l1: attack effectiveness 53.846%.\n",
            "max: attack effectiveness 53.84615384615385%.\n",
            "Mini batch: 999/1450 | training time in 10 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0100 | Train accuracy: 85.49%.\n",
            "pgd linf: attack effectiveness 15.152%.\n",
            "pgd l2: attack effectiveness 16.667%.\n",
            "pgd l1: attack effectiveness 48.485%.\n",
            "max: attack effectiveness 48.484848484848484%.\n",
            "Mini batch: 1000/1450 | training time in 10 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0429 | Train accuracy: 85.05%.\n",
            "pgd linf: attack effectiveness 12.308%.\n",
            "pgd l2: attack effectiveness 10.769%.\n",
            "pgd l1: attack effectiveness 46.154%.\n",
            "max: attack effectiveness 46.15384615384615%.\n",
            "Mini batch: 1001/1450 | training time in 10 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0114 | Train accuracy: 86.53%.\n",
            "pgd linf: attack effectiveness 15.493%.\n",
            "pgd l2: attack effectiveness 11.268%.\n",
            "pgd l1: attack effectiveness 54.930%.\n",
            "max: attack effectiveness 54.929577464788736%.\n",
            "Mini batch: 1002/1450 | training time in 10 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0088 | Train accuracy: 84.92%.\n",
            "pgd linf: attack effectiveness 14.062%.\n",
            "pgd l2: attack effectiveness 17.188%.\n",
            "pgd l1: attack effectiveness 43.750%.\n",
            "max: attack effectiveness 43.75%.\n",
            "Mini batch: 1003/1450 | training time in 10 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0092 | Train accuracy: 86.46%.\n",
            "pgd linf: attack effectiveness 19.403%.\n",
            "pgd l2: attack effectiveness 29.851%.\n",
            "pgd l1: attack effectiveness 44.776%.\n",
            "max: attack effectiveness 46.26865671641791%.\n",
            "Mini batch: 1004/1450 | training time in 11 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0131 | Train accuracy: 86.67%.\n",
            "pgd linf: attack effectiveness 12.500%.\n",
            "pgd l2: attack effectiveness 9.375%.\n",
            "pgd l1: attack effectiveness 50.000%.\n",
            "max: attack effectiveness 50.0%.\n",
            "Mini batch: 1005/1450 | training time in 11 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0122 | Train accuracy: 88.02%.\n",
            "pgd linf: attack effectiveness 21.622%.\n",
            "pgd l2: attack effectiveness 13.514%.\n",
            "pgd l1: attack effectiveness 52.703%.\n",
            "max: attack effectiveness 52.702702702702695%.\n",
            "Mini batch: 1006/1450 | training time in 11 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0219 | Train accuracy: 84.16%.\n",
            "pgd linf: attack effectiveness 13.043%.\n",
            "pgd l2: attack effectiveness 14.493%.\n",
            "pgd l1: attack effectiveness 44.928%.\n",
            "max: attack effectiveness 44.927536231884055%.\n",
            "Mini batch: 1007/1450 | training time in 11 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0109 | Train accuracy: 87.31%.\n",
            "pgd linf: attack effectiveness 14.667%.\n",
            "pgd l2: attack effectiveness 12.000%.\n",
            "pgd l1: attack effectiveness 50.667%.\n",
            "max: attack effectiveness 53.333333333333336%.\n",
            "Mini batch: 1008/1450 | training time in 11 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0134 | Train accuracy: 83.25%.\n",
            "pgd linf: attack effectiveness 10.294%.\n",
            "pgd l2: attack effectiveness 2.941%.\n",
            "pgd l1: attack effectiveness 48.529%.\n",
            "max: attack effectiveness 48.529411764705884%.\n",
            "Mini batch: 1009/1450 | training time in 11 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0098 | Train accuracy: 85.20%.\n",
            "pgd linf: attack effectiveness 16.949%.\n",
            "pgd l2: attack effectiveness 8.475%.\n",
            "pgd l1: attack effectiveness 47.458%.\n",
            "max: attack effectiveness 47.45762711864407%.\n",
            "Mini batch: 1010/1450 | training time in 11 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0262 | Train accuracy: 87.17%.\n",
            "pgd linf: attack effectiveness 17.333%.\n",
            "pgd l2: attack effectiveness 9.333%.\n",
            "pgd l1: attack effectiveness 45.333%.\n",
            "max: attack effectiveness 45.33333333333333%.\n",
            "Mini batch: 1011/1450 | training time in 11 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0145 | Train accuracy: 84.73%.\n",
            "pgd linf: attack effectiveness 15.942%.\n",
            "pgd l2: attack effectiveness 7.246%.\n",
            "pgd l1: attack effectiveness 52.174%.\n",
            "max: attack effectiveness 52.17391304347826%.\n",
            "Mini batch: 1012/1450 | training time in 11 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0132 | Train accuracy: 87.82%.\n",
            "pgd linf: attack effectiveness 9.375%.\n",
            "pgd l2: attack effectiveness 7.812%.\n",
            "pgd l1: attack effectiveness 39.062%.\n",
            "max: attack effectiveness 39.0625%.\n",
            "Mini batch: 1013/1450 | training time in 11 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0261 | Train accuracy: 90.10%.\n",
            "pgd linf: attack effectiveness 3.226%.\n",
            "pgd l2: attack effectiveness 4.839%.\n",
            "pgd l1: attack effectiveness 41.935%.\n",
            "max: attack effectiveness 41.935483870967744%.\n",
            "Mini batch: 1014/1450 | training time in 11 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0104 | Train accuracy: 89.47%.\n",
            "pgd linf: attack effectiveness 16.667%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 1015/1450 | training time in 11 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0057 | Train accuracy: 89.47%.\n",
            "Training loss (epoch level): 0.0150 | Train accuracy: 86.88\n",
            "pgd linf: attack effectiveness 6.810%.\n",
            "pgd l2: attack effectiveness 21.864%.\n",
            "pgd l1: attack effectiveness 59.677%.\n",
            "max: attack effectiveness 60.215053763440864%.\n",
            "\tVal accuracy 68.1% with accuracy 39.78% under attack.\n",
            "\tModel select at epoch 24 with validation accuracy 68.27% and accuracy 39.96% under attack.\n",
            "pgd linf: attack effectiveness 6.061%.\n",
            "pgd l2: attack effectiveness 13.636%.\n",
            "pgd l1: attack effectiveness 45.455%.\n",
            "max: attack effectiveness 45.45454545454545%.\n",
            "Mini batch: 1016/1450 | training time in 11 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0155 | Train accuracy: 87.63%.\n",
            "pgd linf: attack effectiveness 6.349%.\n",
            "pgd l2: attack effectiveness 23.810%.\n",
            "pgd l1: attack effectiveness 50.794%.\n",
            "max: attack effectiveness 50.79365079365079%.\n",
            "Mini batch: 1017/1450 | training time in 11 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0132 | Train accuracy: 86.39%.\n",
            "pgd linf: attack effectiveness 6.061%.\n",
            "pgd l2: attack effectiveness 19.697%.\n",
            "pgd l1: attack effectiveness 45.455%.\n",
            "max: attack effectiveness 45.45454545454545%.\n",
            "Mini batch: 1018/1450 | training time in 11 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0137 | Train accuracy: 88.14%.\n",
            "pgd linf: attack effectiveness 2.857%.\n",
            "pgd l2: attack effectiveness 5.714%.\n",
            "pgd l1: attack effectiveness 51.429%.\n",
            "max: attack effectiveness 51.42857142857142%.\n",
            "Mini batch: 1019/1450 | training time in 11 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0105 | Train accuracy: 84.34%.\n",
            "pgd linf: attack effectiveness 4.225%.\n",
            "pgd l2: attack effectiveness 4.225%.\n",
            "pgd l1: attack effectiveness 52.113%.\n",
            "max: attack effectiveness 52.112676056338024%.\n",
            "Mini batch: 1020/1450 | training time in 11 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0088 | Train accuracy: 88.94%.\n",
            "pgd linf: attack effectiveness 2.632%.\n",
            "pgd l2: attack effectiveness 3.947%.\n",
            "pgd l1: attack effectiveness 51.316%.\n",
            "max: attack effectiveness 52.63157894736842%.\n",
            "Mini batch: 1021/1450 | training time in 11 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0100 | Train accuracy: 85.78%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 3.279%.\n",
            "pgd l1: attack effectiveness 45.902%.\n",
            "max: attack effectiveness 45.90163934426229%.\n",
            "Mini batch: 1022/1450 | training time in 11 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0117 | Train accuracy: 87.30%.\n",
            "pgd linf: attack effectiveness 2.899%.\n",
            "pgd l2: attack effectiveness 2.899%.\n",
            "pgd l1: attack effectiveness 43.478%.\n",
            "max: attack effectiveness 43.47826086956522%.\n",
            "Mini batch: 1023/1450 | training time in 11 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0146 | Train accuracy: 87.82%.\n",
            "pgd linf: attack effectiveness 1.613%.\n",
            "pgd l2: attack effectiveness 6.452%.\n",
            "pgd l1: attack effectiveness 38.710%.\n",
            "max: attack effectiveness 38.70967741935484%.\n",
            "Mini batch: 1024/1450 | training time in 11 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0090 | Train accuracy: 89.47%.\n",
            "pgd linf: attack effectiveness 3.333%.\n",
            "pgd l2: attack effectiveness 11.667%.\n",
            "pgd l1: attack effectiveness 55.000%.\n",
            "max: attack effectiveness 55.00000000000001%.\n",
            "Mini batch: 1025/1450 | training time in 11 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0183 | Train accuracy: 85.64%.\n",
            "pgd linf: attack effectiveness 1.852%.\n",
            "pgd l2: attack effectiveness 3.704%.\n",
            "pgd l1: attack effectiveness 37.037%.\n",
            "max: attack effectiveness 37.03703703703704%.\n",
            "Mini batch: 1026/1450 | training time in 11 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0206 | Train accuracy: 91.21%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 11.111%.\n",
            "pgd l1: attack effectiveness 50.794%.\n",
            "max: attack effectiveness 50.79365079365079%.\n",
            "Mini batch: 1027/1450 | training time in 11 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0282 | Train accuracy: 84.29%.\n",
            "pgd linf: attack effectiveness 4.615%.\n",
            "pgd l2: attack effectiveness 1.538%.\n",
            "pgd l1: attack effectiveness 53.846%.\n",
            "max: attack effectiveness 53.84615384615385%.\n",
            "Mini batch: 1028/1450 | training time in 11 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0070 | Train accuracy: 87.05%.\n",
            "pgd linf: attack effectiveness 9.091%.\n",
            "pgd l2: attack effectiveness 9.091%.\n",
            "pgd l1: attack effectiveness 48.485%.\n",
            "max: attack effectiveness 48.484848484848484%.\n",
            "Mini batch: 1029/1450 | training time in 11 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0300 | Train accuracy: 86.60%.\n",
            "pgd linf: attack effectiveness 7.692%.\n",
            "pgd l2: attack effectiveness 16.923%.\n",
            "pgd l1: attack effectiveness 46.154%.\n",
            "max: attack effectiveness 46.15384615384615%.\n",
            "Mini batch: 1030/1450 | training time in 11 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0155 | Train accuracy: 87.05%.\n",
            "pgd linf: attack effectiveness 22.535%.\n",
            "pgd l2: attack effectiveness 35.211%.\n",
            "pgd l1: attack effectiveness 57.746%.\n",
            "max: attack effectiveness 57.74647887323944%.\n",
            "Mini batch: 1031/1450 | training time in 11 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0223 | Train accuracy: 83.92%.\n",
            "pgd linf: attack effectiveness 20.312%.\n",
            "pgd l2: attack effectiveness 23.438%.\n",
            "pgd l1: attack effectiveness 43.750%.\n",
            "max: attack effectiveness 43.75%.\n",
            "Mini batch: 1032/1450 | training time in 11 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0163 | Train accuracy: 86.98%.\n",
            "pgd linf: attack effectiveness 19.403%.\n",
            "pgd l2: attack effectiveness 20.896%.\n",
            "pgd l1: attack effectiveness 46.269%.\n",
            "max: attack effectiveness 46.26865671641791%.\n",
            "Mini batch: 1033/1450 | training time in 11 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0166 | Train accuracy: 87.18%.\n",
            "pgd linf: attack effectiveness 21.875%.\n",
            "pgd l2: attack effectiveness 29.688%.\n",
            "pgd l1: attack effectiveness 51.562%.\n",
            "max: attack effectiveness 51.5625%.\n",
            "Mini batch: 1034/1450 | training time in 11 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0225 | Train accuracy: 84.90%.\n",
            "pgd linf: attack effectiveness 22.973%.\n",
            "pgd l2: attack effectiveness 36.486%.\n",
            "pgd l1: attack effectiveness 55.405%.\n",
            "max: attack effectiveness 55.4054054054054%.\n",
            "Mini batch: 1035/1450 | training time in 11 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0493 | Train accuracy: 81.19%.\n",
            "pgd linf: attack effectiveness 17.391%.\n",
            "pgd l2: attack effectiveness 34.783%.\n",
            "pgd l1: attack effectiveness 43.478%.\n",
            "max: attack effectiveness 44.927536231884055%.\n",
            "Mini batch: 1036/1450 | training time in 11 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0262 | Train accuracy: 86.29%.\n",
            "pgd linf: attack effectiveness 24.000%.\n",
            "pgd l2: attack effectiveness 22.667%.\n",
            "pgd l1: attack effectiveness 50.667%.\n",
            "max: attack effectiveness 52.0%.\n",
            "Mini batch: 1037/1450 | training time in 11 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0187 | Train accuracy: 82.27%.\n",
            "pgd linf: attack effectiveness 22.059%.\n",
            "pgd l2: attack effectiveness 8.824%.\n",
            "pgd l1: attack effectiveness 48.529%.\n",
            "max: attack effectiveness 48.529411764705884%.\n",
            "Mini batch: 1038/1450 | training time in 11 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0120 | Train accuracy: 86.73%.\n",
            "pgd linf: attack effectiveness 16.949%.\n",
            "pgd l2: attack effectiveness 18.644%.\n",
            "pgd l1: attack effectiveness 47.458%.\n",
            "max: attack effectiveness 47.45762711864407%.\n",
            "Mini batch: 1039/1450 | training time in 11 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0375 | Train accuracy: 85.56%.\n",
            "pgd linf: attack effectiveness 24.000%.\n",
            "pgd l2: attack effectiveness 30.667%.\n",
            "pgd l1: attack effectiveness 45.333%.\n",
            "max: attack effectiveness 45.33333333333333%.\n",
            "Mini batch: 1040/1450 | training time in 11 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0152 | Train accuracy: 84.24%.\n",
            "pgd linf: attack effectiveness 23.188%.\n",
            "pgd l2: attack effectiveness 4.348%.\n",
            "pgd l1: attack effectiveness 52.174%.\n",
            "max: attack effectiveness 52.17391304347826%.\n",
            "Mini batch: 1041/1450 | training time in 11 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0116 | Train accuracy: 87.31%.\n",
            "pgd linf: attack effectiveness 7.812%.\n",
            "pgd l2: attack effectiveness 18.750%.\n",
            "pgd l1: attack effectiveness 37.500%.\n",
            "max: attack effectiveness 37.5%.\n",
            "Mini batch: 1042/1450 | training time in 11 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0263 | Train accuracy: 89.06%.\n",
            "pgd linf: attack effectiveness 6.452%.\n",
            "pgd l2: attack effectiveness 8.065%.\n",
            "pgd l1: attack effectiveness 41.935%.\n",
            "max: attack effectiveness 41.935483870967744%.\n",
            "Mini batch: 1043/1450 | training time in 11 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0142 | Train accuracy: 88.42%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 1044/1450 | training time in 11 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0061 | Train accuracy: 94.74%.\n",
            "Training loss (epoch level): 0.0180 | Train accuracy: 86.77\n",
            "pgd linf: attack effectiveness 10.215%.\n",
            "pgd l2: attack effectiveness 32.616%.\n",
            "pgd l1: attack effectiveness 59.498%.\n",
            "max: attack effectiveness 59.85663082437276%.\n",
            "\tVal accuracy 67.78% with accuracy 40.14% under attack.\n",
            "\tModel select at epoch 24 with validation accuracy 68.27% and accuracy 39.96% under attack.\n",
            "pgd linf: attack effectiveness 9.091%.\n",
            "pgd l2: attack effectiveness 27.273%.\n",
            "pgd l1: attack effectiveness 46.970%.\n",
            "max: attack effectiveness 46.96969696969697%.\n",
            "Mini batch: 1045/1450 | training time in 11 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0195 | Train accuracy: 86.08%.\n",
            "pgd linf: attack effectiveness 11.111%.\n",
            "pgd l2: attack effectiveness 30.159%.\n",
            "pgd l1: attack effectiveness 47.619%.\n",
            "max: attack effectiveness 47.61904761904761%.\n",
            "Mini batch: 1046/1450 | training time in 11 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0123 | Train accuracy: 86.39%.\n",
            "pgd linf: attack effectiveness 7.576%.\n",
            "pgd l2: attack effectiveness 27.273%.\n",
            "pgd l1: attack effectiveness 45.455%.\n",
            "max: attack effectiveness 45.45454545454545%.\n",
            "Mini batch: 1047/1450 | training time in 11 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0174 | Train accuracy: 86.08%.\n",
            "pgd linf: attack effectiveness 5.714%.\n",
            "pgd l2: attack effectiveness 27.143%.\n",
            "pgd l1: attack effectiveness 50.000%.\n",
            "max: attack effectiveness 50.0%.\n",
            "Mini batch: 1048/1450 | training time in 11 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0188 | Train accuracy: 84.85%.\n",
            "pgd linf: attack effectiveness 5.634%.\n",
            "pgd l2: attack effectiveness 11.268%.\n",
            "pgd l1: attack effectiveness 50.704%.\n",
            "max: attack effectiveness 50.70422535211267%.\n",
            "Mini batch: 1049/1450 | training time in 11 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0143 | Train accuracy: 85.43%.\n",
            "pgd linf: attack effectiveness 6.579%.\n",
            "pgd l2: attack effectiveness 22.368%.\n",
            "pgd l1: attack effectiveness 51.316%.\n",
            "max: attack effectiveness 51.31578947368421%.\n",
            "Mini batch: 1050/1450 | training time in 11 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0146 | Train accuracy: 86.76%.\n",
            "pgd linf: attack effectiveness 1.639%.\n",
            "pgd l2: attack effectiveness 16.393%.\n",
            "pgd l1: attack effectiveness 44.262%.\n",
            "max: attack effectiveness 44.26229508196721%.\n",
            "Mini batch: 1051/1450 | training time in 11 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0088 | Train accuracy: 89.95%.\n",
            "pgd linf: attack effectiveness 2.899%.\n",
            "pgd l2: attack effectiveness 10.145%.\n",
            "pgd l1: attack effectiveness 43.478%.\n",
            "max: attack effectiveness 43.47826086956522%.\n",
            "Mini batch: 1052/1450 | training time in 11 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0133 | Train accuracy: 86.80%.\n",
            "pgd linf: attack effectiveness 4.839%.\n",
            "pgd l2: attack effectiveness 8.065%.\n",
            "pgd l1: attack effectiveness 35.484%.\n",
            "max: attack effectiveness 35.483870967741936%.\n",
            "Mini batch: 1053/1450 | training time in 11 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0116 | Train accuracy: 90.00%.\n",
            "pgd linf: attack effectiveness 3.333%.\n",
            "pgd l2: attack effectiveness 5.000%.\n",
            "pgd l1: attack effectiveness 48.333%.\n",
            "max: attack effectiveness 48.333333333333336%.\n",
            "Mini batch: 1054/1450 | training time in 11 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0238 | Train accuracy: 85.64%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 1.852%.\n",
            "pgd l1: attack effectiveness 35.185%.\n",
            "max: attack effectiveness 35.18518518518518%.\n",
            "Mini batch: 1055/1450 | training time in 11 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0096 | Train accuracy: 92.86%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 3.175%.\n",
            "pgd l1: attack effectiveness 46.032%.\n",
            "max: attack effectiveness 46.03174603174603%.\n",
            "Mini batch: 1056/1450 | training time in 11 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0150 | Train accuracy: 90.05%.\n",
            "pgd linf: attack effectiveness 1.538%.\n",
            "pgd l2: attack effectiveness 3.077%.\n",
            "pgd l1: attack effectiveness 50.769%.\n",
            "max: attack effectiveness 50.76923076923077%.\n",
            "Mini batch: 1057/1450 | training time in 11 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0164 | Train accuracy: 86.53%.\n",
            "pgd linf: attack effectiveness 1.515%.\n",
            "pgd l2: attack effectiveness 3.030%.\n",
            "pgd l1: attack effectiveness 43.939%.\n",
            "max: attack effectiveness 43.93939393939394%.\n",
            "Mini batch: 1058/1450 | training time in 11 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0489 | Train accuracy: 87.63%.\n",
            "pgd linf: attack effectiveness 9.231%.\n",
            "pgd l2: attack effectiveness 3.077%.\n",
            "pgd l1: attack effectiveness 38.462%.\n",
            "max: attack effectiveness 38.46153846153847%.\n",
            "Mini batch: 1059/1450 | training time in 11 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0115 | Train accuracy: 88.08%.\n",
            "pgd linf: attack effectiveness 8.451%.\n",
            "pgd l2: attack effectiveness 25.352%.\n",
            "pgd l1: attack effectiveness 52.113%.\n",
            "max: attack effectiveness 52.112676056338024%.\n",
            "Mini batch: 1060/1450 | training time in 11 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0114 | Train accuracy: 84.42%.\n",
            "pgd linf: attack effectiveness 6.250%.\n",
            "pgd l2: attack effectiveness 10.938%.\n",
            "pgd l1: attack effectiveness 37.500%.\n",
            "max: attack effectiveness 37.5%.\n",
            "Mini batch: 1061/1450 | training time in 11 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0109 | Train accuracy: 91.67%.\n",
            "pgd linf: attack effectiveness 8.955%.\n",
            "pgd l2: attack effectiveness 16.418%.\n",
            "pgd l1: attack effectiveness 46.269%.\n",
            "max: attack effectiveness 49.25373134328358%.\n",
            "Mini batch: 1062/1450 | training time in 11 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0117 | Train accuracy: 86.67%.\n",
            "pgd linf: attack effectiveness 18.750%.\n",
            "pgd l2: attack effectiveness 14.062%.\n",
            "pgd l1: attack effectiveness 53.125%.\n",
            "max: attack effectiveness 53.125%.\n",
            "Mini batch: 1063/1450 | training time in 11 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0130 | Train accuracy: 85.94%.\n",
            "pgd linf: attack effectiveness 20.270%.\n",
            "pgd l2: attack effectiveness 12.162%.\n",
            "pgd l1: attack effectiveness 56.757%.\n",
            "max: attack effectiveness 56.75675675675676%.\n",
            "Mini batch: 1064/1450 | training time in 11 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0247 | Train accuracy: 81.19%.\n",
            "pgd linf: attack effectiveness 23.188%.\n",
            "pgd l2: attack effectiveness 10.145%.\n",
            "pgd l1: attack effectiveness 52.174%.\n",
            "max: attack effectiveness 53.62318840579711%.\n",
            "Mini batch: 1065/1450 | training time in 11 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0133 | Train accuracy: 83.76%.\n",
            "pgd linf: attack effectiveness 12.000%.\n",
            "pgd l2: attack effectiveness 22.667%.\n",
            "pgd l1: attack effectiveness 53.333%.\n",
            "max: attack effectiveness 54.666666666666664%.\n",
            "Mini batch: 1066/1450 | training time in 11 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0180 | Train accuracy: 84.24%.\n",
            "pgd linf: attack effectiveness 20.588%.\n",
            "pgd l2: attack effectiveness 25.000%.\n",
            "pgd l1: attack effectiveness 48.529%.\n",
            "max: attack effectiveness 48.529411764705884%.\n",
            "Mini batch: 1067/1450 | training time in 11 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0081 | Train accuracy: 86.22%.\n",
            "pgd linf: attack effectiveness 18.644%.\n",
            "pgd l2: attack effectiveness 8.475%.\n",
            "pgd l1: attack effectiveness 52.542%.\n",
            "max: attack effectiveness 52.54237288135594%.\n",
            "Mini batch: 1068/1450 | training time in 11 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0212 | Train accuracy: 86.63%.\n",
            "pgd linf: attack effectiveness 17.333%.\n",
            "pgd l2: attack effectiveness 10.667%.\n",
            "pgd l1: attack effectiveness 50.667%.\n",
            "max: attack effectiveness 50.66666666666667%.\n",
            "Mini batch: 1069/1450 | training time in 11 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0084 | Train accuracy: 83.74%.\n",
            "pgd linf: attack effectiveness 11.594%.\n",
            "pgd l2: attack effectiveness 26.087%.\n",
            "pgd l1: attack effectiveness 55.072%.\n",
            "max: attack effectiveness 55.072463768115945%.\n",
            "Mini batch: 1070/1450 | training time in 11 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0100 | Train accuracy: 86.29%.\n",
            "pgd linf: attack effectiveness 7.812%.\n",
            "pgd l2: attack effectiveness 9.375%.\n",
            "pgd l1: attack effectiveness 42.188%.\n",
            "max: attack effectiveness 42.1875%.\n",
            "Mini batch: 1071/1450 | training time in 11 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0337 | Train accuracy: 87.50%.\n",
            "pgd linf: attack effectiveness 6.452%.\n",
            "pgd l2: attack effectiveness 6.452%.\n",
            "pgd l1: attack effectiveness 41.935%.\n",
            "max: attack effectiveness 41.935483870967744%.\n",
            "Mini batch: 1072/1450 | training time in 11 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0068 | Train accuracy: 88.42%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 1073/1450 | training time in 11 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0035 | Train accuracy: 94.74%.\n",
            "Training loss (epoch level): 0.0155 | Train accuracy: 87.05\n",
            "pgd linf: attack effectiveness 7.885%.\n",
            "pgd l2: attack effectiveness 12.007%.\n",
            "pgd l1: attack effectiveness 58.244%.\n",
            "max: attack effectiveness 58.24372759856631%.\n",
            "\tVal accuracy 68.92% with accuracy 41.76% under attack.\n",
            "\tModel select at epoch 37 with validation accuracy 68.92% and accuracy 41.76% under attack.\n",
            "pgd linf: attack effectiveness 12.121%.\n",
            "pgd l2: attack effectiveness 9.091%.\n",
            "pgd l1: attack effectiveness 45.455%.\n",
            "max: attack effectiveness 45.45454545454545%.\n",
            "Mini batch: 1074/1450 | training time in 11 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0181 | Train accuracy: 88.14%.\n",
            "pgd linf: attack effectiveness 11.111%.\n",
            "pgd l2: attack effectiveness 11.111%.\n",
            "pgd l1: attack effectiveness 46.032%.\n",
            "max: attack effectiveness 46.03174603174603%.\n",
            "Mini batch: 1075/1450 | training time in 11 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0151 | Train accuracy: 87.96%.\n",
            "pgd linf: attack effectiveness 7.576%.\n",
            "pgd l2: attack effectiveness 6.061%.\n",
            "pgd l1: attack effectiveness 42.424%.\n",
            "max: attack effectiveness 42.42424242424242%.\n",
            "Mini batch: 1076/1450 | training time in 11 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0194 | Train accuracy: 88.14%.\n",
            "pgd linf: attack effectiveness 1.429%.\n",
            "pgd l2: attack effectiveness 7.143%.\n",
            "pgd l1: attack effectiveness 48.571%.\n",
            "max: attack effectiveness 48.57142857142857%.\n",
            "Mini batch: 1077/1450 | training time in 11 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0092 | Train accuracy: 87.88%.\n",
            "pgd linf: attack effectiveness 9.859%.\n",
            "pgd l2: attack effectiveness 11.268%.\n",
            "pgd l1: attack effectiveness 49.296%.\n",
            "max: attack effectiveness 49.29577464788733%.\n",
            "Mini batch: 1078/1450 | training time in 11 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0102 | Train accuracy: 87.44%.\n",
            "pgd linf: attack effectiveness 13.158%.\n",
            "pgd l2: attack effectiveness 5.263%.\n",
            "pgd l1: attack effectiveness 50.000%.\n",
            "max: attack effectiveness 50.0%.\n",
            "Mini batch: 1079/1450 | training time in 11 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0114 | Train accuracy: 84.80%.\n",
            "pgd linf: attack effectiveness 9.836%.\n",
            "pgd l2: attack effectiveness 6.557%.\n",
            "pgd l1: attack effectiveness 44.262%.\n",
            "max: attack effectiveness 44.26229508196721%.\n",
            "Mini batch: 1080/1450 | training time in 11 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0081 | Train accuracy: 89.95%.\n",
            "pgd linf: attack effectiveness 4.348%.\n",
            "pgd l2: attack effectiveness 4.348%.\n",
            "pgd l1: attack effectiveness 42.029%.\n",
            "max: attack effectiveness 42.028985507246375%.\n",
            "Mini batch: 1081/1450 | training time in 11 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0104 | Train accuracy: 88.83%.\n",
            "pgd linf: attack effectiveness 4.839%.\n",
            "pgd l2: attack effectiveness 6.452%.\n",
            "pgd l1: attack effectiveness 41.935%.\n",
            "max: attack effectiveness 41.935483870967744%.\n",
            "Mini batch: 1082/1450 | training time in 11 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0074 | Train accuracy: 87.37%.\n",
            "pgd linf: attack effectiveness 10.000%.\n",
            "pgd l2: attack effectiveness 13.333%.\n",
            "pgd l1: attack effectiveness 51.667%.\n",
            "max: attack effectiveness 51.66666666666667%.\n",
            "Mini batch: 1083/1450 | training time in 11 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0206 | Train accuracy: 86.70%.\n",
            "pgd linf: attack effectiveness 1.852%.\n",
            "pgd l2: attack effectiveness 9.259%.\n",
            "pgd l1: attack effectiveness 38.889%.\n",
            "max: attack effectiveness 38.88888888888889%.\n",
            "Mini batch: 1084/1450 | training time in 11 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0137 | Train accuracy: 89.01%.\n",
            "pgd linf: attack effectiveness 3.175%.\n",
            "pgd l2: attack effectiveness 1.587%.\n",
            "pgd l1: attack effectiveness 47.619%.\n",
            "max: attack effectiveness 47.61904761904761%.\n",
            "Mini batch: 1085/1450 | training time in 11 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0095 | Train accuracy: 88.48%.\n",
            "pgd linf: attack effectiveness 6.154%.\n",
            "pgd l2: attack effectiveness 4.615%.\n",
            "pgd l1: attack effectiveness 53.846%.\n",
            "max: attack effectiveness 53.84615384615385%.\n",
            "Mini batch: 1086/1450 | training time in 11 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0089 | Train accuracy: 86.53%.\n",
            "pgd linf: attack effectiveness 3.030%.\n",
            "pgd l2: attack effectiveness 9.091%.\n",
            "pgd l1: attack effectiveness 48.485%.\n",
            "max: attack effectiveness 48.484848484848484%.\n",
            "Mini batch: 1087/1450 | training time in 11 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0464 | Train accuracy: 85.57%.\n",
            "pgd linf: attack effectiveness 6.154%.\n",
            "pgd l2: attack effectiveness 3.077%.\n",
            "pgd l1: attack effectiveness 41.538%.\n",
            "max: attack effectiveness 41.53846153846154%.\n",
            "Mini batch: 1088/1450 | training time in 11 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0089 | Train accuracy: 88.08%.\n",
            "pgd linf: attack effectiveness 5.634%.\n",
            "pgd l2: attack effectiveness 5.634%.\n",
            "pgd l1: attack effectiveness 52.113%.\n",
            "max: attack effectiveness 52.112676056338024%.\n",
            "Mini batch: 1089/1450 | training time in 11 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0100 | Train accuracy: 85.43%.\n",
            "pgd linf: attack effectiveness 3.125%.\n",
            "pgd l2: attack effectiveness 6.250%.\n",
            "pgd l1: attack effectiveness 37.500%.\n",
            "max: attack effectiveness 37.5%.\n",
            "Mini batch: 1090/1450 | training time in 11 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0068 | Train accuracy: 89.06%.\n",
            "pgd linf: attack effectiveness 4.478%.\n",
            "pgd l2: attack effectiveness 2.985%.\n",
            "pgd l1: attack effectiveness 41.791%.\n",
            "max: attack effectiveness 41.7910447761194%.\n",
            "Mini batch: 1091/1450 | training time in 11 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0085 | Train accuracy: 89.74%.\n",
            "pgd linf: attack effectiveness 4.688%.\n",
            "pgd l2: attack effectiveness 4.688%.\n",
            "pgd l1: attack effectiveness 45.312%.\n",
            "max: attack effectiveness 45.3125%.\n",
            "Mini batch: 1092/1450 | training time in 11 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0079 | Train accuracy: 90.62%.\n",
            "pgd linf: attack effectiveness 9.459%.\n",
            "pgd l2: attack effectiveness 9.459%.\n",
            "pgd l1: attack effectiveness 52.703%.\n",
            "max: attack effectiveness 52.702702702702695%.\n",
            "Mini batch: 1093/1450 | training time in 11 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0202 | Train accuracy: 82.18%.\n",
            "pgd linf: attack effectiveness 1.449%.\n",
            "pgd l2: attack effectiveness 23.188%.\n",
            "pgd l1: attack effectiveness 44.928%.\n",
            "max: attack effectiveness 44.927536231884055%.\n",
            "Mini batch: 1094/1450 | training time in 12 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0076 | Train accuracy: 86.80%.\n",
            "pgd linf: attack effectiveness 9.333%.\n",
            "pgd l2: attack effectiveness 14.667%.\n",
            "pgd l1: attack effectiveness 50.667%.\n",
            "max: attack effectiveness 52.0%.\n",
            "Mini batch: 1095/1450 | training time in 12 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0102 | Train accuracy: 83.25%.\n",
            "pgd linf: attack effectiveness 5.882%.\n",
            "pgd l2: attack effectiveness 5.882%.\n",
            "pgd l1: attack effectiveness 50.000%.\n",
            "max: attack effectiveness 50.0%.\n",
            "Mini batch: 1096/1450 | training time in 12 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0127 | Train accuracy: 85.20%.\n",
            "pgd linf: attack effectiveness 3.390%.\n",
            "pgd l2: attack effectiveness 5.085%.\n",
            "pgd l1: attack effectiveness 50.847%.\n",
            "max: attack effectiveness 50.847457627118644%.\n",
            "Mini batch: 1097/1450 | training time in 12 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0248 | Train accuracy: 86.10%.\n",
            "pgd linf: attack effectiveness 9.333%.\n",
            "pgd l2: attack effectiveness 12.000%.\n",
            "pgd l1: attack effectiveness 46.667%.\n",
            "max: attack effectiveness 46.666666666666664%.\n",
            "Mini batch: 1098/1450 | training time in 12 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0091 | Train accuracy: 87.19%.\n",
            "pgd linf: attack effectiveness 7.246%.\n",
            "pgd l2: attack effectiveness 11.594%.\n",
            "pgd l1: attack effectiveness 50.725%.\n",
            "max: attack effectiveness 50.72463768115942%.\n",
            "Mini batch: 1099/1450 | training time in 12 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0098 | Train accuracy: 83.25%.\n",
            "pgd linf: attack effectiveness 3.125%.\n",
            "pgd l2: attack effectiveness 10.938%.\n",
            "pgd l1: attack effectiveness 37.500%.\n",
            "max: attack effectiveness 37.5%.\n",
            "Mini batch: 1100/1450 | training time in 12 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0282 | Train accuracy: 88.02%.\n",
            "pgd linf: attack effectiveness 3.226%.\n",
            "pgd l2: attack effectiveness 3.226%.\n",
            "pgd l1: attack effectiveness 41.935%.\n",
            "max: attack effectiveness 41.935483870967744%.\n",
            "Mini batch: 1101/1450 | training time in 12 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0112 | Train accuracy: 89.47%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 1102/1450 | training time in 12 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0028 | Train accuracy: 94.74%.\n",
            "Training loss (epoch level): 0.0133 | Train accuracy: 87.45\n",
            "pgd linf: attack effectiveness 4.659%.\n",
            "pgd l2: attack effectiveness 10.036%.\n",
            "pgd l1: attack effectiveness 57.885%.\n",
            "max: attack effectiveness 57.8853046594982%.\n",
            "\tVal accuracy 69.06% with accuracy 42.11% under attack.\n",
            "\tModel select at epoch 38 with validation accuracy 69.06% and accuracy 42.11% under attack.\n",
            "pgd linf: attack effectiveness 10.606%.\n",
            "pgd l2: attack effectiveness 9.091%.\n",
            "pgd l1: attack effectiveness 45.455%.\n",
            "max: attack effectiveness 45.45454545454545%.\n",
            "Mini batch: 1103/1450 | training time in 12 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0130 | Train accuracy: 88.66%.\n",
            "pgd linf: attack effectiveness 3.175%.\n",
            "pgd l2: attack effectiveness 4.762%.\n",
            "pgd l1: attack effectiveness 49.206%.\n",
            "max: attack effectiveness 49.2063492063492%.\n",
            "Mini batch: 1104/1450 | training time in 12 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0102 | Train accuracy: 88.48%.\n",
            "pgd linf: attack effectiveness 4.545%.\n",
            "pgd l2: attack effectiveness 9.091%.\n",
            "pgd l1: attack effectiveness 45.455%.\n",
            "max: attack effectiveness 45.45454545454545%.\n",
            "Mini batch: 1105/1450 | training time in 12 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0108 | Train accuracy: 86.08%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 4.286%.\n",
            "pgd l1: attack effectiveness 47.143%.\n",
            "max: attack effectiveness 47.14285714285714%.\n",
            "Mini batch: 1106/1450 | training time in 12 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0103 | Train accuracy: 87.37%.\n",
            "pgd linf: attack effectiveness 4.225%.\n",
            "pgd l2: attack effectiveness 7.042%.\n",
            "pgd l1: attack effectiveness 50.704%.\n",
            "max: attack effectiveness 50.70422535211267%.\n",
            "Mini batch: 1107/1450 | training time in 12 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0154 | Train accuracy: 83.92%.\n",
            "pgd linf: attack effectiveness 3.947%.\n",
            "pgd l2: attack effectiveness 6.579%.\n",
            "pgd l1: attack effectiveness 47.368%.\n",
            "max: attack effectiveness 47.368421052631575%.\n",
            "Mini batch: 1108/1450 | training time in 12 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0126 | Train accuracy: 86.76%.\n",
            "pgd linf: attack effectiveness 4.918%.\n",
            "pgd l2: attack effectiveness 1.639%.\n",
            "pgd l1: attack effectiveness 42.623%.\n",
            "max: attack effectiveness 42.62295081967213%.\n",
            "Mini batch: 1109/1450 | training time in 12 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0116 | Train accuracy: 90.48%.\n",
            "pgd linf: attack effectiveness 5.797%.\n",
            "pgd l2: attack effectiveness 4.348%.\n",
            "pgd l1: attack effectiveness 42.029%.\n",
            "max: attack effectiveness 42.028985507246375%.\n",
            "Mini batch: 1110/1450 | training time in 12 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0087 | Train accuracy: 88.32%.\n",
            "pgd linf: attack effectiveness 8.065%.\n",
            "pgd l2: attack effectiveness 3.226%.\n",
            "pgd l1: attack effectiveness 37.097%.\n",
            "max: attack effectiveness 37.096774193548384%.\n",
            "Mini batch: 1111/1450 | training time in 12 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0066 | Train accuracy: 93.16%.\n",
            "pgd linf: attack effectiveness 5.000%.\n",
            "pgd l2: attack effectiveness 10.000%.\n",
            "pgd l1: attack effectiveness 50.000%.\n",
            "max: attack effectiveness 50.0%.\n",
            "Mini batch: 1112/1450 | training time in 12 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0155 | Train accuracy: 87.23%.\n",
            "pgd linf: attack effectiveness 7.407%.\n",
            "pgd l2: attack effectiveness 1.852%.\n",
            "pgd l1: attack effectiveness 35.185%.\n",
            "max: attack effectiveness 35.18518518518518%.\n",
            "Mini batch: 1113/1450 | training time in 12 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0103 | Train accuracy: 92.31%.\n",
            "pgd linf: attack effectiveness 1.587%.\n",
            "pgd l2: attack effectiveness 9.524%.\n",
            "pgd l1: attack effectiveness 44.444%.\n",
            "max: attack effectiveness 44.44444444444444%.\n",
            "Mini batch: 1114/1450 | training time in 12 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0111 | Train accuracy: 86.91%.\n",
            "pgd linf: attack effectiveness 3.077%.\n",
            "pgd l2: attack effectiveness 9.231%.\n",
            "pgd l1: attack effectiveness 49.231%.\n",
            "max: attack effectiveness 49.23076923076923%.\n",
            "Mini batch: 1115/1450 | training time in 12 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0084 | Train accuracy: 86.01%.\n",
            "pgd linf: attack effectiveness 4.545%.\n",
            "pgd l2: attack effectiveness 7.576%.\n",
            "pgd l1: attack effectiveness 43.939%.\n",
            "max: attack effectiveness 43.93939393939394%.\n",
            "Mini batch: 1116/1450 | training time in 12 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0338 | Train accuracy: 88.66%.\n",
            "pgd linf: attack effectiveness 7.692%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 36.923%.\n",
            "max: attack effectiveness 36.92307692307693%.\n",
            "Mini batch: 1117/1450 | training time in 12 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0082 | Train accuracy: 88.08%.\n",
            "pgd linf: attack effectiveness 7.042%.\n",
            "pgd l2: attack effectiveness 4.225%.\n",
            "pgd l1: attack effectiveness 50.704%.\n",
            "max: attack effectiveness 50.70422535211267%.\n",
            "Mini batch: 1118/1450 | training time in 12 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0092 | Train accuracy: 86.43%.\n",
            "pgd linf: attack effectiveness 4.688%.\n",
            "pgd l2: attack effectiveness 4.688%.\n",
            "pgd l1: attack effectiveness 35.938%.\n",
            "max: attack effectiveness 35.9375%.\n",
            "Mini batch: 1119/1450 | training time in 12 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0073 | Train accuracy: 90.10%.\n",
            "pgd linf: attack effectiveness 10.448%.\n",
            "pgd l2: attack effectiveness 1.493%.\n",
            "pgd l1: attack effectiveness 38.806%.\n",
            "max: attack effectiveness 38.80597014925373%.\n",
            "Mini batch: 1120/1450 | training time in 12 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0079 | Train accuracy: 88.21%.\n",
            "pgd linf: attack effectiveness 10.938%.\n",
            "pgd l2: attack effectiveness 4.688%.\n",
            "pgd l1: attack effectiveness 43.750%.\n",
            "max: attack effectiveness 43.75%.\n",
            "Mini batch: 1121/1450 | training time in 12 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0109 | Train accuracy: 88.54%.\n",
            "pgd linf: attack effectiveness 16.216%.\n",
            "pgd l2: attack effectiveness 6.757%.\n",
            "pgd l1: attack effectiveness 52.703%.\n",
            "max: attack effectiveness 52.702702702702695%.\n",
            "Mini batch: 1122/1450 | training time in 12 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0201 | Train accuracy: 84.65%.\n",
            "pgd linf: attack effectiveness 4.348%.\n",
            "pgd l2: attack effectiveness 5.797%.\n",
            "pgd l1: attack effectiveness 40.580%.\n",
            "max: attack effectiveness 40.57971014492754%.\n",
            "Mini batch: 1123/1450 | training time in 12 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0109 | Train accuracy: 89.34%.\n",
            "pgd linf: attack effectiveness 10.667%.\n",
            "pgd l2: attack effectiveness 9.333%.\n",
            "pgd l1: attack effectiveness 50.667%.\n",
            "max: attack effectiveness 50.66666666666667%.\n",
            "Mini batch: 1124/1450 | training time in 12 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0138 | Train accuracy: 86.21%.\n",
            "pgd linf: attack effectiveness 14.706%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 48.529%.\n",
            "max: attack effectiveness 48.529411764705884%.\n",
            "Mini batch: 1125/1450 | training time in 12 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0071 | Train accuracy: 84.18%.\n",
            "pgd linf: attack effectiveness 10.169%.\n",
            "pgd l2: attack effectiveness 6.780%.\n",
            "pgd l1: attack effectiveness 47.458%.\n",
            "max: attack effectiveness 47.45762711864407%.\n",
            "Mini batch: 1126/1450 | training time in 12 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0261 | Train accuracy: 87.17%.\n",
            "pgd linf: attack effectiveness 8.000%.\n",
            "pgd l2: attack effectiveness 8.000%.\n",
            "pgd l1: attack effectiveness 45.333%.\n",
            "max: attack effectiveness 45.33333333333333%.\n",
            "Mini batch: 1127/1450 | training time in 12 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0074 | Train accuracy: 86.70%.\n",
            "pgd linf: attack effectiveness 11.594%.\n",
            "pgd l2: attack effectiveness 8.696%.\n",
            "pgd l1: attack effectiveness 52.174%.\n",
            "max: attack effectiveness 52.17391304347826%.\n",
            "Mini batch: 1128/1450 | training time in 12 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0129 | Train accuracy: 84.26%.\n",
            "pgd linf: attack effectiveness 1.562%.\n",
            "pgd l2: attack effectiveness 7.812%.\n",
            "pgd l1: attack effectiveness 34.375%.\n",
            "max: attack effectiveness 34.375%.\n",
            "Mini batch: 1129/1450 | training time in 12 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0327 | Train accuracy: 88.54%.\n",
            "pgd linf: attack effectiveness 6.452%.\n",
            "pgd l2: attack effectiveness 6.452%.\n",
            "pgd l1: attack effectiveness 41.935%.\n",
            "max: attack effectiveness 41.935483870967744%.\n",
            "Mini batch: 1130/1450 | training time in 12 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0079 | Train accuracy: 90.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 1131/1450 | training time in 12 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0041 | Train accuracy: 89.47%.\n",
            "Training loss (epoch level): 0.0126 | Train accuracy: 87.80\n",
            "pgd linf: attack effectiveness 8.781%.\n",
            "pgd l2: attack effectiveness 7.885%.\n",
            "pgd l1: attack effectiveness 54.659%.\n",
            "max: attack effectiveness 54.659498207885306%.\n",
            "\tVal accuracy 70.79% with accuracy 45.34% under attack.\n",
            "\tModel select at epoch 39 with validation accuracy 70.79% and accuracy 45.34% under attack.\n",
            "pgd linf: attack effectiveness 9.091%.\n",
            "pgd l2: attack effectiveness 7.576%.\n",
            "pgd l1: attack effectiveness 39.394%.\n",
            "max: attack effectiveness 39.39393939393939%.\n",
            "Mini batch: 1132/1450 | training time in 12 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0118 | Train accuracy: 87.63%.\n",
            "pgd linf: attack effectiveness 4.762%.\n",
            "pgd l2: attack effectiveness 6.349%.\n",
            "pgd l1: attack effectiveness 46.032%.\n",
            "max: attack effectiveness 46.03174603174603%.\n",
            "Mini batch: 1133/1450 | training time in 12 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0129 | Train accuracy: 88.48%.\n",
            "pgd linf: attack effectiveness 7.576%.\n",
            "pgd l2: attack effectiveness 9.091%.\n",
            "pgd l1: attack effectiveness 40.909%.\n",
            "max: attack effectiveness 40.909090909090914%.\n",
            "Mini batch: 1134/1450 | training time in 12 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0146 | Train accuracy: 89.18%.\n",
            "pgd linf: attack effectiveness 4.286%.\n",
            "pgd l2: attack effectiveness 5.714%.\n",
            "pgd l1: attack effectiveness 47.143%.\n",
            "max: attack effectiveness 47.14285714285714%.\n",
            "Mini batch: 1135/1450 | training time in 12 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0100 | Train accuracy: 86.87%.\n",
            "pgd linf: attack effectiveness 9.859%.\n",
            "pgd l2: attack effectiveness 8.451%.\n",
            "pgd l1: attack effectiveness 49.296%.\n",
            "max: attack effectiveness 49.29577464788733%.\n",
            "Mini batch: 1136/1450 | training time in 12 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0102 | Train accuracy: 85.93%.\n",
            "pgd linf: attack effectiveness 5.263%.\n",
            "pgd l2: attack effectiveness 5.263%.\n",
            "pgd l1: attack effectiveness 46.053%.\n",
            "max: attack effectiveness 46.05263157894737%.\n",
            "Mini batch: 1137/1450 | training time in 12 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0106 | Train accuracy: 87.75%.\n",
            "pgd linf: attack effectiveness 6.557%.\n",
            "pgd l2: attack effectiveness 16.393%.\n",
            "pgd l1: attack effectiveness 39.344%.\n",
            "max: attack effectiveness 39.34426229508197%.\n",
            "Mini batch: 1138/1450 | training time in 12 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0101 | Train accuracy: 89.95%.\n",
            "pgd linf: attack effectiveness 4.348%.\n",
            "pgd l2: attack effectiveness 4.348%.\n",
            "pgd l1: attack effectiveness 39.130%.\n",
            "max: attack effectiveness 39.130434782608695%.\n",
            "Mini batch: 1139/1450 | training time in 12 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0113 | Train accuracy: 88.32%.\n",
            "pgd linf: attack effectiveness 4.839%.\n",
            "pgd l2: attack effectiveness 6.452%.\n",
            "pgd l1: attack effectiveness 35.484%.\n",
            "max: attack effectiveness 35.483870967741936%.\n",
            "Mini batch: 1140/1450 | training time in 12 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0128 | Train accuracy: 92.11%.\n",
            "pgd linf: attack effectiveness 10.000%.\n",
            "pgd l2: attack effectiveness 11.667%.\n",
            "pgd l1: attack effectiveness 41.667%.\n",
            "max: attack effectiveness 41.66666666666667%.\n",
            "Mini batch: 1141/1450 | training time in 12 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0163 | Train accuracy: 89.89%.\n",
            "pgd linf: attack effectiveness 9.259%.\n",
            "pgd l2: attack effectiveness 1.852%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 1142/1450 | training time in 12 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0095 | Train accuracy: 95.05%.\n",
            "pgd linf: attack effectiveness 3.175%.\n",
            "pgd l2: attack effectiveness 6.349%.\n",
            "pgd l1: attack effectiveness 46.032%.\n",
            "max: attack effectiveness 46.03174603174603%.\n",
            "Mini batch: 1143/1450 | training time in 12 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0135 | Train accuracy: 90.05%.\n",
            "pgd linf: attack effectiveness 3.077%.\n",
            "pgd l2: attack effectiveness 1.538%.\n",
            "pgd l1: attack effectiveness 47.692%.\n",
            "max: attack effectiveness 47.69230769230769%.\n",
            "Mini batch: 1144/1450 | training time in 12 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0064 | Train accuracy: 87.05%.\n",
            "pgd linf: attack effectiveness 4.545%.\n",
            "pgd l2: attack effectiveness 1.515%.\n",
            "pgd l1: attack effectiveness 42.424%.\n",
            "max: attack effectiveness 42.42424242424242%.\n",
            "Mini batch: 1145/1450 | training time in 12 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0459 | Train accuracy: 86.08%.\n",
            "pgd linf: attack effectiveness 6.154%.\n",
            "pgd l2: attack effectiveness 3.077%.\n",
            "pgd l1: attack effectiveness 38.462%.\n",
            "max: attack effectiveness 38.46153846153847%.\n",
            "Mini batch: 1146/1450 | training time in 12 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0087 | Train accuracy: 90.16%.\n",
            "pgd linf: attack effectiveness 4.225%.\n",
            "pgd l2: attack effectiveness 8.451%.\n",
            "pgd l1: attack effectiveness 49.296%.\n",
            "max: attack effectiveness 49.29577464788733%.\n",
            "Mini batch: 1147/1450 | training time in 12 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0136 | Train accuracy: 87.44%.\n",
            "pgd linf: attack effectiveness 7.812%.\n",
            "pgd l2: attack effectiveness 7.812%.\n",
            "pgd l1: attack effectiveness 37.500%.\n",
            "max: attack effectiveness 37.5%.\n",
            "Mini batch: 1148/1450 | training time in 12 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0056 | Train accuracy: 91.15%.\n",
            "pgd linf: attack effectiveness 5.970%.\n",
            "pgd l2: attack effectiveness 14.925%.\n",
            "pgd l1: attack effectiveness 40.299%.\n",
            "max: attack effectiveness 40.298507462686565%.\n",
            "Mini batch: 1149/1450 | training time in 12 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0069 | Train accuracy: 90.77%.\n",
            "pgd linf: attack effectiveness 10.938%.\n",
            "pgd l2: attack effectiveness 29.688%.\n",
            "pgd l1: attack effectiveness 46.875%.\n",
            "max: attack effectiveness 46.875%.\n",
            "Mini batch: 1150/1450 | training time in 12 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0123 | Train accuracy: 86.98%.\n",
            "pgd linf: attack effectiveness 20.270%.\n",
            "pgd l2: attack effectiveness 37.838%.\n",
            "pgd l1: attack effectiveness 54.054%.\n",
            "max: attack effectiveness 54.054054054054056%.\n",
            "Mini batch: 1151/1450 | training time in 12 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0289 | Train accuracy: 80.20%.\n",
            "pgd linf: attack effectiveness 7.246%.\n",
            "pgd l2: attack effectiveness 30.435%.\n",
            "pgd l1: attack effectiveness 43.478%.\n",
            "max: attack effectiveness 43.47826086956522%.\n",
            "Mini batch: 1152/1450 | training time in 12 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0146 | Train accuracy: 86.29%.\n",
            "pgd linf: attack effectiveness 14.667%.\n",
            "pgd l2: attack effectiveness 12.000%.\n",
            "pgd l1: attack effectiveness 50.667%.\n",
            "max: attack effectiveness 50.66666666666667%.\n",
            "Mini batch: 1153/1450 | training time in 12 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0108 | Train accuracy: 84.24%.\n",
            "pgd linf: attack effectiveness 14.706%.\n",
            "pgd l2: attack effectiveness 16.176%.\n",
            "pgd l1: attack effectiveness 48.529%.\n",
            "max: attack effectiveness 48.529411764705884%.\n",
            "Mini batch: 1154/1450 | training time in 12 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0142 | Train accuracy: 86.73%.\n",
            "pgd linf: attack effectiveness 16.949%.\n",
            "pgd l2: attack effectiveness 20.339%.\n",
            "pgd l1: attack effectiveness 47.458%.\n",
            "max: attack effectiveness 47.45762711864407%.\n",
            "Mini batch: 1155/1450 | training time in 12 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0353 | Train accuracy: 86.10%.\n",
            "pgd linf: attack effectiveness 16.000%.\n",
            "pgd l2: attack effectiveness 10.667%.\n",
            "pgd l1: attack effectiveness 45.333%.\n",
            "max: attack effectiveness 45.33333333333333%.\n",
            "Mini batch: 1156/1450 | training time in 12 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0096 | Train accuracy: 85.71%.\n",
            "pgd linf: attack effectiveness 17.391%.\n",
            "pgd l2: attack effectiveness 15.942%.\n",
            "pgd l1: attack effectiveness 53.623%.\n",
            "max: attack effectiveness 53.62318840579711%.\n",
            "Mini batch: 1157/1450 | training time in 12 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0163 | Train accuracy: 84.26%.\n",
            "pgd linf: attack effectiveness 10.938%.\n",
            "pgd l2: attack effectiveness 12.500%.\n",
            "pgd l1: attack effectiveness 34.375%.\n",
            "max: attack effectiveness 34.375%.\n",
            "Mini batch: 1158/1450 | training time in 12 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0136 | Train accuracy: 90.10%.\n",
            "pgd linf: attack effectiveness 11.290%.\n",
            "pgd l2: attack effectiveness 8.065%.\n",
            "pgd l1: attack effectiveness 40.323%.\n",
            "max: attack effectiveness 40.32258064516129%.\n",
            "Mini batch: 1159/1450 | training time in 12 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0086 | Train accuracy: 90.53%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 1160/1450 | training time in 12 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0048 | Train accuracy: 89.47%.\n",
            "Training loss (epoch level): 0.0138 | Train accuracy: 88.09\n",
            "pgd linf: attack effectiveness 12.007%.\n",
            "pgd l2: attack effectiveness 9.498%.\n",
            "pgd l1: attack effectiveness 55.376%.\n",
            "max: attack effectiveness 55.55555555555556%.\n",
            "\tVal accuracy 69.6% with accuracy 44.44% under attack.\n",
            "\tModel select at epoch 39 with validation accuracy 70.79% and accuracy 45.34% under attack.\n",
            "pgd linf: attack effectiveness 10.606%.\n",
            "pgd l2: attack effectiveness 9.091%.\n",
            "pgd l1: attack effectiveness 45.455%.\n",
            "max: attack effectiveness 45.45454545454545%.\n",
            "Mini batch: 1161/1450 | training time in 12 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0127 | Train accuracy: 86.60%.\n",
            "pgd linf: attack effectiveness 7.937%.\n",
            "pgd l2: attack effectiveness 22.222%.\n",
            "pgd l1: attack effectiveness 46.032%.\n",
            "max: attack effectiveness 46.03174603174603%.\n",
            "Mini batch: 1162/1450 | training time in 12 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0129 | Train accuracy: 89.53%.\n",
            "pgd linf: attack effectiveness 10.606%.\n",
            "pgd l2: attack effectiveness 9.091%.\n",
            "pgd l1: attack effectiveness 42.424%.\n",
            "max: attack effectiveness 42.42424242424242%.\n",
            "Mini batch: 1163/1450 | training time in 12 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0120 | Train accuracy: 89.18%.\n",
            "pgd linf: attack effectiveness 5.714%.\n",
            "pgd l2: attack effectiveness 1.429%.\n",
            "pgd l1: attack effectiveness 42.857%.\n",
            "max: attack effectiveness 42.857142857142854%.\n",
            "Mini batch: 1164/1450 | training time in 12 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0103 | Train accuracy: 89.90%.\n",
            "pgd linf: attack effectiveness 11.268%.\n",
            "pgd l2: attack effectiveness 7.042%.\n",
            "pgd l1: attack effectiveness 50.704%.\n",
            "max: attack effectiveness 50.70422535211267%.\n",
            "Mini batch: 1165/1450 | training time in 12 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0171 | Train accuracy: 86.43%.\n",
            "pgd linf: attack effectiveness 7.895%.\n",
            "pgd l2: attack effectiveness 6.579%.\n",
            "pgd l1: attack effectiveness 44.737%.\n",
            "max: attack effectiveness 44.73684210526316%.\n",
            "Mini batch: 1166/1450 | training time in 12 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0125 | Train accuracy: 86.76%.\n",
            "pgd linf: attack effectiveness 3.279%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 40.984%.\n",
            "max: attack effectiveness 40.98360655737705%.\n",
            "Mini batch: 1167/1450 | training time in 12 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0082 | Train accuracy: 90.48%.\n",
            "pgd linf: attack effectiveness 10.145%.\n",
            "pgd l2: attack effectiveness 7.246%.\n",
            "pgd l1: attack effectiveness 42.029%.\n",
            "max: attack effectiveness 42.028985507246375%.\n",
            "Mini batch: 1168/1450 | training time in 12 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0124 | Train accuracy: 87.82%.\n",
            "pgd linf: attack effectiveness 3.226%.\n",
            "pgd l2: attack effectiveness 6.452%.\n",
            "pgd l1: attack effectiveness 35.484%.\n",
            "max: attack effectiveness 35.483870967741936%.\n",
            "Mini batch: 1169/1450 | training time in 12 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0082 | Train accuracy: 91.58%.\n",
            "pgd linf: attack effectiveness 8.333%.\n",
            "pgd l2: attack effectiveness 10.000%.\n",
            "pgd l1: attack effectiveness 46.667%.\n",
            "max: attack effectiveness 46.666666666666664%.\n",
            "Mini batch: 1170/1450 | training time in 12 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0165 | Train accuracy: 88.30%.\n",
            "pgd linf: attack effectiveness 9.259%.\n",
            "pgd l2: attack effectiveness 1.852%.\n",
            "pgd l1: attack effectiveness 35.185%.\n",
            "max: attack effectiveness 35.18518518518518%.\n",
            "Mini batch: 1171/1450 | training time in 12 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0129 | Train accuracy: 92.31%.\n",
            "pgd linf: attack effectiveness 3.175%.\n",
            "pgd l2: attack effectiveness 3.175%.\n",
            "pgd l1: attack effectiveness 46.032%.\n",
            "max: attack effectiveness 46.03174603174603%.\n",
            "Mini batch: 1172/1450 | training time in 12 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0109 | Train accuracy: 86.91%.\n",
            "pgd linf: attack effectiveness 1.538%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 46.154%.\n",
            "max: attack effectiveness 46.15384615384615%.\n",
            "Mini batch: 1173/1450 | training time in 12 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0068 | Train accuracy: 87.56%.\n",
            "pgd linf: attack effectiveness 6.061%.\n",
            "pgd l2: attack effectiveness 4.545%.\n",
            "pgd l1: attack effectiveness 42.424%.\n",
            "max: attack effectiveness 42.42424242424242%.\n",
            "Mini batch: 1174/1450 | training time in 12 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0431 | Train accuracy: 89.18%.\n",
            "pgd linf: attack effectiveness 3.077%.\n",
            "pgd l2: attack effectiveness 1.538%.\n",
            "pgd l1: attack effectiveness 40.000%.\n",
            "max: attack effectiveness 40.0%.\n",
            "Mini batch: 1175/1450 | training time in 12 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0103 | Train accuracy: 88.60%.\n",
            "pgd linf: attack effectiveness 4.225%.\n",
            "pgd l2: attack effectiveness 5.634%.\n",
            "pgd l1: attack effectiveness 45.070%.\n",
            "max: attack effectiveness 45.07042253521127%.\n",
            "Mini batch: 1176/1450 | training time in 12 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0076 | Train accuracy: 89.45%.\n",
            "pgd linf: attack effectiveness 6.250%.\n",
            "pgd l2: attack effectiveness 1.562%.\n",
            "pgd l1: attack effectiveness 35.938%.\n",
            "max: attack effectiveness 35.9375%.\n",
            "Mini batch: 1177/1450 | training time in 12 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0090 | Train accuracy: 91.15%.\n",
            "pgd linf: attack effectiveness 1.493%.\n",
            "pgd l2: attack effectiveness 2.985%.\n",
            "pgd l1: attack effectiveness 35.821%.\n",
            "max: attack effectiveness 35.82089552238806%.\n",
            "Mini batch: 1178/1450 | training time in 12 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0159 | Train accuracy: 88.72%.\n",
            "pgd linf: attack effectiveness 7.812%.\n",
            "pgd l2: attack effectiveness 3.125%.\n",
            "pgd l1: attack effectiveness 45.312%.\n",
            "max: attack effectiveness 45.3125%.\n",
            "Mini batch: 1179/1450 | training time in 12 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0083 | Train accuracy: 90.62%.\n",
            "pgd linf: attack effectiveness 6.757%.\n",
            "pgd l2: attack effectiveness 8.108%.\n",
            "pgd l1: attack effectiveness 52.703%.\n",
            "max: attack effectiveness 52.702702702702695%.\n",
            "Mini batch: 1180/1450 | training time in 12 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0186 | Train accuracy: 84.65%.\n",
            "pgd linf: attack effectiveness 4.348%.\n",
            "pgd l2: attack effectiveness 5.797%.\n",
            "pgd l1: attack effectiveness 40.580%.\n",
            "max: attack effectiveness 40.57971014492754%.\n",
            "Mini batch: 1181/1450 | training time in 12 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0065 | Train accuracy: 90.36%.\n",
            "pgd linf: attack effectiveness 10.667%.\n",
            "pgd l2: attack effectiveness 13.333%.\n",
            "pgd l1: attack effectiveness 49.333%.\n",
            "max: attack effectiveness 49.333333333333336%.\n",
            "Mini batch: 1182/1450 | training time in 12 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0103 | Train accuracy: 88.18%.\n",
            "pgd linf: attack effectiveness 10.294%.\n",
            "pgd l2: attack effectiveness 33.824%.\n",
            "pgd l1: attack effectiveness 50.000%.\n",
            "max: attack effectiveness 50.0%.\n",
            "Mini batch: 1183/1450 | training time in 12 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0133 | Train accuracy: 82.65%.\n",
            "pgd linf: attack effectiveness 8.475%.\n",
            "pgd l2: attack effectiveness 8.475%.\n",
            "pgd l1: attack effectiveness 49.153%.\n",
            "max: attack effectiveness 49.152542372881356%.\n",
            "Mini batch: 1184/1450 | training time in 13 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0308 | Train accuracy: 85.56%.\n",
            "pgd linf: attack effectiveness 6.667%.\n",
            "pgd l2: attack effectiveness 5.333%.\n",
            "pgd l1: attack effectiveness 46.667%.\n",
            "max: attack effectiveness 46.666666666666664%.\n",
            "Mini batch: 1185/1450 | training time in 13 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0076 | Train accuracy: 86.70%.\n",
            "pgd linf: attack effectiveness 7.246%.\n",
            "pgd l2: attack effectiveness 15.942%.\n",
            "pgd l1: attack effectiveness 55.072%.\n",
            "max: attack effectiveness 55.072463768115945%.\n",
            "Mini batch: 1186/1450 | training time in 13 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0128 | Train accuracy: 85.79%.\n",
            "pgd linf: attack effectiveness 7.812%.\n",
            "pgd l2: attack effectiveness 7.812%.\n",
            "pgd l1: attack effectiveness 37.500%.\n",
            "max: attack effectiveness 37.5%.\n",
            "Mini batch: 1187/1450 | training time in 13 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0145 | Train accuracy: 90.10%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 3.226%.\n",
            "pgd l1: attack effectiveness 41.935%.\n",
            "max: attack effectiveness 41.935483870967744%.\n",
            "Mini batch: 1188/1450 | training time in 13 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0057 | Train accuracy: 91.58%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 1189/1450 | training time in 13 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0045 | Train accuracy: 89.47%.\n",
            "Training loss (epoch level): 0.0128 | Train accuracy: 88.49\n",
            "pgd linf: attack effectiveness 5.018%.\n",
            "pgd l2: attack effectiveness 6.093%.\n",
            "pgd l1: attack effectiveness 56.631%.\n",
            "max: attack effectiveness 56.63082437275986%.\n",
            "\tVal accuracy 69.47% with accuracy 43.37% under attack.\n",
            "\tModel select at epoch 39 with validation accuracy 70.79% and accuracy 45.34% under attack.\n",
            "pgd linf: attack effectiveness 7.576%.\n",
            "pgd l2: attack effectiveness 4.545%.\n",
            "pgd l1: attack effectiveness 40.909%.\n",
            "max: attack effectiveness 40.909090909090914%.\n",
            "Mini batch: 1190/1450 | training time in 13 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0117 | Train accuracy: 89.69%.\n",
            "pgd linf: attack effectiveness 1.587%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 46.032%.\n",
            "max: attack effectiveness 46.03174603174603%.\n",
            "Mini batch: 1191/1450 | training time in 13 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0105 | Train accuracy: 89.01%.\n",
            "pgd linf: attack effectiveness 6.061%.\n",
            "pgd l2: attack effectiveness 4.545%.\n",
            "pgd l1: attack effectiveness 43.939%.\n",
            "max: attack effectiveness 43.93939393939394%.\n",
            "Mini batch: 1192/1450 | training time in 13 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0135 | Train accuracy: 86.60%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 2.857%.\n",
            "pgd l1: attack effectiveness 45.714%.\n",
            "max: attack effectiveness 45.714285714285715%.\n",
            "Mini batch: 1193/1450 | training time in 13 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0107 | Train accuracy: 88.89%.\n",
            "pgd linf: attack effectiveness 4.225%.\n",
            "pgd l2: attack effectiveness 4.225%.\n",
            "pgd l1: attack effectiveness 46.479%.\n",
            "max: attack effectiveness 46.478873239436616%.\n",
            "Mini batch: 1194/1450 | training time in 13 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0170 | Train accuracy: 85.93%.\n",
            "pgd linf: attack effectiveness 2.632%.\n",
            "pgd l2: attack effectiveness 6.579%.\n",
            "pgd l1: attack effectiveness 46.053%.\n",
            "max: attack effectiveness 46.05263157894737%.\n",
            "Mini batch: 1195/1450 | training time in 13 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0113 | Train accuracy: 86.76%.\n",
            "pgd linf: attack effectiveness 1.639%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 40.984%.\n",
            "max: attack effectiveness 40.98360655737705%.\n",
            "Mini batch: 1196/1450 | training time in 13 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0123 | Train accuracy: 89.95%.\n",
            "pgd linf: attack effectiveness 5.797%.\n",
            "pgd l2: attack effectiveness 10.145%.\n",
            "pgd l1: attack effectiveness 40.580%.\n",
            "max: attack effectiveness 40.57971014492754%.\n",
            "Mini batch: 1197/1450 | training time in 13 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0118 | Train accuracy: 89.85%.\n",
            "pgd linf: attack effectiveness 9.677%.\n",
            "pgd l2: attack effectiveness 3.226%.\n",
            "pgd l1: attack effectiveness 33.871%.\n",
            "max: attack effectiveness 33.87096774193548%.\n",
            "Mini batch: 1198/1450 | training time in 13 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0073 | Train accuracy: 91.58%.\n",
            "pgd linf: attack effectiveness 6.667%.\n",
            "pgd l2: attack effectiveness 13.333%.\n",
            "pgd l1: attack effectiveness 51.667%.\n",
            "max: attack effectiveness 51.66666666666667%.\n",
            "Mini batch: 1199/1450 | training time in 13 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0178 | Train accuracy: 89.89%.\n",
            "pgd linf: attack effectiveness 7.407%.\n",
            "pgd l2: attack effectiveness 9.259%.\n",
            "pgd l1: attack effectiveness 31.481%.\n",
            "max: attack effectiveness 31.48148148148148%.\n",
            "Mini batch: 1200/1450 | training time in 13 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0094 | Train accuracy: 91.21%.\n",
            "pgd linf: attack effectiveness 3.175%.\n",
            "pgd l2: attack effectiveness 6.349%.\n",
            "pgd l1: attack effectiveness 46.032%.\n",
            "max: attack effectiveness 46.03174603174603%.\n",
            "Mini batch: 1201/1450 | training time in 13 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0083 | Train accuracy: 88.48%.\n",
            "pgd linf: attack effectiveness 12.308%.\n",
            "pgd l2: attack effectiveness 6.154%.\n",
            "pgd l1: attack effectiveness 46.154%.\n",
            "max: attack effectiveness 46.15384615384615%.\n",
            "Mini batch: 1202/1450 | training time in 13 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0083 | Train accuracy: 89.64%.\n",
            "pgd linf: attack effectiveness 10.606%.\n",
            "pgd l2: attack effectiveness 4.545%.\n",
            "pgd l1: attack effectiveness 42.424%.\n",
            "max: attack effectiveness 42.42424242424242%.\n",
            "Mini batch: 1203/1450 | training time in 13 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0356 | Train accuracy: 88.14%.\n",
            "pgd linf: attack effectiveness 6.154%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 36.923%.\n",
            "max: attack effectiveness 36.92307692307693%.\n",
            "Mini batch: 1204/1450 | training time in 13 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0120 | Train accuracy: 89.12%.\n",
            "pgd linf: attack effectiveness 7.042%.\n",
            "pgd l2: attack effectiveness 5.634%.\n",
            "pgd l1: attack effectiveness 45.070%.\n",
            "max: attack effectiveness 45.07042253521127%.\n",
            "Mini batch: 1205/1450 | training time in 13 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0091 | Train accuracy: 85.43%.\n",
            "pgd linf: attack effectiveness 1.562%.\n",
            "pgd l2: attack effectiveness 1.562%.\n",
            "pgd l1: attack effectiveness 35.938%.\n",
            "max: attack effectiveness 35.9375%.\n",
            "Mini batch: 1206/1450 | training time in 13 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0064 | Train accuracy: 89.06%.\n",
            "pgd linf: attack effectiveness 1.493%.\n",
            "pgd l2: attack effectiveness 4.478%.\n",
            "pgd l1: attack effectiveness 37.313%.\n",
            "max: attack effectiveness 37.3134328358209%.\n",
            "Mini batch: 1207/1450 | training time in 13 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0089 | Train accuracy: 89.74%.\n",
            "pgd linf: attack effectiveness 7.812%.\n",
            "pgd l2: attack effectiveness 9.375%.\n",
            "pgd l1: attack effectiveness 45.312%.\n",
            "max: attack effectiveness 45.3125%.\n",
            "Mini batch: 1208/1450 | training time in 13 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0113 | Train accuracy: 86.46%.\n",
            "pgd linf: attack effectiveness 8.108%.\n",
            "pgd l2: attack effectiveness 5.405%.\n",
            "pgd l1: attack effectiveness 52.703%.\n",
            "max: attack effectiveness 52.702702702702695%.\n",
            "Mini batch: 1209/1450 | training time in 13 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0206 | Train accuracy: 86.14%.\n",
            "pgd linf: attack effectiveness 1.449%.\n",
            "pgd l2: attack effectiveness 10.145%.\n",
            "pgd l1: attack effectiveness 40.580%.\n",
            "max: attack effectiveness 40.57971014492754%.\n",
            "Mini batch: 1210/1450 | training time in 13 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0115 | Train accuracy: 88.83%.\n",
            "pgd linf: attack effectiveness 9.333%.\n",
            "pgd l2: attack effectiveness 18.667%.\n",
            "pgd l1: attack effectiveness 48.000%.\n",
            "max: attack effectiveness 48.0%.\n",
            "Mini batch: 1211/1450 | training time in 13 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0115 | Train accuracy: 86.70%.\n",
            "pgd linf: attack effectiveness 5.882%.\n",
            "pgd l2: attack effectiveness 5.882%.\n",
            "pgd l1: attack effectiveness 48.529%.\n",
            "max: attack effectiveness 48.529411764705884%.\n",
            "Mini batch: 1212/1450 | training time in 13 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0062 | Train accuracy: 89.29%.\n",
            "pgd linf: attack effectiveness 11.864%.\n",
            "pgd l2: attack effectiveness 6.780%.\n",
            "pgd l1: attack effectiveness 42.373%.\n",
            "max: attack effectiveness 42.3728813559322%.\n",
            "Mini batch: 1213/1450 | training time in 13 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0182 | Train accuracy: 89.84%.\n",
            "pgd linf: attack effectiveness 8.000%.\n",
            "pgd l2: attack effectiveness 6.667%.\n",
            "pgd l1: attack effectiveness 45.333%.\n",
            "max: attack effectiveness 45.33333333333333%.\n",
            "Mini batch: 1214/1450 | training time in 13 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0066 | Train accuracy: 83.74%.\n",
            "pgd linf: attack effectiveness 10.145%.\n",
            "pgd l2: attack effectiveness 4.348%.\n",
            "pgd l1: attack effectiveness 49.275%.\n",
            "max: attack effectiveness 49.275362318840585%.\n",
            "Mini batch: 1215/1450 | training time in 13 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0094 | Train accuracy: 85.79%.\n",
            "pgd linf: attack effectiveness 7.812%.\n",
            "pgd l2: attack effectiveness 3.125%.\n",
            "pgd l1: attack effectiveness 34.375%.\n",
            "max: attack effectiveness 34.375%.\n",
            "Mini batch: 1216/1450 | training time in 13 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0292 | Train accuracy: 90.62%.\n",
            "pgd linf: attack effectiveness 6.452%.\n",
            "pgd l2: attack effectiveness 4.839%.\n",
            "pgd l1: attack effectiveness 40.323%.\n",
            "max: attack effectiveness 40.32258064516129%.\n",
            "Mini batch: 1217/1450 | training time in 13 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0099 | Train accuracy: 88.95%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 1218/1450 | training time in 13 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0033 | Train accuracy: 89.47%.\n",
            "Training loss (epoch level): 0.0124 | Train accuracy: 88.44\n",
            "pgd linf: attack effectiveness 5.197%.\n",
            "pgd l2: attack effectiveness 7.348%.\n",
            "pgd l1: attack effectiveness 55.018%.\n",
            "max: attack effectiveness 55.017921146953405%.\n",
            "\tVal accuracy 69.86% with accuracy 44.98% under attack.\n",
            "\tModel select at epoch 39 with validation accuracy 70.79% and accuracy 45.34% under attack.\n",
            "pgd linf: attack effectiveness 1.515%.\n",
            "pgd l2: attack effectiveness 4.545%.\n",
            "pgd l1: attack effectiveness 40.909%.\n",
            "max: attack effectiveness 40.909090909090914%.\n",
            "Mini batch: 1219/1450 | training time in 13 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0138 | Train accuracy: 92.78%.\n",
            "pgd linf: attack effectiveness 3.175%.\n",
            "pgd l2: attack effectiveness 1.587%.\n",
            "pgd l1: attack effectiveness 44.444%.\n",
            "max: attack effectiveness 44.44444444444444%.\n",
            "Mini batch: 1220/1450 | training time in 13 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0142 | Train accuracy: 89.53%.\n",
            "pgd linf: attack effectiveness 6.061%.\n",
            "pgd l2: attack effectiveness 4.545%.\n",
            "pgd l1: attack effectiveness 42.424%.\n",
            "max: attack effectiveness 42.42424242424242%.\n",
            "Mini batch: 1221/1450 | training time in 13 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0140 | Train accuracy: 88.66%.\n",
            "pgd linf: attack effectiveness 4.286%.\n",
            "pgd l2: attack effectiveness 4.286%.\n",
            "pgd l1: attack effectiveness 48.571%.\n",
            "max: attack effectiveness 48.57142857142857%.\n",
            "Mini batch: 1222/1450 | training time in 13 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0071 | Train accuracy: 86.36%.\n",
            "pgd linf: attack effectiveness 9.859%.\n",
            "pgd l2: attack effectiveness 5.634%.\n",
            "pgd l1: attack effectiveness 47.887%.\n",
            "max: attack effectiveness 47.88732394366197%.\n",
            "Mini batch: 1223/1450 | training time in 13 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0114 | Train accuracy: 86.93%.\n",
            "pgd linf: attack effectiveness 5.263%.\n",
            "pgd l2: attack effectiveness 3.947%.\n",
            "pgd l1: attack effectiveness 47.368%.\n",
            "max: attack effectiveness 47.368421052631575%.\n",
            "Mini batch: 1224/1450 | training time in 13 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0093 | Train accuracy: 85.29%.\n",
            "pgd linf: attack effectiveness 1.639%.\n",
            "pgd l2: attack effectiveness 6.557%.\n",
            "pgd l1: attack effectiveness 40.984%.\n",
            "max: attack effectiveness 40.98360655737705%.\n",
            "Mini batch: 1225/1450 | training time in 13 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0098 | Train accuracy: 89.42%.\n",
            "pgd linf: attack effectiveness 5.797%.\n",
            "pgd l2: attack effectiveness 7.246%.\n",
            "pgd l1: attack effectiveness 40.580%.\n",
            "max: attack effectiveness 40.57971014492754%.\n",
            "Mini batch: 1226/1450 | training time in 13 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0111 | Train accuracy: 90.86%.\n",
            "pgd linf: attack effectiveness 8.065%.\n",
            "pgd l2: attack effectiveness 9.677%.\n",
            "pgd l1: attack effectiveness 35.484%.\n",
            "max: attack effectiveness 37.096774193548384%.\n",
            "Mini batch: 1227/1450 | training time in 13 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0077 | Train accuracy: 88.95%.\n",
            "pgd linf: attack effectiveness 15.000%.\n",
            "pgd l2: attack effectiveness 5.000%.\n",
            "pgd l1: attack effectiveness 43.333%.\n",
            "max: attack effectiveness 43.333333333333336%.\n",
            "Mini batch: 1228/1450 | training time in 13 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0163 | Train accuracy: 89.36%.\n",
            "pgd linf: attack effectiveness 5.556%.\n",
            "pgd l2: attack effectiveness 3.704%.\n",
            "pgd l1: attack effectiveness 29.630%.\n",
            "max: attack effectiveness 31.48148148148148%.\n",
            "Mini batch: 1229/1450 | training time in 13 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0098 | Train accuracy: 92.31%.\n",
            "pgd linf: attack effectiveness 6.349%.\n",
            "pgd l2: attack effectiveness 4.762%.\n",
            "pgd l1: attack effectiveness 46.032%.\n",
            "max: attack effectiveness 46.03174603174603%.\n",
            "Mini batch: 1230/1450 | training time in 13 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0152 | Train accuracy: 87.96%.\n",
            "pgd linf: attack effectiveness 13.846%.\n",
            "pgd l2: attack effectiveness 1.538%.\n",
            "pgd l1: attack effectiveness 47.692%.\n",
            "max: attack effectiveness 47.69230769230769%.\n",
            "Mini batch: 1231/1450 | training time in 13 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0067 | Train accuracy: 87.56%.\n",
            "pgd linf: attack effectiveness 7.576%.\n",
            "pgd l2: attack effectiveness 10.606%.\n",
            "pgd l1: attack effectiveness 42.424%.\n",
            "max: attack effectiveness 42.42424242424242%.\n",
            "Mini batch: 1232/1450 | training time in 13 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0397 | Train accuracy: 87.11%.\n",
            "pgd linf: attack effectiveness 12.308%.\n",
            "pgd l2: attack effectiveness 1.538%.\n",
            "pgd l1: attack effectiveness 36.923%.\n",
            "max: attack effectiveness 36.92307692307693%.\n",
            "Mini batch: 1233/1450 | training time in 13 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0096 | Train accuracy: 89.64%.\n",
            "pgd linf: attack effectiveness 9.859%.\n",
            "pgd l2: attack effectiveness 5.634%.\n",
            "pgd l1: attack effectiveness 49.296%.\n",
            "max: attack effectiveness 49.29577464788733%.\n",
            "Mini batch: 1234/1450 | training time in 13 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0087 | Train accuracy: 87.44%.\n",
            "pgd linf: attack effectiveness 1.562%.\n",
            "pgd l2: attack effectiveness 12.500%.\n",
            "pgd l1: attack effectiveness 35.938%.\n",
            "max: attack effectiveness 35.9375%.\n",
            "Mini batch: 1235/1450 | training time in 13 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0066 | Train accuracy: 89.58%.\n",
            "pgd linf: attack effectiveness 2.985%.\n",
            "pgd l2: attack effectiveness 4.478%.\n",
            "pgd l1: attack effectiveness 38.806%.\n",
            "max: attack effectiveness 38.80597014925373%.\n",
            "Mini batch: 1236/1450 | training time in 13 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0086 | Train accuracy: 89.23%.\n",
            "pgd linf: attack effectiveness 3.125%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 43.750%.\n",
            "max: attack effectiveness 43.75%.\n",
            "Mini batch: 1237/1450 | training time in 13 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0068 | Train accuracy: 90.62%.\n",
            "pgd linf: attack effectiveness 6.757%.\n",
            "pgd l2: attack effectiveness 10.811%.\n",
            "pgd l1: attack effectiveness 52.703%.\n",
            "max: attack effectiveness 52.702702702702695%.\n",
            "Mini batch: 1238/1450 | training time in 13 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0166 | Train accuracy: 85.64%.\n",
            "pgd linf: attack effectiveness 8.696%.\n",
            "pgd l2: attack effectiveness 5.797%.\n",
            "pgd l1: attack effectiveness 40.580%.\n",
            "max: attack effectiveness 40.57971014492754%.\n",
            "Mini batch: 1239/1450 | training time in 13 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0073 | Train accuracy: 89.34%.\n",
            "pgd linf: attack effectiveness 6.667%.\n",
            "pgd l2: attack effectiveness 12.000%.\n",
            "pgd l1: attack effectiveness 48.000%.\n",
            "max: attack effectiveness 48.0%.\n",
            "Mini batch: 1240/1450 | training time in 13 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0118 | Train accuracy: 84.73%.\n",
            "pgd linf: attack effectiveness 2.941%.\n",
            "pgd l2: attack effectiveness 8.824%.\n",
            "pgd l1: attack effectiveness 48.529%.\n",
            "max: attack effectiveness 48.529411764705884%.\n",
            "Mini batch: 1241/1450 | training time in 13 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0092 | Train accuracy: 86.73%.\n",
            "pgd linf: attack effectiveness 5.085%.\n",
            "pgd l2: attack effectiveness 8.475%.\n",
            "pgd l1: attack effectiveness 44.068%.\n",
            "max: attack effectiveness 44.06779661016949%.\n",
            "Mini batch: 1242/1450 | training time in 13 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0249 | Train accuracy: 88.24%.\n",
            "pgd linf: attack effectiveness 1.333%.\n",
            "pgd l2: attack effectiveness 4.000%.\n",
            "pgd l1: attack effectiveness 45.333%.\n",
            "max: attack effectiveness 45.33333333333333%.\n",
            "Mini batch: 1243/1450 | training time in 13 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0060 | Train accuracy: 83.74%.\n",
            "pgd linf: attack effectiveness 5.797%.\n",
            "pgd l2: attack effectiveness 5.797%.\n",
            "pgd l1: attack effectiveness 50.725%.\n",
            "max: attack effectiveness 50.72463768115942%.\n",
            "Mini batch: 1244/1450 | training time in 13 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0109 | Train accuracy: 86.80%.\n",
            "pgd linf: attack effectiveness 1.562%.\n",
            "pgd l2: attack effectiveness 6.250%.\n",
            "pgd l1: attack effectiveness 35.938%.\n",
            "max: attack effectiveness 35.9375%.\n",
            "Mini batch: 1245/1450 | training time in 13 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0179 | Train accuracy: 90.10%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 1.613%.\n",
            "pgd l1: attack effectiveness 38.710%.\n",
            "max: attack effectiveness 38.70967741935484%.\n",
            "Mini batch: 1246/1450 | training time in 13 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0050 | Train accuracy: 89.47%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 1247/1450 | training time in 13 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0036 | Train accuracy: 89.47%.\n",
            "Training loss (epoch level): 0.0117 | Train accuracy: 88.41\n",
            "pgd linf: attack effectiveness 2.509%.\n",
            "pgd l2: attack effectiveness 4.301%.\n",
            "pgd l1: attack effectiveness 53.584%.\n",
            "max: attack effectiveness 53.584229390681%.\n",
            "\tVal accuracy 70.41% with accuracy 46.42% under attack.\n",
            "\tModel select at epoch 39 with validation accuracy 70.79% and accuracy 45.34% under attack.\n",
            "pgd linf: attack effectiveness 3.030%.\n",
            "pgd l2: attack effectiveness 3.030%.\n",
            "pgd l1: attack effectiveness 39.394%.\n",
            "max: attack effectiveness 39.39393939393939%.\n",
            "Mini batch: 1248/1450 | training time in 13 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0101 | Train accuracy: 87.63%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 44.444%.\n",
            "max: attack effectiveness 44.44444444444444%.\n",
            "Mini batch: 1249/1450 | training time in 13 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0134 | Train accuracy: 86.39%.\n",
            "pgd linf: attack effectiveness 3.030%.\n",
            "pgd l2: attack effectiveness 4.545%.\n",
            "pgd l1: attack effectiveness 40.909%.\n",
            "max: attack effectiveness 40.909090909090914%.\n",
            "Mini batch: 1250/1450 | training time in 13 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0144 | Train accuracy: 89.18%.\n",
            "pgd linf: attack effectiveness 1.429%.\n",
            "pgd l2: attack effectiveness 1.429%.\n",
            "pgd l1: attack effectiveness 44.286%.\n",
            "max: attack effectiveness 44.285714285714285%.\n",
            "Mini batch: 1251/1450 | training time in 13 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0233 | Train accuracy: 85.86%.\n",
            "pgd linf: attack effectiveness 4.225%.\n",
            "pgd l2: attack effectiveness 2.817%.\n",
            "pgd l1: attack effectiveness 46.479%.\n",
            "max: attack effectiveness 46.478873239436616%.\n",
            "Mini batch: 1252/1450 | training time in 13 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0112 | Train accuracy: 85.93%.\n",
            "pgd linf: attack effectiveness 6.579%.\n",
            "pgd l2: attack effectiveness 6.579%.\n",
            "pgd l1: attack effectiveness 44.737%.\n",
            "max: attack effectiveness 44.73684210526316%.\n",
            "Mini batch: 1253/1450 | training time in 13 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0112 | Train accuracy: 89.22%.\n",
            "pgd linf: attack effectiveness 14.754%.\n",
            "pgd l2: attack effectiveness 6.557%.\n",
            "pgd l1: attack effectiveness 40.984%.\n",
            "max: attack effectiveness 40.98360655737705%.\n",
            "Mini batch: 1254/1450 | training time in 13 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0081 | Train accuracy: 89.42%.\n",
            "pgd linf: attack effectiveness 8.696%.\n",
            "pgd l2: attack effectiveness 5.797%.\n",
            "pgd l1: attack effectiveness 43.478%.\n",
            "max: attack effectiveness 43.47826086956522%.\n",
            "Mini batch: 1255/1450 | training time in 13 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0108 | Train accuracy: 85.79%.\n",
            "pgd linf: attack effectiveness 16.129%.\n",
            "pgd l2: attack effectiveness 11.290%.\n",
            "pgd l1: attack effectiveness 37.097%.\n",
            "max: attack effectiveness 37.096774193548384%.\n",
            "Mini batch: 1256/1450 | training time in 13 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0079 | Train accuracy: 88.42%.\n",
            "pgd linf: attack effectiveness 18.333%.\n",
            "pgd l2: attack effectiveness 13.333%.\n",
            "pgd l1: attack effectiveness 51.667%.\n",
            "max: attack effectiveness 51.66666666666667%.\n",
            "Mini batch: 1257/1450 | training time in 13 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0160 | Train accuracy: 86.17%.\n",
            "pgd linf: attack effectiveness 22.222%.\n",
            "pgd l2: attack effectiveness 1.852%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 1258/1450 | training time in 13 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0094 | Train accuracy: 91.21%.\n",
            "pgd linf: attack effectiveness 22.222%.\n",
            "pgd l2: attack effectiveness 15.873%.\n",
            "pgd l1: attack effectiveness 47.619%.\n",
            "max: attack effectiveness 49.2063492063492%.\n",
            "Mini batch: 1259/1450 | training time in 13 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0106 | Train accuracy: 86.91%.\n",
            "pgd linf: attack effectiveness 15.385%.\n",
            "pgd l2: attack effectiveness 4.615%.\n",
            "pgd l1: attack effectiveness 50.769%.\n",
            "max: attack effectiveness 50.76923076923077%.\n",
            "Mini batch: 1260/1450 | training time in 13 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0078 | Train accuracy: 86.53%.\n",
            "pgd linf: attack effectiveness 22.727%.\n",
            "pgd l2: attack effectiveness 25.758%.\n",
            "pgd l1: attack effectiveness 46.970%.\n",
            "max: attack effectiveness 46.96969696969697%.\n",
            "Mini batch: 1261/1450 | training time in 13 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0225 | Train accuracy: 85.05%.\n",
            "pgd linf: attack effectiveness 13.846%.\n",
            "pgd l2: attack effectiveness 7.692%.\n",
            "pgd l1: attack effectiveness 41.538%.\n",
            "max: attack effectiveness 44.61538461538462%.\n",
            "Mini batch: 1262/1450 | training time in 13 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0120 | Train accuracy: 87.56%.\n",
            "pgd linf: attack effectiveness 16.901%.\n",
            "pgd l2: attack effectiveness 12.676%.\n",
            "pgd l1: attack effectiveness 47.887%.\n",
            "max: attack effectiveness 49.29577464788733%.\n",
            "Mini batch: 1263/1450 | training time in 13 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0087 | Train accuracy: 87.44%.\n",
            "pgd linf: attack effectiveness 7.812%.\n",
            "pgd l2: attack effectiveness 10.938%.\n",
            "pgd l1: attack effectiveness 35.938%.\n",
            "max: attack effectiveness 35.9375%.\n",
            "Mini batch: 1264/1450 | training time in 13 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0097 | Train accuracy: 89.06%.\n",
            "pgd linf: attack effectiveness 7.463%.\n",
            "pgd l2: attack effectiveness 10.448%.\n",
            "pgd l1: attack effectiveness 35.821%.\n",
            "max: attack effectiveness 41.7910447761194%.\n",
            "Mini batch: 1265/1450 | training time in 13 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0128 | Train accuracy: 88.72%.\n",
            "pgd linf: attack effectiveness 9.375%.\n",
            "pgd l2: attack effectiveness 3.125%.\n",
            "pgd l1: attack effectiveness 42.188%.\n",
            "max: attack effectiveness 43.75%.\n",
            "Mini batch: 1266/1450 | training time in 13 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0108 | Train accuracy: 86.46%.\n",
            "pgd linf: attack effectiveness 6.757%.\n",
            "pgd l2: attack effectiveness 10.811%.\n",
            "pgd l1: attack effectiveness 52.703%.\n",
            "max: attack effectiveness 55.4054054054054%.\n",
            "Mini batch: 1267/1450 | training time in 13 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0148 | Train accuracy: 80.69%.\n",
            "pgd linf: attack effectiveness 4.348%.\n",
            "pgd l2: attack effectiveness 10.145%.\n",
            "pgd l1: attack effectiveness 39.130%.\n",
            "max: attack effectiveness 46.3768115942029%.\n",
            "Mini batch: 1268/1450 | training time in 13 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0125 | Train accuracy: 86.29%.\n",
            "pgd linf: attack effectiveness 2.667%.\n",
            "pgd l2: attack effectiveness 8.000%.\n",
            "pgd l1: attack effectiveness 48.000%.\n",
            "max: attack effectiveness 48.0%.\n",
            "Mini batch: 1269/1450 | training time in 13 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0109 | Train accuracy: 85.22%.\n",
            "pgd linf: attack effectiveness 2.941%.\n",
            "pgd l2: attack effectiveness 1.471%.\n",
            "pgd l1: attack effectiveness 48.529%.\n",
            "max: attack effectiveness 48.529411764705884%.\n",
            "Mini batch: 1270/1450 | training time in 13 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0089 | Train accuracy: 87.76%.\n",
            "pgd linf: attack effectiveness 6.780%.\n",
            "pgd l2: attack effectiveness 10.169%.\n",
            "pgd l1: attack effectiveness 44.068%.\n",
            "max: attack effectiveness 45.76271186440678%.\n",
            "Mini batch: 1271/1450 | training time in 13 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0226 | Train accuracy: 86.10%.\n",
            "pgd linf: attack effectiveness 8.000%.\n",
            "pgd l2: attack effectiveness 6.667%.\n",
            "pgd l1: attack effectiveness 45.333%.\n",
            "max: attack effectiveness 45.33333333333333%.\n",
            "Mini batch: 1272/1450 | training time in 13 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0084 | Train accuracy: 86.70%.\n",
            "pgd linf: attack effectiveness 7.246%.\n",
            "pgd l2: attack effectiveness 5.797%.\n",
            "pgd l1: attack effectiveness 52.174%.\n",
            "max: attack effectiveness 52.17391304347826%.\n",
            "Mini batch: 1273/1450 | training time in 13 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0097 | Train accuracy: 85.79%.\n",
            "pgd linf: attack effectiveness 3.125%.\n",
            "pgd l2: attack effectiveness 9.375%.\n",
            "pgd l1: attack effectiveness 34.375%.\n",
            "max: attack effectiveness 34.375%.\n",
            "Mini batch: 1274/1450 | training time in 14 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0183 | Train accuracy: 91.15%.\n",
            "pgd linf: attack effectiveness 3.226%.\n",
            "pgd l2: attack effectiveness 3.226%.\n",
            "pgd l1: attack effectiveness 41.935%.\n",
            "max: attack effectiveness 41.935483870967744%.\n",
            "Mini batch: 1275/1450 | training time in 14 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0091 | Train accuracy: 91.05%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 1276/1450 | training time in 14 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0036 | Train accuracy: 89.47%.\n",
            "Training loss (epoch level): 0.0121 | Train accuracy: 87.35\n",
            "pgd linf: attack effectiveness 4.659%.\n",
            "pgd l2: attack effectiveness 5.914%.\n",
            "pgd l1: attack effectiveness 56.452%.\n",
            "max: attack effectiveness 56.451612903225815%.\n",
            "\tVal accuracy 69.77% with accuracy 43.55% under attack.\n",
            "\tModel select at epoch 39 with validation accuracy 70.79% and accuracy 45.34% under attack.\n",
            "pgd linf: attack effectiveness 4.545%.\n",
            "pgd l2: attack effectiveness 9.091%.\n",
            "pgd l1: attack effectiveness 45.455%.\n",
            "max: attack effectiveness 45.45454545454545%.\n",
            "Mini batch: 1277/1450 | training time in 14 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0123 | Train accuracy: 86.08%.\n",
            "pgd linf: attack effectiveness 3.175%.\n",
            "pgd l2: attack effectiveness 6.349%.\n",
            "pgd l1: attack effectiveness 47.619%.\n",
            "max: attack effectiveness 47.61904761904761%.\n",
            "Mini batch: 1278/1450 | training time in 14 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0116 | Train accuracy: 89.01%.\n",
            "pgd linf: attack effectiveness 4.545%.\n",
            "pgd l2: attack effectiveness 6.061%.\n",
            "pgd l1: attack effectiveness 45.455%.\n",
            "max: attack effectiveness 45.45454545454545%.\n",
            "Mini batch: 1279/1450 | training time in 14 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0103 | Train accuracy: 89.18%.\n",
            "pgd linf: attack effectiveness 1.429%.\n",
            "pgd l2: attack effectiveness 5.714%.\n",
            "pgd l1: attack effectiveness 45.714%.\n",
            "max: attack effectiveness 45.714285714285715%.\n",
            "Mini batch: 1280/1450 | training time in 14 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0083 | Train accuracy: 87.37%.\n",
            "pgd linf: attack effectiveness 4.225%.\n",
            "pgd l2: attack effectiveness 4.225%.\n",
            "pgd l1: attack effectiveness 50.704%.\n",
            "max: attack effectiveness 50.70422535211267%.\n",
            "Mini batch: 1281/1450 | training time in 14 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0165 | Train accuracy: 87.44%.\n",
            "pgd linf: attack effectiveness 2.632%.\n",
            "pgd l2: attack effectiveness 6.579%.\n",
            "pgd l1: attack effectiveness 47.368%.\n",
            "max: attack effectiveness 47.368421052631575%.\n",
            "Mini batch: 1282/1450 | training time in 14 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0094 | Train accuracy: 85.78%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 8.197%.\n",
            "pgd l1: attack effectiveness 37.705%.\n",
            "max: attack effectiveness 37.704918032786885%.\n",
            "Mini batch: 1283/1450 | training time in 14 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0173 | Train accuracy: 88.89%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 4.348%.\n",
            "pgd l1: attack effectiveness 40.580%.\n",
            "max: attack effectiveness 40.57971014492754%.\n",
            "Mini batch: 1284/1450 | training time in 14 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0103 | Train accuracy: 89.34%.\n",
            "pgd linf: attack effectiveness 6.452%.\n",
            "pgd l2: attack effectiveness 11.290%.\n",
            "pgd l1: attack effectiveness 33.871%.\n",
            "max: attack effectiveness 33.87096774193548%.\n",
            "Mini batch: 1285/1450 | training time in 14 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0085 | Train accuracy: 91.05%.\n",
            "pgd linf: attack effectiveness 1.667%.\n",
            "pgd l2: attack effectiveness 11.667%.\n",
            "pgd l1: attack effectiveness 46.667%.\n",
            "max: attack effectiveness 46.666666666666664%.\n",
            "Mini batch: 1286/1450 | training time in 14 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0150 | Train accuracy: 89.36%.\n",
            "pgd linf: attack effectiveness 9.259%.\n",
            "pgd l2: attack effectiveness 11.111%.\n",
            "pgd l1: attack effectiveness 31.481%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 1287/1450 | training time in 14 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0108 | Train accuracy: 92.86%.\n",
            "pgd linf: attack effectiveness 12.698%.\n",
            "pgd l2: attack effectiveness 7.937%.\n",
            "pgd l1: attack effectiveness 46.032%.\n",
            "max: attack effectiveness 47.61904761904761%.\n",
            "Mini batch: 1288/1450 | training time in 14 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0087 | Train accuracy: 87.43%.\n",
            "pgd linf: attack effectiveness 16.923%.\n",
            "pgd l2: attack effectiveness 4.615%.\n",
            "pgd l1: attack effectiveness 50.769%.\n",
            "max: attack effectiveness 50.76923076923077%.\n",
            "Mini batch: 1289/1450 | training time in 14 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0082 | Train accuracy: 88.08%.\n",
            "pgd linf: attack effectiveness 19.697%.\n",
            "pgd l2: attack effectiveness 9.091%.\n",
            "pgd l1: attack effectiveness 43.939%.\n",
            "max: attack effectiveness 43.93939393939394%.\n",
            "Mini batch: 1290/1450 | training time in 14 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0360 | Train accuracy: 86.08%.\n",
            "pgd linf: attack effectiveness 20.000%.\n",
            "pgd l2: attack effectiveness 1.538%.\n",
            "pgd l1: attack effectiveness 38.462%.\n",
            "max: attack effectiveness 38.46153846153847%.\n",
            "Mini batch: 1291/1450 | training time in 14 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0090 | Train accuracy: 88.60%.\n",
            "pgd linf: attack effectiveness 25.352%.\n",
            "pgd l2: attack effectiveness 8.451%.\n",
            "pgd l1: attack effectiveness 47.887%.\n",
            "max: attack effectiveness 47.88732394366197%.\n",
            "Mini batch: 1292/1450 | training time in 14 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0190 | Train accuracy: 85.43%.\n",
            "pgd linf: attack effectiveness 20.312%.\n",
            "pgd l2: attack effectiveness 4.688%.\n",
            "pgd l1: attack effectiveness 35.938%.\n",
            "max: attack effectiveness 35.9375%.\n",
            "Mini batch: 1293/1450 | training time in 14 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0051 | Train accuracy: 90.10%.\n",
            "pgd linf: attack effectiveness 17.910%.\n",
            "pgd l2: attack effectiveness 13.433%.\n",
            "pgd l1: attack effectiveness 41.791%.\n",
            "max: attack effectiveness 41.7910447761194%.\n",
            "Mini batch: 1294/1450 | training time in 14 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0130 | Train accuracy: 88.72%.\n",
            "pgd linf: attack effectiveness 20.312%.\n",
            "pgd l2: attack effectiveness 3.125%.\n",
            "pgd l1: attack effectiveness 43.750%.\n",
            "max: attack effectiveness 43.75%.\n",
            "Mini batch: 1295/1450 | training time in 14 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0081 | Train accuracy: 86.46%.\n",
            "pgd linf: attack effectiveness 17.568%.\n",
            "pgd l2: attack effectiveness 20.270%.\n",
            "pgd l1: attack effectiveness 54.054%.\n",
            "max: attack effectiveness 54.054054054054056%.\n",
            "Mini batch: 1296/1450 | training time in 14 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0245 | Train accuracy: 83.17%.\n",
            "pgd linf: attack effectiveness 2.899%.\n",
            "pgd l2: attack effectiveness 11.594%.\n",
            "pgd l1: attack effectiveness 42.029%.\n",
            "max: attack effectiveness 42.028985507246375%.\n",
            "Mini batch: 1297/1450 | training time in 14 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0124 | Train accuracy: 87.82%.\n",
            "pgd linf: attack effectiveness 9.333%.\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "pgd l1: attack effectiveness 50.667%.\n",
            "max: attack effectiveness 50.66666666666667%.\n",
            "Mini batch: 1298/1450 | training time in 14 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0176 | Train accuracy: 85.71%.\n",
            "pgd linf: attack effectiveness 1.471%.\n",
            "pgd l2: attack effectiveness 16.176%.\n",
            "pgd l1: attack effectiveness 48.529%.\n",
            "max: attack effectiveness 48.529411764705884%.\n",
            "Mini batch: 1299/1450 | training time in 14 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0173 | Train accuracy: 86.73%.\n",
            "pgd linf: attack effectiveness 3.390%.\n",
            "pgd l2: attack effectiveness 16.949%.\n",
            "pgd l1: attack effectiveness 44.068%.\n",
            "max: attack effectiveness 44.06779661016949%.\n",
            "Mini batch: 1300/1450 | training time in 14 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0341 | Train accuracy: 89.84%.\n",
            "pgd linf: attack effectiveness 9.333%.\n",
            "pgd l2: attack effectiveness 1.333%.\n",
            "pgd l1: attack effectiveness 45.333%.\n",
            "max: attack effectiveness 45.33333333333333%.\n",
            "Mini batch: 1301/1450 | training time in 14 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0058 | Train accuracy: 89.66%.\n",
            "pgd linf: attack effectiveness 2.899%.\n",
            "pgd l2: attack effectiveness 7.246%.\n",
            "pgd l1: attack effectiveness 52.174%.\n",
            "max: attack effectiveness 52.17391304347826%.\n",
            "Mini batch: 1302/1450 | training time in 14 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0084 | Train accuracy: 87.31%.\n",
            "pgd linf: attack effectiveness 3.125%.\n",
            "pgd l2: attack effectiveness 7.812%.\n",
            "pgd l1: attack effectiveness 35.938%.\n",
            "max: attack effectiveness 35.9375%.\n",
            "Mini batch: 1303/1450 | training time in 14 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0133 | Train accuracy: 90.62%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 1.613%.\n",
            "pgd l1: attack effectiveness 38.710%.\n",
            "max: attack effectiveness 38.70967741935484%.\n",
            "Mini batch: 1304/1450 | training time in 14 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0056 | Train accuracy: 88.95%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 1305/1450 | training time in 14 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0033 | Train accuracy: 89.47%.\n",
            "Training loss (epoch level): 0.0131 | Train accuracy: 88.16\n",
            "pgd linf: attack effectiveness 1.971%.\n",
            "pgd l2: attack effectiveness 5.018%.\n",
            "pgd l1: attack effectiveness 52.688%.\n",
            "max: attack effectiveness 52.68817204301075%.\n",
            "\tVal accuracy 70.07% with accuracy 47.31% under attack.\n",
            "\tModel select at epoch 39 with validation accuracy 70.79% and accuracy 45.34% under attack.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 7.576%.\n",
            "pgd l1: attack effectiveness 39.394%.\n",
            "max: attack effectiveness 39.39393939393939%.\n",
            "Mini batch: 1306/1450 | training time in 14 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0151 | Train accuracy: 90.21%.\n",
            "pgd linf: attack effectiveness 1.587%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 44.444%.\n",
            "max: attack effectiveness 44.44444444444444%.\n",
            "Mini batch: 1307/1450 | training time in 14 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0111 | Train accuracy: 91.62%.\n",
            "pgd linf: attack effectiveness 3.030%.\n",
            "pgd l2: attack effectiveness 6.061%.\n",
            "pgd l1: attack effectiveness 40.909%.\n",
            "max: attack effectiveness 40.909090909090914%.\n",
            "Mini batch: 1308/1450 | training time in 14 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0203 | Train accuracy: 86.60%.\n",
            "pgd linf: attack effectiveness 2.857%.\n",
            "pgd l2: attack effectiveness 4.286%.\n",
            "pgd l1: attack effectiveness 44.286%.\n",
            "max: attack effectiveness 44.285714285714285%.\n",
            "Mini batch: 1309/1450 | training time in 14 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0102 | Train accuracy: 87.88%.\n",
            "pgd linf: attack effectiveness 4.225%.\n",
            "pgd l2: attack effectiveness 4.225%.\n",
            "pgd l1: attack effectiveness 49.296%.\n",
            "max: attack effectiveness 49.29577464788733%.\n",
            "Mini batch: 1310/1450 | training time in 14 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0097 | Train accuracy: 86.93%.\n",
            "pgd linf: attack effectiveness 1.316%.\n",
            "pgd l2: attack effectiveness 6.579%.\n",
            "pgd l1: attack effectiveness 46.053%.\n",
            "max: attack effectiveness 46.05263157894737%.\n",
            "Mini batch: 1311/1450 | training time in 14 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0096 | Train accuracy: 85.78%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 37.705%.\n",
            "max: attack effectiveness 37.704918032786885%.\n",
            "Mini batch: 1312/1450 | training time in 14 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0072 | Train accuracy: 93.12%.\n",
            "pgd linf: attack effectiveness 2.899%.\n",
            "pgd l2: attack effectiveness 4.348%.\n",
            "pgd l1: attack effectiveness 42.029%.\n",
            "max: attack effectiveness 42.028985507246375%.\n",
            "Mini batch: 1313/1450 | training time in 14 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0116 | Train accuracy: 87.31%.\n",
            "pgd linf: attack effectiveness 6.452%.\n",
            "pgd l2: attack effectiveness 4.839%.\n",
            "pgd l1: attack effectiveness 35.484%.\n",
            "max: attack effectiveness 35.483870967741936%.\n",
            "Mini batch: 1314/1450 | training time in 14 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0068 | Train accuracy: 90.00%.\n",
            "pgd linf: attack effectiveness 16.667%.\n",
            "pgd l2: attack effectiveness 11.667%.\n",
            "pgd l1: attack effectiveness 50.000%.\n",
            "max: attack effectiveness 50.0%.\n",
            "Mini batch: 1315/1450 | training time in 14 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0148 | Train accuracy: 87.77%.\n",
            "pgd linf: attack effectiveness 9.259%.\n",
            "pgd l2: attack effectiveness 7.407%.\n",
            "pgd l1: attack effectiveness 31.481%.\n",
            "max: attack effectiveness 35.18518518518518%.\n",
            "Mini batch: 1316/1450 | training time in 14 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0088 | Train accuracy: 92.86%.\n",
            "pgd linf: attack effectiveness 4.762%.\n",
            "pgd l2: attack effectiveness 11.111%.\n",
            "pgd l1: attack effectiveness 46.032%.\n",
            "max: attack effectiveness 49.2063492063492%.\n",
            "Mini batch: 1317/1450 | training time in 14 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0116 | Train accuracy: 86.91%.\n",
            "pgd linf: attack effectiveness 15.385%.\n",
            "pgd l2: attack effectiveness 12.308%.\n",
            "pgd l1: attack effectiveness 49.231%.\n",
            "max: attack effectiveness 50.76923076923077%.\n",
            "Mini batch: 1318/1450 | training time in 14 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0109 | Train accuracy: 85.49%.\n",
            "pgd linf: attack effectiveness 12.121%.\n",
            "pgd l2: attack effectiveness 7.576%.\n",
            "pgd l1: attack effectiveness 43.939%.\n",
            "max: attack effectiveness 43.93939393939394%.\n",
            "Mini batch: 1319/1450 | training time in 14 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0343 | Train accuracy: 88.14%.\n",
            "pgd linf: attack effectiveness 3.077%.\n",
            "pgd l2: attack effectiveness 4.615%.\n",
            "pgd l1: attack effectiveness 33.846%.\n",
            "max: attack effectiveness 35.38461538461539%.\n",
            "Mini batch: 1320/1450 | training time in 14 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0099 | Train accuracy: 93.78%.\n",
            "pgd linf: attack effectiveness 15.493%.\n",
            "pgd l2: attack effectiveness 7.042%.\n",
            "pgd l1: attack effectiveness 47.887%.\n",
            "max: attack effectiveness 50.70422535211267%.\n",
            "Mini batch: 1321/1450 | training time in 14 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0084 | Train accuracy: 86.43%.\n",
            "pgd linf: attack effectiveness 6.250%.\n",
            "pgd l2: attack effectiveness 3.125%.\n",
            "pgd l1: attack effectiveness 35.938%.\n",
            "max: attack effectiveness 35.9375%.\n",
            "Mini batch: 1322/1450 | training time in 14 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0067 | Train accuracy: 89.58%.\n",
            "pgd linf: attack effectiveness 8.955%.\n",
            "pgd l2: attack effectiveness 4.478%.\n",
            "pgd l1: attack effectiveness 38.806%.\n",
            "max: attack effectiveness 40.298507462686565%.\n",
            "Mini batch: 1323/1450 | training time in 14 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0084 | Train accuracy: 88.72%.\n",
            "pgd linf: attack effectiveness 10.938%.\n",
            "pgd l2: attack effectiveness 4.688%.\n",
            "pgd l1: attack effectiveness 42.188%.\n",
            "max: attack effectiveness 42.1875%.\n",
            "Mini batch: 1324/1450 | training time in 14 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0073 | Train accuracy: 88.02%.\n",
            "pgd linf: attack effectiveness 13.514%.\n",
            "pgd l2: attack effectiveness 14.865%.\n",
            "pgd l1: attack effectiveness 51.351%.\n",
            "max: attack effectiveness 51.35135135135135%.\n",
            "Mini batch: 1325/1450 | training time in 14 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0148 | Train accuracy: 82.67%.\n",
            "pgd linf: attack effectiveness 10.145%.\n",
            "pgd l2: attack effectiveness 8.696%.\n",
            "pgd l1: attack effectiveness 40.580%.\n",
            "max: attack effectiveness 42.028985507246375%.\n",
            "Mini batch: 1326/1450 | training time in 14 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0071 | Train accuracy: 86.80%.\n",
            "pgd linf: attack effectiveness 16.000%.\n",
            "pgd l2: attack effectiveness 12.000%.\n",
            "pgd l1: attack effectiveness 48.000%.\n",
            "max: attack effectiveness 49.333333333333336%.\n",
            "Mini batch: 1327/1450 | training time in 14 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0115 | Train accuracy: 86.70%.\n",
            "pgd linf: attack effectiveness 17.647%.\n",
            "pgd l2: attack effectiveness 4.412%.\n",
            "pgd l1: attack effectiveness 48.529%.\n",
            "max: attack effectiveness 48.529411764705884%.\n",
            "Mini batch: 1328/1450 | training time in 14 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0074 | Train accuracy: 84.69%.\n",
            "pgd linf: attack effectiveness 11.864%.\n",
            "pgd l2: attack effectiveness 10.169%.\n",
            "pgd l1: attack effectiveness 42.373%.\n",
            "max: attack effectiveness 42.3728813559322%.\n",
            "Mini batch: 1329/1450 | training time in 14 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0196 | Train accuracy: 89.84%.\n",
            "pgd linf: attack effectiveness 18.667%.\n",
            "pgd l2: attack effectiveness 1.333%.\n",
            "pgd l1: attack effectiveness 45.333%.\n",
            "max: attack effectiveness 45.33333333333333%.\n",
            "Mini batch: 1330/1450 | training time in 14 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0057 | Train accuracy: 87.19%.\n",
            "pgd linf: attack effectiveness 5.797%.\n",
            "pgd l2: attack effectiveness 8.696%.\n",
            "pgd l1: attack effectiveness 46.377%.\n",
            "max: attack effectiveness 46.3768115942029%.\n",
            "Mini batch: 1331/1450 | training time in 14 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0081 | Train accuracy: 87.82%.\n",
            "pgd linf: attack effectiveness 3.125%.\n",
            "pgd l2: attack effectiveness 9.375%.\n",
            "pgd l1: attack effectiveness 32.812%.\n",
            "max: attack effectiveness 32.8125%.\n",
            "Mini batch: 1332/1450 | training time in 14 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0210 | Train accuracy: 92.71%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 3.226%.\n",
            "pgd l1: attack effectiveness 38.710%.\n",
            "max: attack effectiveness 38.70967741935484%.\n",
            "Mini batch: 1333/1450 | training time in 14 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0065 | Train accuracy: 89.47%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 1334/1450 | training time in 14 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0027 | Train accuracy: 94.74%.\n",
            "Training loss (epoch level): 0.0113 | Train accuracy: 88.61\n",
            "pgd linf: attack effectiveness 4.480%.\n",
            "pgd l2: attack effectiveness 7.168%.\n",
            "pgd l1: attack effectiveness 52.688%.\n",
            "max: attack effectiveness 52.68817204301075%.\n",
            "\tVal accuracy 71.11% with accuracy 47.31% under attack.\n",
            "\tModel select at epoch 46 with validation accuracy 71.11% and accuracy 47.31% under attack.\n",
            "pgd linf: attack effectiveness 3.030%.\n",
            "pgd l2: attack effectiveness 10.606%.\n",
            "pgd l1: attack effectiveness 39.394%.\n",
            "max: attack effectiveness 42.42424242424242%.\n",
            "Mini batch: 1335/1450 | training time in 14 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0104 | Train accuracy: 86.08%.\n",
            "pgd linf: attack effectiveness 1.587%.\n",
            "pgd l2: attack effectiveness 1.587%.\n",
            "pgd l1: attack effectiveness 46.032%.\n",
            "max: attack effectiveness 46.03174603174603%.\n",
            "Mini batch: 1336/1450 | training time in 14 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0101 | Train accuracy: 90.58%.\n",
            "pgd linf: attack effectiveness 3.030%.\n",
            "pgd l2: attack effectiveness 9.091%.\n",
            "pgd l1: attack effectiveness 42.424%.\n",
            "max: attack effectiveness 42.42424242424242%.\n",
            "Mini batch: 1337/1450 | training time in 14 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0119 | Train accuracy: 87.63%.\n",
            "pgd linf: attack effectiveness 1.429%.\n",
            "pgd l2: attack effectiveness 8.571%.\n",
            "pgd l1: attack effectiveness 41.429%.\n",
            "max: attack effectiveness 41.42857142857143%.\n",
            "Mini batch: 1338/1450 | training time in 14 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0101 | Train accuracy: 88.38%.\n",
            "pgd linf: attack effectiveness 2.817%.\n",
            "pgd l2: attack effectiveness 2.817%.\n",
            "pgd l1: attack effectiveness 46.479%.\n",
            "max: attack effectiveness 46.478873239436616%.\n",
            "Mini batch: 1339/1450 | training time in 14 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0180 | Train accuracy: 86.93%.\n",
            "pgd linf: attack effectiveness 1.316%.\n",
            "pgd l2: attack effectiveness 9.211%.\n",
            "pgd l1: attack effectiveness 44.737%.\n",
            "max: attack effectiveness 44.73684210526316%.\n",
            "Mini batch: 1340/1450 | training time in 14 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0094 | Train accuracy: 86.27%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 1.639%.\n",
            "pgd l1: attack effectiveness 42.623%.\n",
            "max: attack effectiveness 42.62295081967213%.\n",
            "Mini batch: 1341/1450 | training time in 14 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0098 | Train accuracy: 87.83%.\n",
            "pgd linf: attack effectiveness 2.899%.\n",
            "pgd l2: attack effectiveness 2.899%.\n",
            "pgd l1: attack effectiveness 40.580%.\n",
            "max: attack effectiveness 40.57971014492754%.\n",
            "Mini batch: 1342/1450 | training time in 14 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0093 | Train accuracy: 87.82%.\n",
            "pgd linf: attack effectiveness 3.226%.\n",
            "pgd l2: attack effectiveness 16.129%.\n",
            "pgd l1: attack effectiveness 33.871%.\n",
            "max: attack effectiveness 33.87096774193548%.\n",
            "Mini batch: 1343/1450 | training time in 14 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0135 | Train accuracy: 90.53%.\n",
            "pgd linf: attack effectiveness 1.667%.\n",
            "pgd l2: attack effectiveness 6.667%.\n",
            "pgd l1: attack effectiveness 46.667%.\n",
            "max: attack effectiveness 46.666666666666664%.\n",
            "Mini batch: 1344/1450 | training time in 14 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0163 | Train accuracy: 87.23%.\n",
            "pgd linf: attack effectiveness 3.704%.\n",
            "pgd l2: attack effectiveness 3.704%.\n",
            "pgd l1: attack effectiveness 29.630%.\n",
            "max: attack effectiveness 29.629629629629626%.\n",
            "Mini batch: 1345/1450 | training time in 14 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0107 | Train accuracy: 91.76%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 46.032%.\n",
            "max: attack effectiveness 46.03174603174603%.\n",
            "Mini batch: 1346/1450 | training time in 14 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0100 | Train accuracy: 86.91%.\n",
            "pgd linf: attack effectiveness 6.154%.\n",
            "pgd l2: attack effectiveness 3.077%.\n",
            "pgd l1: attack effectiveness 50.769%.\n",
            "max: attack effectiveness 52.307692307692314%.\n",
            "Mini batch: 1347/1450 | training time in 14 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0073 | Train accuracy: 85.49%.\n",
            "pgd linf: attack effectiveness 4.545%.\n",
            "pgd l2: attack effectiveness 1.515%.\n",
            "pgd l1: attack effectiveness 45.455%.\n",
            "max: attack effectiveness 45.45454545454545%.\n",
            "Mini batch: 1348/1450 | training time in 14 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0466 | Train accuracy: 86.60%.\n",
            "pgd linf: attack effectiveness 3.077%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 36.923%.\n",
            "max: attack effectiveness 36.92307692307693%.\n",
            "Mini batch: 1349/1450 | training time in 14 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0135 | Train accuracy: 90.67%.\n",
            "pgd linf: attack effectiveness 4.225%.\n",
            "pgd l2: attack effectiveness 2.817%.\n",
            "pgd l1: attack effectiveness 49.296%.\n",
            "max: attack effectiveness 49.29577464788733%.\n",
            "Mini batch: 1350/1450 | training time in 14 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0075 | Train accuracy: 86.93%.\n",
            "pgd linf: attack effectiveness 3.125%.\n",
            "pgd l2: attack effectiveness 6.250%.\n",
            "pgd l1: attack effectiveness 39.062%.\n",
            "max: attack effectiveness 39.0625%.\n",
            "Mini batch: 1351/1450 | training time in 14 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0059 | Train accuracy: 89.06%.\n",
            "pgd linf: attack effectiveness 10.448%.\n",
            "pgd l2: attack effectiveness 2.985%.\n",
            "pgd l1: attack effectiveness 37.313%.\n",
            "max: attack effectiveness 37.3134328358209%.\n",
            "Mini batch: 1352/1450 | training time in 14 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0113 | Train accuracy: 90.26%.\n",
            "pgd linf: attack effectiveness 12.500%.\n",
            "pgd l2: attack effectiveness 1.562%.\n",
            "pgd l1: attack effectiveness 45.312%.\n",
            "max: attack effectiveness 45.3125%.\n",
            "Mini batch: 1353/1450 | training time in 14 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0077 | Train accuracy: 90.62%.\n",
            "pgd linf: attack effectiveness 17.568%.\n",
            "pgd l2: attack effectiveness 4.054%.\n",
            "pgd l1: attack effectiveness 54.054%.\n",
            "max: attack effectiveness 54.054054054054056%.\n",
            "Mini batch: 1354/1450 | training time in 14 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0148 | Train accuracy: 85.15%.\n",
            "pgd linf: attack effectiveness 10.145%.\n",
            "pgd l2: attack effectiveness 8.696%.\n",
            "pgd l1: attack effectiveness 42.029%.\n",
            "max: attack effectiveness 42.028985507246375%.\n",
            "Mini batch: 1355/1450 | training time in 14 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0080 | Train accuracy: 88.83%.\n",
            "pgd linf: attack effectiveness 8.000%.\n",
            "pgd l2: attack effectiveness 14.667%.\n",
            "pgd l1: attack effectiveness 49.333%.\n",
            "max: attack effectiveness 49.333333333333336%.\n",
            "Mini batch: 1356/1450 | training time in 14 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0179 | Train accuracy: 84.24%.\n",
            "pgd linf: attack effectiveness 8.824%.\n",
            "pgd l2: attack effectiveness 10.294%.\n",
            "pgd l1: attack effectiveness 48.529%.\n",
            "max: attack effectiveness 48.529411764705884%.\n",
            "Mini batch: 1357/1450 | training time in 14 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0076 | Train accuracy: 86.73%.\n",
            "pgd linf: attack effectiveness 10.169%.\n",
            "pgd l2: attack effectiveness 6.780%.\n",
            "pgd l1: attack effectiveness 42.373%.\n",
            "max: attack effectiveness 42.3728813559322%.\n",
            "Mini batch: 1358/1450 | training time in 14 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0246 | Train accuracy: 87.70%.\n",
            "pgd linf: attack effectiveness 4.000%.\n",
            "pgd l2: attack effectiveness 4.000%.\n",
            "pgd l1: attack effectiveness 45.333%.\n",
            "max: attack effectiveness 45.33333333333333%.\n",
            "Mini batch: 1359/1450 | training time in 14 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0067 | Train accuracy: 86.21%.\n",
            "pgd linf: attack effectiveness 17.391%.\n",
            "pgd l2: attack effectiveness 5.797%.\n",
            "pgd l1: attack effectiveness 46.377%.\n",
            "max: attack effectiveness 46.3768115942029%.\n",
            "Mini batch: 1360/1450 | training time in 14 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0123 | Train accuracy: 86.29%.\n",
            "pgd linf: attack effectiveness 9.375%.\n",
            "pgd l2: attack effectiveness 6.250%.\n",
            "pgd l1: attack effectiveness 32.812%.\n",
            "max: attack effectiveness 32.8125%.\n",
            "Mini batch: 1361/1450 | training time in 14 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0128 | Train accuracy: 89.58%.\n",
            "pgd linf: attack effectiveness 12.903%.\n",
            "pgd l2: attack effectiveness 4.839%.\n",
            "pgd l1: attack effectiveness 38.710%.\n",
            "max: attack effectiveness 38.70967741935484%.\n",
            "Mini batch: 1362/1450 | training time in 14 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0090 | Train accuracy: 90.53%.\n",
            "pgd linf: attack effectiveness 16.667%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 1363/1450 | training time in 14 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0026 | Train accuracy: 94.74%.\n",
            "Training loss (epoch level): 0.0123 | Train accuracy: 88.19\n",
            "pgd linf: attack effectiveness 13.799%.\n",
            "pgd l2: attack effectiveness 7.706%.\n",
            "pgd l1: attack effectiveness 52.509%.\n",
            "max: attack effectiveness 52.508960573476706%.\n",
            "\tVal accuracy 70.99% with accuracy 47.49% under attack.\n",
            "\tModel select at epoch 46 with validation accuracy 71.11% and accuracy 47.31% under attack.\n",
            "pgd linf: attack effectiveness 12.121%.\n",
            "pgd l2: attack effectiveness 6.061%.\n",
            "pgd l1: attack effectiveness 40.909%.\n",
            "max: attack effectiveness 40.909090909090914%.\n",
            "Mini batch: 1364/1450 | training time in 14 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0082 | Train accuracy: 90.21%.\n",
            "pgd linf: attack effectiveness 15.873%.\n",
            "pgd l2: attack effectiveness 4.762%.\n",
            "pgd l1: attack effectiveness 44.444%.\n",
            "max: attack effectiveness 44.44444444444444%.\n",
            "Mini batch: 1365/1450 | training time in 15 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0093 | Train accuracy: 87.96%.\n",
            "pgd linf: attack effectiveness 9.091%.\n",
            "pgd l2: attack effectiveness 7.576%.\n",
            "pgd l1: attack effectiveness 42.424%.\n",
            "max: attack effectiveness 42.42424242424242%.\n",
            "Mini batch: 1366/1450 | training time in 15 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0167 | Train accuracy: 89.18%.\n",
            "pgd linf: attack effectiveness 4.286%.\n",
            "pgd l2: attack effectiveness 10.000%.\n",
            "pgd l1: attack effectiveness 42.857%.\n",
            "max: attack effectiveness 42.857142857142854%.\n",
            "Mini batch: 1367/1450 | training time in 15 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0080 | Train accuracy: 87.88%.\n",
            "pgd linf: attack effectiveness 8.451%.\n",
            "pgd l2: attack effectiveness 4.225%.\n",
            "pgd l1: attack effectiveness 45.070%.\n",
            "max: attack effectiveness 45.07042253521127%.\n",
            "Mini batch: 1368/1450 | training time in 15 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0095 | Train accuracy: 87.44%.\n",
            "pgd linf: attack effectiveness 5.263%.\n",
            "pgd l2: attack effectiveness 10.526%.\n",
            "pgd l1: attack effectiveness 44.737%.\n",
            "max: attack effectiveness 44.73684210526316%.\n",
            "Mini batch: 1369/1450 | training time in 15 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0118 | Train accuracy: 85.29%.\n",
            "pgd linf: attack effectiveness 1.639%.\n",
            "pgd l2: attack effectiveness 1.639%.\n",
            "pgd l1: attack effectiveness 37.705%.\n",
            "max: attack effectiveness 37.704918032786885%.\n",
            "Mini batch: 1370/1450 | training time in 15 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0092 | Train accuracy: 91.53%.\n",
            "pgd linf: attack effectiveness 1.449%.\n",
            "pgd l2: attack effectiveness 10.145%.\n",
            "pgd l1: attack effectiveness 39.130%.\n",
            "max: attack effectiveness 40.57971014492754%.\n",
            "Mini batch: 1371/1450 | training time in 15 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0096 | Train accuracy: 89.85%.\n",
            "pgd linf: attack effectiveness 3.226%.\n",
            "pgd l2: attack effectiveness 3.226%.\n",
            "pgd l1: attack effectiveness 32.258%.\n",
            "max: attack effectiveness 32.25806451612903%.\n",
            "Mini batch: 1372/1450 | training time in 15 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0081 | Train accuracy: 92.63%.\n",
            "pgd linf: attack effectiveness 3.333%.\n",
            "pgd l2: attack effectiveness 8.333%.\n",
            "pgd l1: attack effectiveness 41.667%.\n",
            "max: attack effectiveness 41.66666666666667%.\n",
            "Mini batch: 1373/1450 | training time in 15 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0150 | Train accuracy: 88.30%.\n",
            "pgd linf: attack effectiveness 1.852%.\n",
            "pgd l2: attack effectiveness 3.704%.\n",
            "pgd l1: attack effectiveness 29.630%.\n",
            "max: attack effectiveness 29.629629629629626%.\n",
            "Mini batch: 1374/1450 | training time in 15 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0117 | Train accuracy: 91.76%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 4.762%.\n",
            "pgd l1: attack effectiveness 42.857%.\n",
            "max: attack effectiveness 42.857142857142854%.\n",
            "Mini batch: 1375/1450 | training time in 15 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0058 | Train accuracy: 90.58%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 3.077%.\n",
            "pgd l1: attack effectiveness 46.154%.\n",
            "max: attack effectiveness 46.15384615384615%.\n",
            "Mini batch: 1376/1450 | training time in 15 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0074 | Train accuracy: 88.60%.\n",
            "pgd linf: attack effectiveness 4.545%.\n",
            "pgd l2: attack effectiveness 1.515%.\n",
            "pgd l1: attack effectiveness 42.424%.\n",
            "max: attack effectiveness 42.42424242424242%.\n",
            "Mini batch: 1377/1450 | training time in 15 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0254 | Train accuracy: 87.11%.\n",
            "pgd linf: attack effectiveness 1.538%.\n",
            "pgd l2: attack effectiveness 3.077%.\n",
            "pgd l1: attack effectiveness 36.923%.\n",
            "max: attack effectiveness 36.92307692307693%.\n",
            "Mini batch: 1378/1450 | training time in 15 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0096 | Train accuracy: 91.19%.\n",
            "pgd linf: attack effectiveness 2.817%.\n",
            "pgd l2: attack effectiveness 2.817%.\n",
            "pgd l1: attack effectiveness 42.254%.\n",
            "max: attack effectiveness 42.25352112676056%.\n",
            "Mini batch: 1379/1450 | training time in 15 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0070 | Train accuracy: 92.46%.\n",
            "pgd linf: attack effectiveness 1.562%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 34.375%.\n",
            "max: attack effectiveness 34.375%.\n",
            "Mini batch: 1380/1450 | training time in 15 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0082 | Train accuracy: 90.62%.\n",
            "pgd linf: attack effectiveness 4.478%.\n",
            "pgd l2: attack effectiveness 1.493%.\n",
            "pgd l1: attack effectiveness 35.821%.\n",
            "max: attack effectiveness 35.82089552238806%.\n",
            "Mini batch: 1381/1450 | training time in 15 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0104 | Train accuracy: 93.33%.\n",
            "pgd linf: attack effectiveness 7.812%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 42.188%.\n",
            "max: attack effectiveness 42.1875%.\n",
            "Mini batch: 1382/1450 | training time in 15 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0133 | Train accuracy: 89.58%.\n",
            "pgd linf: attack effectiveness 4.054%.\n",
            "pgd l2: attack effectiveness 2.703%.\n",
            "pgd l1: attack effectiveness 51.351%.\n",
            "max: attack effectiveness 51.35135135135135%.\n",
            "Mini batch: 1383/1450 | training time in 15 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0154 | Train accuracy: 83.66%.\n",
            "pgd linf: attack effectiveness 11.594%.\n",
            "pgd l2: attack effectiveness 2.899%.\n",
            "pgd l1: attack effectiveness 40.580%.\n",
            "max: attack effectiveness 40.57971014492754%.\n",
            "Mini batch: 1384/1450 | training time in 15 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0070 | Train accuracy: 87.31%.\n",
            "pgd linf: attack effectiveness 14.667%.\n",
            "pgd l2: attack effectiveness 4.000%.\n",
            "pgd l1: attack effectiveness 49.333%.\n",
            "max: attack effectiveness 49.333333333333336%.\n",
            "Mini batch: 1385/1450 | training time in 15 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0089 | Train accuracy: 86.70%.\n",
            "pgd linf: attack effectiveness 16.176%.\n",
            "pgd l2: attack effectiveness 8.824%.\n",
            "pgd l1: attack effectiveness 48.529%.\n",
            "max: attack effectiveness 48.529411764705884%.\n",
            "Mini batch: 1386/1450 | training time in 15 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0125 | Train accuracy: 84.18%.\n",
            "pgd linf: attack effectiveness 16.949%.\n",
            "pgd l2: attack effectiveness 6.780%.\n",
            "pgd l1: attack effectiveness 45.763%.\n",
            "max: attack effectiveness 47.45762711864407%.\n",
            "Mini batch: 1387/1450 | training time in 15 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0261 | Train accuracy: 87.17%.\n",
            "pgd linf: attack effectiveness 8.000%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 45.333%.\n",
            "max: attack effectiveness 45.33333333333333%.\n",
            "Mini batch: 1388/1450 | training time in 15 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0050 | Train accuracy: 83.74%.\n",
            "pgd linf: attack effectiveness 2.899%.\n",
            "pgd l2: attack effectiveness 4.348%.\n",
            "pgd l1: attack effectiveness 52.174%.\n",
            "max: attack effectiveness 52.17391304347826%.\n",
            "Mini batch: 1389/1450 | training time in 15 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0070 | Train accuracy: 87.82%.\n",
            "pgd linf: attack effectiveness 1.562%.\n",
            "pgd l2: attack effectiveness 3.125%.\n",
            "pgd l1: attack effectiveness 34.375%.\n",
            "max: attack effectiveness 34.375%.\n",
            "Mini batch: 1390/1450 | training time in 15 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0206 | Train accuracy: 89.58%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 1.613%.\n",
            "pgd l1: attack effectiveness 40.323%.\n",
            "max: attack effectiveness 40.32258064516129%.\n",
            "Mini batch: 1391/1450 | training time in 15 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0064 | Train accuracy: 88.42%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 1392/1450 | training time in 15 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0108 | Train accuracy: 89.11\n",
            "pgd linf: attack effectiveness 3.943%.\n",
            "pgd l2: attack effectiveness 5.018%.\n",
            "pgd l1: attack effectiveness 52.509%.\n",
            "max: attack effectiveness 52.68817204301075%.\n",
            "\tVal accuracy 71.11% with accuracy 47.31% under attack.\n",
            "\tModel select at epoch 48 with validation accuracy 71.11% and accuracy 47.31% under attack.\n",
            "pgd linf: attack effectiveness 3.030%.\n",
            "pgd l2: attack effectiveness 3.030%.\n",
            "pgd l1: attack effectiveness 40.909%.\n",
            "max: attack effectiveness 40.909090909090914%.\n",
            "Mini batch: 1393/1450 | training time in 15 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0073 | Train accuracy: 88.14%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 46.032%.\n",
            "max: attack effectiveness 46.03174603174603%.\n",
            "Mini batch: 1394/1450 | training time in 15 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0082 | Train accuracy: 90.58%.\n",
            "pgd linf: attack effectiveness 3.030%.\n",
            "pgd l2: attack effectiveness 6.061%.\n",
            "pgd l1: attack effectiveness 40.909%.\n",
            "max: attack effectiveness 40.909090909090914%.\n",
            "Mini batch: 1395/1450 | training time in 15 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0079 | Train accuracy: 89.18%.\n",
            "pgd linf: attack effectiveness 1.429%.\n",
            "pgd l2: attack effectiveness 1.429%.\n",
            "pgd l1: attack effectiveness 41.429%.\n",
            "max: attack effectiveness 41.42857142857143%.\n",
            "Mini batch: 1396/1450 | training time in 15 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0078 | Train accuracy: 89.39%.\n",
            "pgd linf: attack effectiveness 2.817%.\n",
            "pgd l2: attack effectiveness 4.225%.\n",
            "pgd l1: attack effectiveness 43.662%.\n",
            "max: attack effectiveness 43.66197183098591%.\n",
            "Mini batch: 1397/1450 | training time in 15 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0205 | Train accuracy: 86.93%.\n",
            "pgd linf: attack effectiveness 5.263%.\n",
            "pgd l2: attack effectiveness 15.789%.\n",
            "pgd l1: attack effectiveness 42.105%.\n",
            "max: attack effectiveness 42.10526315789473%.\n",
            "Mini batch: 1398/1450 | training time in 15 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0081 | Train accuracy: 88.73%.\n",
            "pgd linf: attack effectiveness 4.918%.\n",
            "pgd l2: attack effectiveness 4.918%.\n",
            "pgd l1: attack effectiveness 37.705%.\n",
            "max: attack effectiveness 37.704918032786885%.\n",
            "Mini batch: 1399/1450 | training time in 15 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0092 | Train accuracy: 90.48%.\n",
            "pgd linf: attack effectiveness 2.899%.\n",
            "pgd l2: attack effectiveness 7.246%.\n",
            "pgd l1: attack effectiveness 40.580%.\n",
            "max: attack effectiveness 40.57971014492754%.\n",
            "Mini batch: 1400/1450 | training time in 15 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0082 | Train accuracy: 87.82%.\n",
            "pgd linf: attack effectiveness 6.452%.\n",
            "pgd l2: attack effectiveness 16.129%.\n",
            "pgd l1: attack effectiveness 32.258%.\n",
            "max: attack effectiveness 32.25806451612903%.\n",
            "Mini batch: 1401/1450 | training time in 15 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0129 | Train accuracy: 89.47%.\n",
            "pgd linf: attack effectiveness 5.000%.\n",
            "pgd l2: attack effectiveness 3.333%.\n",
            "pgd l1: attack effectiveness 46.667%.\n",
            "max: attack effectiveness 46.666666666666664%.\n",
            "Mini batch: 1402/1450 | training time in 15 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0129 | Train accuracy: 88.30%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 7.407%.\n",
            "pgd l1: attack effectiveness 29.630%.\n",
            "max: attack effectiveness 29.629629629629626%.\n",
            "Mini batch: 1403/1450 | training time in 15 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0087 | Train accuracy: 93.96%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 22.222%.\n",
            "pgd l1: attack effectiveness 46.032%.\n",
            "max: attack effectiveness 46.03174603174603%.\n",
            "Mini batch: 1404/1450 | training time in 15 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0077 | Train accuracy: 85.86%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 12.308%.\n",
            "pgd l1: attack effectiveness 46.154%.\n",
            "max: attack effectiveness 46.15384615384615%.\n",
            "Mini batch: 1405/1450 | training time in 15 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0059 | Train accuracy: 87.56%.\n",
            "pgd linf: attack effectiveness 3.030%.\n",
            "pgd l2: attack effectiveness 7.576%.\n",
            "pgd l1: attack effectiveness 42.424%.\n",
            "max: attack effectiveness 42.42424242424242%.\n",
            "Mini batch: 1406/1450 | training time in 15 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0266 | Train accuracy: 87.63%.\n",
            "pgd linf: attack effectiveness 1.538%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 36.923%.\n",
            "max: attack effectiveness 36.92307692307693%.\n",
            "Mini batch: 1407/1450 | training time in 15 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0128 | Train accuracy: 89.64%.\n",
            "pgd linf: attack effectiveness 4.225%.\n",
            "pgd l2: attack effectiveness 7.042%.\n",
            "pgd l1: attack effectiveness 45.070%.\n",
            "max: attack effectiveness 45.07042253521127%.\n",
            "Mini batch: 1408/1450 | training time in 15 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0074 | Train accuracy: 88.44%.\n",
            "pgd linf: attack effectiveness 1.562%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 35.938%.\n",
            "max: attack effectiveness 35.9375%.\n",
            "Mini batch: 1409/1450 | training time in 15 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0064 | Train accuracy: 91.15%.\n",
            "pgd linf: attack effectiveness 1.493%.\n",
            "pgd l2: attack effectiveness 2.985%.\n",
            "pgd l1: attack effectiveness 34.328%.\n",
            "max: attack effectiveness 34.32835820895522%.\n",
            "Mini batch: 1410/1450 | training time in 15 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0097 | Train accuracy: 92.31%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 1.562%.\n",
            "pgd l1: attack effectiveness 40.625%.\n",
            "max: attack effectiveness 40.625%.\n",
            "Mini batch: 1411/1450 | training time in 15 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0067 | Train accuracy: 89.58%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 4.054%.\n",
            "pgd l1: attack effectiveness 52.703%.\n",
            "max: attack effectiveness 52.702702702702695%.\n",
            "Mini batch: 1412/1450 | training time in 15 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0121 | Train accuracy: 86.63%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 1.449%.\n",
            "pgd l1: attack effectiveness 39.130%.\n",
            "max: attack effectiveness 39.130434782608695%.\n",
            "Mini batch: 1413/1450 | training time in 15 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0075 | Train accuracy: 86.29%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 1.333%.\n",
            "pgd l1: attack effectiveness 49.333%.\n",
            "max: attack effectiveness 49.333333333333336%.\n",
            "Mini batch: 1414/1450 | training time in 15 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0067 | Train accuracy: 84.24%.\n",
            "pgd linf: attack effectiveness 2.941%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 48.529%.\n",
            "max: attack effectiveness 48.529411764705884%.\n",
            "Mini batch: 1415/1450 | training time in 15 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0054 | Train accuracy: 88.78%.\n",
            "pgd linf: attack effectiveness 1.695%.\n",
            "pgd l2: attack effectiveness 8.475%.\n",
            "pgd l1: attack effectiveness 44.068%.\n",
            "max: attack effectiveness 44.06779661016949%.\n",
            "Mini batch: 1416/1450 | training time in 15 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0282 | Train accuracy: 87.17%.\n",
            "pgd linf: attack effectiveness 5.333%.\n",
            "pgd l2: attack effectiveness 4.000%.\n",
            "pgd l1: attack effectiveness 45.333%.\n",
            "max: attack effectiveness 45.33333333333333%.\n",
            "Mini batch: 1417/1450 | training time in 15 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0070 | Train accuracy: 87.19%.\n",
            "pgd linf: attack effectiveness 1.449%.\n",
            "pgd l2: attack effectiveness 4.348%.\n",
            "pgd l1: attack effectiveness 46.377%.\n",
            "max: attack effectiveness 46.3768115942029%.\n",
            "Mini batch: 1418/1450 | training time in 15 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0072 | Train accuracy: 87.31%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 4.688%.\n",
            "pgd l1: attack effectiveness 35.938%.\n",
            "max: attack effectiveness 35.9375%.\n",
            "Mini batch: 1419/1450 | training time in 15 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0249 | Train accuracy: 90.62%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 1.613%.\n",
            "pgd l1: attack effectiveness 40.323%.\n",
            "max: attack effectiveness 40.32258064516129%.\n",
            "Mini batch: 1420/1450 | training time in 15 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0086 | Train accuracy: 89.47%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 1421/1450 | training time in 15 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0049 | Train accuracy: 89.47%.\n",
            "Training loss (epoch level): 0.0106 | Train accuracy: 88.70\n",
            "pgd linf: attack effectiveness 4.659%.\n",
            "pgd l2: attack effectiveness 8.781%.\n",
            "pgd l1: attack effectiveness 52.867%.\n",
            "max: attack effectiveness 52.867383512544805%.\n",
            "\tVal accuracy 71.44% with accuracy 47.13% under attack.\n",
            "\tModel select at epoch 49 with validation accuracy 71.44% and accuracy 47.13% under attack.\n",
            "pgd linf: attack effectiveness 1.515%.\n",
            "pgd l2: attack effectiveness 7.576%.\n",
            "pgd l1: attack effectiveness 42.424%.\n",
            "max: attack effectiveness 42.42424242424242%.\n",
            "Mini batch: 1422/1450 | training time in 15 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0066 | Train accuracy: 88.66%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 4.762%.\n",
            "pgd l1: attack effectiveness 44.444%.\n",
            "max: attack effectiveness 44.44444444444444%.\n",
            "Mini batch: 1423/1450 | training time in 15 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0109 | Train accuracy: 88.48%.\n",
            "pgd linf: attack effectiveness 1.515%.\n",
            "pgd l2: attack effectiveness 9.091%.\n",
            "pgd l1: attack effectiveness 42.424%.\n",
            "max: attack effectiveness 42.42424242424242%.\n",
            "Mini batch: 1424/1450 | training time in 15 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0084 | Train accuracy: 89.69%.\n",
            "pgd linf: attack effectiveness 2.857%.\n",
            "pgd l2: attack effectiveness 11.429%.\n",
            "pgd l1: attack effectiveness 44.286%.\n",
            "max: attack effectiveness 44.285714285714285%.\n",
            "Mini batch: 1425/1450 | training time in 15 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0094 | Train accuracy: 86.87%.\n",
            "pgd linf: attack effectiveness 2.817%.\n",
            "pgd l2: attack effectiveness 2.817%.\n",
            "pgd l1: attack effectiveness 45.070%.\n",
            "max: attack effectiveness 45.07042253521127%.\n",
            "Mini batch: 1426/1450 | training time in 15 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0118 | Train accuracy: 90.45%.\n",
            "pgd linf: attack effectiveness 2.632%.\n",
            "pgd l2: attack effectiveness 21.053%.\n",
            "pgd l1: attack effectiveness 42.105%.\n",
            "max: attack effectiveness 42.10526315789473%.\n",
            "Mini batch: 1427/1450 | training time in 15 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0090 | Train accuracy: 87.75%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 3.279%.\n",
            "pgd l1: attack effectiveness 36.066%.\n",
            "max: attack effectiveness 36.0655737704918%.\n",
            "Mini batch: 1428/1450 | training time in 15 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0146 | Train accuracy: 92.06%.\n",
            "pgd linf: attack effectiveness 2.899%.\n",
            "pgd l2: attack effectiveness 5.797%.\n",
            "pgd l1: attack effectiveness 39.130%.\n",
            "max: attack effectiveness 39.130434782608695%.\n",
            "Mini batch: 1429/1450 | training time in 15 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0104 | Train accuracy: 90.36%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 4.839%.\n",
            "pgd l1: attack effectiveness 32.258%.\n",
            "max: attack effectiveness 32.25806451612903%.\n",
            "Mini batch: 1430/1450 | training time in 15 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0070 | Train accuracy: 91.58%.\n",
            "pgd linf: attack effectiveness 8.333%.\n",
            "pgd l2: attack effectiveness 6.667%.\n",
            "pgd l1: attack effectiveness 46.667%.\n",
            "max: attack effectiveness 46.666666666666664%.\n",
            "Mini batch: 1431/1450 | training time in 15 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0175 | Train accuracy: 90.43%.\n",
            "pgd linf: attack effectiveness 7.407%.\n",
            "pgd l2: attack effectiveness 1.852%.\n",
            "pgd l1: attack effectiveness 31.481%.\n",
            "max: attack effectiveness 31.48148148148148%.\n",
            "Mini batch: 1432/1450 | training time in 15 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0079 | Train accuracy: 92.86%.\n",
            "pgd linf: attack effectiveness 3.175%.\n",
            "pgd l2: attack effectiveness 6.349%.\n",
            "pgd l1: attack effectiveness 44.444%.\n",
            "max: attack effectiveness 44.44444444444444%.\n",
            "Mini batch: 1433/1450 | training time in 15 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0050 | Train accuracy: 90.58%.\n",
            "pgd linf: attack effectiveness 1.538%.\n",
            "pgd l2: attack effectiveness 4.615%.\n",
            "pgd l1: attack effectiveness 46.154%.\n",
            "max: attack effectiveness 46.15384615384615%.\n",
            "Mini batch: 1434/1450 | training time in 15 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0050 | Train accuracy: 87.56%.\n",
            "pgd linf: attack effectiveness 3.030%.\n",
            "pgd l2: attack effectiveness 9.091%.\n",
            "pgd l1: attack effectiveness 42.424%.\n",
            "max: attack effectiveness 42.42424242424242%.\n",
            "Mini batch: 1435/1450 | training time in 15 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0198 | Train accuracy: 89.18%.\n",
            "pgd linf: attack effectiveness 3.077%.\n",
            "pgd l2: attack effectiveness 1.538%.\n",
            "pgd l1: attack effectiveness 40.000%.\n",
            "max: attack effectiveness 40.0%.\n",
            "Mini batch: 1436/1450 | training time in 15 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0087 | Train accuracy: 88.08%.\n",
            "pgd linf: attack effectiveness 1.408%.\n",
            "pgd l2: attack effectiveness 2.817%.\n",
            "pgd l1: attack effectiveness 47.887%.\n",
            "max: attack effectiveness 47.88732394366197%.\n",
            "Mini batch: 1437/1450 | training time in 15 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0064 | Train accuracy: 86.43%.\n",
            "pgd linf: attack effectiveness 1.562%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 35.938%.\n",
            "max: attack effectiveness 35.9375%.\n",
            "Mini batch: 1438/1450 | training time in 15 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0053 | Train accuracy: 91.15%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 1.493%.\n",
            "pgd l1: attack effectiveness 35.821%.\n",
            "max: attack effectiveness 35.82089552238806%.\n",
            "Mini batch: 1439/1450 | training time in 15 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0099 | Train accuracy: 91.79%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 42.188%.\n",
            "max: attack effectiveness 42.1875%.\n",
            "Mini batch: 1440/1450 | training time in 15 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0111 | Train accuracy: 91.15%.\n",
            "pgd linf: attack effectiveness 1.351%.\n",
            "pgd l2: attack effectiveness 6.757%.\n",
            "pgd l1: attack effectiveness 52.703%.\n",
            "max: attack effectiveness 52.702702702702695%.\n",
            "Mini batch: 1441/1450 | training time in 15 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0172 | Train accuracy: 85.15%.\n",
            "pgd linf: attack effectiveness 1.449%.\n",
            "pgd l2: attack effectiveness 4.348%.\n",
            "pgd l1: attack effectiveness 42.029%.\n",
            "max: attack effectiveness 42.028985507246375%.\n",
            "Mini batch: 1442/1450 | training time in 15 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0074 | Train accuracy: 88.83%.\n",
            "pgd linf: attack effectiveness 2.667%.\n",
            "pgd l2: attack effectiveness 9.333%.\n",
            "pgd l1: attack effectiveness 50.667%.\n",
            "max: attack effectiveness 50.66666666666667%.\n",
            "Mini batch: 1443/1450 | training time in 15 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0114 | Train accuracy: 84.24%.\n",
            "pgd linf: attack effectiveness 1.471%.\n",
            "pgd l2: attack effectiveness 1.471%.\n",
            "pgd l1: attack effectiveness 47.059%.\n",
            "max: attack effectiveness 47.05882352941176%.\n",
            "Mini batch: 1444/1450 | training time in 15 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0055 | Train accuracy: 87.76%.\n",
            "pgd linf: attack effectiveness 3.390%.\n",
            "pgd l2: attack effectiveness 3.390%.\n",
            "pgd l1: attack effectiveness 45.763%.\n",
            "max: attack effectiveness 45.76271186440678%.\n",
            "Mini batch: 1445/1450 | training time in 15 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0257 | Train accuracy: 87.17%.\n",
            "pgd linf: attack effectiveness 2.667%.\n",
            "pgd l2: attack effectiveness 2.667%.\n",
            "pgd l1: attack effectiveness 46.667%.\n",
            "max: attack effectiveness 46.666666666666664%.\n",
            "Mini batch: 1446/1450 | training time in 15 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0062 | Train accuracy: 84.24%.\n",
            "pgd linf: attack effectiveness 2.899%.\n",
            "pgd l2: attack effectiveness 7.246%.\n",
            "pgd l1: attack effectiveness 52.174%.\n",
            "max: attack effectiveness 52.17391304347826%.\n",
            "Mini batch: 1447/1450 | training time in 15 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0092 | Train accuracy: 86.80%.\n",
            "pgd linf: attack effectiveness 1.562%.\n",
            "pgd l2: attack effectiveness 6.250%.\n",
            "pgd l1: attack effectiveness 34.375%.\n",
            "max: attack effectiveness 34.375%.\n",
            "Mini batch: 1448/1450 | training time in 15 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0194 | Train accuracy: 90.62%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 1.613%.\n",
            "pgd l1: attack effectiveness 38.710%.\n",
            "max: attack effectiveness 38.70967741935484%.\n",
            "Mini batch: 1449/1450 | training time in 15 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0057 | Train accuracy: 91.05%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 33.333%.\n",
            "max: attack effectiveness 33.33333333333333%.\n",
            "Mini batch: 1450/1450 | training time in 15 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0032 | Train accuracy: 94.74%.\n",
            "Training loss (epoch level): 0.0102 | Train accuracy: 89.16\n",
            "pgd linf: attack effectiveness 3.226%.\n",
            "pgd l2: attack effectiveness 5.376%.\n",
            "pgd l1: attack effectiveness 53.405%.\n",
            "max: attack effectiveness 53.40501792114696%.\n",
            "\tVal accuracy 70.8% with accuracy 46.59% under attack.\n",
            "\tModel select at epoch 49 with validation accuracy 71.44% and accuracy 47.13% under attack.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test: accuracy\n",
        "max_adv_training_model.load()\n",
        "max_adv_training_model.model.predict(test_Loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBkbsgabWKN1",
        "outputId": "e38e9e0e-7fe0-4789-c535-062cf11f4957"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy on the test dataset is 94.82902%\n",
            "The balanced accuracy on the test dataset is 94.94216%\n",
            "Other evaluation metrics we may need:\n",
            "False Negative Rate (FNR) is 1.90311%, False Positive Rate (FPR) is 8.21256%, F1 score is 94.81605%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/malware_detection"
      ],
      "metadata": {
        "id": "V5i4V5h61BLr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc28b6e9-55a7-40a4-f05e-5060018e0f63"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/malware_detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m examples.md_at_ma_test --cuda --cache --beta 0.01 --seed 0 --batch_size 128 --proc_number 2 --epochs 50 --max_vocab_size 10000 --dense_hidden_units \"200,200\" --weight_decay 0.0 --lr 0.001 --dropout 0.6  --ma \"max\" --steps_l1 50 --steps_linf 50 --step_length_linf 0.02 --steps_l2 50 --step_length_l2 0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTTMIue5HQa9",
        "outputId": "c89b1126-431a-4266-ddb6-60b46988c8d8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-30 15:33:08,210 md_dnn.py[line:85] WARNING: Unknown hyper-parameters {'proc_number': 2, 'number_of_smali_files': 1000000, 'max_vocab_size': 10000, 'update': False, 'cuda': True, 'seed': 0, 'batch_size': 128, 'epochs': 50, 'lr': 0.001, 'weight_decay': 0.0, 'cache': True, 'mode': 'train', 'model_name': 'xxxxxxxx-xxxxxx', 'beta': 0.01, 'under_sampling': 1.0, 'ma': 'max', 'steps_l1': 50, 'steps_l2': 50, 'step_length_l2': 0.5, 'steps_linf': 50, 'step_length_linf': 0.02, 'random_start': False, 'round_threshold': 0.5}\n",
            "2023-10-30 15:33:08,223 md_dnn.py[line:62] INFO: ========================================dnn model architecture===============================\n",
            "2023-10-30 15:33:08,223 md_dnn.py[line:63] INFO: MalwareDetectionDNN(\n",
            "  (nn_model_layer_0): Linear(in_features=6693, out_features=200, bias=True)\n",
            "  (nn_model_layer_1): Linear(in_features=200, out_features=200, bias=True)\n",
            "  (nn_model_layer_2): Linear(in_features=200, out_features=2, bias=True)\n",
            ")\n",
            "2023-10-30 15:33:08,223 md_dnn.py[line:64] INFO: ===============================================end==========================================\n",
            "2023-10-30 15:33:08,584 md_at_ma.py[line:47] INFO: Adversarial training incorporating the attack Max\n",
            "2023-10-30 15:33:08,886 md_at_ma.py[line:72] INFO: Max adversarial training is starting ...\n",
            "2023-10-30 15:33:10,375 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:10,500 md_at_ma.py[line:120] INFO: Mini batch: 1/1450 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-30 15:33:10,500 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.7043 | Train accuracy: 31.96%.\n",
            "2023-10-30 15:33:11,386 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:11,400 md_at_ma.py[line:120] INFO: Mini batch: 2/1450 | training time in 0 minutes, 1 seconds.\n",
            "2023-10-30 15:33:11,400 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.6826 | Train accuracy: 45.03%.\n",
            "2023-10-30 15:33:12,550 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:12,563 md_at_ma.py[line:120] INFO: Mini batch: 3/1450 | training time in 0 minutes, 2 seconds.\n",
            "2023-10-30 15:33:12,563 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.6550 | Train accuracy: 48.45%.\n",
            "2023-10-30 15:33:13,314 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:13,330 md_at_ma.py[line:120] INFO: Mini batch: 4/1450 | training time in 0 minutes, 3 seconds.\n",
            "2023-10-30 15:33:13,330 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.6411 | Train accuracy: 46.97%.\n",
            "2023-10-30 15:33:14,256 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:14,269 md_at_ma.py[line:120] INFO: Mini batch: 5/1450 | training time in 0 minutes, 3 seconds.\n",
            "2023-10-30 15:33:14,269 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.6265 | Train accuracy: 47.24%.\n",
            "2023-10-30 15:33:14,948 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:14,962 md_at_ma.py[line:120] INFO: Mini batch: 6/1450 | training time in 0 minutes, 4 seconds.\n",
            "2023-10-30 15:33:14,962 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.5796 | Train accuracy: 51.96%.\n",
            "2023-10-30 15:33:15,653 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:15,667 md_at_ma.py[line:120] INFO: Mini batch: 7/1450 | training time in 0 minutes, 5 seconds.\n",
            "2023-10-30 15:33:15,668 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.5312 | Train accuracy: 60.85%.\n",
            "2023-10-30 15:33:16,235 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:16,252 md_at_ma.py[line:120] INFO: Mini batch: 8/1450 | training time in 0 minutes, 5 seconds.\n",
            "2023-10-30 15:33:16,253 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.4983 | Train accuracy: 59.39%.\n",
            "2023-10-30 15:33:17,078 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:17,094 md_at_ma.py[line:120] INFO: Mini batch: 9/1450 | training time in 0 minutes, 6 seconds.\n",
            "2023-10-30 15:33:17,094 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.4303 | Train accuracy: 61.58%.\n",
            "2023-10-30 15:33:17,740 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:17,749 md_at_ma.py[line:120] INFO: Mini batch: 10/1450 | training time in 0 minutes, 7 seconds.\n",
            "2023-10-30 15:33:17,750 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.4332 | Train accuracy: 63.30%.\n",
            "2023-10-30 15:33:18,408 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:18,417 md_at_ma.py[line:120] INFO: Mini batch: 11/1450 | training time in 0 minutes, 7 seconds.\n",
            "2023-10-30 15:33:18,417 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.3739 | Train accuracy: 64.84%.\n",
            "2023-10-30 15:33:19,100 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:19,109 md_at_ma.py[line:120] INFO: Mini batch: 12/1450 | training time in 0 minutes, 8 seconds.\n",
            "2023-10-30 15:33:19,110 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.3867 | Train accuracy: 60.21%.\n",
            "2023-10-30 15:33:19,869 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:19,881 md_at_ma.py[line:120] INFO: Mini batch: 13/1450 | training time in 0 minutes, 9 seconds.\n",
            "2023-10-30 15:33:19,882 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.3618 | Train accuracy: 60.10%.\n",
            "2023-10-30 15:33:20,615 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:20,633 md_at_ma.py[line:120] INFO: Mini batch: 14/1450 | training time in 0 minutes, 9 seconds.\n",
            "2023-10-30 15:33:20,633 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.2768 | Train accuracy: 62.37%.\n",
            "2023-10-30 15:33:21,215 max.py[line:93] INFO: max: attack effectiveness 98.46153846153847%.\n",
            "2023-10-30 15:33:21,228 md_at_ma.py[line:120] INFO: Mini batch: 15/1450 | training time in 0 minutes, 10 seconds.\n",
            "2023-10-30 15:33:21,228 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.3106 | Train accuracy: 61.14%.\n",
            "2023-10-30 15:33:22,191 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:22,205 md_at_ma.py[line:120] INFO: Mini batch: 16/1450 | training time in 0 minutes, 11 seconds.\n",
            "2023-10-30 15:33:22,205 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.3176 | Train accuracy: 58.29%.\n",
            "2023-10-30 15:33:22,823 max.py[line:93] INFO: max: attack effectiveness 98.4375%.\n",
            "2023-10-30 15:33:22,833 md_at_ma.py[line:120] INFO: Mini batch: 17/1450 | training time in 0 minutes, 12 seconds.\n",
            "2023-10-30 15:33:22,833 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.2705 | Train accuracy: 59.38%.\n",
            "2023-10-30 15:33:23,467 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:23,480 md_at_ma.py[line:120] INFO: Mini batch: 18/1450 | training time in 0 minutes, 12 seconds.\n",
            "2023-10-30 15:33:23,480 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.2878 | Train accuracy: 61.54%.\n",
            "2023-10-30 15:33:24,386 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:24,404 md_at_ma.py[line:120] INFO: Mini batch: 19/1450 | training time in 0 minutes, 13 seconds.\n",
            "2023-10-30 15:33:24,405 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.3957 | Train accuracy: 60.94%.\n",
            "2023-10-30 15:33:25,357 max.py[line:93] INFO: max: attack effectiveness 98.64864864864865%.\n",
            "2023-10-30 15:33:25,379 md_at_ma.py[line:120] INFO: Mini batch: 20/1450 | training time in 0 minutes, 14 seconds.\n",
            "2023-10-30 15:33:25,379 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.3519 | Train accuracy: 55.94%.\n",
            "2023-10-30 15:33:26,342 max.py[line:93] INFO: max: attack effectiveness 98.55072463768117%.\n",
            "2023-10-30 15:33:26,358 md_at_ma.py[line:120] INFO: Mini batch: 21/1450 | training time in 0 minutes, 15 seconds.\n",
            "2023-10-30 15:33:26,358 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.2859 | Train accuracy: 59.39%.\n",
            "2023-10-30 15:33:27,333 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:27,349 md_at_ma.py[line:120] INFO: Mini batch: 22/1450 | training time in 0 minutes, 16 seconds.\n",
            "2023-10-30 15:33:27,349 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.2976 | Train accuracy: 57.64%.\n",
            "2023-10-30 15:33:27,946 max.py[line:93] INFO: max: attack effectiveness 97.05882352941177%.\n",
            "2023-10-30 15:33:27,959 md_at_ma.py[line:120] INFO: Mini batch: 23/1450 | training time in 0 minutes, 17 seconds.\n",
            "2023-10-30 15:33:27,959 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.2517 | Train accuracy: 60.20%.\n",
            "2023-10-30 15:33:28,615 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:28,624 md_at_ma.py[line:120] INFO: Mini batch: 24/1450 | training time in 0 minutes, 17 seconds.\n",
            "2023-10-30 15:33:28,624 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.2844 | Train accuracy: 62.03%.\n",
            "2023-10-30 15:33:29,577 max.py[line:93] INFO: max: attack effectiveness 98.66666666666667%.\n",
            "2023-10-30 15:33:29,589 md_at_ma.py[line:120] INFO: Mini batch: 25/1450 | training time in 0 minutes, 18 seconds.\n",
            "2023-10-30 15:33:29,589 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1819 | Train accuracy: 61.08%.\n",
            "2023-10-30 15:33:30,084 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:30,097 md_at_ma.py[line:120] INFO: Mini batch: 26/1450 | training time in 0 minutes, 19 seconds.\n",
            "2023-10-30 15:33:30,097 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.2314 | Train accuracy: 60.91%.\n",
            "2023-10-30 15:33:30,676 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:30,685 md_at_ma.py[line:120] INFO: Mini batch: 27/1450 | training time in 0 minutes, 19 seconds.\n",
            "2023-10-30 15:33:30,685 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.3367 | Train accuracy: 57.29%.\n",
            "2023-10-30 15:33:31,258 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:31,267 md_at_ma.py[line:120] INFO: Mini batch: 28/1450 | training time in 0 minutes, 20 seconds.\n",
            "2023-10-30 15:33:31,267 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.2459 | Train accuracy: 63.16%.\n",
            "2023-10-30 15:33:31,649 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:31,654 md_at_ma.py[line:120] INFO: Mini batch: 29/1450 | training time in 0 minutes, 20 seconds.\n",
            "2023-10-30 15:33:31,654 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.3513 | Train accuracy: 63.16%.\n",
            "2023-10-30 15:33:31,673 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.3994 | Train accuracy: 57.46\n",
            "2023-10-30 15:33:33,487 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:34,399 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:35,310 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:36,219 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:36,883 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:38,025 md_at_ma.py[line:165] INFO: \tVal accuracy 46.58% with accuracy 0.0% under attack.\n",
            "2023-10-30 15:33:38,025 md_at_ma.py[line:167] INFO: \tModel select at epoch 1 with validation accuracy 46.58% and accuracy 0.0% under attack.\n",
            "2023-10-30 15:33:38,831 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:38,844 md_at_ma.py[line:120] INFO: Mini batch: 30/1450 | training time in 0 minutes, 21 seconds.\n",
            "2023-10-30 15:33:38,845 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.2564 | Train accuracy: 61.34%.\n",
            "2023-10-30 15:33:39,435 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:39,445 md_at_ma.py[line:120] INFO: Mini batch: 31/1450 | training time in 0 minutes, 21 seconds.\n",
            "2023-10-30 15:33:39,445 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.2682 | Train accuracy: 61.78%.\n",
            "2023-10-30 15:33:40,057 max.py[line:93] INFO: max: attack effectiveness 98.48484848484848%.\n",
            "2023-10-30 15:33:40,069 md_at_ma.py[line:120] INFO: Mini batch: 32/1450 | training time in 0 minutes, 22 seconds.\n",
            "2023-10-30 15:33:40,069 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.2533 | Train accuracy: 62.37%.\n",
            "2023-10-30 15:33:40,609 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:40,621 md_at_ma.py[line:120] INFO: Mini batch: 33/1450 | training time in 0 minutes, 23 seconds.\n",
            "2023-10-30 15:33:40,621 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.2876 | Train accuracy: 58.08%.\n",
            "2023-10-30 15:33:41,395 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:41,407 md_at_ma.py[line:120] INFO: Mini batch: 34/1450 | training time in 0 minutes, 23 seconds.\n",
            "2023-10-30 15:33:41,407 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.2139 | Train accuracy: 60.80%.\n",
            "2023-10-30 15:33:42,184 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:42,196 md_at_ma.py[line:120] INFO: Mini batch: 35/1450 | training time in 0 minutes, 24 seconds.\n",
            "2023-10-30 15:33:42,197 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.2065 | Train accuracy: 58.82%.\n",
            "2023-10-30 15:33:42,681 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:42,689 md_at_ma.py[line:120] INFO: Mini batch: 36/1450 | training time in 0 minutes, 25 seconds.\n",
            "2023-10-30 15:33:42,690 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1879 | Train accuracy: 65.61%.\n",
            "2023-10-30 15:33:43,425 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:43,438 md_at_ma.py[line:120] INFO: Mini batch: 37/1450 | training time in 0 minutes, 25 seconds.\n",
            "2023-10-30 15:33:43,438 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.2389 | Train accuracy: 60.91%.\n",
            "2023-10-30 15:33:43,922 max.py[line:93] INFO: max: attack effectiveness 98.38709677419355%.\n",
            "2023-10-30 15:33:43,930 md_at_ma.py[line:120] INFO: Mini batch: 38/1450 | training time in 0 minutes, 26 seconds.\n",
            "2023-10-30 15:33:43,931 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.2143 | Train accuracy: 65.79%.\n",
            "2023-10-30 15:33:44,509 max.py[line:93] INFO: max: attack effectiveness 98.33333333333333%.\n",
            "2023-10-30 15:33:44,518 md_at_ma.py[line:120] INFO: Mini batch: 39/1450 | training time in 0 minutes, 26 seconds.\n",
            "2023-10-30 15:33:44,518 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1997 | Train accuracy: 65.43%.\n",
            "2023-10-30 15:33:45,047 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:45,056 md_at_ma.py[line:120] INFO: Mini batch: 40/1450 | training time in 0 minutes, 27 seconds.\n",
            "2023-10-30 15:33:45,056 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1860 | Train accuracy: 67.58%.\n",
            "2023-10-30 15:33:45,622 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:45,631 md_at_ma.py[line:120] INFO: Mini batch: 41/1450 | training time in 0 minutes, 27 seconds.\n",
            "2023-10-30 15:33:45,631 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1977 | Train accuracy: 64.40%.\n",
            "2023-10-30 15:33:46,227 max.py[line:93] INFO: max: attack effectiveness 98.46153846153847%.\n",
            "2023-10-30 15:33:46,239 md_at_ma.py[line:120] INFO: Mini batch: 42/1450 | training time in 0 minutes, 28 seconds.\n",
            "2023-10-30 15:33:46,239 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1878 | Train accuracy: 61.66%.\n",
            "2023-10-30 15:33:46,732 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:46,744 md_at_ma.py[line:120] INFO: Mini batch: 43/1450 | training time in 0 minutes, 29 seconds.\n",
            "2023-10-30 15:33:46,744 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.2021 | Train accuracy: 61.34%.\n",
            "2023-10-30 15:33:47,236 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:47,248 md_at_ma.py[line:120] INFO: Mini batch: 44/1450 | training time in 0 minutes, 29 seconds.\n",
            "2023-10-30 15:33:47,248 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1511 | Train accuracy: 63.73%.\n",
            "2023-10-30 15:33:48,023 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:48,035 md_at_ma.py[line:120] INFO: Mini batch: 45/1450 | training time in 0 minutes, 30 seconds.\n",
            "2023-10-30 15:33:48,036 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1563 | Train accuracy: 61.81%.\n",
            "2023-10-30 15:33:48,521 max.py[line:93] INFO: max: attack effectiveness 98.4375%.\n",
            "2023-10-30 15:33:48,529 md_at_ma.py[line:120] INFO: Mini batch: 46/1450 | training time in 0 minutes, 30 seconds.\n",
            "2023-10-30 15:33:48,530 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1556 | Train accuracy: 64.06%.\n",
            "2023-10-30 15:33:49,023 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:49,036 md_at_ma.py[line:120] INFO: Mini batch: 47/1450 | training time in 0 minutes, 31 seconds.\n",
            "2023-10-30 15:33:49,036 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1927 | Train accuracy: 62.05%.\n",
            "2023-10-30 15:33:49,625 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:49,634 md_at_ma.py[line:120] INFO: Mini batch: 48/1450 | training time in 0 minutes, 31 seconds.\n",
            "2023-10-30 15:33:49,634 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.2042 | Train accuracy: 64.06%.\n",
            "2023-10-30 15:33:50,412 max.py[line:93] INFO: max: attack effectiveness 98.64864864864865%.\n",
            "2023-10-30 15:33:50,424 md_at_ma.py[line:120] INFO: Mini batch: 49/1450 | training time in 0 minutes, 32 seconds.\n",
            "2023-10-30 15:33:50,425 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.2212 | Train accuracy: 59.41%.\n",
            "2023-10-30 15:33:51,215 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:51,228 md_at_ma.py[line:120] INFO: Mini batch: 50/1450 | training time in 0 minutes, 33 seconds.\n",
            "2023-10-30 15:33:51,228 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1435 | Train accuracy: 62.44%.\n",
            "2023-10-30 15:33:52,008 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:52,020 md_at_ma.py[line:120] INFO: Mini batch: 51/1450 | training time in 0 minutes, 34 seconds.\n",
            "2023-10-30 15:33:52,020 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1617 | Train accuracy: 60.59%.\n",
            "2023-10-30 15:33:52,799 max.py[line:93] INFO: max: attack effectiveness 98.52941176470588%.\n",
            "2023-10-30 15:33:52,811 md_at_ma.py[line:120] INFO: Mini batch: 52/1450 | training time in 0 minutes, 34 seconds.\n",
            "2023-10-30 15:33:52,811 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1803 | Train accuracy: 62.24%.\n",
            "2023-10-30 15:33:53,395 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:53,404 md_at_ma.py[line:120] INFO: Mini batch: 53/1450 | training time in 0 minutes, 35 seconds.\n",
            "2023-10-30 15:33:53,405 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.2085 | Train accuracy: 64.71%.\n",
            "2023-10-30 15:33:54,228 max.py[line:93] INFO: max: attack effectiveness 98.66666666666667%.\n",
            "2023-10-30 15:33:54,240 md_at_ma.py[line:120] INFO: Mini batch: 54/1450 | training time in 0 minutes, 36 seconds.\n",
            "2023-10-30 15:33:54,241 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1065 | Train accuracy: 63.05%.\n",
            "2023-10-30 15:33:54,739 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:54,752 md_at_ma.py[line:120] INFO: Mini batch: 55/1450 | training time in 0 minutes, 36 seconds.\n",
            "2023-10-30 15:33:54,752 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1696 | Train accuracy: 61.42%.\n",
            "2023-10-30 15:33:55,230 max.py[line:93] INFO: max: attack effectiveness 96.875%.\n",
            "2023-10-30 15:33:55,239 md_at_ma.py[line:120] INFO: Mini batch: 56/1450 | training time in 0 minutes, 37 seconds.\n",
            "2023-10-30 15:33:55,239 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1974 | Train accuracy: 66.15%.\n",
            "2023-10-30 15:33:55,819 max.py[line:93] INFO: max: attack effectiveness 96.7741935483871%.\n",
            "2023-10-30 15:33:55,828 md_at_ma.py[line:120] INFO: Mini batch: 57/1450 | training time in 0 minutes, 37 seconds.\n",
            "2023-10-30 15:33:55,828 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1662 | Train accuracy: 64.74%.\n",
            "2023-10-30 15:33:56,212 max.py[line:93] INFO: max: attack effectiveness 83.33333333333334%.\n",
            "2023-10-30 15:33:56,216 md_at_ma.py[line:120] INFO: Mini batch: 58/1450 | training time in 0 minutes, 38 seconds.\n",
            "2023-10-30 15:33:56,217 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.2074 | Train accuracy: 68.42%.\n",
            "2023-10-30 15:33:56,239 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.1973 | Train accuracy: 62.92\n",
            "2023-10-30 15:33:57,932 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:33:58,839 max.py[line:93] INFO: max: attack effectiveness 99.21875%.\n",
            "2023-10-30 15:33:59,742 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:34:00,713 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:34:01,344 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:34:02,031 md_at_ma.py[line:165] INFO: \tVal accuracy 47.42% with accuracy 0.1792% under attack.\n",
            "2023-10-30 15:34:02,031 md_at_ma.py[line:167] INFO: \tModel select at epoch 2 with validation accuracy 47.42% and accuracy 0.1792% under attack.\n",
            "2023-10-30 15:34:02,729 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:34:02,742 md_at_ma.py[line:120] INFO: Mini batch: 59/1450 | training time in 0 minutes, 38 seconds.\n",
            "2023-10-30 15:34:02,742 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1784 | Train accuracy: 62.37%.\n",
            "2023-10-30 15:34:03,341 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:34:03,350 md_at_ma.py[line:120] INFO: Mini batch: 60/1450 | training time in 0 minutes, 39 seconds.\n",
            "2023-10-30 15:34:03,350 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1865 | Train accuracy: 63.35%.\n",
            "2023-10-30 15:34:03,869 max.py[line:93] INFO: max: attack effectiveness 98.48484848484848%.\n",
            "2023-10-30 15:34:03,881 md_at_ma.py[line:120] INFO: Mini batch: 61/1450 | training time in 0 minutes, 39 seconds.\n",
            "2023-10-30 15:34:03,881 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1665 | Train accuracy: 63.92%.\n",
            "2023-10-30 15:34:04,401 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:34:04,414 md_at_ma.py[line:120] INFO: Mini batch: 62/1450 | training time in 0 minutes, 40 seconds.\n",
            "2023-10-30 15:34:04,414 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.2299 | Train accuracy: 60.10%.\n",
            "2023-10-30 15:34:05,205 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:34:05,217 md_at_ma.py[line:120] INFO: Mini batch: 63/1450 | training time in 0 minutes, 41 seconds.\n",
            "2023-10-30 15:34:05,217 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1627 | Train accuracy: 62.31%.\n",
            "2023-10-30 15:34:06,080 max.py[line:93] INFO: max: attack effectiveness 98.68421052631578%.\n",
            "2023-10-30 15:34:06,092 md_at_ma.py[line:120] INFO: Mini batch: 64/1450 | training time in 0 minutes, 42 seconds.\n",
            "2023-10-30 15:34:06,092 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1422 | Train accuracy: 61.76%.\n",
            "2023-10-30 15:34:06,573 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:34:06,582 md_at_ma.py[line:120] INFO: Mini batch: 65/1450 | training time in 0 minutes, 42 seconds.\n",
            "2023-10-30 15:34:06,582 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1274 | Train accuracy: 65.61%.\n",
            "2023-10-30 15:34:07,348 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:34:07,360 md_at_ma.py[line:120] INFO: Mini batch: 66/1450 | training time in 0 minutes, 43 seconds.\n",
            "2023-10-30 15:34:07,361 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1738 | Train accuracy: 63.45%.\n",
            "2023-10-30 15:34:07,844 max.py[line:93] INFO: max: attack effectiveness 98.38709677419355%.\n",
            "2023-10-30 15:34:07,853 md_at_ma.py[line:120] INFO: Mini batch: 67/1450 | training time in 0 minutes, 43 seconds.\n",
            "2023-10-30 15:34:07,853 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1566 | Train accuracy: 66.32%.\n",
            "2023-10-30 15:34:08,429 max.py[line:93] INFO: max: attack effectiveness 98.33333333333333%.\n",
            "2023-10-30 15:34:08,438 md_at_ma.py[line:120] INFO: Mini batch: 68/1450 | training time in 0 minutes, 44 seconds.\n",
            "2023-10-30 15:34:08,438 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1524 | Train accuracy: 67.02%.\n",
            "2023-10-30 15:34:08,963 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:34:08,972 md_at_ma.py[line:120] INFO: Mini batch: 69/1450 | training time in 0 minutes, 44 seconds.\n",
            "2023-10-30 15:34:08,972 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1466 | Train accuracy: 67.58%.\n",
            "2023-10-30 15:34:09,455 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:34:09,463 md_at_ma.py[line:120] INFO: Mini batch: 70/1450 | training time in 0 minutes, 45 seconds.\n",
            "2023-10-30 15:34:09,464 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1417 | Train accuracy: 66.49%.\n",
            "2023-10-30 15:34:09,959 max.py[line:93] INFO: max: attack effectiveness 98.46153846153847%.\n",
            "2023-10-30 15:34:09,971 md_at_ma.py[line:120] INFO: Mini batch: 71/1450 | training time in 0 minutes, 45 seconds.\n",
            "2023-10-30 15:34:09,971 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1292 | Train accuracy: 65.28%.\n",
            "2023-10-30 15:34:10,468 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:34:10,480 md_at_ma.py[line:120] INFO: Mini batch: 72/1450 | training time in 0 minutes, 46 seconds.\n",
            "2023-10-30 15:34:10,481 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1434 | Train accuracy: 64.43%.\n",
            "2023-10-30 15:34:10,977 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:34:10,989 md_at_ma.py[line:120] INFO: Mini batch: 73/1450 | training time in 0 minutes, 46 seconds.\n",
            "2023-10-30 15:34:10,989 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1081 | Train accuracy: 65.28%.\n",
            "2023-10-30 15:34:11,763 max.py[line:93] INFO: max: attack effectiveness 98.59154929577466%.\n",
            "2023-10-30 15:34:11,775 md_at_ma.py[line:120] INFO: Mini batch: 74/1450 | training time in 0 minutes, 47 seconds.\n",
            "2023-10-30 15:34:11,775 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1199 | Train accuracy: 63.32%.\n",
            "2023-10-30 15:34:12,254 max.py[line:93] INFO: max: attack effectiveness 98.4375%.\n",
            "2023-10-30 15:34:12,263 md_at_ma.py[line:120] INFO: Mini batch: 75/1450 | training time in 0 minutes, 48 seconds.\n",
            "2023-10-30 15:34:12,263 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1204 | Train accuracy: 64.06%.\n",
            "2023-10-30 15:34:12,752 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:34:12,764 md_at_ma.py[line:120] INFO: Mini batch: 76/1450 | training time in 0 minutes, 48 seconds.\n",
            "2023-10-30 15:34:12,764 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.2083 | Train accuracy: 62.05%.\n",
            "2023-10-30 15:34:13,322 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:34:13,331 md_at_ma.py[line:120] INFO: Mini batch: 77/1450 | training time in 0 minutes, 49 seconds.\n",
            "2023-10-30 15:34:13,331 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1749 | Train accuracy: 63.02%.\n",
            "2023-10-30 15:34:14,098 max.py[line:93] INFO: max: attack effectiveness 98.64864864864865%.\n",
            "2023-10-30 15:34:14,111 md_at_ma.py[line:120] INFO: Mini batch: 78/1450 | training time in 0 minutes, 49 seconds.\n",
            "2023-10-30 15:34:14,111 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1785 | Train accuracy: 60.89%.\n",
            "2023-10-30 15:34:14,869 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:34:14,881 md_at_ma.py[line:120] INFO: Mini batch: 79/1450 | training time in 0 minutes, 50 seconds.\n",
            "2023-10-30 15:34:14,881 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0966 | Train accuracy: 64.47%.\n",
            "2023-10-30 15:34:15,697 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:34:15,709 md_at_ma.py[line:120] INFO: Mini batch: 80/1450 | training time in 0 minutes, 51 seconds.\n",
            "2023-10-30 15:34:15,710 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1303 | Train accuracy: 62.56%.\n",
            "2023-10-30 15:34:16,485 max.py[line:93] INFO: max: attack effectiveness 97.05882352941177%.\n",
            "2023-10-30 15:34:16,498 md_at_ma.py[line:120] INFO: Mini batch: 81/1450 | training time in 0 minutes, 52 seconds.\n",
            "2023-10-30 15:34:16,498 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1182 | Train accuracy: 63.78%.\n",
            "2023-10-30 15:34:17,121 max.py[line:93] INFO: max: attack effectiveness 98.30508474576271%.\n",
            "2023-10-30 15:34:17,130 md_at_ma.py[line:120] INFO: Mini batch: 82/1450 | training time in 0 minutes, 52 seconds.\n",
            "2023-10-30 15:34:17,131 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1684 | Train accuracy: 65.78%.\n",
            "2023-10-30 15:34:17,969 max.py[line:93] INFO: max: attack effectiveness 98.66666666666667%.\n",
            "2023-10-30 15:34:17,982 md_at_ma.py[line:120] INFO: Mini batch: 83/1450 | training time in 0 minutes, 53 seconds.\n",
            "2023-10-30 15:34:17,982 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0810 | Train accuracy: 63.05%.\n",
            "2023-10-30 15:34:18,741 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:34:18,754 md_at_ma.py[line:120] INFO: Mini batch: 84/1450 | training time in 0 minutes, 54 seconds.\n",
            "2023-10-30 15:34:18,754 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1494 | Train accuracy: 62.94%.\n",
            "2023-10-30 15:34:19,237 max.py[line:93] INFO: max: attack effectiveness 93.75%.\n",
            "2023-10-30 15:34:19,246 md_at_ma.py[line:120] INFO: Mini batch: 85/1450 | training time in 0 minutes, 54 seconds.\n",
            "2023-10-30 15:34:19,246 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1473 | Train accuracy: 66.15%.\n",
            "2023-10-30 15:34:19,720 max.py[line:93] INFO: max: attack effectiveness 96.7741935483871%.\n",
            "2023-10-30 15:34:19,728 md_at_ma.py[line:120] INFO: Mini batch: 86/1450 | training time in 0 minutes, 55 seconds.\n",
            "2023-10-30 15:34:19,729 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1297 | Train accuracy: 67.37%.\n",
            "2023-10-30 15:34:20,109 max.py[line:93] INFO: max: attack effectiveness 83.33333333333334%.\n",
            "2023-10-30 15:34:20,113 md_at_ma.py[line:120] INFO: Mini batch: 87/1450 | training time in 0 minutes, 55 seconds.\n",
            "2023-10-30 15:34:20,114 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1555 | Train accuracy: 68.42%.\n",
            "2023-10-30 15:34:20,137 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.1491 | Train accuracy: 64.25\n",
            "2023-10-30 15:34:21,874 max.py[line:93] INFO: max: attack effectiveness 99.21875%.\n",
            "2023-10-30 15:34:22,897 max.py[line:93] INFO: max: attack effectiveness 99.21875%.\n",
            "2023-10-30 15:34:23,785 max.py[line:93] INFO: max: attack effectiveness 97.65625%.\n",
            "2023-10-30 15:34:24,700 max.py[line:93] INFO: max: attack effectiveness 98.4375%.\n",
            "2023-10-30 15:34:25,280 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:34:25,978 md_at_ma.py[line:165] INFO: \tVal accuracy 48.62% with accuracy 1.254% under attack.\n",
            "2023-10-30 15:34:25,978 md_at_ma.py[line:167] INFO: \tModel select at epoch 3 with validation accuracy 48.62% and accuracy 1.254% under attack.\n",
            "2023-10-30 15:34:26,603 max.py[line:93] INFO: max: attack effectiveness 96.96969696969697%.\n",
            "2023-10-30 15:34:26,616 md_at_ma.py[line:120] INFO: Mini batch: 88/1450 | training time in 0 minutes, 56 seconds.\n",
            "2023-10-30 15:34:26,616 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1271 | Train accuracy: 64.95%.\n",
            "2023-10-30 15:34:27,097 max.py[line:93] INFO: max: attack effectiveness 98.4126984126984%.\n",
            "2023-10-30 15:34:27,106 md_at_ma.py[line:120] INFO: Mini batch: 89/1450 | training time in 0 minutes, 56 seconds.\n",
            "2023-10-30 15:34:27,106 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1373 | Train accuracy: 64.92%.\n",
            "2023-10-30 15:34:27,610 max.py[line:93] INFO: max: attack effectiveness 96.96969696969697%.\n",
            "2023-10-30 15:34:27,622 md_at_ma.py[line:120] INFO: Mini batch: 90/1450 | training time in 0 minutes, 57 seconds.\n",
            "2023-10-30 15:34:27,622 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1310 | Train accuracy: 65.46%.\n",
            "2023-10-30 15:34:28,127 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:34:28,139 md_at_ma.py[line:120] INFO: Mini batch: 91/1450 | training time in 0 minutes, 57 seconds.\n",
            "2023-10-30 15:34:28,139 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1777 | Train accuracy: 61.11%.\n",
            "2023-10-30 15:34:28,908 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:34:28,921 md_at_ma.py[line:120] INFO: Mini batch: 92/1450 | training time in 0 minutes, 58 seconds.\n",
            "2023-10-30 15:34:28,921 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1523 | Train accuracy: 62.31%.\n",
            "2023-10-30 15:34:29,754 max.py[line:93] INFO: max: attack effectiveness 98.68421052631578%.\n",
            "2023-10-30 15:34:29,767 md_at_ma.py[line:120] INFO: Mini batch: 93/1450 | training time in 0 minutes, 59 seconds.\n",
            "2023-10-30 15:34:29,767 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1147 | Train accuracy: 61.76%.\n",
            "2023-10-30 15:34:30,293 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:34:30,303 md_at_ma.py[line:120] INFO: Mini batch: 94/1450 | training time in 0 minutes, 59 seconds.\n",
            "2023-10-30 15:34:30,303 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0791 | Train accuracy: 67.72%.\n",
            "2023-10-30 15:34:31,108 max.py[line:93] INFO: max: attack effectiveness 98.55072463768117%.\n",
            "2023-10-30 15:34:31,120 md_at_ma.py[line:120] INFO: Mini batch: 95/1450 | training time in 1 minutes, 0 seconds.\n",
            "2023-10-30 15:34:31,121 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1329 | Train accuracy: 64.47%.\n",
            "2023-10-30 15:34:31,659 max.py[line:93] INFO: max: attack effectiveness 98.38709677419355%.\n",
            "2023-10-30 15:34:31,668 md_at_ma.py[line:120] INFO: Mini batch: 96/1450 | training time in 1 minutes, 1 seconds.\n",
            "2023-10-30 15:34:31,668 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1090 | Train accuracy: 67.37%.\n",
            "2023-10-30 15:34:32,270 max.py[line:93] INFO: max: attack effectiveness 96.66666666666667%.\n",
            "2023-10-30 15:34:32,279 md_at_ma.py[line:120] INFO: Mini batch: 97/1450 | training time in 1 minutes, 1 seconds.\n",
            "2023-10-30 15:34:32,279 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1091 | Train accuracy: 68.62%.\n",
            "2023-10-30 15:34:32,842 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:34:32,851 md_at_ma.py[line:120] INFO: Mini batch: 98/1450 | training time in 1 minutes, 2 seconds.\n",
            "2023-10-30 15:34:32,851 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1204 | Train accuracy: 69.23%.\n",
            "2023-10-30 15:34:33,342 max.py[line:93] INFO: max: attack effectiveness 98.4126984126984%.\n",
            "2023-10-30 15:34:33,351 md_at_ma.py[line:120] INFO: Mini batch: 99/1450 | training time in 1 minutes, 2 seconds.\n",
            "2023-10-30 15:34:33,351 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1368 | Train accuracy: 65.45%.\n",
            "2023-10-30 15:34:34,084 max.py[line:93] INFO: max: attack effectiveness 98.46153846153847%.\n",
            "2023-10-30 15:34:34,096 md_at_ma.py[line:120] INFO: Mini batch: 100/1450 | training time in 1 minutes, 3 seconds.\n",
            "2023-10-30 15:34:34,096 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1052 | Train accuracy: 65.80%.\n",
            "2023-10-30 15:34:34,834 max.py[line:93] INFO: max: attack effectiveness 96.96969696969697%.\n",
            "2023-10-30 15:34:34,846 md_at_ma.py[line:120] INFO: Mini batch: 101/1450 | training time in 1 minutes, 4 seconds.\n",
            "2023-10-30 15:34:34,847 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1306 | Train accuracy: 64.43%.\n",
            "2023-10-30 15:34:35,345 max.py[line:93] INFO: max: attack effectiveness 98.46153846153847%.\n",
            "2023-10-30 15:34:35,357 md_at_ma.py[line:120] INFO: Mini batch: 102/1450 | training time in 1 minutes, 4 seconds.\n",
            "2023-10-30 15:34:35,357 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0947 | Train accuracy: 67.36%.\n",
            "2023-10-30 15:34:36,134 max.py[line:93] INFO: max: attack effectiveness 98.59154929577466%.\n",
            "2023-10-30 15:34:36,147 md_at_ma.py[line:120] INFO: Mini batch: 103/1450 | training time in 1 minutes, 5 seconds.\n",
            "2023-10-30 15:34:36,147 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1138 | Train accuracy: 63.82%.\n",
            "2023-10-30 15:34:36,630 max.py[line:93] INFO: max: attack effectiveness 98.4375%.\n",
            "2023-10-30 15:34:36,639 md_at_ma.py[line:120] INFO: Mini batch: 104/1450 | training time in 1 minutes, 5 seconds.\n",
            "2023-10-30 15:34:36,639 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0918 | Train accuracy: 66.15%.\n",
            "2023-10-30 15:34:37,134 max.py[line:93] INFO: max: attack effectiveness 98.50746268656717%.\n",
            "2023-10-30 15:34:37,146 md_at_ma.py[line:120] INFO: Mini batch: 105/1450 | training time in 1 minutes, 6 seconds.\n",
            "2023-10-30 15:34:37,146 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1577 | Train accuracy: 63.08%.\n",
            "2023-10-30 15:34:37,731 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:34:37,740 md_at_ma.py[line:120] INFO: Mini batch: 106/1450 | training time in 1 minutes, 7 seconds.\n",
            "2023-10-30 15:34:37,740 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1631 | Train accuracy: 64.58%.\n",
            "2023-10-30 15:34:38,516 max.py[line:93] INFO: max: attack effectiveness 98.64864864864865%.\n",
            "2023-10-30 15:34:38,528 md_at_ma.py[line:120] INFO: Mini batch: 107/1450 | training time in 1 minutes, 7 seconds.\n",
            "2023-10-30 15:34:38,529 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1622 | Train accuracy: 60.89%.\n",
            "2023-10-30 15:34:39,301 max.py[line:93] INFO: max: attack effectiveness 98.55072463768117%.\n",
            "2023-10-30 15:34:39,314 md_at_ma.py[line:120] INFO: Mini batch: 108/1450 | training time in 1 minutes, 8 seconds.\n",
            "2023-10-30 15:34:39,314 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0944 | Train accuracy: 65.99%.\n",
            "2023-10-30 15:34:40,091 max.py[line:93] INFO: max: attack effectiveness 96.0%.\n",
            "2023-10-30 15:34:40,103 md_at_ma.py[line:120] INFO: Mini batch: 109/1450 | training time in 1 minutes, 9 seconds.\n",
            "2023-10-30 15:34:40,103 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1283 | Train accuracy: 64.53%.\n",
            "2023-10-30 15:34:40,872 max.py[line:93] INFO: max: attack effectiveness 92.64705882352942%.\n",
            "2023-10-30 15:34:40,884 md_at_ma.py[line:120] INFO: Mini batch: 110/1450 | training time in 1 minutes, 10 seconds.\n",
            "2023-10-30 15:34:40,885 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1019 | Train accuracy: 68.88%.\n",
            "2023-10-30 15:34:41,471 max.py[line:93] INFO: max: attack effectiveness 96.61016949152543%.\n",
            "2023-10-30 15:34:41,480 md_at_ma.py[line:120] INFO: Mini batch: 111/1450 | training time in 1 minutes, 10 seconds.\n",
            "2023-10-30 15:34:41,481 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1522 | Train accuracy: 70.05%.\n",
            "2023-10-30 15:34:42,309 max.py[line:93] INFO: max: attack effectiveness 90.66666666666666%.\n",
            "2023-10-30 15:34:42,322 md_at_ma.py[line:120] INFO: Mini batch: 112/1450 | training time in 1 minutes, 11 seconds.\n",
            "2023-10-30 15:34:42,322 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0631 | Train accuracy: 69.46%.\n",
            "2023-10-30 15:34:43,101 max.py[line:93] INFO: max: attack effectiveness 94.20289855072464%.\n",
            "2023-10-30 15:34:43,113 md_at_ma.py[line:120] INFO: Mini batch: 113/1450 | training time in 1 minutes, 12 seconds.\n",
            "2023-10-30 15:34:43,113 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1291 | Train accuracy: 68.02%.\n",
            "2023-10-30 15:34:43,612 max.py[line:93] INFO: max: attack effectiveness 82.8125%.\n",
            "2023-10-30 15:34:43,622 md_at_ma.py[line:120] INFO: Mini batch: 114/1450 | training time in 1 minutes, 12 seconds.\n",
            "2023-10-30 15:34:43,622 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1200 | Train accuracy: 73.96%.\n",
            "2023-10-30 15:34:44,106 max.py[line:93] INFO: max: attack effectiveness 93.54838709677419%.\n",
            "2023-10-30 15:34:44,116 md_at_ma.py[line:120] INFO: Mini batch: 115/1450 | training time in 1 minutes, 13 seconds.\n",
            "2023-10-30 15:34:44,116 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1054 | Train accuracy: 69.47%.\n",
            "2023-10-30 15:34:44,516 max.py[line:93] INFO: max: attack effectiveness 83.33333333333334%.\n",
            "2023-10-30 15:34:44,520 md_at_ma.py[line:120] INFO: Mini batch: 116/1450 | training time in 1 minutes, 13 seconds.\n",
            "2023-10-30 15:34:44,525 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0734 | Train accuracy: 78.95%.\n",
            "2023-10-30 15:34:44,562 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.1212 | Train accuracy: 66.51\n",
            "2023-10-30 15:34:46,423 max.py[line:93] INFO: max: attack effectiveness 95.3125%.\n",
            "2023-10-30 15:34:47,371 max.py[line:93] INFO: max: attack effectiveness 98.4375%.\n",
            "2023-10-30 15:34:48,273 max.py[line:93] INFO: max: attack effectiveness 94.53125%.\n",
            "2023-10-30 15:34:49,181 max.py[line:93] INFO: max: attack effectiveness 96.875%.\n",
            "2023-10-30 15:34:49,784 max.py[line:93] INFO: max: attack effectiveness 95.65217391304348%.\n",
            "2023-10-30 15:34:50,523 md_at_ma.py[line:165] INFO: \tVal accuracy 49.75% with accuracy 3.763% under attack.\n",
            "2023-10-30 15:34:50,523 md_at_ma.py[line:167] INFO: \tModel select at epoch 4 with validation accuracy 49.75% and accuracy 3.763% under attack.\n",
            "2023-10-30 15:34:51,346 max.py[line:93] INFO: max: attack effectiveness 96.96969696969697%.\n",
            "2023-10-30 15:34:51,359 md_at_ma.py[line:120] INFO: Mini batch: 117/1450 | training time in 1 minutes, 14 seconds.\n",
            "2023-10-30 15:34:51,359 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0934 | Train accuracy: 70.10%.\n",
            "2023-10-30 15:34:51,853 max.py[line:93] INFO: max: attack effectiveness 98.4126984126984%.\n",
            "2023-10-30 15:34:51,862 md_at_ma.py[line:120] INFO: Mini batch: 118/1450 | training time in 1 minutes, 14 seconds.\n",
            "2023-10-30 15:34:51,862 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0866 | Train accuracy: 67.02%.\n",
            "2023-10-30 15:34:52,600 max.py[line:93] INFO: max: attack effectiveness 92.42424242424242%.\n",
            "2023-10-30 15:34:52,612 md_at_ma.py[line:120] INFO: Mini batch: 119/1450 | training time in 1 minutes, 15 seconds.\n",
            "2023-10-30 15:34:52,612 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0924 | Train accuracy: 68.04%.\n",
            "2023-10-30 15:34:53,379 max.py[line:93] INFO: max: attack effectiveness 98.57142857142858%.\n",
            "2023-10-30 15:34:53,392 md_at_ma.py[line:120] INFO: Mini batch: 120/1450 | training time in 1 minutes, 16 seconds.\n",
            "2023-10-30 15:34:53,392 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1353 | Train accuracy: 63.13%.\n",
            "2023-10-30 15:34:54,163 max.py[line:93] INFO: max: attack effectiveness 97.1830985915493%.\n",
            "2023-10-30 15:34:54,176 md_at_ma.py[line:120] INFO: Mini batch: 121/1450 | training time in 1 minutes, 17 seconds.\n",
            "2023-10-30 15:34:54,176 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1190 | Train accuracy: 64.32%.\n",
            "2023-10-30 15:34:55,002 max.py[line:93] INFO: max: attack effectiveness 97.36842105263158%.\n",
            "2023-10-30 15:34:55,014 md_at_ma.py[line:120] INFO: Mini batch: 122/1450 | training time in 1 minutes, 18 seconds.\n",
            "2023-10-30 15:34:55,014 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1065 | Train accuracy: 62.25%.\n",
            "2023-10-30 15:34:55,515 max.py[line:93] INFO: max: attack effectiveness 100.0%.\n",
            "2023-10-30 15:34:55,524 md_at_ma.py[line:120] INFO: Mini batch: 123/1450 | training time in 1 minutes, 18 seconds.\n",
            "2023-10-30 15:34:55,525 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0622 | Train accuracy: 69.31%.\n",
            "2023-10-30 15:34:56,307 max.py[line:93] INFO: max: attack effectiveness 97.10144927536231%.\n",
            "2023-10-30 15:34:56,320 md_at_ma.py[line:120] INFO: Mini batch: 124/1450 | training time in 1 minutes, 19 seconds.\n",
            "2023-10-30 15:34:56,320 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1364 | Train accuracy: 63.45%.\n",
            "2023-10-30 15:34:56,843 max.py[line:93] INFO: max: attack effectiveness 98.38709677419355%.\n",
            "2023-10-30 15:34:56,852 md_at_ma.py[line:120] INFO: Mini batch: 125/1450 | training time in 1 minutes, 19 seconds.\n",
            "2023-10-30 15:34:56,852 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0771 | Train accuracy: 66.32%.\n",
            "2023-10-30 15:34:57,480 max.py[line:93] INFO: max: attack effectiveness 93.33333333333333%.\n",
            "2023-10-30 15:34:57,489 md_at_ma.py[line:120] INFO: Mini batch: 126/1450 | training time in 1 minutes, 20 seconds.\n",
            "2023-10-30 15:34:57,489 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0938 | Train accuracy: 67.55%.\n",
            "2023-10-30 15:34:58,095 max.py[line:93] INFO: max: attack effectiveness 96.29629629629629%.\n",
            "2023-10-30 15:34:58,103 md_at_ma.py[line:120] INFO: Mini batch: 127/1450 | training time in 1 minutes, 20 seconds.\n",
            "2023-10-30 15:34:58,103 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0733 | Train accuracy: 71.43%.\n",
            "2023-10-30 15:34:58,583 max.py[line:93] INFO: max: attack effectiveness 96.82539682539682%.\n",
            "2023-10-30 15:34:58,592 md_at_ma.py[line:120] INFO: Mini batch: 128/1450 | training time in 1 minutes, 21 seconds.\n",
            "2023-10-30 15:34:58,592 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1171 | Train accuracy: 67.02%.\n",
            "2023-10-30 15:34:59,325 max.py[line:93] INFO: max: attack effectiveness 96.92307692307692%.\n",
            "2023-10-30 15:34:59,338 md_at_ma.py[line:120] INFO: Mini batch: 129/1450 | training time in 1 minutes, 22 seconds.\n",
            "2023-10-30 15:34:59,338 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0803 | Train accuracy: 68.91%.\n",
            "2023-10-30 15:35:00,075 max.py[line:93] INFO: max: attack effectiveness 93.93939393939394%.\n",
            "2023-10-30 15:35:00,087 md_at_ma.py[line:120] INFO: Mini batch: 130/1450 | training time in 1 minutes, 22 seconds.\n",
            "2023-10-30 15:35:00,087 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0926 | Train accuracy: 70.62%.\n",
            "2023-10-30 15:35:00,584 max.py[line:93] INFO: max: attack effectiveness 93.84615384615384%.\n",
            "2023-10-30 15:35:00,597 md_at_ma.py[line:120] INFO: Mini batch: 131/1450 | training time in 1 minutes, 23 seconds.\n",
            "2023-10-30 15:35:00,597 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0858 | Train accuracy: 75.13%.\n",
            "2023-10-30 15:35:01,374 max.py[line:93] INFO: max: attack effectiveness 94.36619718309859%.\n",
            "2023-10-30 15:35:01,387 md_at_ma.py[line:120] INFO: Mini batch: 132/1450 | training time in 1 minutes, 24 seconds.\n",
            "2023-10-30 15:35:01,387 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0812 | Train accuracy: 68.84%.\n",
            "2023-10-30 15:35:01,868 max.py[line:93] INFO: max: attack effectiveness 95.3125%.\n",
            "2023-10-30 15:35:01,877 md_at_ma.py[line:120] INFO: Mini batch: 133/1450 | training time in 1 minutes, 24 seconds.\n",
            "2023-10-30 15:35:01,877 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0662 | Train accuracy: 69.27%.\n",
            "2023-10-30 15:35:02,649 max.py[line:93] INFO: max: attack effectiveness 94.02985074626866%.\n",
            "2023-10-30 15:35:02,661 md_at_ma.py[line:120] INFO: Mini batch: 134/1450 | training time in 1 minutes, 25 seconds.\n",
            "2023-10-30 15:35:02,661 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1331 | Train accuracy: 70.26%.\n",
            "2023-10-30 15:35:03,147 max.py[line:93] INFO: max: attack effectiveness 98.4375%.\n",
            "2023-10-30 15:35:03,156 md_at_ma.py[line:120] INFO: Mini batch: 135/1450 | training time in 1 minutes, 25 seconds.\n",
            "2023-10-30 15:35:03,156 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1182 | Train accuracy: 68.23%.\n",
            "2023-10-30 15:35:03,933 max.py[line:93] INFO: max: attack effectiveness 94.5945945945946%.\n",
            "2023-10-30 15:35:03,945 md_at_ma.py[line:120] INFO: Mini batch: 136/1450 | training time in 1 minutes, 26 seconds.\n",
            "2023-10-30 15:35:03,946 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1408 | Train accuracy: 66.83%.\n",
            "2023-10-30 15:35:04,717 max.py[line:93] INFO: max: attack effectiveness 97.10144927536231%.\n",
            "2023-10-30 15:35:04,730 md_at_ma.py[line:120] INFO: Mini batch: 137/1450 | training time in 1 minutes, 27 seconds.\n",
            "2023-10-30 15:35:04,730 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0767 | Train accuracy: 69.54%.\n",
            "2023-10-30 15:35:05,551 max.py[line:93] INFO: max: attack effectiveness 94.66666666666667%.\n",
            "2023-10-30 15:35:05,563 md_at_ma.py[line:120] INFO: Mini batch: 138/1450 | training time in 1 minutes, 28 seconds.\n",
            "2023-10-30 15:35:05,563 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1126 | Train accuracy: 67.00%.\n",
            "2023-10-30 15:35:06,332 max.py[line:93] INFO: max: attack effectiveness 91.17647058823529%.\n",
            "2023-10-30 15:35:06,344 md_at_ma.py[line:120] INFO: Mini batch: 139/1450 | training time in 1 minutes, 29 seconds.\n",
            "2023-10-30 15:35:06,344 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0747 | Train accuracy: 68.88%.\n",
            "2023-10-30 15:35:06,930 max.py[line:93] INFO: max: attack effectiveness 96.61016949152543%.\n",
            "2023-10-30 15:35:06,939 md_at_ma.py[line:120] INFO: Mini batch: 140/1450 | training time in 1 minutes, 29 seconds.\n",
            "2023-10-30 15:35:06,939 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1147 | Train accuracy: 71.66%.\n",
            "2023-10-30 15:35:07,760 max.py[line:93] INFO: max: attack effectiveness 90.66666666666666%.\n",
            "2023-10-30 15:35:07,772 md_at_ma.py[line:120] INFO: Mini batch: 141/1450 | training time in 1 minutes, 30 seconds.\n",
            "2023-10-30 15:35:07,773 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0648 | Train accuracy: 69.95%.\n",
            "2023-10-30 15:35:08,550 max.py[line:93] INFO: max: attack effectiveness 89.85507246376811%.\n",
            "2023-10-30 15:35:08,563 md_at_ma.py[line:120] INFO: Mini batch: 142/1450 | training time in 1 minutes, 31 seconds.\n",
            "2023-10-30 15:35:08,563 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0921 | Train accuracy: 70.05%.\n",
            "2023-10-30 15:35:09,054 max.py[line:93] INFO: max: attack effectiveness 85.9375%.\n",
            "2023-10-30 15:35:09,063 md_at_ma.py[line:120] INFO: Mini batch: 143/1450 | training time in 1 minutes, 31 seconds.\n",
            "2023-10-30 15:35:09,063 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0864 | Train accuracy: 74.48%.\n",
            "2023-10-30 15:35:09,547 max.py[line:93] INFO: max: attack effectiveness 90.32258064516128%.\n",
            "2023-10-30 15:35:09,556 md_at_ma.py[line:120] INFO: Mini batch: 144/1450 | training time in 1 minutes, 32 seconds.\n",
            "2023-10-30 15:35:09,557 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0658 | Train accuracy: 75.26%.\n",
            "2023-10-30 15:35:09,946 max.py[line:93] INFO: max: attack effectiveness 83.33333333333334%.\n",
            "2023-10-30 15:35:09,950 md_at_ma.py[line:120] INFO: Mini batch: 145/1450 | training time in 1 minutes, 32 seconds.\n",
            "2023-10-30 15:35:09,951 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0494 | Train accuracy: 73.68%.\n",
            "2023-10-30 15:35:09,986 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0941 | Train accuracy: 68.92\n",
            "2023-10-30 15:35:12,114 max.py[line:93] INFO: max: attack effectiveness 95.3125%.\n",
            "2023-10-30 15:35:13,078 max.py[line:93] INFO: max: attack effectiveness 93.75%.\n",
            "2023-10-30 15:35:14,037 max.py[line:93] INFO: max: attack effectiveness 93.75%.\n",
            "2023-10-30 15:35:14,928 max.py[line:93] INFO: max: attack effectiveness 91.40625%.\n",
            "2023-10-30 15:35:15,573 max.py[line:93] INFO: max: attack effectiveness 93.47826086956522%.\n",
            "2023-10-30 15:35:16,224 md_at_ma.py[line:165] INFO: \tVal accuracy 51.33% with accuracy 6.452% under attack.\n",
            "2023-10-30 15:35:16,224 md_at_ma.py[line:167] INFO: \tModel select at epoch 5 with validation accuracy 51.33% and accuracy 6.452% under attack.\n",
            "2023-10-30 15:35:17,112 max.py[line:93] INFO: max: attack effectiveness 95.45454545454545%.\n",
            "2023-10-30 15:35:17,125 md_at_ma.py[line:120] INFO: Mini batch: 146/1450 | training time in 1 minutes, 33 seconds.\n",
            "2023-10-30 15:35:17,125 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0751 | Train accuracy: 72.16%.\n",
            "2023-10-30 15:35:17,609 max.py[line:93] INFO: max: attack effectiveness 98.4126984126984%.\n",
            "2023-10-30 15:35:17,618 md_at_ma.py[line:120] INFO: Mini batch: 147/1450 | training time in 1 minutes, 33 seconds.\n",
            "2023-10-30 15:35:17,618 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0957 | Train accuracy: 71.73%.\n",
            "2023-10-30 15:35:18,355 max.py[line:93] INFO: max: attack effectiveness 87.87878787878788%.\n",
            "2023-10-30 15:35:18,367 md_at_ma.py[line:120] INFO: Mini batch: 148/1450 | training time in 1 minutes, 34 seconds.\n",
            "2023-10-30 15:35:18,367 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0747 | Train accuracy: 74.23%.\n",
            "2023-10-30 15:35:19,137 max.py[line:93] INFO: max: attack effectiveness 94.28571428571428%.\n",
            "2023-10-30 15:35:19,150 md_at_ma.py[line:120] INFO: Mini batch: 149/1450 | training time in 1 minutes, 35 seconds.\n",
            "2023-10-30 15:35:19,150 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0957 | Train accuracy: 69.70%.\n",
            "2023-10-30 15:35:19,922 max.py[line:93] INFO: max: attack effectiveness 95.77464788732394%.\n",
            "2023-10-30 15:35:19,934 md_at_ma.py[line:120] INFO: Mini batch: 150/1450 | training time in 1 minutes, 36 seconds.\n",
            "2023-10-30 15:35:19,934 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1117 | Train accuracy: 67.34%.\n",
            "2023-10-30 15:35:20,757 max.py[line:93] INFO: max: attack effectiveness 94.73684210526315%.\n",
            "2023-10-30 15:35:20,770 md_at_ma.py[line:120] INFO: Mini batch: 151/1450 | training time in 1 minutes, 36 seconds.\n",
            "2023-10-30 15:35:20,770 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0976 | Train accuracy: 68.63%.\n",
            "2023-10-30 15:35:21,259 max.py[line:93] INFO: max: attack effectiveness 95.08196721311475%.\n",
            "2023-10-30 15:35:21,269 md_at_ma.py[line:120] INFO: Mini batch: 152/1450 | training time in 1 minutes, 37 seconds.\n",
            "2023-10-30 15:35:21,270 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0511 | Train accuracy: 71.96%.\n",
            "2023-10-30 15:35:22,056 max.py[line:93] INFO: max: attack effectiveness 91.30434782608695%.\n",
            "2023-10-30 15:35:22,068 md_at_ma.py[line:120] INFO: Mini batch: 153/1450 | training time in 1 minutes, 38 seconds.\n",
            "2023-10-30 15:35:22,069 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1246 | Train accuracy: 69.04%.\n",
            "2023-10-30 15:35:22,563 max.py[line:93] INFO: max: attack effectiveness 96.7741935483871%.\n",
            "2023-10-30 15:35:22,572 md_at_ma.py[line:120] INFO: Mini batch: 154/1450 | training time in 1 minutes, 38 seconds.\n",
            "2023-10-30 15:35:22,572 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0586 | Train accuracy: 72.63%.\n",
            "2023-10-30 15:35:23,162 max.py[line:93] INFO: max: attack effectiveness 88.33333333333333%.\n",
            "2023-10-30 15:35:23,171 md_at_ma.py[line:120] INFO: Mini batch: 155/1450 | training time in 1 minutes, 39 seconds.\n",
            "2023-10-30 15:35:23,171 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0725 | Train accuracy: 72.87%.\n",
            "2023-10-30 15:35:23,774 max.py[line:93] INFO: max: attack effectiveness 96.29629629629629%.\n",
            "2023-10-30 15:35:23,783 md_at_ma.py[line:120] INFO: Mini batch: 156/1450 | training time in 1 minutes, 39 seconds.\n",
            "2023-10-30 15:35:23,783 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0528 | Train accuracy: 72.53%.\n",
            "2023-10-30 15:35:24,286 max.py[line:93] INFO: max: attack effectiveness 92.06349206349206%.\n",
            "2023-10-30 15:35:24,295 md_at_ma.py[line:120] INFO: Mini batch: 157/1450 | training time in 1 minutes, 40 seconds.\n",
            "2023-10-30 15:35:24,295 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0928 | Train accuracy: 71.20%.\n",
            "2023-10-30 15:35:25,037 max.py[line:93] INFO: max: attack effectiveness 90.76923076923077%.\n",
            "2023-10-30 15:35:25,049 md_at_ma.py[line:120] INFO: Mini batch: 158/1450 | training time in 1 minutes, 41 seconds.\n",
            "2023-10-30 15:35:25,049 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0614 | Train accuracy: 70.47%.\n",
            "2023-10-30 15:35:25,787 max.py[line:93] INFO: max: attack effectiveness 78.78787878787878%.\n",
            "2023-10-30 15:35:25,799 md_at_ma.py[line:120] INFO: Mini batch: 159/1450 | training time in 1 minutes, 41 seconds.\n",
            "2023-10-30 15:35:25,800 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0774 | Train accuracy: 73.20%.\n",
            "2023-10-30 15:35:26,294 max.py[line:93] INFO: max: attack effectiveness 73.84615384615385%.\n",
            "2023-10-30 15:35:26,306 md_at_ma.py[line:120] INFO: Mini batch: 160/1450 | training time in 1 minutes, 42 seconds.\n",
            "2023-10-30 15:35:26,307 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0729 | Train accuracy: 75.65%.\n",
            "2023-10-30 15:35:27,087 max.py[line:93] INFO: max: attack effectiveness 87.32394366197182%.\n",
            "2023-10-30 15:35:27,100 md_at_ma.py[line:120] INFO: Mini batch: 161/1450 | training time in 1 minutes, 43 seconds.\n",
            "2023-10-30 15:35:27,100 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0778 | Train accuracy: 72.86%.\n",
            "2023-10-30 15:35:27,584 max.py[line:93] INFO: max: attack effectiveness 78.125%.\n",
            "2023-10-30 15:35:27,593 md_at_ma.py[line:120] INFO: Mini batch: 162/1450 | training time in 1 minutes, 43 seconds.\n",
            "2023-10-30 15:35:27,593 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0467 | Train accuracy: 76.04%.\n",
            "2023-10-30 15:35:28,363 max.py[line:93] INFO: max: attack effectiveness 77.61194029850746%.\n",
            "2023-10-30 15:35:28,375 md_at_ma.py[line:120] INFO: Mini batch: 163/1450 | training time in 1 minutes, 44 seconds.\n",
            "2023-10-30 15:35:28,375 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1176 | Train accuracy: 74.36%.\n",
            "2023-10-30 15:35:28,859 max.py[line:93] INFO: max: attack effectiveness 87.5%.\n",
            "2023-10-30 15:35:28,868 md_at_ma.py[line:120] INFO: Mini batch: 164/1450 | training time in 1 minutes, 44 seconds.\n",
            "2023-10-30 15:35:28,869 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1044 | Train accuracy: 74.48%.\n",
            "2023-10-30 15:35:29,648 max.py[line:93] INFO: max: attack effectiveness 86.48648648648648%.\n",
            "2023-10-30 15:35:29,661 md_at_ma.py[line:120] INFO: Mini batch: 165/1450 | training time in 1 minutes, 45 seconds.\n",
            "2023-10-30 15:35:29,661 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1192 | Train accuracy: 69.31%.\n",
            "2023-10-30 15:35:30,434 max.py[line:93] INFO: max: attack effectiveness 76.81159420289855%.\n",
            "2023-10-30 15:35:30,446 md_at_ma.py[line:120] INFO: Mini batch: 166/1450 | training time in 1 minutes, 46 seconds.\n",
            "2023-10-30 15:35:30,446 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0618 | Train accuracy: 74.11%.\n",
            "2023-10-30 15:35:31,272 max.py[line:93] INFO: max: attack effectiveness 85.33333333333334%.\n",
            "2023-10-30 15:35:31,285 md_at_ma.py[line:120] INFO: Mini batch: 167/1450 | training time in 1 minutes, 47 seconds.\n",
            "2023-10-30 15:35:31,285 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0782 | Train accuracy: 69.46%.\n",
            "2023-10-30 15:35:32,053 max.py[line:93] INFO: max: attack effectiveness 79.41176470588235%.\n",
            "2023-10-30 15:35:32,065 md_at_ma.py[line:120] INFO: Mini batch: 168/1450 | training time in 1 minutes, 47 seconds.\n",
            "2023-10-30 15:35:32,066 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0595 | Train accuracy: 74.49%.\n",
            "2023-10-30 15:35:32,659 max.py[line:93] INFO: max: attack effectiveness 86.4406779661017%.\n",
            "2023-10-30 15:35:32,668 md_at_ma.py[line:120] INFO: Mini batch: 169/1450 | training time in 1 minutes, 48 seconds.\n",
            "2023-10-30 15:35:32,668 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1114 | Train accuracy: 74.87%.\n",
            "2023-10-30 15:35:33,491 max.py[line:93] INFO: max: attack effectiveness 82.66666666666667%.\n",
            "2023-10-30 15:35:33,504 md_at_ma.py[line:120] INFO: Mini batch: 170/1450 | training time in 1 minutes, 49 seconds.\n",
            "2023-10-30 15:35:33,504 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0481 | Train accuracy: 71.43%.\n",
            "2023-10-30 15:35:34,280 max.py[line:93] INFO: max: attack effectiveness 78.26086956521739%.\n",
            "2023-10-30 15:35:34,293 md_at_ma.py[line:120] INFO: Mini batch: 171/1450 | training time in 1 minutes, 50 seconds.\n",
            "2023-10-30 15:35:34,293 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0906 | Train accuracy: 71.57%.\n",
            "2023-10-30 15:35:34,787 max.py[line:93] INFO: max: attack effectiveness 64.0625%.\n",
            "2023-10-30 15:35:34,796 md_at_ma.py[line:120] INFO: Mini batch: 172/1450 | training time in 1 minutes, 50 seconds.\n",
            "2023-10-30 15:35:34,796 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0557 | Train accuracy: 80.73%.\n",
            "2023-10-30 15:35:35,289 max.py[line:93] INFO: max: attack effectiveness 77.41935483870968%.\n",
            "2023-10-30 15:35:35,298 md_at_ma.py[line:120] INFO: Mini batch: 173/1450 | training time in 1 minutes, 51 seconds.\n",
            "2023-10-30 15:35:35,298 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0592 | Train accuracy: 76.32%.\n",
            "2023-10-30 15:35:35,698 max.py[line:93] INFO: max: attack effectiveness 66.66666666666666%.\n",
            "2023-10-30 15:35:35,703 md_at_ma.py[line:120] INFO: Mini batch: 174/1450 | training time in 1 minutes, 51 seconds.\n",
            "2023-10-30 15:35:35,703 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0329 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:35:35,741 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0785 | Train accuracy: 73.20\n",
            "2023-10-30 15:35:37,961 max.py[line:93] INFO: max: attack effectiveness 80.46875%.\n",
            "2023-10-30 15:35:39,052 max.py[line:93] INFO: max: attack effectiveness 84.375%.\n",
            "2023-10-30 15:35:39,996 max.py[line:93] INFO: max: attack effectiveness 86.71875%.\n",
            "2023-10-30 15:35:40,949 max.py[line:93] INFO: max: attack effectiveness 85.15625%.\n",
            "2023-10-30 15:35:41,676 max.py[line:93] INFO: max: attack effectiveness 86.95652173913044%.\n",
            "2023-10-30 15:35:42,429 md_at_ma.py[line:165] INFO: \tVal accuracy 56.09% with accuracy 15.59% under attack.\n",
            "2023-10-30 15:35:42,429 md_at_ma.py[line:167] INFO: \tModel select at epoch 6 with validation accuracy 56.09% and accuracy 15.59% under attack.\n",
            "2023-10-30 15:35:43,315 max.py[line:93] INFO: max: attack effectiveness 83.33333333333334%.\n",
            "2023-10-30 15:35:43,329 md_at_ma.py[line:120] INFO: Mini batch: 175/1450 | training time in 1 minutes, 52 seconds.\n",
            "2023-10-30 15:35:43,329 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0520 | Train accuracy: 73.71%.\n",
            "2023-10-30 15:35:43,819 max.py[line:93] INFO: max: attack effectiveness 85.71428571428571%.\n",
            "2023-10-30 15:35:43,828 md_at_ma.py[line:120] INFO: Mini batch: 176/1450 | training time in 1 minutes, 52 seconds.\n",
            "2023-10-30 15:35:43,828 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0612 | Train accuracy: 74.35%.\n",
            "2023-10-30 15:35:44,595 max.py[line:93] INFO: max: attack effectiveness 71.21212121212122%.\n",
            "2023-10-30 15:35:44,607 md_at_ma.py[line:120] INFO: Mini batch: 177/1450 | training time in 1 minutes, 53 seconds.\n",
            "2023-10-30 15:35:44,607 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0620 | Train accuracy: 78.87%.\n",
            "2023-10-30 15:35:45,378 max.py[line:93] INFO: max: attack effectiveness 87.14285714285714%.\n",
            "2023-10-30 15:35:45,391 md_at_ma.py[line:120] INFO: Mini batch: 178/1450 | training time in 1 minutes, 54 seconds.\n",
            "2023-10-30 15:35:45,391 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0710 | Train accuracy: 70.20%.\n",
            "2023-10-30 15:35:46,163 max.py[line:93] INFO: max: attack effectiveness 88.73239436619718%.\n",
            "2023-10-30 15:35:46,175 md_at_ma.py[line:120] INFO: Mini batch: 179/1450 | training time in 1 minutes, 55 seconds.\n",
            "2023-10-30 15:35:46,175 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0947 | Train accuracy: 71.36%.\n",
            "2023-10-30 15:35:47,001 max.py[line:93] INFO: max: attack effectiveness 89.47368421052632%.\n",
            "2023-10-30 15:35:47,013 md_at_ma.py[line:120] INFO: Mini batch: 180/1450 | training time in 1 minutes, 55 seconds.\n",
            "2023-10-30 15:35:47,014 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0563 | Train accuracy: 70.59%.\n",
            "2023-10-30 15:35:47,544 max.py[line:93] INFO: max: attack effectiveness 90.1639344262295%.\n",
            "2023-10-30 15:35:47,553 md_at_ma.py[line:120] INFO: Mini batch: 181/1450 | training time in 1 minutes, 56 seconds.\n",
            "2023-10-30 15:35:47,554 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0394 | Train accuracy: 70.90%.\n",
            "2023-10-30 15:35:48,377 max.py[line:93] INFO: max: attack effectiveness 81.15942028985508%.\n",
            "2023-10-30 15:35:48,390 md_at_ma.py[line:120] INFO: Mini batch: 182/1450 | training time in 1 minutes, 57 seconds.\n",
            "2023-10-30 15:35:48,390 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0902 | Train accuracy: 74.62%.\n",
            "2023-10-30 15:35:48,902 max.py[line:93] INFO: max: attack effectiveness 85.48387096774194%.\n",
            "2023-10-30 15:35:48,911 md_at_ma.py[line:120] INFO: Mini batch: 183/1450 | training time in 1 minutes, 57 seconds.\n",
            "2023-10-30 15:35:48,911 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0382 | Train accuracy: 77.89%.\n",
            "2023-10-30 15:35:49,529 max.py[line:93] INFO: max: attack effectiveness 85.0%.\n",
            "2023-10-30 15:35:49,538 md_at_ma.py[line:120] INFO: Mini batch: 184/1450 | training time in 1 minutes, 58 seconds.\n",
            "2023-10-30 15:35:49,538 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0527 | Train accuracy: 73.94%.\n",
            "2023-10-30 15:35:50,128 max.py[line:93] INFO: max: attack effectiveness 90.74074074074075%.\n",
            "2023-10-30 15:35:50,137 md_at_ma.py[line:120] INFO: Mini batch: 185/1450 | training time in 1 minutes, 58 seconds.\n",
            "2023-10-30 15:35:50,138 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0349 | Train accuracy: 79.67%.\n",
            "2023-10-30 15:35:50,669 max.py[line:93] INFO: max: attack effectiveness 92.06349206349206%.\n",
            "2023-10-30 15:35:50,678 md_at_ma.py[line:120] INFO: Mini batch: 186/1450 | training time in 1 minutes, 59 seconds.\n",
            "2023-10-30 15:35:50,678 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0844 | Train accuracy: 69.63%.\n",
            "2023-10-30 15:35:51,419 max.py[line:93] INFO: max: attack effectiveness 90.76923076923077%.\n",
            "2023-10-30 15:35:51,431 md_at_ma.py[line:120] INFO: Mini batch: 187/1450 | training time in 2 minutes, 0 seconds.\n",
            "2023-10-30 15:35:51,432 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0587 | Train accuracy: 70.47%.\n",
            "2023-10-30 15:35:52,173 max.py[line:93] INFO: max: attack effectiveness 83.33333333333334%.\n",
            "2023-10-30 15:35:52,185 md_at_ma.py[line:120] INFO: Mini batch: 188/1450 | training time in 2 minutes, 0 seconds.\n",
            "2023-10-30 15:35:52,185 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0778 | Train accuracy: 72.16%.\n",
            "2023-10-30 15:35:52,682 max.py[line:93] INFO: max: attack effectiveness 84.61538461538461%.\n",
            "2023-10-30 15:35:52,694 md_at_ma.py[line:120] INFO: Mini batch: 189/1450 | training time in 2 minutes, 1 seconds.\n",
            "2023-10-30 15:35:52,694 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0895 | Train accuracy: 72.02%.\n",
            "2023-10-30 15:35:53,469 max.py[line:93] INFO: max: attack effectiveness 90.14084507042254%.\n",
            "2023-10-30 15:35:53,482 md_at_ma.py[line:120] INFO: Mini batch: 190/1450 | training time in 2 minutes, 2 seconds.\n",
            "2023-10-30 15:35:53,482 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0638 | Train accuracy: 67.34%.\n",
            "2023-10-30 15:35:53,971 max.py[line:93] INFO: max: attack effectiveness 89.0625%.\n",
            "2023-10-30 15:35:53,980 md_at_ma.py[line:120] INFO: Mini batch: 191/1450 | training time in 2 minutes, 2 seconds.\n",
            "2023-10-30 15:35:53,981 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0438 | Train accuracy: 72.40%.\n",
            "2023-10-30 15:35:54,750 max.py[line:93] INFO: max: attack effectiveness 92.53731343283582%.\n",
            "2023-10-30 15:35:54,762 md_at_ma.py[line:120] INFO: Mini batch: 192/1450 | training time in 2 minutes, 3 seconds.\n",
            "2023-10-30 15:35:54,763 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1129 | Train accuracy: 68.72%.\n",
            "2023-10-30 15:35:55,243 max.py[line:93] INFO: max: attack effectiveness 92.1875%.\n",
            "2023-10-30 15:35:55,252 md_at_ma.py[line:120] INFO: Mini batch: 193/1450 | training time in 2 minutes, 3 seconds.\n",
            "2023-10-30 15:35:55,252 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1137 | Train accuracy: 71.35%.\n",
            "2023-10-30 15:35:56,030 max.py[line:93] INFO: max: attack effectiveness 87.83783783783784%.\n",
            "2023-10-30 15:35:56,042 md_at_ma.py[line:120] INFO: Mini batch: 194/1450 | training time in 2 minutes, 4 seconds.\n",
            "2023-10-30 15:35:56,042 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1174 | Train accuracy: 69.31%.\n",
            "2023-10-30 15:35:56,815 max.py[line:93] INFO: max: attack effectiveness 82.6086956521739%.\n",
            "2023-10-30 15:35:56,827 md_at_ma.py[line:120] INFO: Mini batch: 195/1450 | training time in 2 minutes, 5 seconds.\n",
            "2023-10-30 15:35:56,827 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0606 | Train accuracy: 74.62%.\n",
            "2023-10-30 15:35:57,652 max.py[line:93] INFO: max: attack effectiveness 78.66666666666666%.\n",
            "2023-10-30 15:35:57,665 md_at_ma.py[line:120] INFO: Mini batch: 196/1450 | training time in 2 minutes, 6 seconds.\n",
            "2023-10-30 15:35:57,665 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0755 | Train accuracy: 72.41%.\n",
            "2023-10-30 15:35:58,436 max.py[line:93] INFO: max: attack effectiveness 76.47058823529412%.\n",
            "2023-10-30 15:35:58,448 md_at_ma.py[line:120] INFO: Mini batch: 197/1450 | training time in 2 minutes, 7 seconds.\n",
            "2023-10-30 15:35:58,448 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0588 | Train accuracy: 73.98%.\n",
            "2023-10-30 15:35:59,035 max.py[line:93] INFO: max: attack effectiveness 86.4406779661017%.\n",
            "2023-10-30 15:35:59,044 md_at_ma.py[line:120] INFO: Mini batch: 198/1450 | training time in 2 minutes, 7 seconds.\n",
            "2023-10-30 15:35:59,045 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0737 | Train accuracy: 75.94%.\n",
            "2023-10-30 15:35:59,869 max.py[line:93] INFO: max: attack effectiveness 74.66666666666667%.\n",
            "2023-10-30 15:35:59,881 md_at_ma.py[line:120] INFO: Mini batch: 199/1450 | training time in 2 minutes, 8 seconds.\n",
            "2023-10-30 15:35:59,881 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0470 | Train accuracy: 73.89%.\n",
            "2023-10-30 15:36:00,651 max.py[line:93] INFO: max: attack effectiveness 73.91304347826086%.\n",
            "2023-10-30 15:36:00,663 md_at_ma.py[line:120] INFO: Mini batch: 200/1450 | training time in 2 minutes, 9 seconds.\n",
            "2023-10-30 15:36:00,663 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0798 | Train accuracy: 75.63%.\n",
            "2023-10-30 15:36:01,161 max.py[line:93] INFO: max: attack effectiveness 65.625%.\n",
            "2023-10-30 15:36:01,170 md_at_ma.py[line:120] INFO: Mini batch: 201/1450 | training time in 2 minutes, 9 seconds.\n",
            "2023-10-30 15:36:01,171 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0527 | Train accuracy: 79.17%.\n",
            "2023-10-30 15:36:01,657 max.py[line:93] INFO: max: attack effectiveness 72.58064516129032%.\n",
            "2023-10-30 15:36:01,666 md_at_ma.py[line:120] INFO: Mini batch: 202/1450 | training time in 2 minutes, 10 seconds.\n",
            "2023-10-30 15:36:01,667 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0487 | Train accuracy: 78.42%.\n",
            "2023-10-30 15:36:02,064 max.py[line:93] INFO: max: attack effectiveness 66.66666666666666%.\n",
            "2023-10-30 15:36:02,069 md_at_ma.py[line:120] INFO: Mini batch: 203/1450 | training time in 2 minutes, 10 seconds.\n",
            "2023-10-30 15:36:02,069 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0352 | Train accuracy: 84.21%.\n",
            "2023-10-30 15:36:02,111 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0671 | Train accuracy: 73.72\n",
            "2023-10-30 15:36:04,530 max.py[line:93] INFO: max: attack effectiveness 81.25%.\n",
            "2023-10-30 15:36:05,572 max.py[line:93] INFO: max: attack effectiveness 86.71875%.\n",
            "2023-10-30 15:36:06,464 max.py[line:93] INFO: max: attack effectiveness 84.375%.\n",
            "2023-10-30 15:36:07,542 max.py[line:93] INFO: max: attack effectiveness 84.375%.\n",
            "2023-10-30 15:36:08,125 max.py[line:93] INFO: max: attack effectiveness 86.95652173913044%.\n",
            "2023-10-30 15:36:08,862 md_at_ma.py[line:165] INFO: \tVal accuracy 56.24% with accuracy 15.59% under attack.\n",
            "2023-10-30 15:36:08,863 md_at_ma.py[line:167] INFO: \tModel select at epoch 7 with validation accuracy 56.24% and accuracy 15.59% under attack.\n",
            "2023-10-30 15:36:09,725 max.py[line:93] INFO: max: attack effectiveness 80.3030303030303%.\n",
            "2023-10-30 15:36:09,738 md_at_ma.py[line:120] INFO: Mini batch: 204/1450 | training time in 2 minutes, 11 seconds.\n",
            "2023-10-30 15:36:09,738 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0632 | Train accuracy: 73.20%.\n",
            "2023-10-30 15:36:10,226 max.py[line:93] INFO: max: attack effectiveness 79.36507936507937%.\n",
            "2023-10-30 15:36:10,235 md_at_ma.py[line:120] INFO: Mini batch: 205/1450 | training time in 2 minutes, 11 seconds.\n",
            "2023-10-30 15:36:10,235 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0603 | Train accuracy: 76.96%.\n",
            "2023-10-30 15:36:11,002 max.py[line:93] INFO: max: attack effectiveness 66.66666666666666%.\n",
            "2023-10-30 15:36:11,015 md_at_ma.py[line:120] INFO: Mini batch: 206/1450 | training time in 2 minutes, 12 seconds.\n",
            "2023-10-30 15:36:11,015 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0573 | Train accuracy: 78.35%.\n",
            "2023-10-30 15:36:11,785 max.py[line:93] INFO: max: attack effectiveness 85.71428571428571%.\n",
            "2023-10-30 15:36:11,798 md_at_ma.py[line:120] INFO: Mini batch: 207/1450 | training time in 2 minutes, 13 seconds.\n",
            "2023-10-30 15:36:11,798 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0708 | Train accuracy: 72.22%.\n",
            "2023-10-30 15:36:12,571 max.py[line:93] INFO: max: attack effectiveness 85.91549295774648%.\n",
            "2023-10-30 15:36:12,583 md_at_ma.py[line:120] INFO: Mini batch: 208/1450 | training time in 2 minutes, 14 seconds.\n",
            "2023-10-30 15:36:12,583 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0824 | Train accuracy: 68.84%.\n",
            "2023-10-30 15:36:13,408 max.py[line:93] INFO: max: attack effectiveness 85.52631578947368%.\n",
            "2023-10-30 15:36:13,420 md_at_ma.py[line:120] INFO: Mini batch: 209/1450 | training time in 2 minutes, 14 seconds.\n",
            "2023-10-30 15:36:13,420 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0435 | Train accuracy: 69.12%.\n",
            "2023-10-30 15:36:13,902 max.py[line:93] INFO: max: attack effectiveness 75.40983606557377%.\n",
            "2023-10-30 15:36:13,911 md_at_ma.py[line:120] INFO: Mini batch: 210/1450 | training time in 2 minutes, 15 seconds.\n",
            "2023-10-30 15:36:13,911 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0376 | Train accuracy: 77.78%.\n",
            "2023-10-30 15:36:14,689 max.py[line:93] INFO: max: attack effectiveness 76.81159420289855%.\n",
            "2023-10-30 15:36:14,702 md_at_ma.py[line:120] INFO: Mini batch: 211/1450 | training time in 2 minutes, 16 seconds.\n",
            "2023-10-30 15:36:14,702 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0692 | Train accuracy: 74.11%.\n",
            "2023-10-30 15:36:15,222 max.py[line:93] INFO: max: attack effectiveness 74.19354838709677%.\n",
            "2023-10-30 15:36:15,232 md_at_ma.py[line:120] INFO: Mini batch: 212/1450 | training time in 2 minutes, 16 seconds.\n",
            "2023-10-30 15:36:15,232 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0349 | Train accuracy: 77.89%.\n",
            "2023-10-30 15:36:15,838 max.py[line:93] INFO: max: attack effectiveness 80.0%.\n",
            "2023-10-30 15:36:15,847 md_at_ma.py[line:120] INFO: Mini batch: 213/1450 | training time in 2 minutes, 17 seconds.\n",
            "2023-10-30 15:36:15,847 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0489 | Train accuracy: 76.06%.\n",
            "2023-10-30 15:36:16,466 max.py[line:93] INFO: max: attack effectiveness 90.74074074074075%.\n",
            "2023-10-30 15:36:16,476 md_at_ma.py[line:120] INFO: Mini batch: 214/1450 | training time in 2 minutes, 17 seconds.\n",
            "2023-10-30 15:36:16,476 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0291 | Train accuracy: 78.02%.\n",
            "2023-10-30 15:36:17,002 max.py[line:93] INFO: max: attack effectiveness 88.88888888888889%.\n",
            "2023-10-30 15:36:17,012 md_at_ma.py[line:120] INFO: Mini batch: 215/1450 | training time in 2 minutes, 18 seconds.\n",
            "2023-10-30 15:36:17,012 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0699 | Train accuracy: 73.30%.\n",
            "2023-10-30 15:36:17,766 max.py[line:93] INFO: max: attack effectiveness 84.61538461538461%.\n",
            "2023-10-30 15:36:17,778 md_at_ma.py[line:120] INFO: Mini batch: 216/1450 | training time in 2 minutes, 19 seconds.\n",
            "2023-10-30 15:36:17,778 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0381 | Train accuracy: 71.50%.\n",
            "2023-10-30 15:36:18,513 max.py[line:93] INFO: max: attack effectiveness 74.24242424242425%.\n",
            "2023-10-30 15:36:18,526 md_at_ma.py[line:120] INFO: Mini batch: 217/1450 | training time in 2 minutes, 19 seconds.\n",
            "2023-10-30 15:36:18,526 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0489 | Train accuracy: 76.29%.\n",
            "2023-10-30 15:36:19,020 max.py[line:93] INFO: max: attack effectiveness 73.84615384615385%.\n",
            "2023-10-30 15:36:19,032 md_at_ma.py[line:120] INFO: Mini batch: 218/1450 | training time in 2 minutes, 20 seconds.\n",
            "2023-10-30 15:36:19,032 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0586 | Train accuracy: 77.20%.\n",
            "2023-10-30 15:36:19,808 max.py[line:93] INFO: max: attack effectiveness 77.46478873239437%.\n",
            "2023-10-30 15:36:19,820 md_at_ma.py[line:120] INFO: Mini batch: 219/1450 | training time in 2 minutes, 21 seconds.\n",
            "2023-10-30 15:36:19,820 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0410 | Train accuracy: 72.86%.\n",
            "2023-10-30 15:36:20,307 max.py[line:93] INFO: max: attack effectiveness 71.875%.\n",
            "2023-10-30 15:36:20,316 md_at_ma.py[line:120] INFO: Mini batch: 220/1450 | training time in 2 minutes, 21 seconds.\n",
            "2023-10-30 15:36:20,316 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0274 | Train accuracy: 77.60%.\n",
            "2023-10-30 15:36:21,084 max.py[line:93] INFO: max: attack effectiveness 73.13432835820896%.\n",
            "2023-10-30 15:36:21,096 md_at_ma.py[line:120] INFO: Mini batch: 221/1450 | training time in 2 minutes, 22 seconds.\n",
            "2023-10-30 15:36:21,096 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1003 | Train accuracy: 75.90%.\n",
            "2023-10-30 15:36:21,584 max.py[line:93] INFO: max: attack effectiveness 79.6875%.\n",
            "2023-10-30 15:36:21,594 md_at_ma.py[line:120] INFO: Mini batch: 222/1450 | training time in 2 minutes, 22 seconds.\n",
            "2023-10-30 15:36:21,594 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0625 | Train accuracy: 76.56%.\n",
            "2023-10-30 15:36:22,382 max.py[line:93] INFO: max: attack effectiveness 70.27027027027027%.\n",
            "2023-10-30 15:36:22,395 md_at_ma.py[line:120] INFO: Mini batch: 223/1450 | training time in 2 minutes, 23 seconds.\n",
            "2023-10-30 15:36:22,395 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1068 | Train accuracy: 75.25%.\n",
            "2023-10-30 15:36:23,170 max.py[line:93] INFO: max: attack effectiveness 68.11594202898551%.\n",
            "2023-10-30 15:36:23,182 md_at_ma.py[line:120] INFO: Mini batch: 224/1450 | training time in 2 minutes, 24 seconds.\n",
            "2023-10-30 15:36:23,182 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0431 | Train accuracy: 77.66%.\n",
            "2023-10-30 15:36:24,003 max.py[line:93] INFO: max: attack effectiveness 64.0%.\n",
            "2023-10-30 15:36:24,015 md_at_ma.py[line:120] INFO: Mini batch: 225/1450 | training time in 2 minutes, 25 seconds.\n",
            "2023-10-30 15:36:24,015 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0488 | Train accuracy: 77.34%.\n",
            "2023-10-30 15:36:24,784 max.py[line:93] INFO: max: attack effectiveness 64.70588235294117%.\n",
            "2023-10-30 15:36:24,796 md_at_ma.py[line:120] INFO: Mini batch: 226/1450 | training time in 2 minutes, 26 seconds.\n",
            "2023-10-30 15:36:24,797 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0347 | Train accuracy: 79.59%.\n",
            "2023-10-30 15:36:25,391 max.py[line:93] INFO: max: attack effectiveness 66.10169491525424%.\n",
            "2023-10-30 15:36:25,400 md_at_ma.py[line:120] INFO: Mini batch: 227/1450 | training time in 2 minutes, 26 seconds.\n",
            "2023-10-30 15:36:25,400 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0704 | Train accuracy: 81.82%.\n",
            "2023-10-30 15:36:26,220 max.py[line:93] INFO: max: attack effectiveness 61.33333333333333%.\n",
            "2023-10-30 15:36:26,233 md_at_ma.py[line:120] INFO: Mini batch: 228/1450 | training time in 2 minutes, 27 seconds.\n",
            "2023-10-30 15:36:26,233 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0299 | Train accuracy: 80.79%.\n",
            "2023-10-30 15:36:27,002 max.py[line:93] INFO: max: attack effectiveness 66.66666666666666%.\n",
            "2023-10-30 15:36:27,014 md_at_ma.py[line:120] INFO: Mini batch: 229/1450 | training time in 2 minutes, 28 seconds.\n",
            "2023-10-30 15:36:27,014 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0678 | Train accuracy: 80.20%.\n",
            "2023-10-30 15:36:27,512 max.py[line:93] INFO: max: attack effectiveness 51.5625%.\n",
            "2023-10-30 15:36:27,521 md_at_ma.py[line:120] INFO: Mini batch: 230/1450 | training time in 2 minutes, 28 seconds.\n",
            "2023-10-30 15:36:27,521 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0459 | Train accuracy: 84.90%.\n",
            "2023-10-30 15:36:28,011 max.py[line:93] INFO: max: attack effectiveness 59.67741935483871%.\n",
            "2023-10-30 15:36:28,020 md_at_ma.py[line:120] INFO: Mini batch: 231/1450 | training time in 2 minutes, 29 seconds.\n",
            "2023-10-30 15:36:28,020 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0360 | Train accuracy: 82.11%.\n",
            "2023-10-30 15:36:28,420 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:36:28,426 md_at_ma.py[line:120] INFO: Mini batch: 232/1450 | training time in 2 minutes, 29 seconds.\n",
            "2023-10-30 15:36:28,426 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0292 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:36:28,460 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0537 | Train accuracy: 77.00\n",
            "2023-10-30 15:36:30,885 max.py[line:93] INFO: max: attack effectiveness 75.78125%.\n",
            "2023-10-30 15:36:32,071 max.py[line:93] INFO: max: attack effectiveness 81.25%.\n",
            "2023-10-30 15:36:32,941 max.py[line:93] INFO: max: attack effectiveness 79.6875%.\n",
            "2023-10-30 15:36:33,893 max.py[line:93] INFO: max: attack effectiveness 80.46875%.\n",
            "2023-10-30 15:36:34,564 max.py[line:93] INFO: max: attack effectiveness 80.43478260869566%.\n",
            "2023-10-30 15:36:35,286 md_at_ma.py[line:165] INFO: \tVal accuracy 58.71% with accuracy 20.61% under attack.\n",
            "2023-10-30 15:36:35,287 md_at_ma.py[line:167] INFO: \tModel select at epoch 8 with validation accuracy 58.71% and accuracy 20.61% under attack.\n",
            "2023-10-30 15:36:36,114 max.py[line:93] INFO: max: attack effectiveness 74.24242424242425%.\n",
            "2023-10-30 15:36:36,127 md_at_ma.py[line:120] INFO: Mini batch: 233/1450 | training time in 2 minutes, 30 seconds.\n",
            "2023-10-30 15:36:36,127 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0432 | Train accuracy: 79.90%.\n",
            "2023-10-30 15:36:36,613 max.py[line:93] INFO: max: attack effectiveness 77.77777777777779%.\n",
            "2023-10-30 15:36:36,622 md_at_ma.py[line:120] INFO: Mini batch: 234/1450 | training time in 2 minutes, 30 seconds.\n",
            "2023-10-30 15:36:36,622 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0425 | Train accuracy: 78.01%.\n",
            "2023-10-30 15:36:37,389 max.py[line:93] INFO: max: attack effectiveness 60.60606060606061%.\n",
            "2023-10-30 15:36:37,402 md_at_ma.py[line:120] INFO: Mini batch: 235/1450 | training time in 2 minutes, 31 seconds.\n",
            "2023-10-30 15:36:37,402 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0420 | Train accuracy: 80.93%.\n",
            "2023-10-30 15:36:38,175 max.py[line:93] INFO: max: attack effectiveness 80.0%.\n",
            "2023-10-30 15:36:38,187 md_at_ma.py[line:120] INFO: Mini batch: 236/1450 | training time in 2 minutes, 32 seconds.\n",
            "2023-10-30 15:36:38,187 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0557 | Train accuracy: 72.73%.\n",
            "2023-10-30 15:36:38,959 max.py[line:93] INFO: max: attack effectiveness 88.73239436619718%.\n",
            "2023-10-30 15:36:38,971 md_at_ma.py[line:120] INFO: Mini batch: 237/1450 | training time in 2 minutes, 33 seconds.\n",
            "2023-10-30 15:36:38,972 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0903 | Train accuracy: 69.85%.\n",
            "2023-10-30 15:36:39,798 max.py[line:93] INFO: max: attack effectiveness 89.47368421052632%.\n",
            "2023-10-30 15:36:39,811 md_at_ma.py[line:120] INFO: Mini batch: 238/1450 | training time in 2 minutes, 33 seconds.\n",
            "2023-10-30 15:36:39,811 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0426 | Train accuracy: 69.61%.\n",
            "2023-10-30 15:36:40,287 max.py[line:93] INFO: max: attack effectiveness 88.52459016393442%.\n",
            "2023-10-30 15:36:40,296 md_at_ma.py[line:120] INFO: Mini batch: 239/1450 | training time in 2 minutes, 34 seconds.\n",
            "2023-10-30 15:36:40,296 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0343 | Train accuracy: 74.60%.\n",
            "2023-10-30 15:36:41,075 max.py[line:93] INFO: max: attack effectiveness 78.26086956521739%.\n",
            "2023-10-30 15:36:41,087 md_at_ma.py[line:120] INFO: Mini batch: 240/1450 | training time in 2 minutes, 35 seconds.\n",
            "2023-10-30 15:36:41,087 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0702 | Train accuracy: 76.14%.\n",
            "2023-10-30 15:36:41,602 max.py[line:93] INFO: max: attack effectiveness 80.64516129032258%.\n",
            "2023-10-30 15:36:41,611 md_at_ma.py[line:120] INFO: Mini batch: 241/1450 | training time in 2 minutes, 35 seconds.\n",
            "2023-10-30 15:36:41,611 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0344 | Train accuracy: 75.79%.\n",
            "2023-10-30 15:36:42,207 max.py[line:93] INFO: max: attack effectiveness 83.33333333333334%.\n",
            "2023-10-30 15:36:42,216 md_at_ma.py[line:120] INFO: Mini batch: 242/1450 | training time in 2 minutes, 36 seconds.\n",
            "2023-10-30 15:36:42,216 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0483 | Train accuracy: 75.53%.\n",
            "2023-10-30 15:36:42,823 max.py[line:93] INFO: max: attack effectiveness 87.03703703703704%.\n",
            "2023-10-30 15:36:42,832 md_at_ma.py[line:120] INFO: Mini batch: 243/1450 | training time in 2 minutes, 36 seconds.\n",
            "2023-10-30 15:36:42,833 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0304 | Train accuracy: 77.47%.\n",
            "2023-10-30 15:36:43,366 max.py[line:93] INFO: max: attack effectiveness 88.88888888888889%.\n",
            "2023-10-30 15:36:43,376 md_at_ma.py[line:120] INFO: Mini batch: 244/1450 | training time in 2 minutes, 37 seconds.\n",
            "2023-10-30 15:36:43,376 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0748 | Train accuracy: 75.39%.\n",
            "2023-10-30 15:36:44,128 max.py[line:93] INFO: max: attack effectiveness 89.23076923076924%.\n",
            "2023-10-30 15:36:44,140 md_at_ma.py[line:120] INFO: Mini batch: 245/1450 | training time in 2 minutes, 38 seconds.\n",
            "2023-10-30 15:36:44,140 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0340 | Train accuracy: 72.54%.\n",
            "2023-10-30 15:36:44,875 max.py[line:93] INFO: max: attack effectiveness 80.3030303030303%.\n",
            "2023-10-30 15:36:44,887 md_at_ma.py[line:120] INFO: Mini batch: 246/1450 | training time in 2 minutes, 38 seconds.\n",
            "2023-10-30 15:36:44,887 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0421 | Train accuracy: 74.74%.\n",
            "2023-10-30 15:36:45,383 max.py[line:93] INFO: max: attack effectiveness 83.07692307692308%.\n",
            "2023-10-30 15:36:45,395 md_at_ma.py[line:120] INFO: Mini batch: 247/1450 | training time in 2 minutes, 39 seconds.\n",
            "2023-10-30 15:36:45,396 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0534 | Train accuracy: 74.61%.\n",
            "2023-10-30 15:36:46,172 max.py[line:93] INFO: max: attack effectiveness 81.69014084507043%.\n",
            "2023-10-30 15:36:46,184 md_at_ma.py[line:120] INFO: Mini batch: 248/1450 | training time in 2 minutes, 40 seconds.\n",
            "2023-10-30 15:36:46,184 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0513 | Train accuracy: 71.86%.\n",
            "2023-10-30 15:36:46,670 max.py[line:93] INFO: max: attack effectiveness 75.0%.\n",
            "2023-10-30 15:36:46,679 md_at_ma.py[line:120] INFO: Mini batch: 249/1450 | training time in 2 minutes, 40 seconds.\n",
            "2023-10-30 15:36:46,680 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0313 | Train accuracy: 79.69%.\n",
            "2023-10-30 15:36:47,446 max.py[line:93] INFO: max: attack effectiveness 76.11940298507463%.\n",
            "2023-10-30 15:36:47,458 md_at_ma.py[line:120] INFO: Mini batch: 250/1450 | training time in 2 minutes, 41 seconds.\n",
            "2023-10-30 15:36:47,459 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0805 | Train accuracy: 74.87%.\n",
            "2023-10-30 15:36:47,940 max.py[line:93] INFO: max: attack effectiveness 81.25%.\n",
            "2023-10-30 15:36:47,949 md_at_ma.py[line:120] INFO: Mini batch: 251/1450 | training time in 2 minutes, 41 seconds.\n",
            "2023-10-30 15:36:47,949 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0558 | Train accuracy: 74.48%.\n",
            "2023-10-30 15:36:48,728 max.py[line:93] INFO: max: attack effectiveness 71.62162162162163%.\n",
            "2023-10-30 15:36:48,740 md_at_ma.py[line:120] INFO: Mini batch: 252/1450 | training time in 2 minutes, 42 seconds.\n",
            "2023-10-30 15:36:48,740 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0967 | Train accuracy: 74.75%.\n",
            "2023-10-30 15:36:49,511 max.py[line:93] INFO: max: attack effectiveness 62.31884057971014%.\n",
            "2023-10-30 15:36:49,524 md_at_ma.py[line:120] INFO: Mini batch: 253/1450 | training time in 2 minutes, 43 seconds.\n",
            "2023-10-30 15:36:49,524 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0498 | Train accuracy: 79.70%.\n",
            "2023-10-30 15:36:50,346 max.py[line:93] INFO: max: attack effectiveness 64.0%.\n",
            "2023-10-30 15:36:50,359 md_at_ma.py[line:120] INFO: Mini batch: 254/1450 | training time in 2 minutes, 44 seconds.\n",
            "2023-10-30 15:36:50,359 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0568 | Train accuracy: 79.31%.\n",
            "2023-10-30 15:36:51,133 max.py[line:93] INFO: max: attack effectiveness 60.29411764705882%.\n",
            "2023-10-30 15:36:51,146 md_at_ma.py[line:120] INFO: Mini batch: 255/1450 | training time in 2 minutes, 44 seconds.\n",
            "2023-10-30 15:36:51,146 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0464 | Train accuracy: 82.65%.\n",
            "2023-10-30 15:36:51,738 max.py[line:93] INFO: max: attack effectiveness 64.40677966101694%.\n",
            "2023-10-30 15:36:51,747 md_at_ma.py[line:120] INFO: Mini batch: 256/1450 | training time in 2 minutes, 45 seconds.\n",
            "2023-10-30 15:36:51,747 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0717 | Train accuracy: 81.82%.\n",
            "2023-10-30 15:36:52,570 max.py[line:93] INFO: max: attack effectiveness 61.33333333333333%.\n",
            "2023-10-30 15:36:52,582 md_at_ma.py[line:120] INFO: Mini batch: 257/1450 | training time in 2 minutes, 46 seconds.\n",
            "2023-10-30 15:36:52,583 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0326 | Train accuracy: 78.82%.\n",
            "2023-10-30 15:36:53,350 max.py[line:93] INFO: max: attack effectiveness 63.76811594202898%.\n",
            "2023-10-30 15:36:53,362 md_at_ma.py[line:120] INFO: Mini batch: 258/1450 | training time in 2 minutes, 47 seconds.\n",
            "2023-10-30 15:36:53,362 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0706 | Train accuracy: 81.22%.\n",
            "2023-10-30 15:36:53,857 max.py[line:93] INFO: max: attack effectiveness 51.5625%.\n",
            "2023-10-30 15:36:53,866 md_at_ma.py[line:120] INFO: Mini batch: 259/1450 | training time in 2 minutes, 47 seconds.\n",
            "2023-10-30 15:36:53,866 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0468 | Train accuracy: 86.46%.\n",
            "2023-10-30 15:36:54,359 max.py[line:93] INFO: max: attack effectiveness 56.451612903225815%.\n",
            "2023-10-30 15:36:54,368 md_at_ma.py[line:120] INFO: Mini batch: 260/1450 | training time in 2 minutes, 48 seconds.\n",
            "2023-10-30 15:36:54,368 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0327 | Train accuracy: 84.74%.\n",
            "2023-10-30 15:36:54,776 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:36:54,780 md_at_ma.py[line:120] INFO: Mini batch: 261/1450 | training time in 2 minutes, 48 seconds.\n",
            "2023-10-30 15:36:54,780 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0259 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:36:54,814 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0513 | Train accuracy: 77.51\n",
            "2023-10-30 15:36:57,173 max.py[line:93] INFO: max: attack effectiveness 75.0%.\n",
            "2023-10-30 15:36:58,245 max.py[line:93] INFO: max: attack effectiveness 75.78125%.\n",
            "2023-10-30 15:36:59,169 max.py[line:93] INFO: max: attack effectiveness 76.5625%.\n",
            "2023-10-30 15:37:00,084 max.py[line:93] INFO: max: attack effectiveness 79.6875%.\n",
            "2023-10-30 15:37:00,804 max.py[line:93] INFO: max: attack effectiveness 80.43478260869566%.\n",
            "2023-10-30 15:37:01,527 md_at_ma.py[line:165] INFO: \tVal accuracy 59.88% with accuracy 22.94% under attack.\n",
            "2023-10-30 15:37:01,527 md_at_ma.py[line:167] INFO: \tModel select at epoch 9 with validation accuracy 59.88% and accuracy 22.94% under attack.\n",
            "2023-10-30 15:37:02,374 max.py[line:93] INFO: max: attack effectiveness 63.63636363636363%.\n",
            "2023-10-30 15:37:02,386 md_at_ma.py[line:120] INFO: Mini batch: 262/1450 | training time in 2 minutes, 49 seconds.\n",
            "2023-10-30 15:37:02,387 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0424 | Train accuracy: 79.90%.\n",
            "2023-10-30 15:37:02,868 max.py[line:93] INFO: max: attack effectiveness 63.49206349206349%.\n",
            "2023-10-30 15:37:02,877 md_at_ma.py[line:120] INFO: Mini batch: 263/1450 | training time in 2 minutes, 49 seconds.\n",
            "2023-10-30 15:37:02,877 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0367 | Train accuracy: 83.77%.\n",
            "2023-10-30 15:37:03,658 max.py[line:93] INFO: max: attack effectiveness 56.060606060606055%.\n",
            "2023-10-30 15:37:03,670 md_at_ma.py[line:120] INFO: Mini batch: 264/1450 | training time in 2 minutes, 50 seconds.\n",
            "2023-10-30 15:37:03,670 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0343 | Train accuracy: 81.96%.\n",
            "2023-10-30 15:37:04,441 max.py[line:93] INFO: max: attack effectiveness 75.71428571428571%.\n",
            "2023-10-30 15:37:04,453 md_at_ma.py[line:120] INFO: Mini batch: 265/1450 | training time in 2 minutes, 51 seconds.\n",
            "2023-10-30 15:37:04,453 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0454 | Train accuracy: 75.25%.\n",
            "2023-10-30 15:37:05,223 max.py[line:93] INFO: max: attack effectiveness 83.09859154929578%.\n",
            "2023-10-30 15:37:05,235 md_at_ma.py[line:120] INFO: Mini batch: 266/1450 | training time in 2 minutes, 51 seconds.\n",
            "2023-10-30 15:37:05,235 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0719 | Train accuracy: 72.36%.\n",
            "2023-10-30 15:37:06,059 max.py[line:93] INFO: max: attack effectiveness 81.57894736842105%.\n",
            "2023-10-30 15:37:06,072 md_at_ma.py[line:120] INFO: Mini batch: 267/1450 | training time in 2 minutes, 52 seconds.\n",
            "2023-10-30 15:37:06,072 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0309 | Train accuracy: 71.57%.\n",
            "2023-10-30 15:37:06,554 max.py[line:93] INFO: max: attack effectiveness 75.40983606557377%.\n",
            "2023-10-30 15:37:06,563 md_at_ma.py[line:120] INFO: Mini batch: 268/1450 | training time in 2 minutes, 53 seconds.\n",
            "2023-10-30 15:37:06,563 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0308 | Train accuracy: 80.42%.\n",
            "2023-10-30 15:37:07,340 max.py[line:93] INFO: max: attack effectiveness 71.01449275362319%.\n",
            "2023-10-30 15:37:07,352 md_at_ma.py[line:120] INFO: Mini batch: 269/1450 | training time in 2 minutes, 54 seconds.\n",
            "2023-10-30 15:37:07,352 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0689 | Train accuracy: 75.63%.\n",
            "2023-10-30 15:37:07,867 max.py[line:93] INFO: max: attack effectiveness 72.58064516129032%.\n",
            "2023-10-30 15:37:07,876 md_at_ma.py[line:120] INFO: Mini batch: 270/1450 | training time in 2 minutes, 54 seconds.\n",
            "2023-10-30 15:37:07,876 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0246 | Train accuracy: 80.53%.\n",
            "2023-10-30 15:37:08,481 max.py[line:93] INFO: max: attack effectiveness 83.33333333333334%.\n",
            "2023-10-30 15:37:08,490 md_at_ma.py[line:120] INFO: Mini batch: 271/1450 | training time in 2 minutes, 55 seconds.\n",
            "2023-10-30 15:37:08,490 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0434 | Train accuracy: 74.47%.\n",
            "2023-10-30 15:37:09,064 max.py[line:93] INFO: max: attack effectiveness 79.62962962962963%.\n",
            "2023-10-30 15:37:09,073 md_at_ma.py[line:120] INFO: Mini batch: 272/1450 | training time in 2 minutes, 55 seconds.\n",
            "2023-10-30 15:37:09,073 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0306 | Train accuracy: 81.32%.\n",
            "2023-10-30 15:37:09,587 max.py[line:93] INFO: max: attack effectiveness 84.12698412698413%.\n",
            "2023-10-30 15:37:09,596 md_at_ma.py[line:120] INFO: Mini batch: 273/1450 | training time in 2 minutes, 56 seconds.\n",
            "2023-10-30 15:37:09,596 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0762 | Train accuracy: 74.35%.\n",
            "2023-10-30 15:37:10,333 max.py[line:93] INFO: max: attack effectiveness 84.61538461538461%.\n",
            "2023-10-30 15:37:10,345 md_at_ma.py[line:120] INFO: Mini batch: 274/1450 | training time in 2 minutes, 56 seconds.\n",
            "2023-10-30 15:37:10,346 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0394 | Train accuracy: 73.06%.\n",
            "2023-10-30 15:37:11,080 max.py[line:93] INFO: max: attack effectiveness 72.72727272727273%.\n",
            "2023-10-30 15:37:11,092 md_at_ma.py[line:120] INFO: Mini batch: 275/1450 | training time in 2 minutes, 57 seconds.\n",
            "2023-10-30 15:37:11,092 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0571 | Train accuracy: 77.84%.\n",
            "2023-10-30 15:37:11,584 max.py[line:93] INFO: max: attack effectiveness 76.92307692307693%.\n",
            "2023-10-30 15:37:11,596 md_at_ma.py[line:120] INFO: Mini batch: 276/1450 | training time in 2 minutes, 58 seconds.\n",
            "2023-10-30 15:37:11,596 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0462 | Train accuracy: 76.17%.\n",
            "2023-10-30 15:37:12,369 max.py[line:93] INFO: max: attack effectiveness 78.87323943661971%.\n",
            "2023-10-30 15:37:12,382 md_at_ma.py[line:120] INFO: Mini batch: 277/1450 | training time in 2 minutes, 58 seconds.\n",
            "2023-10-30 15:37:12,382 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0588 | Train accuracy: 72.36%.\n",
            "2023-10-30 15:37:12,870 max.py[line:93] INFO: max: attack effectiveness 73.4375%.\n",
            "2023-10-30 15:37:12,879 md_at_ma.py[line:120] INFO: Mini batch: 278/1450 | training time in 2 minutes, 59 seconds.\n",
            "2023-10-30 15:37:12,879 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0378 | Train accuracy: 76.56%.\n",
            "2023-10-30 15:37:13,651 max.py[line:93] INFO: max: attack effectiveness 61.19402985074627%.\n",
            "2023-10-30 15:37:13,663 md_at_ma.py[line:120] INFO: Mini batch: 279/1450 | training time in 3 minutes, 0 seconds.\n",
            "2023-10-30 15:37:13,663 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0836 | Train accuracy: 79.49%.\n",
            "2023-10-30 15:37:14,144 max.py[line:93] INFO: max: attack effectiveness 79.6875%.\n",
            "2023-10-30 15:37:14,153 md_at_ma.py[line:120] INFO: Mini batch: 280/1450 | training time in 3 minutes, 0 seconds.\n",
            "2023-10-30 15:37:14,153 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0607 | Train accuracy: 73.44%.\n",
            "2023-10-30 15:37:14,931 max.py[line:93] INFO: max: attack effectiveness 74.32432432432432%.\n",
            "2023-10-30 15:37:14,943 md_at_ma.py[line:120] INFO: Mini batch: 281/1450 | training time in 3 minutes, 1 seconds.\n",
            "2023-10-30 15:37:14,943 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1063 | Train accuracy: 72.77%.\n",
            "2023-10-30 15:37:15,714 max.py[line:93] INFO: max: attack effectiveness 66.66666666666666%.\n",
            "2023-10-30 15:37:15,726 md_at_ma.py[line:120] INFO: Mini batch: 282/1450 | training time in 3 minutes, 2 seconds.\n",
            "2023-10-30 15:37:15,726 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0324 | Train accuracy: 78.17%.\n",
            "2023-10-30 15:37:16,548 max.py[line:93] INFO: max: attack effectiveness 65.33333333333333%.\n",
            "2023-10-30 15:37:16,560 md_at_ma.py[line:120] INFO: Mini batch: 283/1450 | training time in 3 minutes, 3 seconds.\n",
            "2023-10-30 15:37:16,561 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0505 | Train accuracy: 76.85%.\n",
            "2023-10-30 15:37:17,328 max.py[line:93] INFO: max: attack effectiveness 64.70588235294117%.\n",
            "2023-10-30 15:37:17,340 md_at_ma.py[line:120] INFO: Mini batch: 284/1450 | training time in 3 minutes, 3 seconds.\n",
            "2023-10-30 15:37:17,341 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0383 | Train accuracy: 81.63%.\n",
            "2023-10-30 15:37:17,929 max.py[line:93] INFO: max: attack effectiveness 64.40677966101694%.\n",
            "2023-10-30 15:37:17,938 md_at_ma.py[line:120] INFO: Mini batch: 285/1450 | training time in 3 minutes, 4 seconds.\n",
            "2023-10-30 15:37:17,938 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0531 | Train accuracy: 81.82%.\n",
            "2023-10-30 15:37:18,763 max.py[line:93] INFO: max: attack effectiveness 62.66666666666667%.\n",
            "2023-10-30 15:37:18,776 md_at_ma.py[line:120] INFO: Mini batch: 286/1450 | training time in 3 minutes, 5 seconds.\n",
            "2023-10-30 15:37:18,776 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0351 | Train accuracy: 77.34%.\n",
            "2023-10-30 15:37:19,542 max.py[line:93] INFO: max: attack effectiveness 68.11594202898551%.\n",
            "2023-10-30 15:37:19,554 md_at_ma.py[line:120] INFO: Mini batch: 287/1450 | training time in 3 minutes, 5 seconds.\n",
            "2023-10-30 15:37:19,554 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0633 | Train accuracy: 77.66%.\n",
            "2023-10-30 15:37:20,050 max.py[line:93] INFO: max: attack effectiveness 53.125%.\n",
            "2023-10-30 15:37:20,060 md_at_ma.py[line:120] INFO: Mini batch: 288/1450 | training time in 3 minutes, 6 seconds.\n",
            "2023-10-30 15:37:20,061 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0388 | Train accuracy: 83.85%.\n",
            "2023-10-30 15:37:20,546 max.py[line:93] INFO: max: attack effectiveness 61.29032258064516%.\n",
            "2023-10-30 15:37:20,555 md_at_ma.py[line:120] INFO: Mini batch: 289/1450 | training time in 3 minutes, 6 seconds.\n",
            "2023-10-30 15:37:20,555 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0400 | Train accuracy: 83.16%.\n",
            "2023-10-30 15:37:20,960 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:37:20,964 md_at_ma.py[line:120] INFO: Mini batch: 290/1450 | training time in 3 minutes, 7 seconds.\n",
            "2023-10-30 15:37:20,964 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0320 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:37:21,006 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0486 | Train accuracy: 78.04\n",
            "2023-10-30 15:37:23,421 max.py[line:93] INFO: max: attack effectiveness 75.0%.\n",
            "2023-10-30 15:37:24,419 max.py[line:93] INFO: max: attack effectiveness 78.125%.\n",
            "2023-10-30 15:37:25,351 max.py[line:93] INFO: max: attack effectiveness 78.125%.\n",
            "2023-10-30 15:37:26,265 max.py[line:93] INFO: max: attack effectiveness 78.125%.\n",
            "2023-10-30 15:37:26,849 max.py[line:93] INFO: max: attack effectiveness 82.6086956521739%.\n",
            "2023-10-30 15:37:27,525 md_at_ma.py[line:165] INFO: \tVal accuracy 59.56% with accuracy 22.22% under attack.\n",
            "2023-10-30 15:37:27,525 md_at_ma.py[line:167] INFO: \tModel select at epoch 9 with validation accuracy 59.88% and accuracy 22.94% under attack.\n",
            "2023-10-30 15:37:28,355 max.py[line:93] INFO: max: attack effectiveness 72.72727272727273%.\n",
            "2023-10-30 15:37:28,368 md_at_ma.py[line:120] INFO: Mini batch: 291/1450 | training time in 3 minutes, 8 seconds.\n",
            "2023-10-30 15:37:28,368 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0400 | Train accuracy: 78.35%.\n",
            "2023-10-30 15:37:28,850 max.py[line:93] INFO: max: attack effectiveness 66.66666666666666%.\n",
            "2023-10-30 15:37:28,859 md_at_ma.py[line:120] INFO: Mini batch: 292/1450 | training time in 3 minutes, 8 seconds.\n",
            "2023-10-30 15:37:28,859 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0420 | Train accuracy: 81.15%.\n",
            "2023-10-30 15:37:29,627 max.py[line:93] INFO: max: attack effectiveness 59.09090909090909%.\n",
            "2023-10-30 15:37:29,639 md_at_ma.py[line:120] INFO: Mini batch: 293/1450 | training time in 3 minutes, 9 seconds.\n",
            "2023-10-30 15:37:29,639 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0827 | Train accuracy: 83.51%.\n",
            "2023-10-30 15:37:30,412 max.py[line:93] INFO: max: attack effectiveness 75.71428571428571%.\n",
            "2023-10-30 15:37:30,424 md_at_ma.py[line:120] INFO: Mini batch: 294/1450 | training time in 3 minutes, 10 seconds.\n",
            "2023-10-30 15:37:30,424 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0360 | Train accuracy: 75.25%.\n",
            "2023-10-30 15:37:31,196 max.py[line:93] INFO: max: attack effectiveness 80.28169014084507%.\n",
            "2023-10-30 15:37:31,208 md_at_ma.py[line:120] INFO: Mini batch: 295/1450 | training time in 3 minutes, 10 seconds.\n",
            "2023-10-30 15:37:31,208 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0594 | Train accuracy: 73.37%.\n",
            "2023-10-30 15:37:32,032 max.py[line:93] INFO: max: attack effectiveness 75.0%.\n",
            "2023-10-30 15:37:32,044 md_at_ma.py[line:120] INFO: Mini batch: 296/1450 | training time in 3 minutes, 11 seconds.\n",
            "2023-10-30 15:37:32,044 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0324 | Train accuracy: 74.51%.\n",
            "2023-10-30 15:37:32,525 max.py[line:93] INFO: max: attack effectiveness 67.21311475409836%.\n",
            "2023-10-30 15:37:32,534 md_at_ma.py[line:120] INFO: Mini batch: 297/1450 | training time in 3 minutes, 12 seconds.\n",
            "2023-10-30 15:37:32,534 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0260 | Train accuracy: 82.54%.\n",
            "2023-10-30 15:37:33,310 max.py[line:93] INFO: max: attack effectiveness 68.11594202898551%.\n",
            "2023-10-30 15:37:33,322 md_at_ma.py[line:120] INFO: Mini batch: 298/1450 | training time in 3 minutes, 12 seconds.\n",
            "2023-10-30 15:37:33,323 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0556 | Train accuracy: 78.17%.\n",
            "2023-10-30 15:37:33,842 max.py[line:93] INFO: max: attack effectiveness 69.35483870967742%.\n",
            "2023-10-30 15:37:33,852 md_at_ma.py[line:120] INFO: Mini batch: 299/1450 | training time in 3 minutes, 13 seconds.\n",
            "2023-10-30 15:37:33,852 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0314 | Train accuracy: 80.53%.\n",
            "2023-10-30 15:37:34,471 max.py[line:93] INFO: max: attack effectiveness 76.66666666666667%.\n",
            "2023-10-30 15:37:34,481 md_at_ma.py[line:120] INFO: Mini batch: 300/1450 | training time in 3 minutes, 14 seconds.\n",
            "2023-10-30 15:37:34,481 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0404 | Train accuracy: 78.19%.\n",
            "2023-10-30 15:37:35,084 max.py[line:93] INFO: max: attack effectiveness 74.07407407407408%.\n",
            "2023-10-30 15:37:35,093 md_at_ma.py[line:120] INFO: Mini batch: 301/1450 | training time in 3 minutes, 14 seconds.\n",
            "2023-10-30 15:37:35,093 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0246 | Train accuracy: 80.22%.\n",
            "2023-10-30 15:37:35,617 max.py[line:93] INFO: max: attack effectiveness 77.77777777777779%.\n",
            "2023-10-30 15:37:35,626 md_at_ma.py[line:120] INFO: Mini batch: 302/1450 | training time in 3 minutes, 15 seconds.\n",
            "2023-10-30 15:37:35,627 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0627 | Train accuracy: 75.92%.\n",
            "2023-10-30 15:37:36,391 max.py[line:93] INFO: max: attack effectiveness 73.84615384615385%.\n",
            "2023-10-30 15:37:36,403 md_at_ma.py[line:120] INFO: Mini batch: 303/1450 | training time in 3 minutes, 15 seconds.\n",
            "2023-10-30 15:37:36,404 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0278 | Train accuracy: 78.24%.\n",
            "2023-10-30 15:37:37,138 max.py[line:93] INFO: max: attack effectiveness 63.63636363636363%.\n",
            "2023-10-30 15:37:37,150 md_at_ma.py[line:120] INFO: Mini batch: 304/1450 | training time in 3 minutes, 16 seconds.\n",
            "2023-10-30 15:37:37,150 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0485 | Train accuracy: 79.90%.\n",
            "2023-10-30 15:37:37,646 max.py[line:93] INFO: max: attack effectiveness 56.92307692307692%.\n",
            "2023-10-30 15:37:37,658 md_at_ma.py[line:120] INFO: Mini batch: 305/1450 | training time in 3 minutes, 17 seconds.\n",
            "2023-10-30 15:37:37,659 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0444 | Train accuracy: 82.90%.\n",
            "2023-10-30 15:37:38,438 max.py[line:93] INFO: max: attack effectiveness 69.01408450704226%.\n",
            "2023-10-30 15:37:38,450 md_at_ma.py[line:120] INFO: Mini batch: 306/1450 | training time in 3 minutes, 17 seconds.\n",
            "2023-10-30 15:37:38,451 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0509 | Train accuracy: 76.88%.\n",
            "2023-10-30 15:37:38,937 max.py[line:93] INFO: max: attack effectiveness 54.6875%.\n",
            "2023-10-30 15:37:38,946 md_at_ma.py[line:120] INFO: Mini batch: 307/1450 | training time in 3 minutes, 18 seconds.\n",
            "2023-10-30 15:37:38,946 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0295 | Train accuracy: 87.50%.\n",
            "2023-10-30 15:37:39,722 max.py[line:93] INFO: max: attack effectiveness 58.2089552238806%.\n",
            "2023-10-30 15:37:39,735 md_at_ma.py[line:120] INFO: Mini batch: 308/1450 | training time in 3 minutes, 19 seconds.\n",
            "2023-10-30 15:37:39,735 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0776 | Train accuracy: 81.03%.\n",
            "2023-10-30 15:37:40,219 max.py[line:93] INFO: max: attack effectiveness 65.625%.\n",
            "2023-10-30 15:37:40,228 md_at_ma.py[line:120] INFO: Mini batch: 309/1450 | training time in 3 minutes, 19 seconds.\n",
            "2023-10-30 15:37:40,228 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0479 | Train accuracy: 81.25%.\n",
            "2023-10-30 15:37:41,006 max.py[line:93] INFO: max: attack effectiveness 67.56756756756756%.\n",
            "2023-10-30 15:37:41,018 md_at_ma.py[line:120] INFO: Mini batch: 310/1450 | training time in 3 minutes, 20 seconds.\n",
            "2023-10-30 15:37:41,018 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0753 | Train accuracy: 76.24%.\n",
            "2023-10-30 15:37:41,789 max.py[line:93] INFO: max: attack effectiveness 56.52173913043478%.\n",
            "2023-10-30 15:37:41,801 md_at_ma.py[line:120] INFO: Mini batch: 311/1450 | training time in 3 minutes, 21 seconds.\n",
            "2023-10-30 15:37:41,801 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0300 | Train accuracy: 81.73%.\n",
            "2023-10-30 15:37:42,625 max.py[line:93] INFO: max: attack effectiveness 60.0%.\n",
            "2023-10-30 15:37:42,637 md_at_ma.py[line:120] INFO: Mini batch: 312/1450 | training time in 3 minutes, 21 seconds.\n",
            "2023-10-30 15:37:42,637 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0427 | Train accuracy: 78.82%.\n",
            "2023-10-30 15:37:43,408 max.py[line:93] INFO: max: attack effectiveness 55.88235294117647%.\n",
            "2023-10-30 15:37:43,421 md_at_ma.py[line:120] INFO: Mini batch: 313/1450 | training time in 3 minutes, 22 seconds.\n",
            "2023-10-30 15:37:43,421 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0297 | Train accuracy: 82.14%.\n",
            "2023-10-30 15:37:44,014 max.py[line:93] INFO: max: attack effectiveness 61.016949152542374%.\n",
            "2023-10-30 15:37:44,023 md_at_ma.py[line:120] INFO: Mini batch: 314/1450 | training time in 3 minutes, 23 seconds.\n",
            "2023-10-30 15:37:44,023 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0508 | Train accuracy: 83.42%.\n",
            "2023-10-30 15:37:44,845 max.py[line:93] INFO: max: attack effectiveness 58.666666666666664%.\n",
            "2023-10-30 15:37:44,857 md_at_ma.py[line:120] INFO: Mini batch: 315/1450 | training time in 3 minutes, 24 seconds.\n",
            "2023-10-30 15:37:44,857 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0167 | Train accuracy: 80.30%.\n",
            "2023-10-30 15:37:45,624 max.py[line:93] INFO: max: attack effectiveness 59.42028985507246%.\n",
            "2023-10-30 15:37:45,636 md_at_ma.py[line:120] INFO: Mini batch: 316/1450 | training time in 3 minutes, 24 seconds.\n",
            "2023-10-30 15:37:45,636 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0622 | Train accuracy: 79.70%.\n",
            "2023-10-30 15:37:46,135 max.py[line:93] INFO: max: attack effectiveness 48.4375%.\n",
            "2023-10-30 15:37:46,144 md_at_ma.py[line:120] INFO: Mini batch: 317/1450 | training time in 3 minutes, 25 seconds.\n",
            "2023-10-30 15:37:46,144 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0304 | Train accuracy: 85.42%.\n",
            "2023-10-30 15:37:46,640 max.py[line:93] INFO: max: attack effectiveness 53.2258064516129%.\n",
            "2023-10-30 15:37:46,649 md_at_ma.py[line:120] INFO: Mini batch: 318/1450 | training time in 3 minutes, 25 seconds.\n",
            "2023-10-30 15:37:46,649 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0333 | Train accuracy: 85.26%.\n",
            "2023-10-30 15:37:47,049 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:37:47,054 md_at_ma.py[line:120] INFO: Mini batch: 319/1450 | training time in 3 minutes, 26 seconds.\n",
            "2023-10-30 15:37:47,054 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0191 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:37:47,083 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0431 | Train accuracy: 80.41\n",
            "2023-10-30 15:37:49,489 max.py[line:93] INFO: max: attack effectiveness 71.09375%.\n",
            "2023-10-30 15:37:50,539 max.py[line:93] INFO: max: attack effectiveness 75.0%.\n",
            "2023-10-30 15:37:51,430 max.py[line:93] INFO: max: attack effectiveness 73.4375%.\n",
            "2023-10-30 15:37:52,432 max.py[line:93] INFO: max: attack effectiveness 70.3125%.\n",
            "2023-10-30 15:37:52,976 max.py[line:93] INFO: max: attack effectiveness 78.26086956521739%.\n",
            "2023-10-30 15:37:53,701 md_at_ma.py[line:165] INFO: \tVal accuracy 61.99% with accuracy 27.06% under attack.\n",
            "2023-10-30 15:37:53,702 md_at_ma.py[line:167] INFO: \tModel select at epoch 11 with validation accuracy 61.99% and accuracy 27.06% under attack.\n",
            "2023-10-30 15:37:54,596 max.py[line:93] INFO: max: attack effectiveness 59.09090909090909%.\n",
            "2023-10-30 15:37:54,609 md_at_ma.py[line:120] INFO: Mini batch: 320/1450 | training time in 3 minutes, 27 seconds.\n",
            "2023-10-30 15:37:54,609 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0371 | Train accuracy: 83.51%.\n",
            "2023-10-30 15:37:55,105 max.py[line:93] INFO: max: attack effectiveness 61.904761904761905%.\n",
            "2023-10-30 15:37:55,114 md_at_ma.py[line:120] INFO: Mini batch: 321/1450 | training time in 3 minutes, 27 seconds.\n",
            "2023-10-30 15:37:55,114 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0631 | Train accuracy: 79.58%.\n",
            "2023-10-30 15:37:55,881 max.py[line:93] INFO: max: attack effectiveness 51.515151515151516%.\n",
            "2023-10-30 15:37:55,893 md_at_ma.py[line:120] INFO: Mini batch: 322/1450 | training time in 3 minutes, 28 seconds.\n",
            "2023-10-30 15:37:55,893 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0298 | Train accuracy: 86.60%.\n",
            "2023-10-30 15:37:56,667 max.py[line:93] INFO: max: attack effectiveness 72.85714285714285%.\n",
            "2023-10-30 15:37:56,679 md_at_ma.py[line:120] INFO: Mini batch: 323/1450 | training time in 3 minutes, 29 seconds.\n",
            "2023-10-30 15:37:56,679 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0362 | Train accuracy: 78.79%.\n",
            "2023-10-30 15:37:57,456 max.py[line:93] INFO: max: attack effectiveness 77.46478873239437%.\n",
            "2023-10-30 15:37:57,468 md_at_ma.py[line:120] INFO: Mini batch: 324/1450 | training time in 3 minutes, 29 seconds.\n",
            "2023-10-30 15:37:57,469 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0699 | Train accuracy: 74.87%.\n",
            "2023-10-30 15:37:58,297 max.py[line:93] INFO: max: attack effectiveness 80.26315789473685%.\n",
            "2023-10-30 15:37:58,309 md_at_ma.py[line:120] INFO: Mini batch: 325/1450 | training time in 3 minutes, 30 seconds.\n",
            "2023-10-30 15:37:58,309 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0281 | Train accuracy: 73.53%.\n",
            "2023-10-30 15:37:58,791 max.py[line:93] INFO: max: attack effectiveness 72.1311475409836%.\n",
            "2023-10-30 15:37:58,800 md_at_ma.py[line:120] INFO: Mini batch: 326/1450 | training time in 3 minutes, 31 seconds.\n",
            "2023-10-30 15:37:58,800 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0219 | Train accuracy: 79.37%.\n",
            "2023-10-30 15:37:59,583 max.py[line:93] INFO: max: attack effectiveness 72.46376811594203%.\n",
            "2023-10-30 15:37:59,595 md_at_ma.py[line:120] INFO: Mini batch: 327/1450 | training time in 3 minutes, 31 seconds.\n",
            "2023-10-30 15:37:59,595 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0531 | Train accuracy: 76.65%.\n",
            "2023-10-30 15:38:00,122 max.py[line:93] INFO: max: attack effectiveness 75.80645161290323%.\n",
            "2023-10-30 15:38:00,131 md_at_ma.py[line:120] INFO: Mini batch: 328/1450 | training time in 3 minutes, 32 seconds.\n",
            "2023-10-30 15:38:00,132 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0326 | Train accuracy: 77.89%.\n",
            "2023-10-30 15:38:00,753 max.py[line:93] INFO: max: attack effectiveness 75.0%.\n",
            "2023-10-30 15:38:00,762 md_at_ma.py[line:120] INFO: Mini batch: 329/1450 | training time in 3 minutes, 33 seconds.\n",
            "2023-10-30 15:38:00,763 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0417 | Train accuracy: 78.19%.\n",
            "2023-10-30 15:38:01,370 max.py[line:93] INFO: max: attack effectiveness 75.92592592592592%.\n",
            "2023-10-30 15:38:01,379 md_at_ma.py[line:120] INFO: Mini batch: 330/1450 | training time in 3 minutes, 33 seconds.\n",
            "2023-10-30 15:38:01,379 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0267 | Train accuracy: 81.32%.\n",
            "2023-10-30 15:38:01,900 max.py[line:93] INFO: max: attack effectiveness 76.19047619047619%.\n",
            "2023-10-30 15:38:01,909 md_at_ma.py[line:120] INFO: Mini batch: 331/1450 | training time in 3 minutes, 34 seconds.\n",
            "2023-10-30 15:38:01,909 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0662 | Train accuracy: 76.44%.\n",
            "2023-10-30 15:38:02,645 max.py[line:93] INFO: max: attack effectiveness 81.53846153846153%.\n",
            "2023-10-30 15:38:02,657 md_at_ma.py[line:120] INFO: Mini batch: 332/1450 | training time in 3 minutes, 34 seconds.\n",
            "2023-10-30 15:38:02,657 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0248 | Train accuracy: 76.68%.\n",
            "2023-10-30 15:38:03,422 max.py[line:93] INFO: max: attack effectiveness 65.15151515151516%.\n",
            "2023-10-30 15:38:03,434 md_at_ma.py[line:120] INFO: Mini batch: 333/1450 | training time in 3 minutes, 35 seconds.\n",
            "2023-10-30 15:38:03,434 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0429 | Train accuracy: 81.44%.\n",
            "2023-10-30 15:38:04,174 max.py[line:93] INFO: max: attack effectiveness 61.53846153846154%.\n",
            "2023-10-30 15:38:04,186 md_at_ma.py[line:120] INFO: Mini batch: 334/1450 | training time in 3 minutes, 36 seconds.\n",
            "2023-10-30 15:38:04,186 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0360 | Train accuracy: 82.38%.\n",
            "2023-10-30 15:38:04,964 max.py[line:93] INFO: max: attack effectiveness 76.05633802816901%.\n",
            "2023-10-30 15:38:04,976 md_at_ma.py[line:120] INFO: Mini batch: 335/1450 | training time in 3 minutes, 37 seconds.\n",
            "2023-10-30 15:38:04,976 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0504 | Train accuracy: 76.38%.\n",
            "2023-10-30 15:38:05,464 max.py[line:93] INFO: max: attack effectiveness 57.8125%.\n",
            "2023-10-30 15:38:05,473 md_at_ma.py[line:120] INFO: Mini batch: 336/1450 | training time in 3 minutes, 37 seconds.\n",
            "2023-10-30 15:38:05,473 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0206 | Train accuracy: 83.33%.\n",
            "2023-10-30 15:38:06,237 max.py[line:93] INFO: max: attack effectiveness 64.17910447761194%.\n",
            "2023-10-30 15:38:06,250 md_at_ma.py[line:120] INFO: Mini batch: 337/1450 | training time in 3 minutes, 38 seconds.\n",
            "2023-10-30 15:38:06,250 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0789 | Train accuracy: 79.49%.\n",
            "2023-10-30 15:38:06,730 max.py[line:93] INFO: max: attack effectiveness 67.1875%.\n",
            "2023-10-30 15:38:06,739 md_at_ma.py[line:120] INFO: Mini batch: 338/1450 | training time in 3 minutes, 38 seconds.\n",
            "2023-10-30 15:38:06,739 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0555 | Train accuracy: 78.12%.\n",
            "2023-10-30 15:38:07,523 max.py[line:93] INFO: max: attack effectiveness 67.56756756756756%.\n",
            "2023-10-30 15:38:07,536 md_at_ma.py[line:120] INFO: Mini batch: 339/1450 | training time in 3 minutes, 39 seconds.\n",
            "2023-10-30 15:38:07,536 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0930 | Train accuracy: 75.25%.\n",
            "2023-10-30 15:38:08,313 max.py[line:93] INFO: max: attack effectiveness 60.86956521739131%.\n",
            "2023-10-30 15:38:08,325 md_at_ma.py[line:120] INFO: Mini batch: 340/1450 | training time in 3 minutes, 40 seconds.\n",
            "2023-10-30 15:38:08,325 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0308 | Train accuracy: 81.73%.\n",
            "2023-10-30 15:38:09,149 max.py[line:93] INFO: max: attack effectiveness 65.33333333333333%.\n",
            "2023-10-30 15:38:09,162 md_at_ma.py[line:120] INFO: Mini batch: 341/1450 | training time in 3 minutes, 41 seconds.\n",
            "2023-10-30 15:38:09,162 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0326 | Train accuracy: 78.33%.\n",
            "2023-10-30 15:38:09,933 max.py[line:93] INFO: max: attack effectiveness 55.88235294117647%.\n",
            "2023-10-30 15:38:09,946 md_at_ma.py[line:120] INFO: Mini batch: 342/1450 | training time in 3 minutes, 41 seconds.\n",
            "2023-10-30 15:38:09,946 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0422 | Train accuracy: 83.16%.\n",
            "2023-10-30 15:38:10,534 max.py[line:93] INFO: max: attack effectiveness 62.71186440677966%.\n",
            "2023-10-30 15:38:10,543 md_at_ma.py[line:120] INFO: Mini batch: 343/1450 | training time in 3 minutes, 42 seconds.\n",
            "2023-10-30 15:38:10,543 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0420 | Train accuracy: 81.82%.\n",
            "2023-10-30 15:38:11,367 max.py[line:93] INFO: max: attack effectiveness 58.666666666666664%.\n",
            "2023-10-30 15:38:11,379 md_at_ma.py[line:120] INFO: Mini batch: 344/1450 | training time in 3 minutes, 43 seconds.\n",
            "2023-10-30 15:38:11,379 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0288 | Train accuracy: 80.30%.\n",
            "2023-10-30 15:38:12,154 max.py[line:93] INFO: max: attack effectiveness 57.971014492753625%.\n",
            "2023-10-30 15:38:12,167 md_at_ma.py[line:120] INFO: Mini batch: 345/1450 | training time in 3 minutes, 44 seconds.\n",
            "2023-10-30 15:38:12,167 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0666 | Train accuracy: 84.26%.\n",
            "2023-10-30 15:38:12,654 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:38:12,663 md_at_ma.py[line:120] INFO: Mini batch: 346/1450 | training time in 3 minutes, 44 seconds.\n",
            "2023-10-30 15:38:12,663 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0276 | Train accuracy: 84.90%.\n",
            "2023-10-30 15:38:13,150 max.py[line:93] INFO: max: attack effectiveness 56.451612903225815%.\n",
            "2023-10-30 15:38:13,159 md_at_ma.py[line:120] INFO: Mini batch: 347/1450 | training time in 3 minutes, 45 seconds.\n",
            "2023-10-30 15:38:13,160 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0277 | Train accuracy: 87.89%.\n",
            "2023-10-30 15:38:13,550 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:38:13,554 md_at_ma.py[line:120] INFO: Mini batch: 348/1450 | training time in 3 minutes, 45 seconds.\n",
            "2023-10-30 15:38:13,554 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0240 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:38:13,600 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0424 | Train accuracy: 80.40\n",
            "2023-10-30 15:38:15,943 max.py[line:93] INFO: max: attack effectiveness 71.09375%.\n",
            "2023-10-30 15:38:16,889 max.py[line:93] INFO: max: attack effectiveness 74.21875%.\n",
            "2023-10-30 15:38:17,793 max.py[line:93] INFO: max: attack effectiveness 72.65625%.\n",
            "2023-10-30 15:38:18,686 max.py[line:93] INFO: max: attack effectiveness 69.53125%.\n",
            "2023-10-30 15:38:19,337 max.py[line:93] INFO: max: attack effectiveness 82.6086956521739%.\n",
            "2023-10-30 15:38:20,026 md_at_ma.py[line:165] INFO: \tVal accuracy 62.07% with accuracy 27.24% under attack.\n",
            "2023-10-30 15:38:20,026 md_at_ma.py[line:167] INFO: \tModel select at epoch 12 with validation accuracy 62.07% and accuracy 27.24% under attack.\n",
            "2023-10-30 15:38:20,876 max.py[line:93] INFO: max: attack effectiveness 57.57575757575758%.\n",
            "2023-10-30 15:38:20,889 md_at_ma.py[line:120] INFO: Mini batch: 349/1450 | training time in 3 minutes, 46 seconds.\n",
            "2023-10-30 15:38:20,889 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0370 | Train accuracy: 82.47%.\n",
            "2023-10-30 15:38:21,390 max.py[line:93] INFO: max: attack effectiveness 60.317460317460316%.\n",
            "2023-10-30 15:38:21,399 md_at_ma.py[line:120] INFO: Mini batch: 350/1450 | training time in 3 minutes, 46 seconds.\n",
            "2023-10-30 15:38:21,400 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0461 | Train accuracy: 80.63%.\n",
            "2023-10-30 15:38:22,165 max.py[line:93] INFO: max: attack effectiveness 48.484848484848484%.\n",
            "2023-10-30 15:38:22,177 md_at_ma.py[line:120] INFO: Mini batch: 351/1450 | training time in 3 minutes, 47 seconds.\n",
            "2023-10-30 15:38:22,177 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0385 | Train accuracy: 84.54%.\n",
            "2023-10-30 15:38:22,951 max.py[line:93] INFO: max: attack effectiveness 65.71428571428571%.\n",
            "2023-10-30 15:38:22,963 md_at_ma.py[line:120] INFO: Mini batch: 352/1450 | training time in 3 minutes, 48 seconds.\n",
            "2023-10-30 15:38:22,964 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0312 | Train accuracy: 76.77%.\n",
            "2023-10-30 15:38:23,737 max.py[line:93] INFO: max: attack effectiveness 67.6056338028169%.\n",
            "2023-10-30 15:38:23,749 md_at_ma.py[line:120] INFO: Mini batch: 353/1450 | training time in 3 minutes, 49 seconds.\n",
            "2023-10-30 15:38:23,749 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0463 | Train accuracy: 75.38%.\n",
            "2023-10-30 15:38:24,572 max.py[line:93] INFO: max: attack effectiveness 71.05263157894737%.\n",
            "2023-10-30 15:38:24,585 md_at_ma.py[line:120] INFO: Mini batch: 354/1450 | training time in 3 minutes, 49 seconds.\n",
            "2023-10-30 15:38:24,585 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0277 | Train accuracy: 75.98%.\n",
            "2023-10-30 15:38:25,065 max.py[line:93] INFO: max: attack effectiveness 63.934426229508205%.\n",
            "2023-10-30 15:38:25,075 md_at_ma.py[line:120] INFO: Mini batch: 355/1450 | training time in 3 minutes, 50 seconds.\n",
            "2023-10-30 15:38:25,076 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0329 | Train accuracy: 80.95%.\n",
            "2023-10-30 15:38:25,870 max.py[line:93] INFO: max: attack effectiveness 65.21739130434783%.\n",
            "2023-10-30 15:38:25,882 md_at_ma.py[line:120] INFO: Mini batch: 356/1450 | training time in 3 minutes, 51 seconds.\n",
            "2023-10-30 15:38:25,883 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0690 | Train accuracy: 79.70%.\n",
            "2023-10-30 15:38:26,400 max.py[line:93] INFO: max: attack effectiveness 62.903225806451616%.\n",
            "2023-10-30 15:38:26,410 md_at_ma.py[line:120] INFO: Mini batch: 357/1450 | training time in 3 minutes, 51 seconds.\n",
            "2023-10-30 15:38:26,410 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0224 | Train accuracy: 83.16%.\n",
            "2023-10-30 15:38:27,005 max.py[line:93] INFO: max: attack effectiveness 73.33333333333333%.\n",
            "2023-10-30 15:38:27,014 md_at_ma.py[line:120] INFO: Mini batch: 358/1450 | training time in 3 minutes, 52 seconds.\n",
            "2023-10-30 15:38:27,014 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0403 | Train accuracy: 79.79%.\n",
            "2023-10-30 15:38:27,598 max.py[line:93] INFO: max: attack effectiveness 61.111111111111114%.\n",
            "2023-10-30 15:38:27,607 md_at_ma.py[line:120] INFO: Mini batch: 359/1450 | training time in 3 minutes, 52 seconds.\n",
            "2023-10-30 15:38:27,608 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0211 | Train accuracy: 84.62%.\n",
            "2023-10-30 15:38:28,128 max.py[line:93] INFO: max: attack effectiveness 73.01587301587301%.\n",
            "2023-10-30 15:38:28,137 md_at_ma.py[line:120] INFO: Mini batch: 360/1450 | training time in 3 minutes, 53 seconds.\n",
            "2023-10-30 15:38:28,137 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0580 | Train accuracy: 79.06%.\n",
            "2023-10-30 15:38:28,872 max.py[line:93] INFO: max: attack effectiveness 75.38461538461539%.\n",
            "2023-10-30 15:38:28,885 md_at_ma.py[line:120] INFO: Mini batch: 361/1450 | training time in 3 minutes, 54 seconds.\n",
            "2023-10-30 15:38:28,885 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0262 | Train accuracy: 77.72%.\n",
            "2023-10-30 15:38:29,651 max.py[line:93] INFO: max: attack effectiveness 60.60606060606061%.\n",
            "2023-10-30 15:38:29,663 md_at_ma.py[line:120] INFO: Mini batch: 362/1450 | training time in 3 minutes, 54 seconds.\n",
            "2023-10-30 15:38:29,663 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0495 | Train accuracy: 80.41%.\n",
            "2023-10-30 15:38:30,396 max.py[line:93] INFO: max: attack effectiveness 58.46153846153847%.\n",
            "2023-10-30 15:38:30,408 md_at_ma.py[line:120] INFO: Mini batch: 363/1450 | training time in 3 minutes, 55 seconds.\n",
            "2023-10-30 15:38:30,409 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0242 | Train accuracy: 82.38%.\n",
            "2023-10-30 15:38:31,183 max.py[line:93] INFO: max: attack effectiveness 70.4225352112676%.\n",
            "2023-10-30 15:38:31,196 md_at_ma.py[line:120] INFO: Mini batch: 364/1450 | training time in 3 minutes, 56 seconds.\n",
            "2023-10-30 15:38:31,196 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0349 | Train accuracy: 76.38%.\n",
            "2023-10-30 15:38:31,685 max.py[line:93] INFO: max: attack effectiveness 60.9375%.\n",
            "2023-10-30 15:38:31,694 md_at_ma.py[line:120] INFO: Mini batch: 365/1450 | training time in 3 minutes, 56 seconds.\n",
            "2023-10-30 15:38:31,694 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0214 | Train accuracy: 83.85%.\n",
            "2023-10-30 15:38:32,465 max.py[line:93] INFO: max: attack effectiveness 61.19402985074627%.\n",
            "2023-10-30 15:38:32,477 md_at_ma.py[line:120] INFO: Mini batch: 366/1450 | training time in 3 minutes, 57 seconds.\n",
            "2023-10-30 15:38:32,478 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0743 | Train accuracy: 78.46%.\n",
            "2023-10-30 15:38:32,975 max.py[line:93] INFO: max: attack effectiveness 65.625%.\n",
            "2023-10-30 15:38:32,984 md_at_ma.py[line:120] INFO: Mini batch: 367/1450 | training time in 3 minutes, 58 seconds.\n",
            "2023-10-30 15:38:32,985 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0359 | Train accuracy: 78.12%.\n",
            "2023-10-30 15:38:33,760 max.py[line:93] INFO: max: attack effectiveness 70.27027027027027%.\n",
            "2023-10-30 15:38:33,772 md_at_ma.py[line:120] INFO: Mini batch: 368/1450 | training time in 3 minutes, 58 seconds.\n",
            "2023-10-30 15:38:33,773 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0848 | Train accuracy: 74.26%.\n",
            "2023-10-30 15:38:34,544 max.py[line:93] INFO: max: attack effectiveness 65.21739130434783%.\n",
            "2023-10-30 15:38:34,557 md_at_ma.py[line:120] INFO: Mini batch: 369/1450 | training time in 3 minutes, 59 seconds.\n",
            "2023-10-30 15:38:34,557 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0341 | Train accuracy: 79.19%.\n",
            "2023-10-30 15:38:35,377 max.py[line:93] INFO: max: attack effectiveness 65.33333333333333%.\n",
            "2023-10-30 15:38:35,389 md_at_ma.py[line:120] INFO: Mini batch: 370/1450 | training time in 4 minutes, 0 seconds.\n",
            "2023-10-30 15:38:35,390 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0324 | Train accuracy: 77.83%.\n",
            "2023-10-30 15:38:36,158 max.py[line:93] INFO: max: attack effectiveness 58.82352941176471%.\n",
            "2023-10-30 15:38:36,170 md_at_ma.py[line:120] INFO: Mini batch: 371/1450 | training time in 4 minutes, 1 seconds.\n",
            "2023-10-30 15:38:36,170 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0300 | Train accuracy: 80.61%.\n",
            "2023-10-30 15:38:36,756 max.py[line:93] INFO: max: attack effectiveness 62.71186440677966%.\n",
            "2023-10-30 15:38:36,764 md_at_ma.py[line:120] INFO: Mini batch: 372/1450 | training time in 4 minutes, 1 seconds.\n",
            "2023-10-30 15:38:36,765 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0414 | Train accuracy: 82.35%.\n",
            "2023-10-30 15:38:37,588 max.py[line:93] INFO: max: attack effectiveness 58.666666666666664%.\n",
            "2023-10-30 15:38:37,600 md_at_ma.py[line:120] INFO: Mini batch: 373/1450 | training time in 4 minutes, 2 seconds.\n",
            "2023-10-30 15:38:37,600 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0257 | Train accuracy: 78.82%.\n",
            "2023-10-30 15:38:38,375 max.py[line:93] INFO: max: attack effectiveness 57.971014492753625%.\n",
            "2023-10-30 15:38:38,388 md_at_ma.py[line:120] INFO: Mini batch: 374/1450 | training time in 4 minutes, 3 seconds.\n",
            "2023-10-30 15:38:38,388 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0601 | Train accuracy: 80.71%.\n",
            "2023-10-30 15:38:38,881 max.py[line:93] INFO: max: attack effectiveness 48.4375%.\n",
            "2023-10-30 15:38:38,890 md_at_ma.py[line:120] INFO: Mini batch: 375/1450 | training time in 4 minutes, 3 seconds.\n",
            "2023-10-30 15:38:38,890 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0324 | Train accuracy: 84.90%.\n",
            "2023-10-30 15:38:39,378 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:38:39,387 md_at_ma.py[line:120] INFO: Mini batch: 376/1450 | training time in 4 minutes, 4 seconds.\n",
            "2023-10-30 15:38:39,387 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0327 | Train accuracy: 85.26%.\n",
            "2023-10-30 15:38:39,793 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:38:39,797 md_at_ma.py[line:120] INFO: Mini batch: 377/1450 | training time in 4 minutes, 4 seconds.\n",
            "2023-10-30 15:38:39,798 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0320 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:38:39,838 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0394 | Train accuracy: 80.47\n",
            "2023-10-30 15:38:42,023 max.py[line:93] INFO: max: attack effectiveness 67.1875%.\n",
            "2023-10-30 15:38:43,038 max.py[line:93] INFO: max: attack effectiveness 70.3125%.\n",
            "2023-10-30 15:38:43,948 max.py[line:93] INFO: max: attack effectiveness 70.3125%.\n",
            "2023-10-30 15:38:44,843 max.py[line:93] INFO: max: attack effectiveness 64.84375%.\n",
            "2023-10-30 15:38:45,391 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:38:46,228 md_at_ma.py[line:165] INFO: \tVal accuracy 63.82% with accuracy 31.18% under attack.\n",
            "2023-10-30 15:38:46,228 md_at_ma.py[line:167] INFO: \tModel select at epoch 13 with validation accuracy 63.82% and accuracy 31.18% under attack.\n",
            "2023-10-30 15:38:47,074 max.py[line:93] INFO: max: attack effectiveness 53.03030303030303%.\n",
            "2023-10-30 15:38:47,087 md_at_ma.py[line:120] INFO: Mini batch: 378/1450 | training time in 4 minutes, 5 seconds.\n",
            "2023-10-30 15:38:47,087 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0354 | Train accuracy: 84.54%.\n",
            "2023-10-30 15:38:47,571 max.py[line:93] INFO: max: attack effectiveness 58.730158730158735%.\n",
            "2023-10-30 15:38:47,580 md_at_ma.py[line:120] INFO: Mini batch: 379/1450 | training time in 4 minutes, 5 seconds.\n",
            "2023-10-30 15:38:47,580 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0511 | Train accuracy: 81.68%.\n",
            "2023-10-30 15:38:48,347 max.py[line:93] INFO: max: attack effectiveness 46.96969696969697%.\n",
            "2023-10-30 15:38:48,359 md_at_ma.py[line:120] INFO: Mini batch: 380/1450 | training time in 4 minutes, 6 seconds.\n",
            "2023-10-30 15:38:48,360 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0377 | Train accuracy: 85.05%.\n",
            "2023-10-30 15:38:49,133 max.py[line:93] INFO: max: attack effectiveness 67.14285714285714%.\n",
            "2023-10-30 15:38:49,145 md_at_ma.py[line:120] INFO: Mini batch: 381/1450 | training time in 4 minutes, 7 seconds.\n",
            "2023-10-30 15:38:49,146 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0237 | Train accuracy: 78.79%.\n",
            "2023-10-30 15:38:49,918 max.py[line:93] INFO: max: attack effectiveness 76.05633802816901%.\n",
            "2023-10-30 15:38:49,930 md_at_ma.py[line:120] INFO: Mini batch: 382/1450 | training time in 4 minutes, 8 seconds.\n",
            "2023-10-30 15:38:49,931 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0405 | Train accuracy: 77.89%.\n",
            "2023-10-30 15:38:50,754 max.py[line:93] INFO: max: attack effectiveness 73.68421052631578%.\n",
            "2023-10-30 15:38:50,767 md_at_ma.py[line:120] INFO: Mini batch: 383/1450 | training time in 4 minutes, 9 seconds.\n",
            "2023-10-30 15:38:50,767 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0338 | Train accuracy: 74.51%.\n",
            "2023-10-30 15:38:51,252 max.py[line:93] INFO: max: attack effectiveness 63.934426229508205%.\n",
            "2023-10-30 15:38:51,261 md_at_ma.py[line:120] INFO: Mini batch: 384/1450 | training time in 4 minutes, 9 seconds.\n",
            "2023-10-30 15:38:51,261 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0296 | Train accuracy: 83.07%.\n",
            "2023-10-30 15:38:52,037 max.py[line:93] INFO: max: attack effectiveness 63.76811594202898%.\n",
            "2023-10-30 15:38:52,050 md_at_ma.py[line:120] INFO: Mini batch: 385/1450 | training time in 4 minutes, 10 seconds.\n",
            "2023-10-30 15:38:52,050 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0508 | Train accuracy: 78.68%.\n",
            "2023-10-30 15:38:52,564 max.py[line:93] INFO: max: attack effectiveness 67.74193548387096%.\n",
            "2023-10-30 15:38:52,574 md_at_ma.py[line:120] INFO: Mini batch: 386/1450 | training time in 4 minutes, 10 seconds.\n",
            "2023-10-30 15:38:52,574 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0211 | Train accuracy: 82.11%.\n",
            "2023-10-30 15:38:53,161 max.py[line:93] INFO: max: attack effectiveness 78.33333333333333%.\n",
            "2023-10-30 15:38:53,170 md_at_ma.py[line:120] INFO: Mini batch: 387/1450 | training time in 4 minutes, 11 seconds.\n",
            "2023-10-30 15:38:53,170 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0425 | Train accuracy: 77.13%.\n",
            "2023-10-30 15:38:53,765 max.py[line:93] INFO: max: attack effectiveness 74.07407407407408%.\n",
            "2023-10-30 15:38:53,774 md_at_ma.py[line:120] INFO: Mini batch: 388/1450 | training time in 4 minutes, 11 seconds.\n",
            "2023-10-30 15:38:53,774 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0197 | Train accuracy: 82.97%.\n",
            "2023-10-30 15:38:54,296 max.py[line:93] INFO: max: attack effectiveness 76.19047619047619%.\n",
            "2023-10-30 15:38:54,305 md_at_ma.py[line:120] INFO: Mini batch: 389/1450 | training time in 4 minutes, 12 seconds.\n",
            "2023-10-30 15:38:54,305 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0376 | Train accuracy: 79.06%.\n",
            "2023-10-30 15:38:55,044 max.py[line:93] INFO: max: attack effectiveness 76.92307692307693%.\n",
            "2023-10-30 15:38:55,056 md_at_ma.py[line:120] INFO: Mini batch: 390/1450 | training time in 4 minutes, 13 seconds.\n",
            "2023-10-30 15:38:55,056 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0289 | Train accuracy: 77.20%.\n",
            "2023-10-30 15:38:55,823 max.py[line:93] INFO: max: attack effectiveness 63.63636363636363%.\n",
            "2023-10-30 15:38:55,835 md_at_ma.py[line:120] INFO: Mini batch: 391/1450 | training time in 4 minutes, 13 seconds.\n",
            "2023-10-30 15:38:55,836 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0541 | Train accuracy: 79.90%.\n",
            "2023-10-30 15:38:56,569 max.py[line:93] INFO: max: attack effectiveness 56.92307692307692%.\n",
            "2023-10-30 15:38:56,582 md_at_ma.py[line:120] INFO: Mini batch: 392/1450 | training time in 4 minutes, 14 seconds.\n",
            "2023-10-30 15:38:56,582 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0249 | Train accuracy: 82.38%.\n",
            "2023-10-30 15:38:57,356 max.py[line:93] INFO: max: attack effectiveness 69.01408450704226%.\n",
            "2023-10-30 15:38:57,368 md_at_ma.py[line:120] INFO: Mini batch: 393/1450 | training time in 4 minutes, 15 seconds.\n",
            "2023-10-30 15:38:57,369 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0380 | Train accuracy: 76.88%.\n",
            "2023-10-30 15:38:57,856 max.py[line:93] INFO: max: attack effectiveness 53.125%.\n",
            "2023-10-30 15:38:57,865 md_at_ma.py[line:120] INFO: Mini batch: 394/1450 | training time in 4 minutes, 15 seconds.\n",
            "2023-10-30 15:38:57,865 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0194 | Train accuracy: 83.33%.\n",
            "2023-10-30 15:38:58,634 max.py[line:93] INFO: max: attack effectiveness 56.71641791044776%.\n",
            "2023-10-30 15:38:58,646 md_at_ma.py[line:120] INFO: Mini batch: 395/1450 | training time in 4 minutes, 16 seconds.\n",
            "2023-10-30 15:38:58,646 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0510 | Train accuracy: 80.51%.\n",
            "2023-10-30 15:38:59,131 max.py[line:93] INFO: max: attack effectiveness 65.625%.\n",
            "2023-10-30 15:38:59,140 md_at_ma.py[line:120] INFO: Mini batch: 396/1450 | training time in 4 minutes, 17 seconds.\n",
            "2023-10-30 15:38:59,140 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0265 | Train accuracy: 81.25%.\n",
            "2023-10-30 15:38:59,918 max.py[line:93] INFO: max: attack effectiveness 66.21621621621621%.\n",
            "2023-10-30 15:38:59,930 md_at_ma.py[line:120] INFO: Mini batch: 397/1450 | training time in 4 minutes, 17 seconds.\n",
            "2023-10-30 15:38:59,930 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0795 | Train accuracy: 76.73%.\n",
            "2023-10-30 15:39:00,705 max.py[line:93] INFO: max: attack effectiveness 57.971014492753625%.\n",
            "2023-10-30 15:39:00,717 md_at_ma.py[line:120] INFO: Mini batch: 398/1450 | training time in 4 minutes, 18 seconds.\n",
            "2023-10-30 15:39:00,717 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0294 | Train accuracy: 81.22%.\n",
            "2023-10-30 15:39:01,546 max.py[line:93] INFO: max: attack effectiveness 61.33333333333333%.\n",
            "2023-10-30 15:39:01,559 md_at_ma.py[line:120] INFO: Mini batch: 399/1450 | training time in 4 minutes, 19 seconds.\n",
            "2023-10-30 15:39:01,559 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0326 | Train accuracy: 79.80%.\n",
            "2023-10-30 15:39:02,328 max.py[line:93] INFO: max: attack effectiveness 57.35294117647059%.\n",
            "2023-10-30 15:39:02,341 md_at_ma.py[line:120] INFO: Mini batch: 400/1450 | training time in 4 minutes, 20 seconds.\n",
            "2023-10-30 15:39:02,341 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0388 | Train accuracy: 80.61%.\n",
            "2023-10-30 15:39:02,938 max.py[line:93] INFO: max: attack effectiveness 59.32203389830508%.\n",
            "2023-10-30 15:39:02,947 md_at_ma.py[line:120] INFO: Mini batch: 401/1450 | training time in 4 minutes, 20 seconds.\n",
            "2023-10-30 15:39:02,947 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0429 | Train accuracy: 83.96%.\n",
            "2023-10-30 15:39:03,775 max.py[line:93] INFO: max: attack effectiveness 60.0%.\n",
            "2023-10-30 15:39:03,787 md_at_ma.py[line:120] INFO: Mini batch: 402/1450 | training time in 4 minutes, 21 seconds.\n",
            "2023-10-30 15:39:03,787 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0262 | Train accuracy: 78.33%.\n",
            "2023-10-30 15:39:04,562 max.py[line:93] INFO: max: attack effectiveness 57.971014492753625%.\n",
            "2023-10-30 15:39:04,574 md_at_ma.py[line:120] INFO: Mini batch: 403/1450 | training time in 4 minutes, 22 seconds.\n",
            "2023-10-30 15:39:04,575 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0509 | Train accuracy: 80.71%.\n",
            "2023-10-30 15:39:05,075 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:39:05,084 md_at_ma.py[line:120] INFO: Mini batch: 404/1450 | training time in 4 minutes, 23 seconds.\n",
            "2023-10-30 15:39:05,084 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0236 | Train accuracy: 84.90%.\n",
            "2023-10-30 15:39:05,576 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:39:05,585 md_at_ma.py[line:120] INFO: Mini batch: 405/1450 | training time in 4 minutes, 23 seconds.\n",
            "2023-10-30 15:39:05,585 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0258 | Train accuracy: 84.74%.\n",
            "2023-10-30 15:39:05,987 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:39:05,991 md_at_ma.py[line:120] INFO: Mini batch: 406/1450 | training time in 4 minutes, 23 seconds.\n",
            "2023-10-30 15:39:05,991 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0177 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:39:06,030 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0356 | Train accuracy: 80.94\n",
            "2023-10-30 15:39:08,208 max.py[line:93] INFO: max: attack effectiveness 66.40625%.\n",
            "2023-10-30 15:39:09,201 max.py[line:93] INFO: max: attack effectiveness 67.96875%.\n",
            "2023-10-30 15:39:10,110 max.py[line:93] INFO: max: attack effectiveness 66.40625%.\n",
            "2023-10-30 15:39:11,064 max.py[line:93] INFO: max: attack effectiveness 63.28125%.\n",
            "2023-10-30 15:39:11,657 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:39:12,404 md_at_ma.py[line:165] INFO: \tVal accuracy 64.76% with accuracy 33.15% under attack.\n",
            "2023-10-30 15:39:12,404 md_at_ma.py[line:167] INFO: \tModel select at epoch 14 with validation accuracy 64.76% and accuracy 33.15% under attack.\n",
            "2023-10-30 15:39:13,245 max.py[line:93] INFO: max: attack effectiveness 51.515151515151516%.\n",
            "2023-10-30 15:39:13,258 md_at_ma.py[line:120] INFO: Mini batch: 407/1450 | training time in 4 minutes, 24 seconds.\n",
            "2023-10-30 15:39:13,258 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0359 | Train accuracy: 86.60%.\n",
            "2023-10-30 15:39:13,740 max.py[line:93] INFO: max: attack effectiveness 58.730158730158735%.\n",
            "2023-10-30 15:39:13,749 md_at_ma.py[line:120] INFO: Mini batch: 408/1450 | training time in 4 minutes, 25 seconds.\n",
            "2023-10-30 15:39:13,749 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0605 | Train accuracy: 84.82%.\n",
            "2023-10-30 15:39:14,512 max.py[line:93] INFO: max: attack effectiveness 46.96969696969697%.\n",
            "2023-10-30 15:39:14,525 md_at_ma.py[line:120] INFO: Mini batch: 409/1450 | training time in 4 minutes, 25 seconds.\n",
            "2023-10-30 15:39:14,525 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0315 | Train accuracy: 87.63%.\n",
            "2023-10-30 15:39:15,297 max.py[line:93] INFO: max: attack effectiveness 55.714285714285715%.\n",
            "2023-10-30 15:39:15,310 md_at_ma.py[line:120] INFO: Mini batch: 410/1450 | training time in 4 minutes, 26 seconds.\n",
            "2023-10-30 15:39:15,310 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0270 | Train accuracy: 80.81%.\n",
            "2023-10-30 15:39:16,083 max.py[line:93] INFO: max: attack effectiveness 66.19718309859155%.\n",
            "2023-10-30 15:39:16,096 md_at_ma.py[line:120] INFO: Mini batch: 411/1450 | training time in 4 minutes, 27 seconds.\n",
            "2023-10-30 15:39:16,096 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0431 | Train accuracy: 76.88%.\n",
            "2023-10-30 15:39:16,919 max.py[line:93] INFO: max: attack effectiveness 65.78947368421053%.\n",
            "2023-10-30 15:39:16,931 md_at_ma.py[line:120] INFO: Mini batch: 412/1450 | training time in 4 minutes, 28 seconds.\n",
            "2023-10-30 15:39:16,932 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0263 | Train accuracy: 79.41%.\n",
            "2023-10-30 15:39:17,420 max.py[line:93] INFO: max: attack effectiveness 63.934426229508205%.\n",
            "2023-10-30 15:39:17,429 md_at_ma.py[line:120] INFO: Mini batch: 413/1450 | training time in 4 minutes, 28 seconds.\n",
            "2023-10-30 15:39:17,429 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0197 | Train accuracy: 81.48%.\n",
            "2023-10-30 15:39:18,221 max.py[line:93] INFO: max: attack effectiveness 63.76811594202898%.\n",
            "2023-10-30 15:39:18,234 md_at_ma.py[line:120] INFO: Mini batch: 414/1450 | training time in 4 minutes, 29 seconds.\n",
            "2023-10-30 15:39:18,235 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0834 | Train accuracy: 78.68%.\n",
            "2023-10-30 15:39:18,752 max.py[line:93] INFO: max: attack effectiveness 54.83870967741935%.\n",
            "2023-10-30 15:39:18,761 md_at_ma.py[line:120] INFO: Mini batch: 415/1450 | training time in 4 minutes, 30 seconds.\n",
            "2023-10-30 15:39:18,761 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0299 | Train accuracy: 84.21%.\n",
            "2023-10-30 15:39:19,354 max.py[line:93] INFO: max: attack effectiveness 70.0%.\n",
            "2023-10-30 15:39:19,363 md_at_ma.py[line:120] INFO: Mini batch: 416/1450 | training time in 4 minutes, 30 seconds.\n",
            "2023-10-30 15:39:19,363 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0399 | Train accuracy: 81.91%.\n",
            "2023-10-30 15:39:19,959 max.py[line:93] INFO: max: attack effectiveness 64.81481481481481%.\n",
            "2023-10-30 15:39:19,968 md_at_ma.py[line:120] INFO: Mini batch: 417/1450 | training time in 4 minutes, 31 seconds.\n",
            "2023-10-30 15:39:19,968 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0251 | Train accuracy: 83.52%.\n",
            "2023-10-30 15:39:20,495 max.py[line:93] INFO: max: attack effectiveness 71.42857142857143%.\n",
            "2023-10-30 15:39:20,504 md_at_ma.py[line:120] INFO: Mini batch: 418/1450 | training time in 4 minutes, 31 seconds.\n",
            "2023-10-30 15:39:20,504 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0405 | Train accuracy: 81.15%.\n",
            "2023-10-30 15:39:21,239 max.py[line:93] INFO: max: attack effectiveness 78.46153846153847%.\n",
            "2023-10-30 15:39:21,251 md_at_ma.py[line:120] INFO: Mini batch: 419/1450 | training time in 4 minutes, 32 seconds.\n",
            "2023-10-30 15:39:21,251 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0194 | Train accuracy: 79.27%.\n",
            "2023-10-30 15:39:22,013 max.py[line:93] INFO: max: attack effectiveness 54.54545454545454%.\n",
            "2023-10-30 15:39:22,025 md_at_ma.py[line:120] INFO: Mini batch: 420/1450 | training time in 4 minutes, 33 seconds.\n",
            "2023-10-30 15:39:22,025 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0409 | Train accuracy: 84.02%.\n",
            "2023-10-30 15:39:22,761 max.py[line:93] INFO: max: attack effectiveness 55.38461538461539%.\n",
            "2023-10-30 15:39:22,773 md_at_ma.py[line:120] INFO: Mini batch: 421/1450 | training time in 4 minutes, 33 seconds.\n",
            "2023-10-30 15:39:22,773 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0234 | Train accuracy: 83.94%.\n",
            "2023-10-30 15:39:23,547 max.py[line:93] INFO: max: attack effectiveness 67.6056338028169%.\n",
            "2023-10-30 15:39:23,559 md_at_ma.py[line:120] INFO: Mini batch: 422/1450 | training time in 4 minutes, 34 seconds.\n",
            "2023-10-30 15:39:23,560 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0322 | Train accuracy: 78.39%.\n",
            "2023-10-30 15:39:24,048 max.py[line:93] INFO: max: attack effectiveness 51.5625%.\n",
            "2023-10-30 15:39:24,057 md_at_ma.py[line:120] INFO: Mini batch: 423/1450 | training time in 4 minutes, 35 seconds.\n",
            "2023-10-30 15:39:24,057 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0316 | Train accuracy: 87.50%.\n",
            "2023-10-30 15:39:24,821 max.py[line:93] INFO: max: attack effectiveness 56.71641791044776%.\n",
            "2023-10-30 15:39:24,833 md_at_ma.py[line:120] INFO: Mini batch: 424/1450 | training time in 4 minutes, 35 seconds.\n",
            "2023-10-30 15:39:24,833 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0580 | Train accuracy: 80.51%.\n",
            "2023-10-30 15:39:25,317 max.py[line:93] INFO: max: attack effectiveness 67.1875%.\n",
            "2023-10-30 15:39:25,326 md_at_ma.py[line:120] INFO: Mini batch: 425/1450 | training time in 4 minutes, 36 seconds.\n",
            "2023-10-30 15:39:25,326 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0430 | Train accuracy: 78.65%.\n",
            "2023-10-30 15:39:26,106 max.py[line:93] INFO: max: attack effectiveness 68.91891891891892%.\n",
            "2023-10-30 15:39:26,119 md_at_ma.py[line:120] INFO: Mini batch: 426/1450 | training time in 4 minutes, 37 seconds.\n",
            "2023-10-30 15:39:26,119 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0746 | Train accuracy: 76.24%.\n",
            "2023-10-30 15:39:26,889 max.py[line:93] INFO: max: attack effectiveness 65.21739130434783%.\n",
            "2023-10-30 15:39:26,901 md_at_ma.py[line:120] INFO: Mini batch: 427/1450 | training time in 4 minutes, 37 seconds.\n",
            "2023-10-30 15:39:26,902 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0289 | Train accuracy: 78.68%.\n",
            "2023-10-30 15:39:27,724 max.py[line:93] INFO: max: attack effectiveness 73.33333333333333%.\n",
            "2023-10-30 15:39:27,736 md_at_ma.py[line:120] INFO: Mini batch: 428/1450 | training time in 4 minutes, 38 seconds.\n",
            "2023-10-30 15:39:27,736 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0407 | Train accuracy: 73.89%.\n",
            "2023-10-30 15:39:28,511 max.py[line:93] INFO: max: attack effectiveness 60.29411764705882%.\n",
            "2023-10-30 15:39:28,523 md_at_ma.py[line:120] INFO: Mini batch: 429/1450 | training time in 4 minutes, 39 seconds.\n",
            "2023-10-30 15:39:28,523 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0336 | Train accuracy: 80.61%.\n",
            "2023-10-30 15:39:29,109 max.py[line:93] INFO: max: attack effectiveness 62.71186440677966%.\n",
            "2023-10-30 15:39:29,118 md_at_ma.py[line:120] INFO: Mini batch: 430/1450 | training time in 4 minutes, 40 seconds.\n",
            "2023-10-30 15:39:29,118 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0415 | Train accuracy: 80.75%.\n",
            "2023-10-30 15:39:29,942 max.py[line:93] INFO: max: attack effectiveness 60.0%.\n",
            "2023-10-30 15:39:29,954 md_at_ma.py[line:120] INFO: Mini batch: 431/1450 | training time in 4 minutes, 40 seconds.\n",
            "2023-10-30 15:39:29,954 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0219 | Train accuracy: 79.80%.\n",
            "2023-10-30 15:39:30,730 max.py[line:93] INFO: max: attack effectiveness 57.971014492753625%.\n",
            "2023-10-30 15:39:30,743 md_at_ma.py[line:120] INFO: Mini batch: 432/1450 | training time in 4 minutes, 41 seconds.\n",
            "2023-10-30 15:39:30,743 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0463 | Train accuracy: 82.23%.\n",
            "2023-10-30 15:39:31,242 max.py[line:93] INFO: max: attack effectiveness 48.4375%.\n",
            "2023-10-30 15:39:31,251 md_at_ma.py[line:120] INFO: Mini batch: 433/1450 | training time in 4 minutes, 42 seconds.\n",
            "2023-10-30 15:39:31,252 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0373 | Train accuracy: 84.90%.\n",
            "2023-10-30 15:39:31,739 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:39:31,748 md_at_ma.py[line:120] INFO: Mini batch: 434/1450 | training time in 4 minutes, 42 seconds.\n",
            "2023-10-30 15:39:31,748 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0223 | Train accuracy: 86.84%.\n",
            "2023-10-30 15:39:32,145 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:39:32,149 md_at_ma.py[line:120] INFO: Mini batch: 435/1450 | training time in 4 minutes, 43 seconds.\n",
            "2023-10-30 15:39:32,150 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0272 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:39:32,198 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0374 | Train accuracy: 81.82\n",
            "2023-10-30 15:39:34,392 max.py[line:93] INFO: max: attack effectiveness 67.96875%.\n",
            "2023-10-30 15:39:35,387 max.py[line:93] INFO: max: attack effectiveness 68.75%.\n",
            "2023-10-30 15:39:36,312 max.py[line:93] INFO: max: attack effectiveness 67.96875%.\n",
            "2023-10-30 15:39:37,256 max.py[line:93] INFO: max: attack effectiveness 64.0625%.\n",
            "2023-10-30 15:39:37,897 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:39:38,550 md_at_ma.py[line:165] INFO: \tVal accuracy 64.23% with accuracy 32.08% under attack.\n",
            "2023-10-30 15:39:38,550 md_at_ma.py[line:167] INFO: \tModel select at epoch 14 with validation accuracy 64.76% and accuracy 33.15% under attack.\n",
            "2023-10-30 15:39:39,439 max.py[line:93] INFO: max: attack effectiveness 51.515151515151516%.\n",
            "2023-10-30 15:39:39,452 md_at_ma.py[line:120] INFO: Mini batch: 436/1450 | training time in 4 minutes, 43 seconds.\n",
            "2023-10-30 15:39:39,452 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0336 | Train accuracy: 83.51%.\n",
            "2023-10-30 15:39:39,933 max.py[line:93] INFO: max: attack effectiveness 57.14285714285714%.\n",
            "2023-10-30 15:39:39,942 md_at_ma.py[line:120] INFO: Mini batch: 437/1450 | training time in 4 minutes, 44 seconds.\n",
            "2023-10-30 15:39:39,943 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0478 | Train accuracy: 81.68%.\n",
            "2023-10-30 15:39:40,708 max.py[line:93] INFO: max: attack effectiveness 46.96969696969697%.\n",
            "2023-10-30 15:39:40,720 md_at_ma.py[line:120] INFO: Mini batch: 438/1450 | training time in 4 minutes, 45 seconds.\n",
            "2023-10-30 15:39:40,720 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0318 | Train accuracy: 85.57%.\n",
            "2023-10-30 15:39:41,494 max.py[line:93] INFO: max: attack effectiveness 54.285714285714285%.\n",
            "2023-10-30 15:39:41,506 md_at_ma.py[line:120] INFO: Mini batch: 439/1450 | training time in 4 minutes, 45 seconds.\n",
            "2023-10-30 15:39:41,506 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0240 | Train accuracy: 82.83%.\n",
            "2023-10-30 15:39:42,280 max.py[line:93] INFO: max: attack effectiveness 60.56338028169014%.\n",
            "2023-10-30 15:39:42,292 md_at_ma.py[line:120] INFO: Mini batch: 440/1450 | training time in 4 minutes, 46 seconds.\n",
            "2023-10-30 15:39:42,292 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0398 | Train accuracy: 80.40%.\n",
            "2023-10-30 15:39:43,116 max.py[line:93] INFO: max: attack effectiveness 59.210526315789465%.\n",
            "2023-10-30 15:39:43,129 md_at_ma.py[line:120] INFO: Mini batch: 441/1450 | training time in 4 minutes, 47 seconds.\n",
            "2023-10-30 15:39:43,129 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0281 | Train accuracy: 78.43%.\n",
            "2023-10-30 15:39:43,616 max.py[line:93] INFO: max: attack effectiveness 59.01639344262295%.\n",
            "2023-10-30 15:39:43,625 md_at_ma.py[line:120] INFO: Mini batch: 442/1450 | training time in 4 minutes, 47 seconds.\n",
            "2023-10-30 15:39:43,625 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0297 | Train accuracy: 81.48%.\n",
            "2023-10-30 15:39:44,434 max.py[line:93] INFO: max: attack effectiveness 56.52173913043478%.\n",
            "2023-10-30 15:39:44,446 md_at_ma.py[line:120] INFO: Mini batch: 443/1450 | training time in 4 minutes, 48 seconds.\n",
            "2023-10-30 15:39:44,447 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0454 | Train accuracy: 82.23%.\n",
            "2023-10-30 15:39:44,942 max.py[line:93] INFO: max: attack effectiveness 51.61290322580645%.\n",
            "2023-10-30 15:39:44,951 md_at_ma.py[line:120] INFO: Mini batch: 444/1450 | training time in 4 minutes, 49 seconds.\n",
            "2023-10-30 15:39:44,951 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0328 | Train accuracy: 83.68%.\n",
            "2023-10-30 15:39:45,566 max.py[line:93] INFO: max: attack effectiveness 61.66666666666667%.\n",
            "2023-10-30 15:39:45,575 md_at_ma.py[line:120] INFO: Mini batch: 445/1450 | training time in 4 minutes, 49 seconds.\n",
            "2023-10-30 15:39:45,575 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0534 | Train accuracy: 81.91%.\n",
            "2023-10-30 15:39:46,189 max.py[line:93] INFO: max: attack effectiveness 51.85185185185185%.\n",
            "2023-10-30 15:39:46,198 md_at_ma.py[line:120] INFO: Mini batch: 446/1450 | training time in 4 minutes, 50 seconds.\n",
            "2023-10-30 15:39:46,198 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0228 | Train accuracy: 85.71%.\n",
            "2023-10-30 15:39:46,717 max.py[line:93] INFO: max: attack effectiveness 65.07936507936508%.\n",
            "2023-10-30 15:39:46,726 md_at_ma.py[line:120] INFO: Mini batch: 447/1450 | training time in 4 minutes, 50 seconds.\n",
            "2023-10-30 15:39:46,727 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0302 | Train accuracy: 79.58%.\n",
            "2023-10-30 15:39:47,460 max.py[line:93] INFO: max: attack effectiveness 66.15384615384615%.\n",
            "2023-10-30 15:39:47,473 md_at_ma.py[line:120] INFO: Mini batch: 448/1450 | training time in 4 minutes, 51 seconds.\n",
            "2023-10-30 15:39:47,473 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0186 | Train accuracy: 81.87%.\n",
            "2023-10-30 15:39:48,238 max.py[line:93] INFO: max: attack effectiveness 53.03030303030303%.\n",
            "2023-10-30 15:39:48,250 md_at_ma.py[line:120] INFO: Mini batch: 449/1450 | training time in 4 minutes, 52 seconds.\n",
            "2023-10-30 15:39:48,251 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0456 | Train accuracy: 83.51%.\n",
            "2023-10-30 15:39:48,987 max.py[line:93] INFO: max: attack effectiveness 49.23076923076923%.\n",
            "2023-10-30 15:39:48,999 md_at_ma.py[line:120] INFO: Mini batch: 450/1450 | training time in 4 minutes, 53 seconds.\n",
            "2023-10-30 15:39:48,999 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1001 | Train accuracy: 84.46%.\n",
            "2023-10-30 15:39:49,774 max.py[line:93] INFO: max: attack effectiveness 66.19718309859155%.\n",
            "2023-10-30 15:39:49,786 md_at_ma.py[line:120] INFO: Mini batch: 451/1450 | training time in 4 minutes, 53 seconds.\n",
            "2023-10-30 15:39:49,786 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0239 | Train accuracy: 79.40%.\n",
            "2023-10-30 15:39:50,273 max.py[line:93] INFO: max: attack effectiveness 46.875%.\n",
            "2023-10-30 15:39:50,282 md_at_ma.py[line:120] INFO: Mini batch: 452/1450 | training time in 4 minutes, 54 seconds.\n",
            "2023-10-30 15:39:50,282 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0181 | Train accuracy: 84.90%.\n",
            "2023-10-30 15:39:51,048 max.py[line:93] INFO: max: attack effectiveness 55.223880597014926%.\n",
            "2023-10-30 15:39:51,060 md_at_ma.py[line:120] INFO: Mini batch: 453/1450 | training time in 4 minutes, 55 seconds.\n",
            "2023-10-30 15:39:51,061 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0333 | Train accuracy: 82.05%.\n",
            "2023-10-30 15:39:51,546 max.py[line:93] INFO: max: attack effectiveness 71.875%.\n",
            "2023-10-30 15:39:51,555 md_at_ma.py[line:120] INFO: Mini batch: 454/1450 | training time in 4 minutes, 55 seconds.\n",
            "2023-10-30 15:39:51,556 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0314 | Train accuracy: 78.65%.\n",
            "2023-10-30 15:39:52,334 max.py[line:93] INFO: max: attack effectiveness 83.78378378378379%.\n",
            "2023-10-30 15:39:52,346 md_at_ma.py[line:120] INFO: Mini batch: 455/1450 | training time in 4 minutes, 56 seconds.\n",
            "2023-10-30 15:39:52,346 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0615 | Train accuracy: 70.30%.\n",
            "2023-10-30 15:39:53,117 max.py[line:93] INFO: max: attack effectiveness 76.81159420289855%.\n",
            "2023-10-30 15:39:53,129 md_at_ma.py[line:120] INFO: Mini batch: 456/1450 | training time in 4 minutes, 57 seconds.\n",
            "2023-10-30 15:39:53,129 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0294 | Train accuracy: 73.60%.\n",
            "2023-10-30 15:39:53,953 max.py[line:93] INFO: max: attack effectiveness 70.66666666666667%.\n",
            "2023-10-30 15:39:53,965 md_at_ma.py[line:120] INFO: Mini batch: 457/1450 | training time in 4 minutes, 58 seconds.\n",
            "2023-10-30 15:39:53,965 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0346 | Train accuracy: 73.40%.\n",
            "2023-10-30 15:39:54,735 max.py[line:93] INFO: max: attack effectiveness 58.82352941176471%.\n",
            "2023-10-30 15:39:54,747 md_at_ma.py[line:120] INFO: Mini batch: 458/1450 | training time in 4 minutes, 58 seconds.\n",
            "2023-10-30 15:39:54,747 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0249 | Train accuracy: 81.63%.\n",
            "2023-10-30 15:39:55,333 max.py[line:93] INFO: max: attack effectiveness 57.6271186440678%.\n",
            "2023-10-30 15:39:55,342 md_at_ma.py[line:120] INFO: Mini batch: 459/1450 | training time in 4 minutes, 59 seconds.\n",
            "2023-10-30 15:39:55,342 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0362 | Train accuracy: 81.82%.\n",
            "2023-10-30 15:39:56,171 max.py[line:93] INFO: max: attack effectiveness 58.666666666666664%.\n",
            "2023-10-30 15:39:56,183 md_at_ma.py[line:120] INFO: Mini batch: 460/1450 | training time in 5 minutes, 0 seconds.\n",
            "2023-10-30 15:39:56,184 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0189 | Train accuracy: 82.27%.\n",
            "2023-10-30 15:39:56,959 max.py[line:93] INFO: max: attack effectiveness 56.52173913043478%.\n",
            "2023-10-30 15:39:56,972 md_at_ma.py[line:120] INFO: Mini batch: 461/1450 | training time in 5 minutes, 0 seconds.\n",
            "2023-10-30 15:39:56,972 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0378 | Train accuracy: 82.74%.\n",
            "2023-10-30 15:39:57,464 max.py[line:93] INFO: max: attack effectiveness 48.4375%.\n",
            "2023-10-30 15:39:57,473 md_at_ma.py[line:120] INFO: Mini batch: 462/1450 | training time in 5 minutes, 1 seconds.\n",
            "2023-10-30 15:39:57,473 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0194 | Train accuracy: 88.02%.\n",
            "2023-10-30 15:39:57,963 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:39:57,972 md_at_ma.py[line:120] INFO: Mini batch: 463/1450 | training time in 5 minutes, 1 seconds.\n",
            "2023-10-30 15:39:57,972 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0202 | Train accuracy: 84.21%.\n",
            "2023-10-30 15:39:58,364 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:39:58,369 md_at_ma.py[line:120] INFO: Mini batch: 464/1450 | training time in 5 minutes, 2 seconds.\n",
            "2023-10-30 15:39:58,369 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0156 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:39:58,411 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0341 | Train accuracy: 81.70\n",
            "2023-10-30 15:40:00,565 max.py[line:93] INFO: max: attack effectiveness 67.1875%.\n",
            "2023-10-30 15:40:01,565 max.py[line:93] INFO: max: attack effectiveness 69.53125%.\n",
            "2023-10-30 15:40:02,483 max.py[line:93] INFO: max: attack effectiveness 67.96875%.\n",
            "2023-10-30 15:40:03,447 max.py[line:93] INFO: max: attack effectiveness 65.625%.\n",
            "2023-10-30 15:40:04,092 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:40:04,776 md_at_ma.py[line:165] INFO: \tVal accuracy 64.36% with accuracy 31.72% under attack.\n",
            "2023-10-30 15:40:04,777 md_at_ma.py[line:167] INFO: \tModel select at epoch 14 with validation accuracy 64.76% and accuracy 33.15% under attack.\n",
            "2023-10-30 15:40:05,615 max.py[line:93] INFO: max: attack effectiveness 54.54545454545454%.\n",
            "2023-10-30 15:40:05,628 md_at_ma.py[line:120] INFO: Mini batch: 465/1450 | training time in 5 minutes, 3 seconds.\n",
            "2023-10-30 15:40:05,628 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0416 | Train accuracy: 82.47%.\n",
            "2023-10-30 15:40:06,112 max.py[line:93] INFO: max: attack effectiveness 57.14285714285714%.\n",
            "2023-10-30 15:40:06,121 md_at_ma.py[line:120] INFO: Mini batch: 466/1450 | training time in 5 minutes, 3 seconds.\n",
            "2023-10-30 15:40:06,121 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0368 | Train accuracy: 81.68%.\n",
            "2023-10-30 15:40:06,886 max.py[line:93] INFO: max: attack effectiveness 46.96969696969697%.\n",
            "2023-10-30 15:40:06,899 md_at_ma.py[line:120] INFO: Mini batch: 467/1450 | training time in 5 minutes, 4 seconds.\n",
            "2023-10-30 15:40:06,899 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0436 | Train accuracy: 84.54%.\n",
            "2023-10-30 15:40:07,672 max.py[line:93] INFO: max: attack effectiveness 54.285714285714285%.\n",
            "2023-10-30 15:40:07,684 md_at_ma.py[line:120] INFO: Mini batch: 468/1450 | training time in 5 minutes, 5 seconds.\n",
            "2023-10-30 15:40:07,684 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0206 | Train accuracy: 83.33%.\n",
            "2023-10-30 15:40:08,458 max.py[line:93] INFO: max: attack effectiveness 57.74647887323944%.\n",
            "2023-10-30 15:40:08,470 md_at_ma.py[line:120] INFO: Mini batch: 469/1450 | training time in 5 minutes, 5 seconds.\n",
            "2023-10-30 15:40:08,470 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0331 | Train accuracy: 79.90%.\n",
            "2023-10-30 15:40:09,295 max.py[line:93] INFO: max: attack effectiveness 57.89473684210527%.\n",
            "2023-10-30 15:40:09,308 md_at_ma.py[line:120] INFO: Mini batch: 470/1450 | training time in 5 minutes, 6 seconds.\n",
            "2023-10-30 15:40:09,308 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0303 | Train accuracy: 81.86%.\n",
            "2023-10-30 15:40:09,787 max.py[line:93] INFO: max: attack effectiveness 52.459016393442624%.\n",
            "2023-10-30 15:40:09,796 md_at_ma.py[line:120] INFO: Mini batch: 471/1450 | training time in 5 minutes, 7 seconds.\n",
            "2023-10-30 15:40:09,796 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0264 | Train accuracy: 85.19%.\n",
            "2023-10-30 15:40:10,578 max.py[line:93] INFO: max: attack effectiveness 49.275362318840585%.\n",
            "2023-10-30 15:40:10,590 md_at_ma.py[line:120] INFO: Mini batch: 472/1450 | training time in 5 minutes, 7 seconds.\n",
            "2023-10-30 15:40:10,591 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0462 | Train accuracy: 85.28%.\n",
            "2023-10-30 15:40:11,105 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:40:11,115 md_at_ma.py[line:120] INFO: Mini batch: 473/1450 | training time in 5 minutes, 8 seconds.\n",
            "2023-10-30 15:40:11,115 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0276 | Train accuracy: 86.32%.\n",
            "2023-10-30 15:40:11,739 max.py[line:93] INFO: max: attack effectiveness 61.66666666666667%.\n",
            "2023-10-30 15:40:11,748 md_at_ma.py[line:120] INFO: Mini batch: 474/1450 | training time in 5 minutes, 9 seconds.\n",
            "2023-10-30 15:40:11,748 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0497 | Train accuracy: 81.91%.\n",
            "2023-10-30 15:40:12,348 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:40:12,357 md_at_ma.py[line:120] INFO: Mini batch: 475/1450 | training time in 5 minutes, 9 seconds.\n",
            "2023-10-30 15:40:12,357 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0302 | Train accuracy: 84.62%.\n",
            "2023-10-30 15:40:12,889 max.py[line:93] INFO: max: attack effectiveness 61.904761904761905%.\n",
            "2023-10-30 15:40:12,898 md_at_ma.py[line:120] INFO: Mini batch: 476/1450 | training time in 5 minutes, 10 seconds.\n",
            "2023-10-30 15:40:12,898 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0420 | Train accuracy: 81.68%.\n",
            "2023-10-30 15:40:13,647 max.py[line:93] INFO: max: attack effectiveness 64.61538461538461%.\n",
            "2023-10-30 15:40:13,659 md_at_ma.py[line:120] INFO: Mini batch: 477/1450 | training time in 5 minutes, 10 seconds.\n",
            "2023-10-30 15:40:13,659 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0305 | Train accuracy: 79.79%.\n",
            "2023-10-30 15:40:14,425 max.py[line:93] INFO: max: attack effectiveness 57.57575757575758%.\n",
            "2023-10-30 15:40:14,437 md_at_ma.py[line:120] INFO: Mini batch: 478/1450 | training time in 5 minutes, 11 seconds.\n",
            "2023-10-30 15:40:14,437 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0278 | Train accuracy: 82.47%.\n",
            "2023-10-30 15:40:15,169 max.py[line:93] INFO: max: attack effectiveness 52.307692307692314%.\n",
            "2023-10-30 15:40:15,181 md_at_ma.py[line:120] INFO: Mini batch: 479/1450 | training time in 5 minutes, 12 seconds.\n",
            "2023-10-30 15:40:15,181 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0695 | Train accuracy: 83.94%.\n",
            "2023-10-30 15:40:15,957 max.py[line:93] INFO: max: attack effectiveness 63.38028169014085%.\n",
            "2023-10-30 15:40:15,969 md_at_ma.py[line:120] INFO: Mini batch: 480/1450 | training time in 5 minutes, 13 seconds.\n",
            "2023-10-30 15:40:15,969 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0212 | Train accuracy: 80.40%.\n",
            "2023-10-30 15:40:16,452 max.py[line:93] INFO: max: attack effectiveness 45.3125%.\n",
            "2023-10-30 15:40:16,461 md_at_ma.py[line:120] INFO: Mini batch: 481/1450 | training time in 5 minutes, 13 seconds.\n",
            "2023-10-30 15:40:16,461 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0206 | Train accuracy: 86.98%.\n",
            "2023-10-30 15:40:17,229 max.py[line:93] INFO: max: attack effectiveness 49.25373134328358%.\n",
            "2023-10-30 15:40:17,241 md_at_ma.py[line:120] INFO: Mini batch: 482/1450 | training time in 5 minutes, 14 seconds.\n",
            "2023-10-30 15:40:17,241 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0246 | Train accuracy: 83.08%.\n",
            "2023-10-30 15:40:17,728 max.py[line:93] INFO: max: attack effectiveness 56.25%.\n",
            "2023-10-30 15:40:17,737 md_at_ma.py[line:120] INFO: Mini batch: 483/1450 | training time in 5 minutes, 14 seconds.\n",
            "2023-10-30 15:40:17,738 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0272 | Train accuracy: 83.85%.\n",
            "2023-10-30 15:40:18,555 max.py[line:93] INFO: max: attack effectiveness 60.810810810810814%.\n",
            "2023-10-30 15:40:18,567 md_at_ma.py[line:120] INFO: Mini batch: 484/1450 | training time in 5 minutes, 15 seconds.\n",
            "2023-10-30 15:40:18,568 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0432 | Train accuracy: 78.71%.\n",
            "2023-10-30 15:40:19,342 max.py[line:93] INFO: max: attack effectiveness 50.72463768115942%.\n",
            "2023-10-30 15:40:19,354 md_at_ma.py[line:120] INFO: Mini batch: 485/1450 | training time in 5 minutes, 16 seconds.\n",
            "2023-10-30 15:40:19,354 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0184 | Train accuracy: 84.26%.\n",
            "2023-10-30 15:40:20,183 max.py[line:93] INFO: max: attack effectiveness 57.333333333333336%.\n",
            "2023-10-30 15:40:20,196 md_at_ma.py[line:120] INFO: Mini batch: 486/1450 | training time in 5 minutes, 17 seconds.\n",
            "2023-10-30 15:40:20,196 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0343 | Train accuracy: 80.30%.\n",
            "2023-10-30 15:40:20,968 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:40:20,981 md_at_ma.py[line:120] INFO: Mini batch: 487/1450 | training time in 5 minutes, 18 seconds.\n",
            "2023-10-30 15:40:20,981 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0211 | Train accuracy: 83.67%.\n",
            "2023-10-30 15:40:21,573 max.py[line:93] INFO: max: attack effectiveness 57.6271186440678%.\n",
            "2023-10-30 15:40:21,582 md_at_ma.py[line:120] INFO: Mini batch: 488/1450 | training time in 5 minutes, 18 seconds.\n",
            "2023-10-30 15:40:21,582 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0369 | Train accuracy: 85.03%.\n",
            "2023-10-30 15:40:22,404 max.py[line:93] INFO: max: attack effectiveness 58.666666666666664%.\n",
            "2023-10-30 15:40:22,417 md_at_ma.py[line:120] INFO: Mini batch: 489/1450 | training time in 5 minutes, 19 seconds.\n",
            "2023-10-30 15:40:22,417 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0226 | Train accuracy: 80.79%.\n",
            "2023-10-30 15:40:23,191 max.py[line:93] INFO: max: attack effectiveness 57.971014492753625%.\n",
            "2023-10-30 15:40:23,203 md_at_ma.py[line:120] INFO: Mini batch: 490/1450 | training time in 5 minutes, 20 seconds.\n",
            "2023-10-30 15:40:23,203 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0348 | Train accuracy: 79.19%.\n",
            "2023-10-30 15:40:23,703 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:40:23,712 md_at_ma.py[line:120] INFO: Mini batch: 491/1450 | training time in 5 minutes, 20 seconds.\n",
            "2023-10-30 15:40:23,712 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0228 | Train accuracy: 85.42%.\n",
            "2023-10-30 15:40:24,203 max.py[line:93] INFO: max: attack effectiveness 54.83870967741935%.\n",
            "2023-10-30 15:40:24,212 md_at_ma.py[line:120] INFO: Mini batch: 492/1450 | training time in 5 minutes, 21 seconds.\n",
            "2023-10-30 15:40:24,212 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0201 | Train accuracy: 83.16%.\n",
            "2023-10-30 15:40:24,606 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:40:24,610 md_at_ma.py[line:120] INFO: Mini batch: 493/1450 | training time in 5 minutes, 21 seconds.\n",
            "2023-10-30 15:40:24,610 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0152 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:40:24,649 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0317 | Train accuracy: 83.08\n",
            "2023-10-30 15:40:26,892 max.py[line:93] INFO: max: attack effectiveness 66.40625%.\n",
            "2023-10-30 15:40:27,858 max.py[line:93] INFO: max: attack effectiveness 69.53125%.\n",
            "2023-10-30 15:40:28,792 max.py[line:93] INFO: max: attack effectiveness 66.40625%.\n",
            "2023-10-30 15:40:29,716 max.py[line:93] INFO: max: attack effectiveness 62.5%.\n",
            "2023-10-30 15:40:30,291 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:40:30,991 md_at_ma.py[line:165] INFO: \tVal accuracy 64.99% with accuracy 32.97% under attack.\n",
            "2023-10-30 15:40:30,991 md_at_ma.py[line:167] INFO: \tModel select at epoch 17 with validation accuracy 64.99% and accuracy 32.97% under attack.\n",
            "2023-10-30 15:40:31,880 max.py[line:93] INFO: max: attack effectiveness 51.515151515151516%.\n",
            "2023-10-30 15:40:31,893 md_at_ma.py[line:120] INFO: Mini batch: 494/1450 | training time in 5 minutes, 22 seconds.\n",
            "2023-10-30 15:40:31,893 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0332 | Train accuracy: 84.54%.\n",
            "2023-10-30 15:40:32,376 max.py[line:93] INFO: max: attack effectiveness 57.14285714285714%.\n",
            "2023-10-30 15:40:32,385 md_at_ma.py[line:120] INFO: Mini batch: 495/1450 | training time in 5 minutes, 22 seconds.\n",
            "2023-10-30 15:40:32,385 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0258 | Train accuracy: 85.34%.\n",
            "2023-10-30 15:40:33,154 max.py[line:93] INFO: max: attack effectiveness 46.96969696969697%.\n",
            "2023-10-30 15:40:33,166 md_at_ma.py[line:120] INFO: Mini batch: 496/1450 | training time in 5 minutes, 23 seconds.\n",
            "2023-10-30 15:40:33,166 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0207 | Train accuracy: 85.57%.\n",
            "2023-10-30 15:40:33,937 max.py[line:93] INFO: max: attack effectiveness 52.85714285714286%.\n",
            "2023-10-30 15:40:33,950 md_at_ma.py[line:120] INFO: Mini batch: 497/1450 | training time in 5 minutes, 24 seconds.\n",
            "2023-10-30 15:40:33,950 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0234 | Train accuracy: 84.34%.\n",
            "2023-10-30 15:40:34,725 max.py[line:93] INFO: max: attack effectiveness 56.33802816901409%.\n",
            "2023-10-30 15:40:34,737 md_at_ma.py[line:120] INFO: Mini batch: 498/1450 | training time in 5 minutes, 25 seconds.\n",
            "2023-10-30 15:40:34,737 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0251 | Train accuracy: 81.91%.\n",
            "2023-10-30 15:40:35,561 max.py[line:93] INFO: max: attack effectiveness 56.57894736842105%.\n",
            "2023-10-30 15:40:35,573 md_at_ma.py[line:120] INFO: Mini batch: 499/1450 | training time in 5 minutes, 25 seconds.\n",
            "2023-10-30 15:40:35,573 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0255 | Train accuracy: 81.86%.\n",
            "2023-10-30 15:40:36,059 max.py[line:93] INFO: max: attack effectiveness 52.459016393442624%.\n",
            "2023-10-30 15:40:36,068 md_at_ma.py[line:120] INFO: Mini batch: 500/1450 | training time in 5 minutes, 26 seconds.\n",
            "2023-10-30 15:40:36,068 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0190 | Train accuracy: 85.71%.\n",
            "2023-10-30 15:40:36,875 max.py[line:93] INFO: max: attack effectiveness 47.82608695652174%.\n",
            "2023-10-30 15:40:36,888 md_at_ma.py[line:120] INFO: Mini batch: 501/1450 | training time in 5 minutes, 27 seconds.\n",
            "2023-10-30 15:40:36,888 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0426 | Train accuracy: 84.77%.\n",
            "2023-10-30 15:40:37,413 max.py[line:93] INFO: max: attack effectiveness 43.54838709677419%.\n",
            "2023-10-30 15:40:37,422 md_at_ma.py[line:120] INFO: Mini batch: 502/1450 | training time in 5 minutes, 27 seconds.\n",
            "2023-10-30 15:40:37,423 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0243 | Train accuracy: 86.84%.\n",
            "2023-10-30 15:40:38,052 max.py[line:93] INFO: max: attack effectiveness 56.666666666666664%.\n",
            "2023-10-30 15:40:38,061 md_at_ma.py[line:120] INFO: Mini batch: 503/1450 | training time in 5 minutes, 28 seconds.\n",
            "2023-10-30 15:40:38,061 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0507 | Train accuracy: 81.91%.\n",
            "2023-10-30 15:40:38,651 max.py[line:93] INFO: max: attack effectiveness 44.44444444444444%.\n",
            "2023-10-30 15:40:38,660 md_at_ma.py[line:120] INFO: Mini batch: 504/1450 | training time in 5 minutes, 28 seconds.\n",
            "2023-10-30 15:40:38,660 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0212 | Train accuracy: 88.46%.\n",
            "2023-10-30 15:40:39,155 max.py[line:93] INFO: max: attack effectiveness 58.730158730158735%.\n",
            "2023-10-30 15:40:39,163 md_at_ma.py[line:120] INFO: Mini batch: 505/1450 | training time in 5 minutes, 29 seconds.\n",
            "2023-10-30 15:40:39,164 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0313 | Train accuracy: 81.68%.\n",
            "2023-10-30 15:40:39,895 max.py[line:93] INFO: max: attack effectiveness 56.92307692307692%.\n",
            "2023-10-30 15:40:39,908 md_at_ma.py[line:120] INFO: Mini batch: 506/1450 | training time in 5 minutes, 30 seconds.\n",
            "2023-10-30 15:40:39,908 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0286 | Train accuracy: 82.90%.\n",
            "2023-10-30 15:40:40,678 max.py[line:93] INFO: max: attack effectiveness 53.03030303030303%.\n",
            "2023-10-30 15:40:40,690 md_at_ma.py[line:120] INFO: Mini batch: 507/1450 | training time in 5 minutes, 30 seconds.\n",
            "2023-10-30 15:40:40,690 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0373 | Train accuracy: 82.99%.\n",
            "2023-10-30 15:40:41,424 max.py[line:93] INFO: max: attack effectiveness 49.23076923076923%.\n",
            "2023-10-30 15:40:41,436 md_at_ma.py[line:120] INFO: Mini batch: 508/1450 | training time in 5 minutes, 31 seconds.\n",
            "2023-10-30 15:40:41,437 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0625 | Train accuracy: 83.42%.\n",
            "2023-10-30 15:40:42,212 max.py[line:93] INFO: max: attack effectiveness 61.97183098591549%.\n",
            "2023-10-30 15:40:42,225 md_at_ma.py[line:120] INFO: Mini batch: 509/1450 | training time in 5 minutes, 32 seconds.\n",
            "2023-10-30 15:40:42,225 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0317 | Train accuracy: 79.90%.\n",
            "2023-10-30 15:40:42,715 max.py[line:93] INFO: max: attack effectiveness 43.75%.\n",
            "2023-10-30 15:40:42,724 md_at_ma.py[line:120] INFO: Mini batch: 510/1450 | training time in 5 minutes, 32 seconds.\n",
            "2023-10-30 15:40:42,725 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0211 | Train accuracy: 86.46%.\n",
            "2023-10-30 15:40:43,490 max.py[line:93] INFO: max: attack effectiveness 49.25373134328358%.\n",
            "2023-10-30 15:40:43,503 md_at_ma.py[line:120] INFO: Mini batch: 511/1450 | training time in 5 minutes, 33 seconds.\n",
            "2023-10-30 15:40:43,503 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0343 | Train accuracy: 84.10%.\n",
            "2023-10-30 15:40:43,987 max.py[line:93] INFO: max: attack effectiveness 54.6875%.\n",
            "2023-10-30 15:40:43,996 md_at_ma.py[line:120] INFO: Mini batch: 512/1450 | training time in 5 minutes, 34 seconds.\n",
            "2023-10-30 15:40:43,996 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0302 | Train accuracy: 83.85%.\n",
            "2023-10-30 15:40:44,817 max.py[line:93] INFO: max: attack effectiveness 60.810810810810814%.\n",
            "2023-10-30 15:40:44,829 md_at_ma.py[line:120] INFO: Mini batch: 513/1450 | training time in 5 minutes, 34 seconds.\n",
            "2023-10-30 15:40:44,829 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0440 | Train accuracy: 78.71%.\n",
            "2023-10-30 15:40:45,603 max.py[line:93] INFO: max: attack effectiveness 50.72463768115942%.\n",
            "2023-10-30 15:40:45,615 md_at_ma.py[line:120] INFO: Mini batch: 514/1450 | training time in 5 minutes, 35 seconds.\n",
            "2023-10-30 15:40:45,615 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0214 | Train accuracy: 83.76%.\n",
            "2023-10-30 15:40:46,438 max.py[line:93] INFO: max: attack effectiveness 54.666666666666664%.\n",
            "2023-10-30 15:40:46,450 md_at_ma.py[line:120] INFO: Mini batch: 515/1450 | training time in 5 minutes, 36 seconds.\n",
            "2023-10-30 15:40:46,450 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0255 | Train accuracy: 81.28%.\n",
            "2023-10-30 15:40:47,219 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:40:47,231 md_at_ma.py[line:120] INFO: Mini batch: 516/1450 | training time in 5 minutes, 37 seconds.\n",
            "2023-10-30 15:40:47,232 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0200 | Train accuracy: 83.67%.\n",
            "2023-10-30 15:40:47,826 max.py[line:93] INFO: max: attack effectiveness 57.6271186440678%.\n",
            "2023-10-30 15:40:47,835 md_at_ma.py[line:120] INFO: Mini batch: 517/1450 | training time in 5 minutes, 37 seconds.\n",
            "2023-10-30 15:40:47,835 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0362 | Train accuracy: 82.35%.\n",
            "2023-10-30 15:40:48,662 max.py[line:93] INFO: max: attack effectiveness 58.666666666666664%.\n",
            "2023-10-30 15:40:48,675 md_at_ma.py[line:120] INFO: Mini batch: 518/1450 | training time in 5 minutes, 38 seconds.\n",
            "2023-10-30 15:40:48,675 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0213 | Train accuracy: 80.30%.\n",
            "2023-10-30 15:40:49,452 max.py[line:93] INFO: max: attack effectiveness 56.52173913043478%.\n",
            "2023-10-30 15:40:49,465 md_at_ma.py[line:120] INFO: Mini batch: 519/1450 | training time in 5 minutes, 39 seconds.\n",
            "2023-10-30 15:40:49,465 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0259 | Train accuracy: 81.73%.\n",
            "2023-10-30 15:40:49,963 max.py[line:93] INFO: max: attack effectiveness 46.875%.\n",
            "2023-10-30 15:40:49,972 md_at_ma.py[line:120] INFO: Mini batch: 520/1450 | training time in 5 minutes, 39 seconds.\n",
            "2023-10-30 15:40:49,972 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0218 | Train accuracy: 84.38%.\n",
            "2023-10-30 15:40:50,458 max.py[line:93] INFO: max: attack effectiveness 48.38709677419355%.\n",
            "2023-10-30 15:40:50,467 md_at_ma.py[line:120] INFO: Mini batch: 521/1450 | training time in 5 minutes, 40 seconds.\n",
            "2023-10-30 15:40:50,467 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0171 | Train accuracy: 87.37%.\n",
            "2023-10-30 15:40:50,862 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:40:50,866 md_at_ma.py[line:120] INFO: Mini batch: 522/1450 | training time in 5 minutes, 40 seconds.\n",
            "2023-10-30 15:40:50,866 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0125 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:40:50,901 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0288 | Train accuracy: 83.78\n",
            "2023-10-30 15:40:53,120 max.py[line:93] INFO: max: attack effectiveness 66.40625%.\n",
            "2023-10-30 15:40:54,231 max.py[line:93] INFO: max: attack effectiveness 67.1875%.\n",
            "2023-10-30 15:40:55,150 max.py[line:93] INFO: max: attack effectiveness 64.0625%.\n",
            "2023-10-30 15:40:56,066 max.py[line:93] INFO: max: attack effectiveness 60.9375%.\n",
            "2023-10-30 15:40:56,722 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:40:57,434 md_at_ma.py[line:165] INFO: \tVal accuracy 65.55% with accuracy 34.41% under attack.\n",
            "2023-10-30 15:40:57,435 md_at_ma.py[line:167] INFO: \tModel select at epoch 18 with validation accuracy 65.55% and accuracy 34.41% under attack.\n",
            "2023-10-30 15:40:58,307 max.py[line:93] INFO: max: attack effectiveness 48.484848484848484%.\n",
            "2023-10-30 15:40:58,320 md_at_ma.py[line:120] INFO: Mini batch: 523/1450 | training time in 5 minutes, 41 seconds.\n",
            "2023-10-30 15:40:58,320 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0269 | Train accuracy: 87.11%.\n",
            "2023-10-30 15:40:58,803 max.py[line:93] INFO: max: attack effectiveness 57.14285714285714%.\n",
            "2023-10-30 15:40:58,812 md_at_ma.py[line:120] INFO: Mini batch: 524/1450 | training time in 5 minutes, 42 seconds.\n",
            "2023-10-30 15:40:58,813 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0330 | Train accuracy: 83.25%.\n",
            "2023-10-30 15:40:59,577 max.py[line:93] INFO: max: attack effectiveness 46.96969696969697%.\n",
            "2023-10-30 15:40:59,589 md_at_ma.py[line:120] INFO: Mini batch: 525/1450 | training time in 5 minutes, 42 seconds.\n",
            "2023-10-30 15:40:59,589 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0226 | Train accuracy: 86.08%.\n",
            "2023-10-30 15:41:00,366 max.py[line:93] INFO: max: attack effectiveness 52.85714285714286%.\n",
            "2023-10-30 15:41:00,378 md_at_ma.py[line:120] INFO: Mini batch: 526/1450 | training time in 5 minutes, 43 seconds.\n",
            "2023-10-30 15:41:00,378 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0199 | Train accuracy: 82.83%.\n",
            "2023-10-30 15:41:01,155 max.py[line:93] INFO: max: attack effectiveness 59.154929577464785%.\n",
            "2023-10-30 15:41:01,167 md_at_ma.py[line:120] INFO: Mini batch: 527/1450 | training time in 5 minutes, 44 seconds.\n",
            "2023-10-30 15:41:01,167 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0291 | Train accuracy: 80.90%.\n",
            "2023-10-30 15:41:01,992 max.py[line:93] INFO: max: attack effectiveness 57.89473684210527%.\n",
            "2023-10-30 15:41:02,005 md_at_ma.py[line:120] INFO: Mini batch: 528/1450 | training time in 5 minutes, 45 seconds.\n",
            "2023-10-30 15:41:02,005 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0219 | Train accuracy: 80.88%.\n",
            "2023-10-30 15:41:02,497 max.py[line:93] INFO: max: attack effectiveness 55.73770491803278%.\n",
            "2023-10-30 15:41:02,508 md_at_ma.py[line:120] INFO: Mini batch: 529/1450 | training time in 5 minutes, 45 seconds.\n",
            "2023-10-30 15:41:02,508 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0188 | Train accuracy: 85.19%.\n",
            "2023-10-30 15:41:03,323 max.py[line:93] INFO: max: attack effectiveness 53.62318840579711%.\n",
            "2023-10-30 15:41:03,335 md_at_ma.py[line:120] INFO: Mini batch: 530/1450 | training time in 5 minutes, 46 seconds.\n",
            "2023-10-30 15:41:03,336 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0414 | Train accuracy: 83.25%.\n",
            "2023-10-30 15:41:03,851 max.py[line:93] INFO: max: attack effectiveness 45.16129032258064%.\n",
            "2023-10-30 15:41:03,860 md_at_ma.py[line:120] INFO: Mini batch: 531/1450 | training time in 5 minutes, 47 seconds.\n",
            "2023-10-30 15:41:03,860 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0218 | Train accuracy: 86.32%.\n",
            "2023-10-30 15:41:04,462 max.py[line:93] INFO: max: attack effectiveness 60.0%.\n",
            "2023-10-30 15:41:04,471 md_at_ma.py[line:120] INFO: Mini batch: 532/1450 | training time in 5 minutes, 47 seconds.\n",
            "2023-10-30 15:41:04,471 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0361 | Train accuracy: 81.91%.\n",
            "2023-10-30 15:41:05,076 max.py[line:93] INFO: max: attack effectiveness 44.44444444444444%.\n",
            "2023-10-30 15:41:05,087 md_at_ma.py[line:120] INFO: Mini batch: 533/1450 | training time in 5 minutes, 48 seconds.\n",
            "2023-10-30 15:41:05,090 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0164 | Train accuracy: 89.56%.\n",
            "2023-10-30 15:41:05,573 max.py[line:93] INFO: max: attack effectiveness 53.96825396825397%.\n",
            "2023-10-30 15:41:05,582 md_at_ma.py[line:120] INFO: Mini batch: 534/1450 | training time in 5 minutes, 48 seconds.\n",
            "2023-10-30 15:41:05,582 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0242 | Train accuracy: 84.29%.\n",
            "2023-10-30 15:41:06,314 max.py[line:93] INFO: max: attack effectiveness 58.46153846153847%.\n",
            "2023-10-30 15:41:06,326 md_at_ma.py[line:120] INFO: Mini batch: 535/1450 | training time in 5 minutes, 49 seconds.\n",
            "2023-10-30 15:41:06,326 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0184 | Train accuracy: 82.90%.\n",
            "2023-10-30 15:41:07,104 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:41:07,116 md_at_ma.py[line:120] INFO: Mini batch: 536/1450 | training time in 5 minutes, 50 seconds.\n",
            "2023-10-30 15:41:07,116 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0212 | Train accuracy: 85.05%.\n",
            "2023-10-30 15:41:07,849 max.py[line:93] INFO: max: attack effectiveness 46.15384615384615%.\n",
            "2023-10-30 15:41:07,861 md_at_ma.py[line:120] INFO: Mini batch: 537/1450 | training time in 5 minutes, 50 seconds.\n",
            "2023-10-30 15:41:07,862 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0909 | Train accuracy: 86.53%.\n",
            "2023-10-30 15:41:08,635 max.py[line:93] INFO: max: attack effectiveness 59.154929577464785%.\n",
            "2023-10-30 15:41:08,647 md_at_ma.py[line:120] INFO: Mini batch: 538/1450 | training time in 5 minutes, 51 seconds.\n",
            "2023-10-30 15:41:08,648 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0262 | Train accuracy: 81.91%.\n",
            "2023-10-30 15:41:09,133 max.py[line:93] INFO: max: attack effectiveness 43.75%.\n",
            "2023-10-30 15:41:09,142 md_at_ma.py[line:120] INFO: Mini batch: 539/1450 | training time in 5 minutes, 52 seconds.\n",
            "2023-10-30 15:41:09,142 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0224 | Train accuracy: 85.42%.\n",
            "2023-10-30 15:41:09,909 max.py[line:93] INFO: max: attack effectiveness 52.23880597014925%.\n",
            "2023-10-30 15:41:09,921 md_at_ma.py[line:120] INFO: Mini batch: 540/1450 | training time in 5 minutes, 52 seconds.\n",
            "2023-10-30 15:41:09,921 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0251 | Train accuracy: 82.05%.\n",
            "2023-10-30 15:41:10,409 max.py[line:93] INFO: max: attack effectiveness 67.1875%.\n",
            "2023-10-30 15:41:10,418 md_at_ma.py[line:120] INFO: Mini batch: 541/1450 | training time in 5 minutes, 53 seconds.\n",
            "2023-10-30 15:41:10,418 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0331 | Train accuracy: 79.17%.\n",
            "2023-10-30 15:41:11,237 max.py[line:93] INFO: max: attack effectiveness 79.72972972972973%.\n",
            "2023-10-30 15:41:11,250 md_at_ma.py[line:120] INFO: Mini batch: 542/1450 | training time in 5 minutes, 54 seconds.\n",
            "2023-10-30 15:41:11,250 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0602 | Train accuracy: 72.77%.\n",
            "2023-10-30 15:41:12,019 max.py[line:93] INFO: max: attack effectiveness 68.11594202898551%.\n",
            "2023-10-30 15:41:12,032 md_at_ma.py[line:120] INFO: Mini batch: 543/1450 | training time in 5 minutes, 55 seconds.\n",
            "2023-10-30 15:41:12,032 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0271 | Train accuracy: 76.65%.\n",
            "2023-10-30 15:41:12,856 max.py[line:93] INFO: max: attack effectiveness 74.66666666666667%.\n",
            "2023-10-30 15:41:12,869 md_at_ma.py[line:120] INFO: Mini batch: 544/1450 | training time in 5 minutes, 55 seconds.\n",
            "2023-10-30 15:41:12,869 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0340 | Train accuracy: 74.88%.\n",
            "2023-10-30 15:41:13,636 max.py[line:93] INFO: max: attack effectiveness 70.58823529411765%.\n",
            "2023-10-30 15:41:13,648 md_at_ma.py[line:120] INFO: Mini batch: 545/1450 | training time in 5 minutes, 56 seconds.\n",
            "2023-10-30 15:41:13,648 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0286 | Train accuracy: 76.02%.\n",
            "2023-10-30 15:41:14,232 max.py[line:93] INFO: max: attack effectiveness 71.1864406779661%.\n",
            "2023-10-30 15:41:14,241 md_at_ma.py[line:120] INFO: Mini batch: 546/1450 | training time in 5 minutes, 57 seconds.\n",
            "2023-10-30 15:41:14,241 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0487 | Train accuracy: 78.07%.\n",
            "2023-10-30 15:41:15,062 max.py[line:93] INFO: max: attack effectiveness 66.66666666666666%.\n",
            "2023-10-30 15:41:15,075 md_at_ma.py[line:120] INFO: Mini batch: 547/1450 | training time in 5 minutes, 57 seconds.\n",
            "2023-10-30 15:41:15,075 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0190 | Train accuracy: 76.85%.\n",
            "2023-10-30 15:41:15,849 max.py[line:93] INFO: max: attack effectiveness 65.21739130434783%.\n",
            "2023-10-30 15:41:15,861 md_at_ma.py[line:120] INFO: Mini batch: 548/1450 | training time in 5 minutes, 58 seconds.\n",
            "2023-10-30 15:41:15,861 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0249 | Train accuracy: 78.68%.\n",
            "2023-10-30 15:41:16,359 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:41:16,368 md_at_ma.py[line:120] INFO: Mini batch: 549/1450 | training time in 5 minutes, 59 seconds.\n",
            "2023-10-30 15:41:16,369 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0275 | Train accuracy: 86.46%.\n",
            "2023-10-30 15:41:16,859 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:41:16,868 md_at_ma.py[line:120] INFO: Mini batch: 550/1450 | training time in 5 minutes, 59 seconds.\n",
            "2023-10-30 15:41:16,869 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0228 | Train accuracy: 83.68%.\n",
            "2023-10-30 15:41:17,267 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:41:17,271 md_at_ma.py[line:120] INFO: Mini batch: 551/1450 | training time in 6 minutes, 0 seconds.\n",
            "2023-10-30 15:41:17,271 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0105 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:41:17,311 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0294 | Train accuracy: 82.35\n",
            "2023-10-30 15:41:19,304 max.py[line:93] INFO: max: attack effectiveness 67.1875%.\n",
            "2023-10-30 15:41:20,280 max.py[line:93] INFO: max: attack effectiveness 67.96875%.\n",
            "2023-10-30 15:41:21,167 max.py[line:93] INFO: max: attack effectiveness 65.625%.\n",
            "2023-10-30 15:41:22,141 max.py[line:93] INFO: max: attack effectiveness 62.5%.\n",
            "2023-10-30 15:41:22,743 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:41:23,351 md_at_ma.py[line:165] INFO: \tVal accuracy 64.85% with accuracy 33.33% under attack.\n",
            "2023-10-30 15:41:23,351 md_at_ma.py[line:167] INFO: \tModel select at epoch 18 with validation accuracy 65.55% and accuracy 34.41% under attack.\n",
            "2023-10-30 15:41:24,221 max.py[line:93] INFO: max: attack effectiveness 51.515151515151516%.\n",
            "2023-10-30 15:41:24,234 md_at_ma.py[line:120] INFO: Mini batch: 552/1450 | training time in 6 minutes, 0 seconds.\n",
            "2023-10-30 15:41:24,234 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0325 | Train accuracy: 83.51%.\n",
            "2023-10-30 15:41:24,721 max.py[line:93] INFO: max: attack effectiveness 60.317460317460316%.\n",
            "2023-10-30 15:41:24,730 md_at_ma.py[line:120] INFO: Mini batch: 553/1450 | training time in 6 minutes, 1 seconds.\n",
            "2023-10-30 15:41:24,731 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0345 | Train accuracy: 81.15%.\n",
            "2023-10-30 15:41:25,495 max.py[line:93] INFO: max: attack effectiveness 48.484848484848484%.\n",
            "2023-10-30 15:41:25,507 md_at_ma.py[line:120] INFO: Mini batch: 554/1450 | training time in 6 minutes, 2 seconds.\n",
            "2023-10-30 15:41:25,508 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0315 | Train accuracy: 84.02%.\n",
            "2023-10-30 15:41:26,282 max.py[line:93] INFO: max: attack effectiveness 52.85714285714286%.\n",
            "2023-10-30 15:41:26,294 md_at_ma.py[line:120] INFO: Mini batch: 555/1450 | training time in 6 minutes, 2 seconds.\n",
            "2023-10-30 15:41:26,294 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0221 | Train accuracy: 83.33%.\n",
            "2023-10-30 15:41:27,072 max.py[line:93] INFO: max: attack effectiveness 56.33802816901409%.\n",
            "2023-10-30 15:41:27,084 md_at_ma.py[line:120] INFO: Mini batch: 556/1450 | training time in 6 minutes, 3 seconds.\n",
            "2023-10-30 15:41:27,084 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0307 | Train accuracy: 81.91%.\n",
            "2023-10-30 15:41:27,909 max.py[line:93] INFO: max: attack effectiveness 56.57894736842105%.\n",
            "2023-10-30 15:41:27,921 md_at_ma.py[line:120] INFO: Mini batch: 557/1450 | training time in 6 minutes, 4 seconds.\n",
            "2023-10-30 15:41:27,921 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0234 | Train accuracy: 79.90%.\n",
            "2023-10-30 15:41:28,414 max.py[line:93] INFO: max: attack effectiveness 55.73770491803278%.\n",
            "2023-10-30 15:41:28,423 md_at_ma.py[line:120] INFO: Mini batch: 558/1450 | training time in 6 minutes, 4 seconds.\n",
            "2023-10-30 15:41:28,423 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0255 | Train accuracy: 84.66%.\n",
            "2023-10-30 15:41:29,228 max.py[line:93] INFO: max: attack effectiveness 49.275362318840585%.\n",
            "2023-10-30 15:41:29,240 md_at_ma.py[line:120] INFO: Mini batch: 559/1450 | training time in 6 minutes, 5 seconds.\n",
            "2023-10-30 15:41:29,240 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0335 | Train accuracy: 84.26%.\n",
            "2023-10-30 15:41:29,727 max.py[line:93] INFO: max: attack effectiveness 48.38709677419355%.\n",
            "2023-10-30 15:41:29,736 md_at_ma.py[line:120] INFO: Mini batch: 560/1450 | training time in 6 minutes, 6 seconds.\n",
            "2023-10-30 15:41:29,736 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0225 | Train accuracy: 85.26%.\n",
            "2023-10-30 15:41:30,363 max.py[line:93] INFO: max: attack effectiveness 58.333333333333336%.\n",
            "2023-10-30 15:41:30,372 md_at_ma.py[line:120] INFO: Mini batch: 561/1450 | training time in 6 minutes, 6 seconds.\n",
            "2023-10-30 15:41:30,372 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0352 | Train accuracy: 83.51%.\n",
            "2023-10-30 15:41:30,986 max.py[line:93] INFO: max: attack effectiveness 42.592592592592595%.\n",
            "2023-10-30 15:41:30,995 md_at_ma.py[line:120] INFO: Mini batch: 562/1450 | training time in 6 minutes, 7 seconds.\n",
            "2023-10-30 15:41:30,995 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0192 | Train accuracy: 90.11%.\n",
            "2023-10-30 15:41:31,506 max.py[line:93] INFO: max: attack effectiveness 57.14285714285714%.\n",
            "2023-10-30 15:41:31,514 md_at_ma.py[line:120] INFO: Mini batch: 563/1450 | training time in 6 minutes, 7 seconds.\n",
            "2023-10-30 15:41:31,515 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0167 | Train accuracy: 85.34%.\n",
            "2023-10-30 15:41:32,252 max.py[line:93] INFO: max: attack effectiveness 58.46153846153847%.\n",
            "2023-10-30 15:41:32,264 md_at_ma.py[line:120] INFO: Mini batch: 564/1450 | training time in 6 minutes, 8 seconds.\n",
            "2023-10-30 15:41:32,264 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0133 | Train accuracy: 82.38%.\n",
            "2023-10-30 15:41:33,031 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:41:33,043 md_at_ma.py[line:120] INFO: Mini batch: 565/1450 | training time in 6 minutes, 9 seconds.\n",
            "2023-10-30 15:41:33,043 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0221 | Train accuracy: 84.02%.\n",
            "2023-10-30 15:41:33,775 max.py[line:93] INFO: max: attack effectiveness 47.69230769230769%.\n",
            "2023-10-30 15:41:33,787 md_at_ma.py[line:120] INFO: Mini batch: 566/1450 | training time in 6 minutes, 10 seconds.\n",
            "2023-10-30 15:41:33,787 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0691 | Train accuracy: 84.97%.\n",
            "2023-10-30 15:41:34,562 max.py[line:93] INFO: max: attack effectiveness 63.38028169014085%.\n",
            "2023-10-30 15:41:34,574 md_at_ma.py[line:120] INFO: Mini batch: 567/1450 | training time in 6 minutes, 10 seconds.\n",
            "2023-10-30 15:41:34,574 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0243 | Train accuracy: 79.90%.\n",
            "2023-10-30 15:41:35,060 max.py[line:93] INFO: max: attack effectiveness 45.3125%.\n",
            "2023-10-30 15:41:35,069 md_at_ma.py[line:120] INFO: Mini batch: 568/1450 | training time in 6 minutes, 11 seconds.\n",
            "2023-10-30 15:41:35,069 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0141 | Train accuracy: 87.50%.\n",
            "2023-10-30 15:41:35,834 max.py[line:93] INFO: max: attack effectiveness 52.23880597014925%.\n",
            "2023-10-30 15:41:35,847 md_at_ma.py[line:120] INFO: Mini batch: 569/1450 | training time in 6 minutes, 12 seconds.\n",
            "2023-10-30 15:41:35,847 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0254 | Train accuracy: 83.08%.\n",
            "2023-10-30 15:41:36,336 max.py[line:93] INFO: max: attack effectiveness 62.5%.\n",
            "2023-10-30 15:41:36,344 md_at_ma.py[line:120] INFO: Mini batch: 570/1450 | training time in 6 minutes, 12 seconds.\n",
            "2023-10-30 15:41:36,345 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0303 | Train accuracy: 81.77%.\n",
            "2023-10-30 15:41:37,121 max.py[line:93] INFO: max: attack effectiveness 68.91891891891892%.\n",
            "2023-10-30 15:41:37,134 md_at_ma.py[line:120] INFO: Mini batch: 571/1450 | training time in 6 minutes, 13 seconds.\n",
            "2023-10-30 15:41:37,134 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0454 | Train accuracy: 74.75%.\n",
            "2023-10-30 15:41:37,905 max.py[line:93] INFO: max: attack effectiveness 56.52173913043478%.\n",
            "2023-10-30 15:41:37,917 md_at_ma.py[line:120] INFO: Mini batch: 572/1450 | training time in 6 minutes, 14 seconds.\n",
            "2023-10-30 15:41:37,917 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0183 | Train accuracy: 83.76%.\n",
            "2023-10-30 15:41:38,739 max.py[line:93] INFO: max: attack effectiveness 56.00000000000001%.\n",
            "2023-10-30 15:41:38,751 md_at_ma.py[line:120] INFO: Mini batch: 573/1450 | training time in 6 minutes, 15 seconds.\n",
            "2023-10-30 15:41:38,751 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0247 | Train accuracy: 79.80%.\n",
            "2023-10-30 15:41:39,521 max.py[line:93] INFO: max: attack effectiveness 57.35294117647059%.\n",
            "2023-10-30 15:41:39,533 md_at_ma.py[line:120] INFO: Mini batch: 574/1450 | training time in 6 minutes, 15 seconds.\n",
            "2023-10-30 15:41:39,533 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0200 | Train accuracy: 82.65%.\n",
            "2023-10-30 15:41:40,125 max.py[line:93] INFO: max: attack effectiveness 57.6271186440678%.\n",
            "2023-10-30 15:41:40,134 md_at_ma.py[line:120] INFO: Mini batch: 575/1450 | training time in 6 minutes, 16 seconds.\n",
            "2023-10-30 15:41:40,134 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0381 | Train accuracy: 82.35%.\n",
            "2023-10-30 15:41:40,956 max.py[line:93] INFO: max: attack effectiveness 60.0%.\n",
            "2023-10-30 15:41:40,968 md_at_ma.py[line:120] INFO: Mini batch: 576/1450 | training time in 6 minutes, 17 seconds.\n",
            "2023-10-30 15:41:40,969 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0198 | Train accuracy: 77.83%.\n",
            "2023-10-30 15:41:41,746 max.py[line:93] INFO: max: attack effectiveness 66.66666666666666%.\n",
            "2023-10-30 15:41:41,758 md_at_ma.py[line:120] INFO: Mini batch: 577/1450 | training time in 6 minutes, 17 seconds.\n",
            "2023-10-30 15:41:41,758 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0288 | Train accuracy: 79.70%.\n",
            "2023-10-30 15:41:42,251 max.py[line:93] INFO: max: attack effectiveness 46.875%.\n",
            "2023-10-30 15:41:42,261 md_at_ma.py[line:120] INFO: Mini batch: 578/1450 | training time in 6 minutes, 18 seconds.\n",
            "2023-10-30 15:41:42,261 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0177 | Train accuracy: 87.50%.\n",
            "2023-10-30 15:41:42,746 max.py[line:93] INFO: max: attack effectiveness 53.2258064516129%.\n",
            "2023-10-30 15:41:42,756 md_at_ma.py[line:120] INFO: Mini batch: 579/1450 | training time in 6 minutes, 18 seconds.\n",
            "2023-10-30 15:41:42,756 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0236 | Train accuracy: 83.68%.\n",
            "2023-10-30 15:41:43,157 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:41:43,162 md_at_ma.py[line:120] INFO: Mini batch: 580/1450 | training time in 6 minutes, 19 seconds.\n",
            "2023-10-30 15:41:43,162 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0121 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:41:43,199 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0267 | Train accuracy: 83.18\n",
            "2023-10-30 15:41:45,272 max.py[line:93] INFO: max: attack effectiveness 67.96875%.\n",
            "2023-10-30 15:41:46,310 max.py[line:93] INFO: max: attack effectiveness 71.09375%.\n",
            "2023-10-30 15:41:47,194 max.py[line:93] INFO: max: attack effectiveness 70.3125%.\n",
            "2023-10-30 15:41:48,082 max.py[line:93] INFO: max: attack effectiveness 66.40625%.\n",
            "2023-10-30 15:41:48,732 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:41:49,355 md_at_ma.py[line:165] INFO: \tVal accuracy 63.76% with accuracy 30.47% under attack.\n",
            "2023-10-30 15:41:49,355 md_at_ma.py[line:167] INFO: \tModel select at epoch 18 with validation accuracy 65.55% and accuracy 34.41% under attack.\n",
            "2023-10-30 15:41:50,252 max.py[line:93] INFO: max: attack effectiveness 53.03030303030303%.\n",
            "2023-10-30 15:41:50,265 md_at_ma.py[line:120] INFO: Mini batch: 581/1450 | training time in 6 minutes, 20 seconds.\n",
            "2023-10-30 15:41:50,265 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0270 | Train accuracy: 82.99%.\n",
            "2023-10-30 15:41:50,751 max.py[line:93] INFO: max: attack effectiveness 63.49206349206349%.\n",
            "2023-10-30 15:41:50,759 md_at_ma.py[line:120] INFO: Mini batch: 582/1450 | training time in 6 minutes, 20 seconds.\n",
            "2023-10-30 15:41:50,760 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0274 | Train accuracy: 81.68%.\n",
            "2023-10-30 15:41:51,530 max.py[line:93] INFO: max: attack effectiveness 46.96969696969697%.\n",
            "2023-10-30 15:41:51,542 md_at_ma.py[line:120] INFO: Mini batch: 583/1450 | training time in 6 minutes, 21 seconds.\n",
            "2023-10-30 15:41:51,542 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0217 | Train accuracy: 86.08%.\n",
            "2023-10-30 15:41:52,313 max.py[line:93] INFO: max: attack effectiveness 57.14285714285714%.\n",
            "2023-10-30 15:41:52,325 md_at_ma.py[line:120] INFO: Mini batch: 584/1450 | training time in 6 minutes, 22 seconds.\n",
            "2023-10-30 15:41:52,325 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0209 | Train accuracy: 83.84%.\n",
            "2023-10-30 15:41:53,101 max.py[line:93] INFO: max: attack effectiveness 63.38028169014085%.\n",
            "2023-10-30 15:41:53,113 md_at_ma.py[line:120] INFO: Mini batch: 585/1450 | training time in 6 minutes, 22 seconds.\n",
            "2023-10-30 15:41:53,113 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0343 | Train accuracy: 79.90%.\n",
            "2023-10-30 15:41:53,937 max.py[line:93] INFO: max: attack effectiveness 60.526315789473685%.\n",
            "2023-10-30 15:41:53,949 md_at_ma.py[line:120] INFO: Mini batch: 586/1450 | training time in 6 minutes, 23 seconds.\n",
            "2023-10-30 15:41:53,949 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0216 | Train accuracy: 79.41%.\n",
            "2023-10-30 15:41:54,442 max.py[line:93] INFO: max: attack effectiveness 57.377049180327866%.\n",
            "2023-10-30 15:41:54,452 md_at_ma.py[line:120] INFO: Mini batch: 587/1450 | training time in 6 minutes, 24 seconds.\n",
            "2023-10-30 15:41:54,452 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0219 | Train accuracy: 84.66%.\n",
            "2023-10-30 15:41:55,238 max.py[line:93] INFO: max: attack effectiveness 55.072463768115945%.\n",
            "2023-10-30 15:41:55,251 md_at_ma.py[line:120] INFO: Mini batch: 588/1450 | training time in 6 minutes, 25 seconds.\n",
            "2023-10-30 15:41:55,251 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0395 | Train accuracy: 80.20%.\n",
            "2023-10-30 15:41:55,785 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:41:55,794 md_at_ma.py[line:120] INFO: Mini batch: 589/1450 | training time in 6 minutes, 25 seconds.\n",
            "2023-10-30 15:41:55,794 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0190 | Train accuracy: 85.79%.\n",
            "2023-10-30 15:41:56,396 max.py[line:93] INFO: max: attack effectiveness 61.66666666666667%.\n",
            "2023-10-30 15:41:56,405 md_at_ma.py[line:120] INFO: Mini batch: 590/1450 | training time in 6 minutes, 26 seconds.\n",
            "2023-10-30 15:41:56,405 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0346 | Train accuracy: 80.85%.\n",
            "2023-10-30 15:41:56,999 max.py[line:93] INFO: max: attack effectiveness 42.592592592592595%.\n",
            "2023-10-30 15:41:57,009 md_at_ma.py[line:120] INFO: Mini batch: 591/1450 | training time in 6 minutes, 26 seconds.\n",
            "2023-10-30 15:41:57,009 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0177 | Train accuracy: 87.91%.\n",
            "2023-10-30 15:41:57,512 max.py[line:93] INFO: max: attack effectiveness 57.14285714285714%.\n",
            "2023-10-30 15:41:57,521 md_at_ma.py[line:120] INFO: Mini batch: 592/1450 | training time in 6 minutes, 27 seconds.\n",
            "2023-10-30 15:41:57,521 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0284 | Train accuracy: 82.72%.\n",
            "2023-10-30 15:41:58,254 max.py[line:93] INFO: max: attack effectiveness 60.0%.\n",
            "2023-10-30 15:41:58,266 md_at_ma.py[line:120] INFO: Mini batch: 593/1450 | training time in 6 minutes, 27 seconds.\n",
            "2023-10-30 15:41:58,266 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0133 | Train accuracy: 83.94%.\n",
            "2023-10-30 15:41:59,031 max.py[line:93] INFO: max: attack effectiveness 51.515151515151516%.\n",
            "2023-10-30 15:41:59,043 md_at_ma.py[line:120] INFO: Mini batch: 594/1450 | training time in 6 minutes, 28 seconds.\n",
            "2023-10-30 15:41:59,043 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0500 | Train accuracy: 84.54%.\n",
            "2023-10-30 15:41:59,776 max.py[line:93] INFO: max: attack effectiveness 46.15384615384615%.\n",
            "2023-10-30 15:41:59,789 md_at_ma.py[line:120] INFO: Mini batch: 595/1450 | training time in 6 minutes, 29 seconds.\n",
            "2023-10-30 15:41:59,789 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0670 | Train accuracy: 84.46%.\n",
            "2023-10-30 15:42:00,562 max.py[line:93] INFO: max: attack effectiveness 60.56338028169014%.\n",
            "2023-10-30 15:42:00,574 md_at_ma.py[line:120] INFO: Mini batch: 596/1450 | training time in 6 minutes, 30 seconds.\n",
            "2023-10-30 15:42:00,575 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0261 | Train accuracy: 79.40%.\n",
            "2023-10-30 15:42:01,062 max.py[line:93] INFO: max: attack effectiveness 48.4375%.\n",
            "2023-10-30 15:42:01,071 md_at_ma.py[line:120] INFO: Mini batch: 597/1450 | training time in 6 minutes, 30 seconds.\n",
            "2023-10-30 15:42:01,071 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0239 | Train accuracy: 84.90%.\n",
            "2023-10-30 15:42:01,838 max.py[line:93] INFO: max: attack effectiveness 58.2089552238806%.\n",
            "2023-10-30 15:42:01,850 md_at_ma.py[line:120] INFO: Mini batch: 598/1450 | training time in 6 minutes, 31 seconds.\n",
            "2023-10-30 15:42:01,850 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0287 | Train accuracy: 82.05%.\n",
            "2023-10-30 15:42:02,333 max.py[line:93] INFO: max: attack effectiveness 75.0%.\n",
            "2023-10-30 15:42:02,342 md_at_ma.py[line:120] INFO: Mini batch: 599/1450 | training time in 6 minutes, 31 seconds.\n",
            "2023-10-30 15:42:02,343 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0371 | Train accuracy: 76.56%.\n",
            "2023-10-30 15:42:03,160 max.py[line:93] INFO: max: attack effectiveness 68.91891891891892%.\n",
            "2023-10-30 15:42:03,172 md_at_ma.py[line:120] INFO: Mini batch: 600/1450 | training time in 6 minutes, 32 seconds.\n",
            "2023-10-30 15:42:03,172 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0515 | Train accuracy: 75.25%.\n",
            "2023-10-30 15:42:03,947 max.py[line:93] INFO: max: attack effectiveness 69.56521739130434%.\n",
            "2023-10-30 15:42:03,959 md_at_ma.py[line:120] INFO: Mini batch: 601/1450 | training time in 6 minutes, 33 seconds.\n",
            "2023-10-30 15:42:03,959 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0291 | Train accuracy: 77.66%.\n",
            "2023-10-30 15:42:04,782 max.py[line:93] INFO: max: attack effectiveness 69.33333333333334%.\n",
            "2023-10-30 15:42:04,795 md_at_ma.py[line:120] INFO: Mini batch: 602/1450 | training time in 6 minutes, 34 seconds.\n",
            "2023-10-30 15:42:04,795 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0321 | Train accuracy: 75.86%.\n",
            "2023-10-30 15:42:05,562 max.py[line:93] INFO: max: attack effectiveness 57.35294117647059%.\n",
            "2023-10-30 15:42:05,574 md_at_ma.py[line:120] INFO: Mini batch: 603/1450 | training time in 6 minutes, 35 seconds.\n",
            "2023-10-30 15:42:05,575 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0182 | Train accuracy: 82.65%.\n",
            "2023-10-30 15:42:06,162 max.py[line:93] INFO: max: attack effectiveness 59.32203389830508%.\n",
            "2023-10-30 15:42:06,171 md_at_ma.py[line:120] INFO: Mini batch: 604/1450 | training time in 6 minutes, 35 seconds.\n",
            "2023-10-30 15:42:06,171 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0320 | Train accuracy: 81.82%.\n",
            "2023-10-30 15:42:06,992 max.py[line:93] INFO: max: attack effectiveness 62.66666666666667%.\n",
            "2023-10-30 15:42:07,004 md_at_ma.py[line:120] INFO: Mini batch: 605/1450 | training time in 6 minutes, 36 seconds.\n",
            "2023-10-30 15:42:07,005 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0155 | Train accuracy: 79.31%.\n",
            "2023-10-30 15:42:07,785 max.py[line:93] INFO: max: attack effectiveness 79.71014492753623%.\n",
            "2023-10-30 15:42:07,798 md_at_ma.py[line:120] INFO: Mini batch: 606/1450 | training time in 6 minutes, 37 seconds.\n",
            "2023-10-30 15:42:07,798 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0248 | Train accuracy: 76.14%.\n",
            "2023-10-30 15:42:08,290 max.py[line:93] INFO: max: attack effectiveness 64.0625%.\n",
            "2023-10-30 15:42:08,299 md_at_ma.py[line:120] INFO: Mini batch: 607/1450 | training time in 6 minutes, 37 seconds.\n",
            "2023-10-30 15:42:08,299 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0292 | Train accuracy: 83.85%.\n",
            "2023-10-30 15:42:08,787 max.py[line:93] INFO: max: attack effectiveness 69.35483870967742%.\n",
            "2023-10-30 15:42:08,796 md_at_ma.py[line:120] INFO: Mini batch: 608/1450 | training time in 6 minutes, 38 seconds.\n",
            "2023-10-30 15:42:08,796 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0241 | Train accuracy: 79.47%.\n",
            "2023-10-30 15:42:09,186 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:42:09,191 md_at_ma.py[line:120] INFO: Mini batch: 609/1450 | training time in 6 minutes, 38 seconds.\n",
            "2023-10-30 15:42:09,191 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0197 | Train accuracy: 84.21%.\n",
            "2023-10-30 15:42:09,232 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0288 | Train accuracy: 81.66\n",
            "2023-10-30 15:42:11,300 max.py[line:93] INFO: max: attack effectiveness 71.09375%.\n",
            "2023-10-30 15:42:12,304 max.py[line:93] INFO: max: attack effectiveness 67.96875%.\n",
            "2023-10-30 15:42:13,218 max.py[line:93] INFO: max: attack effectiveness 67.96875%.\n",
            "2023-10-30 15:42:14,171 max.py[line:93] INFO: max: attack effectiveness 67.1875%.\n",
            "2023-10-30 15:42:14,751 max.py[line:93] INFO: max: attack effectiveness 78.26086956521739%.\n",
            "2023-10-30 15:42:15,430 md_at_ma.py[line:165] INFO: \tVal accuracy 63.63% with accuracy 30.65% under attack.\n",
            "2023-10-30 15:42:15,430 md_at_ma.py[line:167] INFO: \tModel select at epoch 18 with validation accuracy 65.55% and accuracy 34.41% under attack.\n",
            "2023-10-30 15:42:16,310 max.py[line:93] INFO: max: attack effectiveness 59.09090909090909%.\n",
            "2023-10-30 15:42:16,323 md_at_ma.py[line:120] INFO: Mini batch: 610/1450 | training time in 6 minutes, 39 seconds.\n",
            "2023-10-30 15:42:16,323 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0363 | Train accuracy: 81.44%.\n",
            "2023-10-30 15:42:16,808 max.py[line:93] INFO: max: attack effectiveness 65.07936507936508%.\n",
            "2023-10-30 15:42:16,817 md_at_ma.py[line:120] INFO: Mini batch: 611/1450 | training time in 6 minutes, 39 seconds.\n",
            "2023-10-30 15:42:16,817 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0283 | Train accuracy: 78.53%.\n",
            "2023-10-30 15:42:17,589 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:42:17,602 md_at_ma.py[line:120] INFO: Mini batch: 612/1450 | training time in 6 minutes, 40 seconds.\n",
            "2023-10-30 15:42:17,602 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0226 | Train accuracy: 86.08%.\n",
            "2023-10-30 15:42:18,376 max.py[line:93] INFO: max: attack effectiveness 54.285714285714285%.\n",
            "2023-10-30 15:42:18,388 md_at_ma.py[line:120] INFO: Mini batch: 613/1450 | training time in 6 minutes, 41 seconds.\n",
            "2023-10-30 15:42:18,389 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0193 | Train accuracy: 82.32%.\n",
            "2023-10-30 15:42:19,163 max.py[line:93] INFO: max: attack effectiveness 57.74647887323944%.\n",
            "2023-10-30 15:42:19,175 md_at_ma.py[line:120] INFO: Mini batch: 614/1450 | training time in 6 minutes, 42 seconds.\n",
            "2023-10-30 15:42:19,175 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0314 | Train accuracy: 81.41%.\n",
            "2023-10-30 15:42:20,000 max.py[line:93] INFO: max: attack effectiveness 57.89473684210527%.\n",
            "2023-10-30 15:42:20,012 md_at_ma.py[line:120] INFO: Mini batch: 615/1450 | training time in 6 minutes, 42 seconds.\n",
            "2023-10-30 15:42:20,012 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0211 | Train accuracy: 80.88%.\n",
            "2023-10-30 15:42:20,497 max.py[line:93] INFO: max: attack effectiveness 54.09836065573771%.\n",
            "2023-10-30 15:42:20,506 md_at_ma.py[line:120] INFO: Mini batch: 616/1450 | training time in 6 minutes, 43 seconds.\n",
            "2023-10-30 15:42:20,506 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0234 | Train accuracy: 84.66%.\n",
            "2023-10-30 15:42:21,290 max.py[line:93] INFO: max: attack effectiveness 49.275362318840585%.\n",
            "2023-10-30 15:42:21,303 md_at_ma.py[line:120] INFO: Mini batch: 617/1450 | training time in 6 minutes, 44 seconds.\n",
            "2023-10-30 15:42:21,303 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0278 | Train accuracy: 84.26%.\n",
            "2023-10-30 15:42:21,808 max.py[line:93] INFO: max: attack effectiveness 45.16129032258064%.\n",
            "2023-10-30 15:42:21,817 md_at_ma.py[line:120] INFO: Mini batch: 618/1450 | training time in 6 minutes, 44 seconds.\n",
            "2023-10-30 15:42:21,817 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0192 | Train accuracy: 86.84%.\n",
            "2023-10-30 15:42:22,437 max.py[line:93] INFO: max: attack effectiveness 60.0%.\n",
            "2023-10-30 15:42:22,447 md_at_ma.py[line:120] INFO: Mini batch: 619/1450 | training time in 6 minutes, 45 seconds.\n",
            "2023-10-30 15:42:22,447 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0320 | Train accuracy: 84.04%.\n",
            "2023-10-30 15:42:23,033 max.py[line:93] INFO: max: attack effectiveness 42.592592592592595%.\n",
            "2023-10-30 15:42:23,042 md_at_ma.py[line:120] INFO: Mini batch: 620/1450 | training time in 6 minutes, 45 seconds.\n",
            "2023-10-30 15:42:23,042 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0164 | Train accuracy: 89.01%.\n",
            "2023-10-30 15:42:23,580 max.py[line:93] INFO: max: attack effectiveness 55.55555555555556%.\n",
            "2023-10-30 15:42:23,589 md_at_ma.py[line:120] INFO: Mini batch: 621/1450 | training time in 6 minutes, 46 seconds.\n",
            "2023-10-30 15:42:23,589 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0234 | Train accuracy: 83.25%.\n",
            "2023-10-30 15:42:24,324 max.py[line:93] INFO: max: attack effectiveness 56.92307692307692%.\n",
            "2023-10-30 15:42:24,336 md_at_ma.py[line:120] INFO: Mini batch: 622/1450 | training time in 6 minutes, 47 seconds.\n",
            "2023-10-30 15:42:24,336 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0110 | Train accuracy: 86.01%.\n",
            "2023-10-30 15:42:25,101 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:42:25,113 md_at_ma.py[line:120] INFO: Mini batch: 623/1450 | training time in 6 minutes, 47 seconds.\n",
            "2023-10-30 15:42:25,113 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0376 | Train accuracy: 84.54%.\n",
            "2023-10-30 15:42:25,847 max.py[line:93] INFO: max: attack effectiveness 46.15384615384615%.\n",
            "2023-10-30 15:42:25,859 md_at_ma.py[line:120] INFO: Mini batch: 624/1450 | training time in 6 minutes, 48 seconds.\n",
            "2023-10-30 15:42:25,860 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0876 | Train accuracy: 86.53%.\n",
            "2023-10-30 15:42:26,635 max.py[line:93] INFO: max: attack effectiveness 56.33802816901409%.\n",
            "2023-10-30 15:42:26,647 md_at_ma.py[line:120] INFO: Mini batch: 625/1450 | training time in 6 minutes, 49 seconds.\n",
            "2023-10-30 15:42:26,647 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0231 | Train accuracy: 84.42%.\n",
            "2023-10-30 15:42:27,131 max.py[line:93] INFO: max: attack effectiveness 43.75%.\n",
            "2023-10-30 15:42:27,140 md_at_ma.py[line:120] INFO: Mini batch: 626/1450 | training time in 6 minutes, 49 seconds.\n",
            "2023-10-30 15:42:27,140 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0155 | Train accuracy: 88.02%.\n",
            "2023-10-30 15:42:27,907 max.py[line:93] INFO: max: attack effectiveness 44.776119402985074%.\n",
            "2023-10-30 15:42:27,919 md_at_ma.py[line:120] INFO: Mini batch: 627/1450 | training time in 6 minutes, 50 seconds.\n",
            "2023-10-30 15:42:27,919 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0198 | Train accuracy: 86.67%.\n",
            "2023-10-30 15:42:28,407 max.py[line:93] INFO: max: attack effectiveness 54.6875%.\n",
            "2023-10-30 15:42:28,416 md_at_ma.py[line:120] INFO: Mini batch: 628/1450 | training time in 6 minutes, 51 seconds.\n",
            "2023-10-30 15:42:28,416 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0256 | Train accuracy: 82.29%.\n",
            "2023-10-30 15:42:29,234 max.py[line:93] INFO: max: attack effectiveness 56.75675675675676%.\n",
            "2023-10-30 15:42:29,246 md_at_ma.py[line:120] INFO: Mini batch: 629/1450 | training time in 6 minutes, 51 seconds.\n",
            "2023-10-30 15:42:29,247 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0382 | Train accuracy: 79.70%.\n",
            "2023-10-30 15:42:30,017 max.py[line:93] INFO: max: attack effectiveness 50.72463768115942%.\n",
            "2023-10-30 15:42:30,029 md_at_ma.py[line:120] INFO: Mini batch: 630/1450 | training time in 6 minutes, 52 seconds.\n",
            "2023-10-30 15:42:30,029 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0209 | Train accuracy: 83.25%.\n",
            "2023-10-30 15:42:30,852 max.py[line:93] INFO: max: attack effectiveness 52.0%.\n",
            "2023-10-30 15:42:30,865 md_at_ma.py[line:120] INFO: Mini batch: 631/1450 | training time in 6 minutes, 53 seconds.\n",
            "2023-10-30 15:42:30,865 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0269 | Train accuracy: 81.77%.\n",
            "2023-10-30 15:42:31,643 max.py[line:93] INFO: max: attack effectiveness 48.529411764705884%.\n",
            "2023-10-30 15:42:31,656 md_at_ma.py[line:120] INFO: Mini batch: 632/1450 | training time in 6 minutes, 54 seconds.\n",
            "2023-10-30 15:42:31,656 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0203 | Train accuracy: 83.67%.\n",
            "2023-10-30 15:42:32,244 max.py[line:93] INFO: max: attack effectiveness 57.6271186440678%.\n",
            "2023-10-30 15:42:32,253 md_at_ma.py[line:120] INFO: Mini batch: 633/1450 | training time in 6 minutes, 54 seconds.\n",
            "2023-10-30 15:42:32,253 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0406 | Train accuracy: 82.89%.\n",
            "2023-10-30 15:42:33,076 max.py[line:93] INFO: max: attack effectiveness 57.333333333333336%.\n",
            "2023-10-30 15:42:33,088 md_at_ma.py[line:120] INFO: Mini batch: 634/1450 | training time in 6 minutes, 55 seconds.\n",
            "2023-10-30 15:42:33,088 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0152 | Train accuracy: 80.79%.\n",
            "2023-10-30 15:42:33,867 max.py[line:93] INFO: max: attack effectiveness 56.52173913043478%.\n",
            "2023-10-30 15:42:33,880 md_at_ma.py[line:120] INFO: Mini batch: 635/1450 | training time in 6 minutes, 56 seconds.\n",
            "2023-10-30 15:42:33,880 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0215 | Train accuracy: 81.73%.\n",
            "2023-10-30 15:42:34,371 max.py[line:93] INFO: max: attack effectiveness 42.1875%.\n",
            "2023-10-30 15:42:34,380 md_at_ma.py[line:120] INFO: Mini batch: 636/1450 | training time in 6 minutes, 57 seconds.\n",
            "2023-10-30 15:42:34,380 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0161 | Train accuracy: 88.54%.\n",
            "2023-10-30 15:42:34,869 max.py[line:93] INFO: max: attack effectiveness 45.16129032258064%.\n",
            "2023-10-30 15:42:34,878 md_at_ma.py[line:120] INFO: Mini batch: 637/1450 | training time in 6 minutes, 57 seconds.\n",
            "2023-10-30 15:42:34,879 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0262 | Train accuracy: 85.79%.\n",
            "2023-10-30 15:42:35,273 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:42:35,277 md_at_ma.py[line:120] INFO: Mini batch: 638/1450 | training time in 6 minutes, 57 seconds.\n",
            "2023-10-30 15:42:35,278 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0105 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:42:35,314 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0261 | Train accuracy: 84.10\n",
            "2023-10-30 15:42:37,568 max.py[line:93] INFO: max: attack effectiveness 64.0625%.\n",
            "2023-10-30 15:42:38,472 max.py[line:93] INFO: max: attack effectiveness 64.0625%.\n",
            "2023-10-30 15:42:39,441 max.py[line:93] INFO: max: attack effectiveness 64.0625%.\n",
            "2023-10-30 15:42:40,497 max.py[line:93] INFO: max: attack effectiveness 57.8125%.\n",
            "2023-10-30 15:42:41,139 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:42:41,900 md_at_ma.py[line:165] INFO: \tVal accuracy 66.3% with accuracy 36.38% under attack.\n",
            "2023-10-30 15:42:41,901 md_at_ma.py[line:167] INFO: \tModel select at epoch 22 with validation accuracy 66.3% and accuracy 36.38% under attack.\n",
            "2023-10-30 15:42:42,771 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:42:42,784 md_at_ma.py[line:120] INFO: Mini batch: 639/1450 | training time in 6 minutes, 58 seconds.\n",
            "2023-10-30 15:42:42,784 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0242 | Train accuracy: 85.05%.\n",
            "2023-10-30 15:42:43,267 max.py[line:93] INFO: max: attack effectiveness 57.14285714285714%.\n",
            "2023-10-30 15:42:43,276 md_at_ma.py[line:120] INFO: Mini batch: 640/1450 | training time in 6 minutes, 59 seconds.\n",
            "2023-10-30 15:42:43,276 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0242 | Train accuracy: 82.20%.\n",
            "2023-10-30 15:42:44,042 max.py[line:93] INFO: max: attack effectiveness 48.484848484848484%.\n",
            "2023-10-30 15:42:44,054 md_at_ma.py[line:120] INFO: Mini batch: 641/1450 | training time in 6 minutes, 59 seconds.\n",
            "2023-10-30 15:42:44,055 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0211 | Train accuracy: 84.54%.\n",
            "2023-10-30 15:42:44,833 max.py[line:93] INFO: max: attack effectiveness 55.714285714285715%.\n",
            "2023-10-30 15:42:44,845 md_at_ma.py[line:120] INFO: Mini batch: 642/1450 | training time in 7 minutes, 0 seconds.\n",
            "2023-10-30 15:42:44,845 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0189 | Train accuracy: 81.31%.\n",
            "2023-10-30 15:42:45,629 max.py[line:93] INFO: max: attack effectiveness 56.33802816901409%.\n",
            "2023-10-30 15:42:45,642 md_at_ma.py[line:120] INFO: Mini batch: 643/1450 | training time in 7 minutes, 1 seconds.\n",
            "2023-10-30 15:42:45,642 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0236 | Train accuracy: 81.91%.\n",
            "2023-10-30 15:42:46,467 max.py[line:93] INFO: max: attack effectiveness 56.57894736842105%.\n",
            "2023-10-30 15:42:46,480 md_at_ma.py[line:120] INFO: Mini batch: 644/1450 | training time in 7 minutes, 2 seconds.\n",
            "2023-10-30 15:42:46,480 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0207 | Train accuracy: 80.88%.\n",
            "2023-10-30 15:42:46,966 max.py[line:93] INFO: max: attack effectiveness 54.09836065573771%.\n",
            "2023-10-30 15:42:46,975 md_at_ma.py[line:120] INFO: Mini batch: 645/1450 | training time in 7 minutes, 2 seconds.\n",
            "2023-10-30 15:42:46,976 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0242 | Train accuracy: 84.13%.\n",
            "2023-10-30 15:42:47,753 max.py[line:93] INFO: max: attack effectiveness 53.62318840579711%.\n",
            "2023-10-30 15:42:47,765 md_at_ma.py[line:120] INFO: Mini batch: 646/1450 | training time in 7 minutes, 3 seconds.\n",
            "2023-10-30 15:42:47,765 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0248 | Train accuracy: 82.74%.\n",
            "2023-10-30 15:42:48,262 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:42:48,271 md_at_ma.py[line:120] INFO: Mini batch: 647/1450 | training time in 7 minutes, 4 seconds.\n",
            "2023-10-30 15:42:48,271 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0202 | Train accuracy: 86.32%.\n",
            "2023-10-30 15:42:48,870 max.py[line:93] INFO: max: attack effectiveness 63.33333333333333%.\n",
            "2023-10-30 15:42:48,879 md_at_ma.py[line:120] INFO: Mini batch: 648/1450 | training time in 7 minutes, 4 seconds.\n",
            "2023-10-30 15:42:48,879 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0450 | Train accuracy: 80.32%.\n",
            "2023-10-30 15:42:49,487 max.py[line:93] INFO: max: attack effectiveness 42.592592592592595%.\n",
            "2023-10-30 15:42:49,496 md_at_ma.py[line:120] INFO: Mini batch: 649/1450 | training time in 7 minutes, 5 seconds.\n",
            "2023-10-30 15:42:49,497 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0180 | Train accuracy: 88.46%.\n",
            "2023-10-30 15:42:49,995 max.py[line:93] INFO: max: attack effectiveness 52.38095238095239%.\n",
            "2023-10-30 15:42:50,004 md_at_ma.py[line:120] INFO: Mini batch: 650/1450 | training time in 7 minutes, 5 seconds.\n",
            "2023-10-30 15:42:50,005 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0209 | Train accuracy: 84.29%.\n",
            "2023-10-30 15:42:50,750 max.py[line:93] INFO: max: attack effectiveness 56.92307692307692%.\n",
            "2023-10-30 15:42:50,762 md_at_ma.py[line:120] INFO: Mini batch: 651/1450 | training time in 7 minutes, 6 seconds.\n",
            "2023-10-30 15:42:50,762 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0159 | Train accuracy: 83.42%.\n",
            "2023-10-30 15:42:51,535 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:42:51,548 md_at_ma.py[line:120] INFO: Mini batch: 652/1450 | training time in 7 minutes, 7 seconds.\n",
            "2023-10-30 15:42:51,548 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0268 | Train accuracy: 89.18%.\n",
            "2023-10-30 15:42:52,284 max.py[line:93] INFO: max: attack effectiveness 46.15384615384615%.\n",
            "2023-10-30 15:42:52,296 md_at_ma.py[line:120] INFO: Mini batch: 653/1450 | training time in 7 minutes, 7 seconds.\n",
            "2023-10-30 15:42:52,296 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0352 | Train accuracy: 85.49%.\n",
            "2023-10-30 15:42:53,073 max.py[line:93] INFO: max: attack effectiveness 56.33802816901409%.\n",
            "2023-10-30 15:42:53,085 md_at_ma.py[line:120] INFO: Mini batch: 654/1450 | training time in 7 minutes, 8 seconds.\n",
            "2023-10-30 15:42:53,085 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0170 | Train accuracy: 82.41%.\n",
            "2023-10-30 15:42:53,579 max.py[line:93] INFO: max: attack effectiveness 42.1875%.\n",
            "2023-10-30 15:42:53,588 md_at_ma.py[line:120] INFO: Mini batch: 655/1450 | training time in 7 minutes, 9 seconds.\n",
            "2023-10-30 15:42:53,588 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0175 | Train accuracy: 88.02%.\n",
            "2023-10-30 15:42:54,359 max.py[line:93] INFO: max: attack effectiveness 44.776119402985074%.\n",
            "2023-10-30 15:42:54,371 md_at_ma.py[line:120] INFO: Mini batch: 656/1450 | training time in 7 minutes, 9 seconds.\n",
            "2023-10-30 15:42:54,371 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0146 | Train accuracy: 87.69%.\n",
            "2023-10-30 15:42:54,861 max.py[line:93] INFO: max: attack effectiveness 53.125%.\n",
            "2023-10-30 15:42:54,870 md_at_ma.py[line:120] INFO: Mini batch: 657/1450 | training time in 7 minutes, 10 seconds.\n",
            "2023-10-30 15:42:54,871 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0259 | Train accuracy: 83.85%.\n",
            "2023-10-30 15:42:55,696 max.py[line:93] INFO: max: attack effectiveness 56.75675675675676%.\n",
            "2023-10-30 15:42:55,708 md_at_ma.py[line:120] INFO: Mini batch: 658/1450 | training time in 7 minutes, 11 seconds.\n",
            "2023-10-30 15:42:55,708 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0318 | Train accuracy: 79.21%.\n",
            "2023-10-30 15:42:56,488 max.py[line:93] INFO: max: attack effectiveness 52.17391304347826%.\n",
            "2023-10-30 15:42:56,500 md_at_ma.py[line:120] INFO: Mini batch: 659/1450 | training time in 7 minutes, 12 seconds.\n",
            "2023-10-30 15:42:56,500 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0216 | Train accuracy: 84.26%.\n",
            "2023-10-30 15:42:57,326 max.py[line:93] INFO: max: attack effectiveness 54.666666666666664%.\n",
            "2023-10-30 15:42:57,339 md_at_ma.py[line:120] INFO: Mini batch: 660/1450 | training time in 7 minutes, 12 seconds.\n",
            "2023-10-30 15:42:57,339 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0276 | Train accuracy: 81.28%.\n",
            "2023-10-30 15:42:58,112 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:42:58,124 md_at_ma.py[line:120] INFO: Mini batch: 661/1450 | training time in 7 minutes, 13 seconds.\n",
            "2023-10-30 15:42:58,124 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0218 | Train accuracy: 84.69%.\n",
            "2023-10-30 15:42:58,718 max.py[line:93] INFO: max: attack effectiveness 55.932203389830505%.\n",
            "2023-10-30 15:42:58,727 md_at_ma.py[line:120] INFO: Mini batch: 662/1450 | training time in 7 minutes, 14 seconds.\n",
            "2023-10-30 15:42:58,727 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0293 | Train accuracy: 83.96%.\n",
            "2023-10-30 15:42:59,551 max.py[line:93] INFO: max: attack effectiveness 54.666666666666664%.\n",
            "2023-10-30 15:42:59,564 md_at_ma.py[line:120] INFO: Mini batch: 663/1450 | training time in 7 minutes, 15 seconds.\n",
            "2023-10-30 15:42:59,564 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0135 | Train accuracy: 82.27%.\n",
            "2023-10-30 15:43:00,345 max.py[line:93] INFO: max: attack effectiveness 55.072463768115945%.\n",
            "2023-10-30 15:43:00,358 md_at_ma.py[line:120] INFO: Mini batch: 664/1450 | training time in 7 minutes, 15 seconds.\n",
            "2023-10-30 15:43:00,358 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0216 | Train accuracy: 80.71%.\n",
            "2023-10-30 15:43:00,853 max.py[line:93] INFO: max: attack effectiveness 45.3125%.\n",
            "2023-10-30 15:43:00,862 md_at_ma.py[line:120] INFO: Mini batch: 665/1450 | training time in 7 minutes, 16 seconds.\n",
            "2023-10-30 15:43:00,862 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0157 | Train accuracy: 88.02%.\n",
            "2023-10-30 15:43:01,363 max.py[line:93] INFO: max: attack effectiveness 45.16129032258064%.\n",
            "2023-10-30 15:43:01,373 md_at_ma.py[line:120] INFO: Mini batch: 666/1450 | training time in 7 minutes, 16 seconds.\n",
            "2023-10-30 15:43:01,374 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0135 | Train accuracy: 85.79%.\n",
            "2023-10-30 15:43:01,779 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:43:01,783 md_at_ma.py[line:120] INFO: Mini batch: 667/1450 | training time in 7 minutes, 17 seconds.\n",
            "2023-10-30 15:43:01,783 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0075 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:43:01,828 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0222 | Train accuracy: 84.20\n",
            "2023-10-30 15:43:04,278 max.py[line:93] INFO: max: attack effectiveness 62.5%.\n",
            "2023-10-30 15:43:05,378 max.py[line:93] INFO: max: attack effectiveness 62.5%.\n",
            "2023-10-30 15:43:06,330 max.py[line:93] INFO: max: attack effectiveness 61.71875%.\n",
            "2023-10-30 15:43:07,376 max.py[line:93] INFO: max: attack effectiveness 57.03125%.\n",
            "2023-10-30 15:43:08,143 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:43:08,918 md_at_ma.py[line:165] INFO: \tVal accuracy 67.13% with accuracy 37.81% under attack.\n",
            "2023-10-30 15:43:08,918 md_at_ma.py[line:167] INFO: \tModel select at epoch 23 with validation accuracy 67.13% and accuracy 37.81% under attack.\n",
            "2023-10-30 15:43:09,801 max.py[line:93] INFO: max: attack effectiveness 48.484848484848484%.\n",
            "2023-10-30 15:43:09,814 md_at_ma.py[line:120] INFO: Mini batch: 668/1450 | training time in 7 minutes, 18 seconds.\n",
            "2023-10-30 15:43:09,815 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0186 | Train accuracy: 86.08%.\n",
            "2023-10-30 15:43:10,300 max.py[line:93] INFO: max: attack effectiveness 55.55555555555556%.\n",
            "2023-10-30 15:43:10,309 md_at_ma.py[line:120] INFO: Mini batch: 669/1450 | training time in 7 minutes, 18 seconds.\n",
            "2023-10-30 15:43:10,310 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0196 | Train accuracy: 83.25%.\n",
            "2023-10-30 15:43:11,084 max.py[line:93] INFO: max: attack effectiveness 46.96969696969697%.\n",
            "2023-10-30 15:43:11,096 md_at_ma.py[line:120] INFO: Mini batch: 670/1450 | training time in 7 minutes, 19 seconds.\n",
            "2023-10-30 15:43:11,096 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0215 | Train accuracy: 87.63%.\n",
            "2023-10-30 15:43:11,871 max.py[line:93] INFO: max: attack effectiveness 51.42857142857142%.\n",
            "2023-10-30 15:43:11,883 md_at_ma.py[line:120] INFO: Mini batch: 671/1450 | training time in 7 minutes, 20 seconds.\n",
            "2023-10-30 15:43:11,884 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0165 | Train accuracy: 84.34%.\n",
            "2023-10-30 15:43:12,661 max.py[line:93] INFO: max: attack effectiveness 53.52112676056338%.\n",
            "2023-10-30 15:43:12,673 md_at_ma.py[line:120] INFO: Mini batch: 672/1450 | training time in 7 minutes, 20 seconds.\n",
            "2023-10-30 15:43:12,673 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0244 | Train accuracy: 83.42%.\n",
            "2023-10-30 15:43:13,497 max.py[line:93] INFO: max: attack effectiveness 53.94736842105263%.\n",
            "2023-10-30 15:43:13,509 md_at_ma.py[line:120] INFO: Mini batch: 673/1450 | training time in 7 minutes, 21 seconds.\n",
            "2023-10-30 15:43:13,509 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0202 | Train accuracy: 84.31%.\n",
            "2023-10-30 15:43:13,997 max.py[line:93] INFO: max: attack effectiveness 50.81967213114754%.\n",
            "2023-10-30 15:43:14,006 md_at_ma.py[line:120] INFO: Mini batch: 674/1450 | training time in 7 minutes, 22 seconds.\n",
            "2023-10-30 15:43:14,006 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0181 | Train accuracy: 86.24%.\n",
            "2023-10-30 15:43:14,783 max.py[line:93] INFO: max: attack effectiveness 49.275362318840585%.\n",
            "2023-10-30 15:43:14,796 md_at_ma.py[line:120] INFO: Mini batch: 675/1450 | training time in 7 minutes, 22 seconds.\n",
            "2023-10-30 15:43:14,796 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0295 | Train accuracy: 84.77%.\n",
            "2023-10-30 15:43:15,283 max.py[line:93] INFO: max: attack effectiveness 46.774193548387096%.\n",
            "2023-10-30 15:43:15,292 md_at_ma.py[line:120] INFO: Mini batch: 676/1450 | training time in 7 minutes, 23 seconds.\n",
            "2023-10-30 15:43:15,292 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0245 | Train accuracy: 85.26%.\n",
            "2023-10-30 15:43:15,915 max.py[line:93] INFO: max: attack effectiveness 60.0%.\n",
            "2023-10-30 15:43:15,924 md_at_ma.py[line:120] INFO: Mini batch: 677/1450 | training time in 7 minutes, 23 seconds.\n",
            "2023-10-30 15:43:15,924 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0371 | Train accuracy: 81.38%.\n",
            "2023-10-30 15:43:16,502 max.py[line:93] INFO: max: attack effectiveness 44.44444444444444%.\n",
            "2023-10-30 15:43:16,511 md_at_ma.py[line:120] INFO: Mini batch: 678/1450 | training time in 7 minutes, 24 seconds.\n",
            "2023-10-30 15:43:16,511 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0204 | Train accuracy: 87.36%.\n",
            "2023-10-30 15:43:17,031 max.py[line:93] INFO: max: attack effectiveness 57.14285714285714%.\n",
            "2023-10-30 15:43:17,040 md_at_ma.py[line:120] INFO: Mini batch: 679/1450 | training time in 7 minutes, 25 seconds.\n",
            "2023-10-30 15:43:17,040 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0319 | Train accuracy: 82.72%.\n",
            "2023-10-30 15:43:17,773 max.py[line:93] INFO: max: attack effectiveness 60.0%.\n",
            "2023-10-30 15:43:17,785 md_at_ma.py[line:120] INFO: Mini batch: 680/1450 | training time in 7 minutes, 25 seconds.\n",
            "2023-10-30 15:43:17,786 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0144 | Train accuracy: 82.38%.\n",
            "2023-10-30 15:43:18,552 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:43:18,565 md_at_ma.py[line:120] INFO: Mini batch: 681/1450 | training time in 7 minutes, 26 seconds.\n",
            "2023-10-30 15:43:18,565 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0431 | Train accuracy: 83.51%.\n",
            "2023-10-30 15:43:19,297 max.py[line:93] INFO: max: attack effectiveness 44.61538461538462%.\n",
            "2023-10-30 15:43:19,309 md_at_ma.py[line:120] INFO: Mini batch: 682/1450 | training time in 7 minutes, 27 seconds.\n",
            "2023-10-30 15:43:19,309 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0413 | Train accuracy: 85.49%.\n",
            "2023-10-30 15:43:20,085 max.py[line:93] INFO: max: attack effectiveness 56.33802816901409%.\n",
            "2023-10-30 15:43:20,097 md_at_ma.py[line:120] INFO: Mini batch: 683/1450 | training time in 7 minutes, 28 seconds.\n",
            "2023-10-30 15:43:20,097 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0129 | Train accuracy: 81.91%.\n",
            "2023-10-30 15:43:20,583 max.py[line:93] INFO: max: attack effectiveness 43.75%.\n",
            "2023-10-30 15:43:20,592 md_at_ma.py[line:120] INFO: Mini batch: 684/1450 | training time in 7 minutes, 28 seconds.\n",
            "2023-10-30 15:43:20,592 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0163 | Train accuracy: 88.02%.\n",
            "2023-10-30 15:43:21,359 max.py[line:93] INFO: max: attack effectiveness 47.76119402985074%.\n",
            "2023-10-30 15:43:21,371 md_at_ma.py[line:120] INFO: Mini batch: 685/1450 | training time in 7 minutes, 29 seconds.\n",
            "2023-10-30 15:43:21,371 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0186 | Train accuracy: 85.13%.\n",
            "2023-10-30 15:43:21,856 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:43:21,865 md_at_ma.py[line:120] INFO: Mini batch: 686/1450 | training time in 7 minutes, 29 seconds.\n",
            "2023-10-30 15:43:21,865 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0203 | Train accuracy: 84.90%.\n",
            "2023-10-30 15:43:22,683 max.py[line:93] INFO: max: attack effectiveness 54.054054054054056%.\n",
            "2023-10-30 15:43:22,695 md_at_ma.py[line:120] INFO: Mini batch: 687/1450 | training time in 7 minutes, 30 seconds.\n",
            "2023-10-30 15:43:22,696 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0300 | Train accuracy: 80.69%.\n",
            "2023-10-30 15:43:23,466 max.py[line:93] INFO: max: attack effectiveness 46.3768115942029%.\n",
            "2023-10-30 15:43:23,478 md_at_ma.py[line:120] INFO: Mini batch: 688/1450 | training time in 7 minutes, 31 seconds.\n",
            "2023-10-30 15:43:23,478 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0148 | Train accuracy: 84.77%.\n",
            "2023-10-30 15:43:24,299 max.py[line:93] INFO: max: attack effectiveness 52.0%.\n",
            "2023-10-30 15:43:24,312 md_at_ma.py[line:120] INFO: Mini batch: 689/1450 | training time in 7 minutes, 32 seconds.\n",
            "2023-10-30 15:43:24,312 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0251 | Train accuracy: 81.28%.\n",
            "2023-10-30 15:43:25,082 max.py[line:93] INFO: max: attack effectiveness 48.529411764705884%.\n",
            "2023-10-30 15:43:25,094 md_at_ma.py[line:120] INFO: Mini batch: 690/1450 | training time in 7 minutes, 32 seconds.\n",
            "2023-10-30 15:43:25,094 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0195 | Train accuracy: 84.18%.\n",
            "2023-10-30 15:43:25,681 max.py[line:93] INFO: max: attack effectiveness 50.847457627118644%.\n",
            "2023-10-30 15:43:25,690 md_at_ma.py[line:120] INFO: Mini batch: 691/1450 | training time in 7 minutes, 33 seconds.\n",
            "2023-10-30 15:43:25,690 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0343 | Train accuracy: 83.96%.\n",
            "2023-10-30 15:43:26,511 max.py[line:93] INFO: max: attack effectiveness 54.666666666666664%.\n",
            "2023-10-30 15:43:26,523 md_at_ma.py[line:120] INFO: Mini batch: 692/1450 | training time in 7 minutes, 34 seconds.\n",
            "2023-10-30 15:43:26,523 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0139 | Train accuracy: 80.79%.\n",
            "2023-10-30 15:43:27,313 max.py[line:93] INFO: max: attack effectiveness 53.62318840579711%.\n",
            "2023-10-30 15:43:27,325 md_at_ma.py[line:120] INFO: Mini batch: 693/1450 | training time in 7 minutes, 35 seconds.\n",
            "2023-10-30 15:43:27,326 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0159 | Train accuracy: 83.76%.\n",
            "2023-10-30 15:43:27,826 max.py[line:93] INFO: max: attack effectiveness 42.1875%.\n",
            "2023-10-30 15:43:27,835 md_at_ma.py[line:120] INFO: Mini batch: 694/1450 | training time in 7 minutes, 35 seconds.\n",
            "2023-10-30 15:43:27,835 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0232 | Train accuracy: 88.02%.\n",
            "2023-10-30 15:43:28,327 max.py[line:93] INFO: max: attack effectiveness 43.54838709677419%.\n",
            "2023-10-30 15:43:28,336 md_at_ma.py[line:120] INFO: Mini batch: 695/1450 | training time in 7 minutes, 36 seconds.\n",
            "2023-10-30 15:43:28,336 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0116 | Train accuracy: 88.42%.\n",
            "2023-10-30 15:43:28,731 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:43:28,736 md_at_ma.py[line:120] INFO: Mini batch: 696/1450 | training time in 7 minutes, 36 seconds.\n",
            "2023-10-30 15:43:28,736 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0063 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:43:28,768 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0222 | Train accuracy: 84.60\n",
            "2023-10-30 15:43:30,820 max.py[line:93] INFO: max: attack effectiveness 63.28125%.\n",
            "2023-10-30 15:43:31,884 max.py[line:93] INFO: max: attack effectiveness 62.5%.\n",
            "2023-10-30 15:43:32,755 max.py[line:93] INFO: max: attack effectiveness 63.28125%.\n",
            "2023-10-30 15:43:33,645 max.py[line:93] INFO: max: attack effectiveness 56.25%.\n",
            "2023-10-30 15:43:34,335 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:43:34,905 md_at_ma.py[line:165] INFO: \tVal accuracy 67.07% with accuracy 37.46% under attack.\n",
            "2023-10-30 15:43:34,906 md_at_ma.py[line:167] INFO: \tModel select at epoch 23 with validation accuracy 67.13% and accuracy 37.81% under attack.\n",
            "2023-10-30 15:43:35,790 max.py[line:93] INFO: max: attack effectiveness 45.45454545454545%.\n",
            "2023-10-30 15:43:35,803 md_at_ma.py[line:120] INFO: Mini batch: 697/1450 | training time in 7 minutes, 37 seconds.\n",
            "2023-10-30 15:43:35,803 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0270 | Train accuracy: 86.08%.\n",
            "2023-10-30 15:43:36,286 max.py[line:93] INFO: max: attack effectiveness 55.55555555555556%.\n",
            "2023-10-30 15:43:36,295 md_at_ma.py[line:120] INFO: Mini batch: 698/1450 | training time in 7 minutes, 37 seconds.\n",
            "2023-10-30 15:43:36,295 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0189 | Train accuracy: 85.34%.\n",
            "2023-10-30 15:43:37,062 max.py[line:93] INFO: max: attack effectiveness 45.45454545454545%.\n",
            "2023-10-30 15:43:37,074 md_at_ma.py[line:120] INFO: Mini batch: 699/1450 | training time in 7 minutes, 38 seconds.\n",
            "2023-10-30 15:43:37,074 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0150 | Train accuracy: 85.05%.\n",
            "2023-10-30 15:43:37,852 max.py[line:93] INFO: max: attack effectiveness 51.42857142857142%.\n",
            "2023-10-30 15:43:37,864 md_at_ma.py[line:120] INFO: Mini batch: 700/1450 | training time in 7 minutes, 39 seconds.\n",
            "2023-10-30 15:43:37,864 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0138 | Train accuracy: 84.85%.\n",
            "2023-10-30 15:43:38,641 max.py[line:93] INFO: max: attack effectiveness 53.52112676056338%.\n",
            "2023-10-30 15:43:38,653 md_at_ma.py[line:120] INFO: Mini batch: 701/1450 | training time in 7 minutes, 40 seconds.\n",
            "2023-10-30 15:43:38,653 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0188 | Train accuracy: 82.41%.\n",
            "2023-10-30 15:43:39,485 max.py[line:93] INFO: max: attack effectiveness 51.31578947368421%.\n",
            "2023-10-30 15:43:39,497 md_at_ma.py[line:120] INFO: Mini batch: 702/1450 | training time in 7 minutes, 40 seconds.\n",
            "2023-10-30 15:43:39,497 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0156 | Train accuracy: 84.80%.\n",
            "2023-10-30 15:43:39,989 max.py[line:93] INFO: max: attack effectiveness 47.540983606557376%.\n",
            "2023-10-30 15:43:39,998 md_at_ma.py[line:120] INFO: Mini batch: 703/1450 | training time in 7 minutes, 41 seconds.\n",
            "2023-10-30 15:43:39,998 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0234 | Train accuracy: 85.71%.\n",
            "2023-10-30 15:43:40,804 max.py[line:93] INFO: max: attack effectiveness 47.82608695652174%.\n",
            "2023-10-30 15:43:40,817 md_at_ma.py[line:120] INFO: Mini batch: 704/1450 | training time in 7 minutes, 42 seconds.\n",
            "2023-10-30 15:43:40,817 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0243 | Train accuracy: 85.79%.\n",
            "2023-10-30 15:43:41,305 max.py[line:93] INFO: max: attack effectiveness 38.70967741935484%.\n",
            "2023-10-30 15:43:41,314 md_at_ma.py[line:120] INFO: Mini batch: 705/1450 | training time in 7 minutes, 42 seconds.\n",
            "2023-10-30 15:43:41,314 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0183 | Train accuracy: 87.89%.\n",
            "2023-10-30 15:43:41,906 max.py[line:93] INFO: max: attack effectiveness 55.00000000000001%.\n",
            "2023-10-30 15:43:41,915 md_at_ma.py[line:120] INFO: Mini batch: 706/1450 | training time in 7 minutes, 43 seconds.\n",
            "2023-10-30 15:43:41,915 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0339 | Train accuracy: 83.51%.\n",
            "2023-10-30 15:43:42,518 max.py[line:93] INFO: max: attack effectiveness 42.592592592592595%.\n",
            "2023-10-30 15:43:42,527 md_at_ma.py[line:120] INFO: Mini batch: 707/1450 | training time in 7 minutes, 43 seconds.\n",
            "2023-10-30 15:43:42,527 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0162 | Train accuracy: 90.66%.\n",
            "2023-10-30 15:43:43,009 max.py[line:93] INFO: max: attack effectiveness 53.96825396825397%.\n",
            "2023-10-30 15:43:43,018 md_at_ma.py[line:120] INFO: Mini batch: 708/1450 | training time in 7 minutes, 44 seconds.\n",
            "2023-10-30 15:43:43,019 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0269 | Train accuracy: 83.25%.\n",
            "2023-10-30 15:43:43,753 max.py[line:93] INFO: max: attack effectiveness 55.38461538461539%.\n",
            "2023-10-30 15:43:43,765 md_at_ma.py[line:120] INFO: Mini batch: 709/1450 | training time in 7 minutes, 45 seconds.\n",
            "2023-10-30 15:43:43,765 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0161 | Train accuracy: 84.97%.\n",
            "2023-10-30 15:43:44,533 max.py[line:93] INFO: max: attack effectiveness 48.484848484848484%.\n",
            "2023-10-30 15:43:44,545 md_at_ma.py[line:120] INFO: Mini batch: 710/1450 | training time in 7 minutes, 45 seconds.\n",
            "2023-10-30 15:43:44,545 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0404 | Train accuracy: 84.02%.\n",
            "2023-10-30 15:43:45,279 max.py[line:93] INFO: max: attack effectiveness 43.07692307692308%.\n",
            "2023-10-30 15:43:45,291 md_at_ma.py[line:120] INFO: Mini batch: 711/1450 | training time in 7 minutes, 46 seconds.\n",
            "2023-10-30 15:43:45,291 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0783 | Train accuracy: 86.53%.\n",
            "2023-10-30 15:43:46,067 max.py[line:93] INFO: max: attack effectiveness 56.33802816901409%.\n",
            "2023-10-30 15:43:46,079 md_at_ma.py[line:120] INFO: Mini batch: 712/1450 | training time in 7 minutes, 47 seconds.\n",
            "2023-10-30 15:43:46,079 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0284 | Train accuracy: 83.92%.\n",
            "2023-10-30 15:43:46,570 max.py[line:93] INFO: max: attack effectiveness 42.1875%.\n",
            "2023-10-30 15:43:46,579 md_at_ma.py[line:120] INFO: Mini batch: 713/1450 | training time in 7 minutes, 47 seconds.\n",
            "2023-10-30 15:43:46,579 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0210 | Train accuracy: 88.02%.\n",
            "2023-10-30 15:43:47,345 max.py[line:93] INFO: max: attack effectiveness 44.776119402985074%.\n",
            "2023-10-30 15:43:47,358 md_at_ma.py[line:120] INFO: Mini batch: 714/1450 | training time in 7 minutes, 48 seconds.\n",
            "2023-10-30 15:43:47,358 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0242 | Train accuracy: 84.62%.\n",
            "2023-10-30 15:43:47,852 max.py[line:93] INFO: max: attack effectiveness 51.5625%.\n",
            "2023-10-30 15:43:47,861 md_at_ma.py[line:120] INFO: Mini batch: 715/1450 | training time in 7 minutes, 49 seconds.\n",
            "2023-10-30 15:43:47,861 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0367 | Train accuracy: 83.85%.\n",
            "2023-10-30 15:43:48,679 max.py[line:93] INFO: max: attack effectiveness 60.810810810810814%.\n",
            "2023-10-30 15:43:48,691 md_at_ma.py[line:120] INFO: Mini batch: 716/1450 | training time in 7 minutes, 49 seconds.\n",
            "2023-10-30 15:43:48,691 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0439 | Train accuracy: 78.22%.\n",
            "2023-10-30 15:43:49,459 max.py[line:93] INFO: max: attack effectiveness 56.52173913043478%.\n",
            "2023-10-30 15:43:49,471 md_at_ma.py[line:120] INFO: Mini batch: 717/1450 | training time in 7 minutes, 50 seconds.\n",
            "2023-10-30 15:43:49,471 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0253 | Train accuracy: 79.19%.\n",
            "2023-10-30 15:43:50,292 max.py[line:93] INFO: max: attack effectiveness 66.66666666666666%.\n",
            "2023-10-30 15:43:50,305 md_at_ma.py[line:120] INFO: Mini batch: 718/1450 | training time in 7 minutes, 51 seconds.\n",
            "2023-10-30 15:43:50,305 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0287 | Train accuracy: 74.88%.\n",
            "2023-10-30 15:43:51,074 max.py[line:93] INFO: max: attack effectiveness 61.76470588235294%.\n",
            "2023-10-30 15:43:51,086 md_at_ma.py[line:120] INFO: Mini batch: 719/1450 | training time in 7 minutes, 52 seconds.\n",
            "2023-10-30 15:43:51,086 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0222 | Train accuracy: 79.08%.\n",
            "2023-10-30 15:43:51,676 max.py[line:93] INFO: max: attack effectiveness 57.6271186440678%.\n",
            "2023-10-30 15:43:51,685 md_at_ma.py[line:120] INFO: Mini batch: 720/1450 | training time in 7 minutes, 52 seconds.\n",
            "2023-10-30 15:43:51,685 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0309 | Train accuracy: 80.75%.\n",
            "2023-10-30 15:43:52,506 max.py[line:93] INFO: max: attack effectiveness 57.333333333333336%.\n",
            "2023-10-30 15:43:52,518 md_at_ma.py[line:120] INFO: Mini batch: 721/1450 | training time in 7 minutes, 53 seconds.\n",
            "2023-10-30 15:43:52,519 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0164 | Train accuracy: 77.34%.\n",
            "2023-10-30 15:43:53,293 max.py[line:93] INFO: max: attack effectiveness 60.86956521739131%.\n",
            "2023-10-30 15:43:53,306 md_at_ma.py[line:120] INFO: Mini batch: 722/1450 | training time in 7 minutes, 54 seconds.\n",
            "2023-10-30 15:43:53,306 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0196 | Train accuracy: 81.22%.\n",
            "2023-10-30 15:43:53,806 max.py[line:93] INFO: max: attack effectiveness 45.3125%.\n",
            "2023-10-30 15:43:53,815 md_at_ma.py[line:120] INFO: Mini batch: 723/1450 | training time in 7 minutes, 54 seconds.\n",
            "2023-10-30 15:43:53,815 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0156 | Train accuracy: 84.90%.\n",
            "2023-10-30 15:43:54,303 max.py[line:93] INFO: max: attack effectiveness 45.16129032258064%.\n",
            "2023-10-30 15:43:54,312 md_at_ma.py[line:120] INFO: Mini batch: 724/1450 | training time in 7 minutes, 55 seconds.\n",
            "2023-10-30 15:43:54,313 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0123 | Train accuracy: 88.42%.\n",
            "2023-10-30 15:43:54,714 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:43:54,718 md_at_ma.py[line:120] INFO: Mini batch: 725/1450 | training time in 7 minutes, 55 seconds.\n",
            "2023-10-30 15:43:54,720 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0069 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:43:54,773 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0248 | Train accuracy: 83.96\n",
            "2023-10-30 15:43:56,861 max.py[line:93] INFO: max: attack effectiveness 63.28125%.\n",
            "2023-10-30 15:43:57,900 max.py[line:93] INFO: max: attack effectiveness 62.5%.\n",
            "2023-10-30 15:43:58,807 max.py[line:93] INFO: max: attack effectiveness 60.9375%.\n",
            "2023-10-30 15:43:59,693 max.py[line:93] INFO: max: attack effectiveness 57.8125%.\n",
            "2023-10-30 15:44:00,300 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:44:01,009 md_at_ma.py[line:165] INFO: \tVal accuracy 67.0% with accuracy 37.63% under attack.\n",
            "2023-10-30 15:44:01,009 md_at_ma.py[line:167] INFO: \tModel select at epoch 23 with validation accuracy 67.13% and accuracy 37.81% under attack.\n",
            "2023-10-30 15:44:01,893 max.py[line:93] INFO: max: attack effectiveness 48.484848484848484%.\n",
            "2023-10-30 15:44:01,906 md_at_ma.py[line:120] INFO: Mini batch: 726/1450 | training time in 7 minutes, 56 seconds.\n",
            "2023-10-30 15:44:01,906 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0274 | Train accuracy: 86.08%.\n",
            "2023-10-30 15:44:02,386 max.py[line:93] INFO: max: attack effectiveness 55.55555555555556%.\n",
            "2023-10-30 15:44:02,395 md_at_ma.py[line:120] INFO: Mini batch: 727/1450 | training time in 7 minutes, 56 seconds.\n",
            "2023-10-30 15:44:02,395 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0190 | Train accuracy: 83.77%.\n",
            "2023-10-30 15:44:03,162 max.py[line:93] INFO: max: attack effectiveness 45.45454545454545%.\n",
            "2023-10-30 15:44:03,174 md_at_ma.py[line:120] INFO: Mini batch: 728/1450 | training time in 7 minutes, 57 seconds.\n",
            "2023-10-30 15:44:03,174 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0149 | Train accuracy: 87.11%.\n",
            "2023-10-30 15:44:03,955 max.py[line:93] INFO: max: attack effectiveness 51.42857142857142%.\n",
            "2023-10-30 15:44:03,967 md_at_ma.py[line:120] INFO: Mini batch: 729/1450 | training time in 7 minutes, 58 seconds.\n",
            "2023-10-30 15:44:03,967 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0144 | Train accuracy: 85.35%.\n",
            "2023-10-30 15:44:04,742 max.py[line:93] INFO: max: attack effectiveness 54.929577464788736%.\n",
            "2023-10-30 15:44:04,754 md_at_ma.py[line:120] INFO: Mini batch: 730/1450 | training time in 7 minutes, 59 seconds.\n",
            "2023-10-30 15:44:04,754 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0219 | Train accuracy: 82.91%.\n",
            "2023-10-30 15:44:05,585 max.py[line:93] INFO: max: attack effectiveness 55.26315789473685%.\n",
            "2023-10-30 15:44:05,598 md_at_ma.py[line:120] INFO: Mini batch: 731/1450 | training time in 8 minutes, 0 seconds.\n",
            "2023-10-30 15:44:05,598 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0238 | Train accuracy: 79.41%.\n",
            "2023-10-30 15:44:06,104 max.py[line:93] INFO: max: attack effectiveness 47.540983606557376%.\n",
            "2023-10-30 15:44:06,113 md_at_ma.py[line:120] INFO: Mini batch: 732/1450 | training time in 8 minutes, 0 seconds.\n",
            "2023-10-30 15:44:06,114 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0185 | Train accuracy: 86.24%.\n",
            "2023-10-30 15:44:06,892 max.py[line:93] INFO: max: attack effectiveness 44.927536231884055%.\n",
            "2023-10-30 15:44:06,905 md_at_ma.py[line:120] INFO: Mini batch: 733/1450 | training time in 8 minutes, 1 seconds.\n",
            "2023-10-30 15:44:06,905 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0238 | Train accuracy: 85.28%.\n",
            "2023-10-30 15:44:07,427 max.py[line:93] INFO: max: attack effectiveness 38.70967741935484%.\n",
            "2023-10-30 15:44:07,436 md_at_ma.py[line:120] INFO: Mini batch: 734/1450 | training time in 8 minutes, 1 seconds.\n",
            "2023-10-30 15:44:07,436 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0173 | Train accuracy: 87.89%.\n",
            "2023-10-30 15:44:08,058 max.py[line:93] INFO: max: attack effectiveness 55.00000000000001%.\n",
            "2023-10-30 15:44:08,067 md_at_ma.py[line:120] INFO: Mini batch: 735/1450 | training time in 8 minutes, 2 seconds.\n",
            "2023-10-30 15:44:08,067 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0369 | Train accuracy: 82.98%.\n",
            "2023-10-30 15:44:08,679 max.py[line:93] INFO: max: attack effectiveness 38.88888888888889%.\n",
            "2023-10-30 15:44:08,688 md_at_ma.py[line:120] INFO: Mini batch: 736/1450 | training time in 8 minutes, 3 seconds.\n",
            "2023-10-30 15:44:08,688 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0145 | Train accuracy: 89.01%.\n",
            "2023-10-30 15:44:09,172 max.py[line:93] INFO: max: attack effectiveness 52.38095238095239%.\n",
            "2023-10-30 15:44:09,180 md_at_ma.py[line:120] INFO: Mini batch: 737/1450 | training time in 8 minutes, 3 seconds.\n",
            "2023-10-30 15:44:09,181 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0216 | Train accuracy: 84.29%.\n",
            "2023-10-30 15:44:09,917 max.py[line:93] INFO: max: attack effectiveness 53.84615384615385%.\n",
            "2023-10-30 15:44:09,929 md_at_ma.py[line:120] INFO: Mini batch: 738/1450 | training time in 8 minutes, 4 seconds.\n",
            "2023-10-30 15:44:09,929 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0106 | Train accuracy: 87.05%.\n",
            "2023-10-30 15:44:10,695 max.py[line:93] INFO: max: attack effectiveness 48.484848484848484%.\n",
            "2023-10-30 15:44:10,707 md_at_ma.py[line:120] INFO: Mini batch: 739/1450 | training time in 8 minutes, 5 seconds.\n",
            "2023-10-30 15:44:10,708 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0426 | Train accuracy: 87.63%.\n",
            "2023-10-30 15:44:11,443 max.py[line:93] INFO: max: attack effectiveness 41.53846153846154%.\n",
            "2023-10-30 15:44:11,455 md_at_ma.py[line:120] INFO: Mini batch: 740/1450 | training time in 8 minutes, 5 seconds.\n",
            "2023-10-30 15:44:11,455 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0713 | Train accuracy: 86.01%.\n",
            "2023-10-30 15:44:12,233 max.py[line:93] INFO: max: attack effectiveness 54.929577464788736%.\n",
            "2023-10-30 15:44:12,246 md_at_ma.py[line:120] INFO: Mini batch: 741/1450 | training time in 8 minutes, 6 seconds.\n",
            "2023-10-30 15:44:12,246 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0196 | Train accuracy: 83.92%.\n",
            "2023-10-30 15:44:12,731 max.py[line:93] INFO: max: attack effectiveness 42.1875%.\n",
            "2023-10-30 15:44:12,740 md_at_ma.py[line:120] INFO: Mini batch: 742/1450 | training time in 8 minutes, 7 seconds.\n",
            "2023-10-30 15:44:12,740 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0170 | Train accuracy: 87.50%.\n",
            "2023-10-30 15:44:13,507 max.py[line:93] INFO: max: attack effectiveness 44.776119402985074%.\n",
            "2023-10-30 15:44:13,519 md_at_ma.py[line:120] INFO: Mini batch: 743/1450 | training time in 8 minutes, 7 seconds.\n",
            "2023-10-30 15:44:13,520 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0209 | Train accuracy: 86.67%.\n",
            "2023-10-30 15:44:14,006 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:44:14,015 md_at_ma.py[line:120] INFO: Mini batch: 744/1450 | training time in 8 minutes, 8 seconds.\n",
            "2023-10-30 15:44:14,015 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0197 | Train accuracy: 85.94%.\n",
            "2023-10-30 15:44:14,834 max.py[line:93] INFO: max: attack effectiveness 55.4054054054054%.\n",
            "2023-10-30 15:44:14,846 md_at_ma.py[line:120] INFO: Mini batch: 745/1450 | training time in 8 minutes, 9 seconds.\n",
            "2023-10-30 15:44:14,846 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0285 | Train accuracy: 81.68%.\n",
            "2023-10-30 15:44:15,619 max.py[line:93] INFO: max: attack effectiveness 47.82608695652174%.\n",
            "2023-10-30 15:44:15,631 md_at_ma.py[line:120] INFO: Mini batch: 746/1450 | training time in 8 minutes, 9 seconds.\n",
            "2023-10-30 15:44:15,632 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0141 | Train accuracy: 83.76%.\n",
            "2023-10-30 15:44:16,456 max.py[line:93] INFO: max: attack effectiveness 52.0%.\n",
            "2023-10-30 15:44:16,468 md_at_ma.py[line:120] INFO: Mini batch: 747/1450 | training time in 8 minutes, 10 seconds.\n",
            "2023-10-30 15:44:16,468 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0188 | Train accuracy: 82.76%.\n",
            "2023-10-30 15:44:17,236 max.py[line:93] INFO: max: attack effectiveness 48.529411764705884%.\n",
            "2023-10-30 15:44:17,248 md_at_ma.py[line:120] INFO: Mini batch: 748/1450 | training time in 8 minutes, 11 seconds.\n",
            "2023-10-30 15:44:17,249 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0145 | Train accuracy: 84.18%.\n",
            "2023-10-30 15:44:17,838 max.py[line:93] INFO: max: attack effectiveness 52.54237288135594%.\n",
            "2023-10-30 15:44:17,848 md_at_ma.py[line:120] INFO: Mini batch: 749/1450 | training time in 8 minutes, 12 seconds.\n",
            "2023-10-30 15:44:17,848 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0306 | Train accuracy: 83.96%.\n",
            "2023-10-30 15:44:18,671 max.py[line:93] INFO: max: attack effectiveness 50.66666666666667%.\n",
            "2023-10-30 15:44:18,683 md_at_ma.py[line:120] INFO: Mini batch: 750/1450 | training time in 8 minutes, 12 seconds.\n",
            "2023-10-30 15:44:18,683 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0123 | Train accuracy: 81.28%.\n",
            "2023-10-30 15:44:19,469 max.py[line:93] INFO: max: attack effectiveness 55.072463768115945%.\n",
            "2023-10-30 15:44:19,481 md_at_ma.py[line:120] INFO: Mini batch: 751/1450 | training time in 8 minutes, 13 seconds.\n",
            "2023-10-30 15:44:19,481 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0167 | Train accuracy: 83.25%.\n",
            "2023-10-30 15:44:19,978 max.py[line:93] INFO: max: attack effectiveness 43.75%.\n",
            "2023-10-30 15:44:19,987 md_at_ma.py[line:120] INFO: Mini batch: 752/1450 | training time in 8 minutes, 14 seconds.\n",
            "2023-10-30 15:44:19,988 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0200 | Train accuracy: 88.54%.\n",
            "2023-10-30 15:44:20,482 max.py[line:93] INFO: max: attack effectiveness 43.54838709677419%.\n",
            "2023-10-30 15:44:20,491 md_at_ma.py[line:120] INFO: Mini batch: 753/1450 | training time in 8 minutes, 14 seconds.\n",
            "2023-10-30 15:44:20,492 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0215 | Train accuracy: 84.21%.\n",
            "2023-10-30 15:44:20,886 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:44:20,890 md_at_ma.py[line:120] INFO: Mini batch: 754/1450 | training time in 8 minutes, 15 seconds.\n",
            "2023-10-30 15:44:20,890 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0068 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:44:20,927 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0221 | Train accuracy: 85.11\n",
            "2023-10-30 15:44:22,949 max.py[line:93] INFO: max: attack effectiveness 62.5%.\n",
            "2023-10-30 15:44:23,981 max.py[line:93] INFO: max: attack effectiveness 63.28125%.\n",
            "2023-10-30 15:44:24,857 max.py[line:93] INFO: max: attack effectiveness 61.71875%.\n",
            "2023-10-30 15:44:25,731 max.py[line:93] INFO: max: attack effectiveness 54.6875%.\n",
            "2023-10-30 15:44:26,361 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:44:27,042 md_at_ma.py[line:165] INFO: \tVal accuracy 67.35% with accuracy 38.17% under attack.\n",
            "2023-10-30 15:44:27,043 md_at_ma.py[line:167] INFO: \tModel select at epoch 26 with validation accuracy 67.35% and accuracy 38.17% under attack.\n",
            "2023-10-30 15:44:27,903 max.py[line:93] INFO: max: attack effectiveness 48.484848484848484%.\n",
            "2023-10-30 15:44:27,916 md_at_ma.py[line:120] INFO: Mini batch: 755/1450 | training time in 8 minutes, 15 seconds.\n",
            "2023-10-30 15:44:27,916 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0176 | Train accuracy: 85.57%.\n",
            "2023-10-30 15:44:28,405 max.py[line:93] INFO: max: attack effectiveness 55.55555555555556%.\n",
            "2023-10-30 15:44:28,414 md_at_ma.py[line:120] INFO: Mini batch: 756/1450 | training time in 8 minutes, 16 seconds.\n",
            "2023-10-30 15:44:28,414 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0169 | Train accuracy: 85.86%.\n",
            "2023-10-30 15:44:29,188 max.py[line:93] INFO: max: attack effectiveness 45.45454545454545%.\n",
            "2023-10-30 15:44:29,200 md_at_ma.py[line:120] INFO: Mini batch: 757/1450 | training time in 8 minutes, 17 seconds.\n",
            "2023-10-30 15:44:29,200 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0299 | Train accuracy: 84.54%.\n",
            "2023-10-30 15:44:29,973 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:44:29,985 md_at_ma.py[line:120] INFO: Mini batch: 758/1450 | training time in 8 minutes, 17 seconds.\n",
            "2023-10-30 15:44:29,986 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0137 | Train accuracy: 82.32%.\n",
            "2023-10-30 15:44:30,767 max.py[line:93] INFO: max: attack effectiveness 56.33802816901409%.\n",
            "2023-10-30 15:44:30,779 md_at_ma.py[line:120] INFO: Mini batch: 759/1450 | training time in 8 minutes, 18 seconds.\n",
            "2023-10-30 15:44:30,779 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0164 | Train accuracy: 78.39%.\n",
            "2023-10-30 15:44:31,612 max.py[line:93] INFO: max: attack effectiveness 55.26315789473685%.\n",
            "2023-10-30 15:44:31,624 md_at_ma.py[line:120] INFO: Mini batch: 760/1450 | training time in 8 minutes, 19 seconds.\n",
            "2023-10-30 15:44:31,624 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0284 | Train accuracy: 79.41%.\n",
            "2023-10-30 15:44:32,120 max.py[line:93] INFO: max: attack effectiveness 50.81967213114754%.\n",
            "2023-10-30 15:44:32,129 md_at_ma.py[line:120] INFO: Mini batch: 761/1450 | training time in 8 minutes, 19 seconds.\n",
            "2023-10-30 15:44:32,129 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0436 | Train accuracy: 86.24%.\n",
            "2023-10-30 15:44:32,927 max.py[line:93] INFO: max: attack effectiveness 56.52173913043478%.\n",
            "2023-10-30 15:44:32,939 md_at_ma.py[line:120] INFO: Mini batch: 762/1450 | training time in 8 minutes, 20 seconds.\n",
            "2023-10-30 15:44:32,939 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0434 | Train accuracy: 80.20%.\n",
            "2023-10-30 15:44:33,427 max.py[line:93] INFO: max: attack effectiveness 43.54838709677419%.\n",
            "2023-10-30 15:44:33,437 md_at_ma.py[line:120] INFO: Mini batch: 763/1450 | training time in 8 minutes, 21 seconds.\n",
            "2023-10-30 15:44:33,437 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0287 | Train accuracy: 84.74%.\n",
            "2023-10-30 15:44:34,037 max.py[line:93] INFO: max: attack effectiveness 56.666666666666664%.\n",
            "2023-10-30 15:44:34,046 md_at_ma.py[line:120] INFO: Mini batch: 764/1450 | training time in 8 minutes, 21 seconds.\n",
            "2023-10-30 15:44:34,046 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0331 | Train accuracy: 80.85%.\n",
            "2023-10-30 15:44:34,648 max.py[line:93] INFO: max: attack effectiveness 38.88888888888889%.\n",
            "2023-10-30 15:44:34,657 md_at_ma.py[line:120] INFO: Mini batch: 765/1450 | training time in 8 minutes, 22 seconds.\n",
            "2023-10-30 15:44:34,658 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0103 | Train accuracy: 90.66%.\n",
            "2023-10-30 15:44:35,165 max.py[line:93] INFO: max: attack effectiveness 49.2063492063492%.\n",
            "2023-10-30 15:44:35,174 md_at_ma.py[line:120] INFO: Mini batch: 766/1450 | training time in 8 minutes, 22 seconds.\n",
            "2023-10-30 15:44:35,174 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0177 | Train accuracy: 86.39%.\n",
            "2023-10-30 15:44:35,907 max.py[line:93] INFO: max: attack effectiveness 52.307692307692314%.\n",
            "2023-10-30 15:44:35,919 md_at_ma.py[line:120] INFO: Mini batch: 767/1450 | training time in 8 minutes, 23 seconds.\n",
            "2023-10-30 15:44:35,920 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0170 | Train accuracy: 84.46%.\n",
            "2023-10-30 15:44:36,684 max.py[line:93] INFO: max: attack effectiveness 48.484848484848484%.\n",
            "2023-10-30 15:44:36,696 md_at_ma.py[line:120] INFO: Mini batch: 768/1450 | training time in 8 minutes, 24 seconds.\n",
            "2023-10-30 15:44:36,696 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0512 | Train accuracy: 86.60%.\n",
            "2023-10-30 15:44:37,434 max.py[line:93] INFO: max: attack effectiveness 43.07692307692308%.\n",
            "2023-10-30 15:44:37,446 md_at_ma.py[line:120] INFO: Mini batch: 769/1450 | training time in 8 minutes, 25 seconds.\n",
            "2023-10-30 15:44:37,446 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0220 | Train accuracy: 86.53%.\n",
            "2023-10-30 15:44:38,226 max.py[line:93] INFO: max: attack effectiveness 53.52112676056338%.\n",
            "2023-10-30 15:44:38,238 md_at_ma.py[line:120] INFO: Mini batch: 770/1450 | training time in 8 minutes, 25 seconds.\n",
            "2023-10-30 15:44:38,238 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0213 | Train accuracy: 82.41%.\n",
            "2023-10-30 15:44:38,723 max.py[line:93] INFO: max: attack effectiveness 42.1875%.\n",
            "2023-10-30 15:44:38,731 md_at_ma.py[line:120] INFO: Mini batch: 771/1450 | training time in 8 minutes, 26 seconds.\n",
            "2023-10-30 15:44:38,732 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0210 | Train accuracy: 88.54%.\n",
            "2023-10-30 15:44:39,497 max.py[line:93] INFO: max: attack effectiveness 43.28358208955223%.\n",
            "2023-10-30 15:44:39,509 md_at_ma.py[line:120] INFO: Mini batch: 772/1450 | training time in 8 minutes, 27 seconds.\n",
            "2023-10-30 15:44:39,509 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0215 | Train accuracy: 85.64%.\n",
            "2023-10-30 15:44:40,003 max.py[line:93] INFO: max: attack effectiveness 48.4375%.\n",
            "2023-10-30 15:44:40,012 md_at_ma.py[line:120] INFO: Mini batch: 773/1450 | training time in 8 minutes, 27 seconds.\n",
            "2023-10-30 15:44:40,012 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0176 | Train accuracy: 86.46%.\n",
            "2023-10-30 15:44:40,830 max.py[line:93] INFO: max: attack effectiveness 55.4054054054054%.\n",
            "2023-10-30 15:44:40,842 md_at_ma.py[line:120] INFO: Mini batch: 774/1450 | training time in 8 minutes, 28 seconds.\n",
            "2023-10-30 15:44:40,843 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0397 | Train accuracy: 79.70%.\n",
            "2023-10-30 15:44:41,613 max.py[line:93] INFO: max: attack effectiveness 47.82608695652174%.\n",
            "2023-10-30 15:44:41,625 md_at_ma.py[line:120] INFO: Mini batch: 775/1450 | training time in 8 minutes, 29 seconds.\n",
            "2023-10-30 15:44:41,625 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0226 | Train accuracy: 85.79%.\n",
            "2023-10-30 15:44:42,447 max.py[line:93] INFO: max: attack effectiveness 50.66666666666667%.\n",
            "2023-10-30 15:44:42,460 md_at_ma.py[line:120] INFO: Mini batch: 776/1450 | training time in 8 minutes, 29 seconds.\n",
            "2023-10-30 15:44:42,460 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0257 | Train accuracy: 81.28%.\n",
            "2023-10-30 15:44:43,229 max.py[line:93] INFO: max: attack effectiveness 48.529411764705884%.\n",
            "2023-10-30 15:44:43,241 md_at_ma.py[line:120] INFO: Mini batch: 777/1450 | training time in 8 minutes, 30 seconds.\n",
            "2023-10-30 15:44:43,242 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0240 | Train accuracy: 82.65%.\n",
            "2023-10-30 15:44:43,828 max.py[line:93] INFO: max: attack effectiveness 50.847457627118644%.\n",
            "2023-10-30 15:44:43,837 md_at_ma.py[line:120] INFO: Mini batch: 778/1450 | training time in 8 minutes, 31 seconds.\n",
            "2023-10-30 15:44:43,837 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0214 | Train accuracy: 85.03%.\n",
            "2023-10-30 15:44:44,663 max.py[line:93] INFO: max: attack effectiveness 53.333333333333336%.\n",
            "2023-10-30 15:44:44,675 md_at_ma.py[line:120] INFO: Mini batch: 779/1450 | training time in 8 minutes, 32 seconds.\n",
            "2023-10-30 15:44:44,675 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0180 | Train accuracy: 82.27%.\n",
            "2023-10-30 15:44:45,459 max.py[line:93] INFO: max: attack effectiveness 56.52173913043478%.\n",
            "2023-10-30 15:44:45,471 md_at_ma.py[line:120] INFO: Mini batch: 780/1450 | training time in 8 minutes, 32 seconds.\n",
            "2023-10-30 15:44:45,471 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0219 | Train accuracy: 82.23%.\n",
            "2023-10-30 15:44:45,964 max.py[line:93] INFO: max: attack effectiveness 45.3125%.\n",
            "2023-10-30 15:44:45,973 md_at_ma.py[line:120] INFO: Mini batch: 781/1450 | training time in 8 minutes, 33 seconds.\n",
            "2023-10-30 15:44:45,973 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0140 | Train accuracy: 88.54%.\n",
            "2023-10-30 15:44:46,461 max.py[line:93] INFO: max: attack effectiveness 45.16129032258064%.\n",
            "2023-10-30 15:44:46,470 md_at_ma.py[line:120] INFO: Mini batch: 782/1450 | training time in 8 minutes, 33 seconds.\n",
            "2023-10-30 15:44:46,470 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0129 | Train accuracy: 87.89%.\n",
            "2023-10-30 15:44:46,870 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:44:46,874 md_at_ma.py[line:120] INFO: Mini batch: 783/1450 | training time in 8 minutes, 34 seconds.\n",
            "2023-10-30 15:44:46,874 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0046 | Train accuracy: 100.00%.\n",
            "2023-10-30 15:44:46,914 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0233 | Train accuracy: 84.87\n",
            "2023-10-30 15:44:49,000 max.py[line:93] INFO: max: attack effectiveness 65.625%.\n",
            "2023-10-30 15:44:49,957 max.py[line:93] INFO: max: attack effectiveness 60.15625%.\n",
            "2023-10-30 15:44:50,865 max.py[line:93] INFO: max: attack effectiveness 64.84375%.\n",
            "2023-10-30 15:44:51,841 max.py[line:93] INFO: max: attack effectiveness 57.03125%.\n",
            "2023-10-30 15:44:52,490 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:44:53,164 md_at_ma.py[line:165] INFO: \tVal accuracy 66.72% with accuracy 36.92% under attack.\n",
            "2023-10-30 15:44:53,165 md_at_ma.py[line:167] INFO: \tModel select at epoch 26 with validation accuracy 67.35% and accuracy 38.17% under attack.\n",
            "2023-10-30 15:44:54,051 max.py[line:93] INFO: max: attack effectiveness 48.484848484848484%.\n",
            "2023-10-30 15:44:54,064 md_at_ma.py[line:120] INFO: Mini batch: 784/1450 | training time in 8 minutes, 35 seconds.\n",
            "2023-10-30 15:44:54,064 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0205 | Train accuracy: 85.57%.\n",
            "2023-10-30 15:44:54,551 max.py[line:93] INFO: max: attack effectiveness 53.96825396825397%.\n",
            "2023-10-30 15:44:54,559 md_at_ma.py[line:120] INFO: Mini batch: 785/1450 | training time in 8 minutes, 35 seconds.\n",
            "2023-10-30 15:44:54,560 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0202 | Train accuracy: 85.86%.\n",
            "2023-10-30 15:44:55,324 max.py[line:93] INFO: max: attack effectiveness 45.45454545454545%.\n",
            "2023-10-30 15:44:55,336 md_at_ma.py[line:120] INFO: Mini batch: 786/1450 | training time in 8 minutes, 36 seconds.\n",
            "2023-10-30 15:44:55,336 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1549 | Train accuracy: 86.08%.\n",
            "2023-10-30 15:44:56,108 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:44:56,120 md_at_ma.py[line:120] INFO: Mini batch: 787/1450 | training time in 8 minutes, 37 seconds.\n",
            "2023-10-30 15:44:56,121 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0128 | Train accuracy: 86.87%.\n",
            "2023-10-30 15:44:56,895 max.py[line:93] INFO: max: attack effectiveness 53.52112676056338%.\n",
            "2023-10-30 15:44:56,908 md_at_ma.py[line:120] INFO: Mini batch: 788/1450 | training time in 8 minutes, 37 seconds.\n",
            "2023-10-30 15:44:56,908 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0160 | Train accuracy: 84.92%.\n",
            "2023-10-30 15:44:57,731 max.py[line:93] INFO: max: attack effectiveness 55.26315789473685%.\n",
            "2023-10-30 15:44:57,743 md_at_ma.py[line:120] INFO: Mini batch: 789/1450 | training time in 8 minutes, 38 seconds.\n",
            "2023-10-30 15:44:57,744 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0168 | Train accuracy: 80.88%.\n",
            "2023-10-30 15:44:58,231 max.py[line:93] INFO: max: attack effectiveness 52.459016393442624%.\n",
            "2023-10-30 15:44:58,240 md_at_ma.py[line:120] INFO: Mini batch: 790/1450 | training time in 8 minutes, 39 seconds.\n",
            "2023-10-30 15:44:58,240 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0161 | Train accuracy: 83.07%.\n",
            "2023-10-30 15:44:59,048 max.py[line:93] INFO: max: attack effectiveness 50.72463768115942%.\n",
            "2023-10-30 15:44:59,060 md_at_ma.py[line:120] INFO: Mini batch: 791/1450 | training time in 8 minutes, 39 seconds.\n",
            "2023-10-30 15:44:59,060 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0243 | Train accuracy: 84.26%.\n",
            "2023-10-30 15:44:59,575 max.py[line:93] INFO: max: attack effectiveness 48.38709677419355%.\n",
            "2023-10-30 15:44:59,585 md_at_ma.py[line:120] INFO: Mini batch: 792/1450 | training time in 8 minutes, 40 seconds.\n",
            "2023-10-30 15:44:59,585 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0170 | Train accuracy: 83.68%.\n",
            "2023-10-30 15:45:00,194 max.py[line:93] INFO: max: attack effectiveness 63.33333333333333%.\n",
            "2023-10-30 15:45:00,203 md_at_ma.py[line:120] INFO: Mini batch: 793/1450 | training time in 8 minutes, 41 seconds.\n",
            "2023-10-30 15:45:00,203 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0313 | Train accuracy: 78.72%.\n",
            "2023-10-30 15:45:00,802 max.py[line:93] INFO: max: attack effectiveness 55.55555555555556%.\n",
            "2023-10-30 15:45:00,811 md_at_ma.py[line:120] INFO: Mini batch: 794/1450 | training time in 8 minutes, 41 seconds.\n",
            "2023-10-30 15:45:00,811 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0164 | Train accuracy: 81.87%.\n",
            "2023-10-30 15:45:01,317 max.py[line:93] INFO: max: attack effectiveness 53.96825396825397%.\n",
            "2023-10-30 15:45:01,325 md_at_ma.py[line:120] INFO: Mini batch: 795/1450 | training time in 8 minutes, 42 seconds.\n",
            "2023-10-30 15:45:01,326 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0417 | Train accuracy: 83.25%.\n",
            "2023-10-30 15:45:02,061 max.py[line:93] INFO: max: attack effectiveness 55.38461538461539%.\n",
            "2023-10-30 15:45:02,073 md_at_ma.py[line:120] INFO: Mini batch: 796/1450 | training time in 8 minutes, 42 seconds.\n",
            "2023-10-30 15:45:02,073 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0154 | Train accuracy: 80.83%.\n",
            "2023-10-30 15:45:02,839 max.py[line:93] INFO: max: attack effectiveness 46.96969696969697%.\n",
            "2023-10-30 15:45:02,851 md_at_ma.py[line:120] INFO: Mini batch: 797/1450 | training time in 8 minutes, 43 seconds.\n",
            "2023-10-30 15:45:02,851 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0503 | Train accuracy: 87.63%.\n",
            "2023-10-30 15:45:03,587 max.py[line:93] INFO: max: attack effectiveness 44.61538461538462%.\n",
            "2023-10-30 15:45:03,599 md_at_ma.py[line:120] INFO: Mini batch: 798/1450 | training time in 8 minutes, 44 seconds.\n",
            "2023-10-30 15:45:03,599 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0289 | Train accuracy: 84.46%.\n",
            "2023-10-30 15:45:04,373 max.py[line:93] INFO: max: attack effectiveness 52.112676056338024%.\n",
            "2023-10-30 15:45:04,385 md_at_ma.py[line:120] INFO: Mini batch: 799/1450 | training time in 8 minutes, 45 seconds.\n",
            "2023-10-30 15:45:04,385 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0208 | Train accuracy: 84.42%.\n",
            "2023-10-30 15:45:04,867 max.py[line:93] INFO: max: attack effectiveness 42.1875%.\n",
            "2023-10-30 15:45:04,876 md_at_ma.py[line:120] INFO: Mini batch: 800/1450 | training time in 8 minutes, 45 seconds.\n",
            "2023-10-30 15:45:04,876 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0235 | Train accuracy: 86.46%.\n",
            "2023-10-30 15:45:05,645 max.py[line:93] INFO: max: attack effectiveness 41.7910447761194%.\n",
            "2023-10-30 15:45:05,657 md_at_ma.py[line:120] INFO: Mini batch: 801/1450 | training time in 8 minutes, 46 seconds.\n",
            "2023-10-30 15:45:05,657 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0296 | Train accuracy: 86.15%.\n",
            "2023-10-30 15:45:06,155 max.py[line:93] INFO: max: attack effectiveness 45.3125%.\n",
            "2023-10-30 15:45:06,164 md_at_ma.py[line:120] INFO: Mini batch: 802/1450 | training time in 8 minutes, 46 seconds.\n",
            "2023-10-30 15:45:06,164 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0253 | Train accuracy: 86.46%.\n",
            "2023-10-30 15:45:06,986 max.py[line:93] INFO: max: attack effectiveness 51.35135135135135%.\n",
            "2023-10-30 15:45:06,998 md_at_ma.py[line:120] INFO: Mini batch: 803/1450 | training time in 8 minutes, 47 seconds.\n",
            "2023-10-30 15:45:06,998 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0413 | Train accuracy: 82.18%.\n",
            "2023-10-30 15:45:07,771 max.py[line:93] INFO: max: attack effectiveness 43.47826086956522%.\n",
            "2023-10-30 15:45:07,783 md_at_ma.py[line:120] INFO: Mini batch: 804/1450 | training time in 8 minutes, 48 seconds.\n",
            "2023-10-30 15:45:07,783 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0235 | Train accuracy: 86.29%.\n",
            "2023-10-30 15:45:08,605 max.py[line:93] INFO: max: attack effectiveness 49.333333333333336%.\n",
            "2023-10-30 15:45:08,617 md_at_ma.py[line:120] INFO: Mini batch: 805/1450 | training time in 8 minutes, 49 seconds.\n",
            "2023-10-30 15:45:08,617 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0238 | Train accuracy: 83.25%.\n",
            "2023-10-30 15:45:09,385 max.py[line:93] INFO: max: attack effectiveness 48.529411764705884%.\n",
            "2023-10-30 15:45:09,397 md_at_ma.py[line:120] INFO: Mini batch: 806/1450 | training time in 8 minutes, 49 seconds.\n",
            "2023-10-30 15:45:09,397 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0201 | Train accuracy: 84.18%.\n",
            "2023-10-30 15:45:09,983 max.py[line:93] INFO: max: attack effectiveness 47.45762711864407%.\n",
            "2023-10-30 15:45:09,991 md_at_ma.py[line:120] INFO: Mini batch: 807/1450 | training time in 8 minutes, 50 seconds.\n",
            "2023-10-30 15:45:09,992 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0266 | Train accuracy: 88.24%.\n",
            "2023-10-30 15:45:10,815 max.py[line:93] INFO: max: attack effectiveness 45.33333333333333%.\n",
            "2023-10-30 15:45:10,828 md_at_ma.py[line:120] INFO: Mini batch: 808/1450 | training time in 8 minutes, 51 seconds.\n",
            "2023-10-30 15:45:10,828 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0223 | Train accuracy: 83.74%.\n",
            "2023-10-30 15:45:11,617 max.py[line:93] INFO: max: attack effectiveness 50.72463768115942%.\n",
            "2023-10-30 15:45:11,629 md_at_ma.py[line:120] INFO: Mini batch: 809/1450 | training time in 8 minutes, 52 seconds.\n",
            "2023-10-30 15:45:11,629 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0312 | Train accuracy: 83.25%.\n",
            "2023-10-30 15:45:12,135 max.py[line:93] INFO: max: attack effectiveness 43.75%.\n",
            "2023-10-30 15:45:12,144 md_at_ma.py[line:120] INFO: Mini batch: 810/1450 | training time in 8 minutes, 52 seconds.\n",
            "2023-10-30 15:45:12,144 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0181 | Train accuracy: 86.98%.\n",
            "2023-10-30 15:45:12,631 max.py[line:93] INFO: max: attack effectiveness 41.935483870967744%.\n",
            "2023-10-30 15:45:12,640 md_at_ma.py[line:120] INFO: Mini batch: 811/1450 | training time in 8 minutes, 53 seconds.\n",
            "2023-10-30 15:45:12,641 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0141 | Train accuracy: 87.89%.\n",
            "2023-10-30 15:45:13,045 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:45:13,050 md_at_ma.py[line:120] INFO: Mini batch: 812/1450 | training time in 8 minutes, 53 seconds.\n",
            "2023-10-30 15:45:13,050 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0050 | Train accuracy: 94.74%.\n",
            "2023-10-30 15:45:13,081 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0279 | Train accuracy: 84.90\n",
            "2023-10-30 15:45:15,174 max.py[line:93] INFO: max: attack effectiveness 61.71875%.\n",
            "2023-10-30 15:45:16,150 max.py[line:93] INFO: max: attack effectiveness 59.375%.\n",
            "2023-10-30 15:45:17,054 max.py[line:93] INFO: max: attack effectiveness 62.5%.\n",
            "2023-10-30 15:45:17,951 max.py[line:93] INFO: max: attack effectiveness 55.46875%.\n",
            "2023-10-30 15:45:18,560 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:45:19,316 md_at_ma.py[line:165] INFO: \tVal accuracy 67.68% with accuracy 38.89% under attack.\n",
            "2023-10-30 15:45:19,317 md_at_ma.py[line:167] INFO: \tModel select at epoch 28 with validation accuracy 67.68% and accuracy 38.89% under attack.\n",
            "2023-10-30 15:45:20,188 max.py[line:93] INFO: max: attack effectiveness 45.45454545454545%.\n",
            "2023-10-30 15:45:20,201 md_at_ma.py[line:120] INFO: Mini batch: 813/1450 | training time in 8 minutes, 54 seconds.\n",
            "2023-10-30 15:45:20,201 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0243 | Train accuracy: 85.57%.\n",
            "2023-10-30 15:45:20,695 max.py[line:93] INFO: max: attack effectiveness 55.55555555555556%.\n",
            "2023-10-30 15:45:20,704 md_at_ma.py[line:120] INFO: Mini batch: 814/1450 | training time in 8 minutes, 54 seconds.\n",
            "2023-10-30 15:45:20,704 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0264 | Train accuracy: 82.20%.\n",
            "2023-10-30 15:45:21,479 max.py[line:93] INFO: max: attack effectiveness 45.45454545454545%.\n",
            "2023-10-30 15:45:21,491 md_at_ma.py[line:120] INFO: Mini batch: 815/1450 | training time in 8 minutes, 55 seconds.\n",
            "2023-10-30 15:45:21,491 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1097 | Train accuracy: 85.57%.\n",
            "2023-10-30 15:45:22,267 max.py[line:93] INFO: max: attack effectiveness 48.57142857142857%.\n",
            "2023-10-30 15:45:22,279 md_at_ma.py[line:120] INFO: Mini batch: 816/1450 | training time in 8 minutes, 56 seconds.\n",
            "2023-10-30 15:45:22,279 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0253 | Train accuracy: 86.36%.\n",
            "2023-10-30 15:45:23,057 max.py[line:93] INFO: max: attack effectiveness 52.112676056338024%.\n",
            "2023-10-30 15:45:23,069 md_at_ma.py[line:120] INFO: Mini batch: 817/1450 | training time in 8 minutes, 57 seconds.\n",
            "2023-10-30 15:45:23,069 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0176 | Train accuracy: 84.92%.\n",
            "2023-10-30 15:45:23,893 max.py[line:93] INFO: max: attack effectiveness 51.31578947368421%.\n",
            "2023-10-30 15:45:23,906 md_at_ma.py[line:120] INFO: Mini batch: 818/1450 | training time in 8 minutes, 57 seconds.\n",
            "2023-10-30 15:45:23,906 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0155 | Train accuracy: 84.31%.\n",
            "2023-10-30 15:45:24,391 max.py[line:93] INFO: max: attack effectiveness 52.459016393442624%.\n",
            "2023-10-30 15:45:24,402 md_at_ma.py[line:120] INFO: Mini batch: 819/1450 | training time in 8 minutes, 58 seconds.\n",
            "2023-10-30 15:45:24,402 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0135 | Train accuracy: 88.36%.\n",
            "2023-10-30 15:45:25,179 max.py[line:93] INFO: max: attack effectiveness 46.3768115942029%.\n",
            "2023-10-30 15:45:25,193 md_at_ma.py[line:120] INFO: Mini batch: 820/1450 | training time in 8 minutes, 59 seconds.\n",
            "2023-10-30 15:45:25,193 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0156 | Train accuracy: 85.28%.\n",
            "2023-10-30 15:45:25,714 max.py[line:93] INFO: max: attack effectiveness 41.935483870967744%.\n",
            "2023-10-30 15:45:25,723 md_at_ma.py[line:120] INFO: Mini batch: 821/1450 | training time in 8 minutes, 59 seconds.\n",
            "2023-10-30 15:45:25,723 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0130 | Train accuracy: 88.42%.\n",
            "2023-10-30 15:45:26,341 max.py[line:93] INFO: max: attack effectiveness 56.666666666666664%.\n",
            "2023-10-30 15:45:26,350 md_at_ma.py[line:120] INFO: Mini batch: 822/1450 | training time in 9 minutes, 0 seconds.\n",
            "2023-10-30 15:45:26,350 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0283 | Train accuracy: 81.38%.\n",
            "2023-10-30 15:45:26,956 max.py[line:93] INFO: max: attack effectiveness 40.74074074074074%.\n",
            "2023-10-30 15:45:26,965 md_at_ma.py[line:120] INFO: Mini batch: 823/1450 | training time in 9 minutes, 0 seconds.\n",
            "2023-10-30 15:45:26,965 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0112 | Train accuracy: 90.66%.\n",
            "2023-10-30 15:45:27,473 max.py[line:93] INFO: max: attack effectiveness 55.55555555555556%.\n",
            "2023-10-30 15:45:27,482 md_at_ma.py[line:120] INFO: Mini batch: 824/1450 | training time in 9 minutes, 1 seconds.\n",
            "2023-10-30 15:45:27,482 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0213 | Train accuracy: 82.72%.\n",
            "2023-10-30 15:45:28,216 max.py[line:93] INFO: max: attack effectiveness 50.76923076923077%.\n",
            "2023-10-30 15:45:28,228 md_at_ma.py[line:120] INFO: Mini batch: 825/1450 | training time in 9 minutes, 2 seconds.\n",
            "2023-10-30 15:45:28,229 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0116 | Train accuracy: 82.90%.\n",
            "2023-10-30 15:45:28,994 max.py[line:93] INFO: max: attack effectiveness 51.515151515151516%.\n",
            "2023-10-30 15:45:29,006 md_at_ma.py[line:120] INFO: Mini batch: 826/1450 | training time in 9 minutes, 2 seconds.\n",
            "2023-10-30 15:45:29,006 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0399 | Train accuracy: 87.63%.\n",
            "2023-10-30 15:45:29,738 max.py[line:93] INFO: max: attack effectiveness 44.61538461538462%.\n",
            "2023-10-30 15:45:29,750 md_at_ma.py[line:120] INFO: Mini batch: 827/1450 | training time in 9 minutes, 3 seconds.\n",
            "2023-10-30 15:45:29,750 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0137 | Train accuracy: 87.05%.\n",
            "2023-10-30 15:45:30,529 max.py[line:93] INFO: max: attack effectiveness 53.52112676056338%.\n",
            "2023-10-30 15:45:30,541 md_at_ma.py[line:120] INFO: Mini batch: 828/1450 | training time in 9 minutes, 4 seconds.\n",
            "2023-10-30 15:45:30,541 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0180 | Train accuracy: 84.92%.\n",
            "2023-10-30 15:45:31,031 max.py[line:93] INFO: max: attack effectiveness 39.0625%.\n",
            "2023-10-30 15:45:31,040 md_at_ma.py[line:120] INFO: Mini batch: 829/1450 | training time in 9 minutes, 4 seconds.\n",
            "2023-10-30 15:45:31,040 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0154 | Train accuracy: 89.58%.\n",
            "2023-10-30 15:45:31,807 max.py[line:93] INFO: max: attack effectiveness 44.776119402985074%.\n",
            "2023-10-30 15:45:31,820 md_at_ma.py[line:120] INFO: Mini batch: 830/1450 | training time in 9 minutes, 5 seconds.\n",
            "2023-10-30 15:45:31,820 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0159 | Train accuracy: 85.13%.\n",
            "2023-10-30 15:45:32,308 max.py[line:93] INFO: max: attack effectiveness 48.4375%.\n",
            "2023-10-30 15:45:32,317 md_at_ma.py[line:120] INFO: Mini batch: 831/1450 | training time in 9 minutes, 6 seconds.\n",
            "2023-10-30 15:45:32,317 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0180 | Train accuracy: 85.42%.\n",
            "2023-10-30 15:45:33,139 max.py[line:93] INFO: max: attack effectiveness 55.4054054054054%.\n",
            "2023-10-30 15:45:33,151 md_at_ma.py[line:120] INFO: Mini batch: 832/1450 | training time in 9 minutes, 6 seconds.\n",
            "2023-10-30 15:45:33,151 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0361 | Train accuracy: 80.20%.\n",
            "2023-10-30 15:45:33,928 max.py[line:93] INFO: max: attack effectiveness 43.47826086956522%.\n",
            "2023-10-30 15:45:33,941 md_at_ma.py[line:120] INFO: Mini batch: 833/1450 | training time in 9 minutes, 7 seconds.\n",
            "2023-10-30 15:45:33,941 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0418 | Train accuracy: 85.79%.\n",
            "2023-10-30 15:45:34,762 max.py[line:93] INFO: max: attack effectiveness 52.0%.\n",
            "2023-10-30 15:45:34,775 md_at_ma.py[line:120] INFO: Mini batch: 834/1450 | training time in 9 minutes, 8 seconds.\n",
            "2023-10-30 15:45:34,775 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0190 | Train accuracy: 82.76%.\n",
            "2023-10-30 15:45:35,543 max.py[line:93] INFO: max: attack effectiveness 48.529411764705884%.\n",
            "2023-10-30 15:45:35,555 md_at_ma.py[line:120] INFO: Mini batch: 835/1450 | training time in 9 minutes, 9 seconds.\n",
            "2023-10-30 15:45:35,555 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0193 | Train accuracy: 85.20%.\n",
            "2023-10-30 15:45:36,147 max.py[line:93] INFO: max: attack effectiveness 50.847457627118644%.\n",
            "2023-10-30 15:45:36,156 md_at_ma.py[line:120] INFO: Mini batch: 836/1450 | training time in 9 minutes, 9 seconds.\n",
            "2023-10-30 15:45:36,156 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0289 | Train accuracy: 86.63%.\n",
            "2023-10-30 15:45:36,978 max.py[line:93] INFO: max: attack effectiveness 56.00000000000001%.\n",
            "2023-10-30 15:45:36,990 md_at_ma.py[line:120] INFO: Mini batch: 837/1450 | training time in 9 minutes, 10 seconds.\n",
            "2023-10-30 15:45:36,990 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0258 | Train accuracy: 80.79%.\n",
            "2023-10-30 15:45:37,772 max.py[line:93] INFO: max: attack effectiveness 55.072463768115945%.\n",
            "2023-10-30 15:45:37,785 md_at_ma.py[line:120] INFO: Mini batch: 838/1450 | training time in 9 minutes, 11 seconds.\n",
            "2023-10-30 15:45:37,785 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0177 | Train accuracy: 83.25%.\n",
            "2023-10-30 15:45:38,276 max.py[line:93] INFO: max: attack effectiveness 42.1875%.\n",
            "2023-10-30 15:45:38,285 md_at_ma.py[line:120] INFO: Mini batch: 839/1450 | training time in 9 minutes, 11 seconds.\n",
            "2023-10-30 15:45:38,286 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0275 | Train accuracy: 87.50%.\n",
            "2023-10-30 15:45:38,781 max.py[line:93] INFO: max: attack effectiveness 45.16129032258064%.\n",
            "2023-10-30 15:45:38,790 md_at_ma.py[line:120] INFO: Mini batch: 840/1450 | training time in 9 minutes, 12 seconds.\n",
            "2023-10-30 15:45:38,790 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0183 | Train accuracy: 88.95%.\n",
            "2023-10-30 15:45:39,179 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:45:39,183 md_at_ma.py[line:120] INFO: Mini batch: 841/1450 | training time in 9 minutes, 12 seconds.\n",
            "2023-10-30 15:45:39,183 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0056 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:45:39,225 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0239 | Train accuracy: 85.48\n",
            "2023-10-30 15:45:41,400 max.py[line:93] INFO: max: attack effectiveness 63.28125%.\n",
            "2023-10-30 15:45:42,379 max.py[line:93] INFO: max: attack effectiveness 64.0625%.\n",
            "2023-10-30 15:45:43,266 max.py[line:93] INFO: max: attack effectiveness 62.5%.\n",
            "2023-10-30 15:45:44,189 max.py[line:93] INFO: max: attack effectiveness 59.375%.\n",
            "2023-10-30 15:45:44,791 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:45:45,467 md_at_ma.py[line:165] INFO: \tVal accuracy 66.27% with accuracy 36.56% under attack.\n",
            "2023-10-30 15:45:45,467 md_at_ma.py[line:167] INFO: \tModel select at epoch 28 with validation accuracy 67.68% and accuracy 38.89% under attack.\n",
            "2023-10-30 15:45:46,349 max.py[line:93] INFO: max: attack effectiveness 46.96969696969697%.\n",
            "2023-10-30 15:45:46,362 md_at_ma.py[line:120] INFO: Mini batch: 842/1450 | training time in 9 minutes, 13 seconds.\n",
            "2023-10-30 15:45:46,362 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0272 | Train accuracy: 86.08%.\n",
            "2023-10-30 15:45:46,857 max.py[line:93] INFO: max: attack effectiveness 52.38095238095239%.\n",
            "2023-10-30 15:45:46,866 md_at_ma.py[line:120] INFO: Mini batch: 843/1450 | training time in 9 minutes, 14 seconds.\n",
            "2023-10-30 15:45:46,866 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0321 | Train accuracy: 83.77%.\n",
            "2023-10-30 15:45:47,632 max.py[line:93] INFO: max: attack effectiveness 46.96969696969697%.\n",
            "2023-10-30 15:45:47,644 md_at_ma.py[line:120] INFO: Mini batch: 844/1450 | training time in 9 minutes, 14 seconds.\n",
            "2023-10-30 15:45:47,644 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0385 | Train accuracy: 85.05%.\n",
            "2023-10-30 15:45:48,428 max.py[line:93] INFO: max: attack effectiveness 54.285714285714285%.\n",
            "2023-10-30 15:45:48,440 md_at_ma.py[line:120] INFO: Mini batch: 845/1450 | training time in 9 minutes, 15 seconds.\n",
            "2023-10-30 15:45:48,440 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0173 | Train accuracy: 85.86%.\n",
            "2023-10-30 15:45:49,217 max.py[line:93] INFO: max: attack effectiveness 60.56338028169014%.\n",
            "2023-10-30 15:45:49,229 md_at_ma.py[line:120] INFO: Mini batch: 846/1450 | training time in 9 minutes, 16 seconds.\n",
            "2023-10-30 15:45:49,229 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0190 | Train accuracy: 77.89%.\n",
            "2023-10-30 15:45:50,055 max.py[line:93] INFO: max: attack effectiveness 57.89473684210527%.\n",
            "2023-10-30 15:45:50,067 md_at_ma.py[line:120] INFO: Mini batch: 847/1450 | training time in 9 minutes, 17 seconds.\n",
            "2023-10-30 15:45:50,068 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0152 | Train accuracy: 82.35%.\n",
            "2023-10-30 15:45:50,557 max.py[line:93] INFO: max: attack effectiveness 55.73770491803278%.\n",
            "2023-10-30 15:45:50,566 md_at_ma.py[line:120] INFO: Mini batch: 848/1450 | training time in 9 minutes, 17 seconds.\n",
            "2023-10-30 15:45:50,566 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0181 | Train accuracy: 85.19%.\n",
            "2023-10-30 15:45:51,353 max.py[line:93] INFO: max: attack effectiveness 50.72463768115942%.\n",
            "2023-10-30 15:45:51,366 md_at_ma.py[line:120] INFO: Mini batch: 849/1450 | training time in 9 minutes, 18 seconds.\n",
            "2023-10-30 15:45:51,366 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0192 | Train accuracy: 84.77%.\n",
            "2023-10-30 15:45:51,889 max.py[line:93] INFO: max: attack effectiveness 48.38709677419355%.\n",
            "2023-10-30 15:45:51,898 md_at_ma.py[line:120] INFO: Mini batch: 850/1450 | training time in 9 minutes, 18 seconds.\n",
            "2023-10-30 15:45:51,899 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0122 | Train accuracy: 87.37%.\n",
            "2023-10-30 15:45:52,518 max.py[line:93] INFO: max: attack effectiveness 61.66666666666667%.\n",
            "2023-10-30 15:45:52,527 md_at_ma.py[line:120] INFO: Mini batch: 851/1450 | training time in 9 minutes, 19 seconds.\n",
            "2023-10-30 15:45:52,527 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0242 | Train accuracy: 84.04%.\n",
            "2023-10-30 15:45:53,143 max.py[line:93] INFO: max: attack effectiveness 44.44444444444444%.\n",
            "2023-10-30 15:45:53,152 md_at_ma.py[line:120] INFO: Mini batch: 852/1450 | training time in 9 minutes, 20 seconds.\n",
            "2023-10-30 15:45:53,152 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0128 | Train accuracy: 86.81%.\n",
            "2023-10-30 15:45:53,674 max.py[line:93] INFO: max: attack effectiveness 57.14285714285714%.\n",
            "2023-10-30 15:45:53,683 md_at_ma.py[line:120] INFO: Mini batch: 853/1450 | training time in 9 minutes, 20 seconds.\n",
            "2023-10-30 15:45:53,683 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0147 | Train accuracy: 84.82%.\n",
            "2023-10-30 15:45:54,418 max.py[line:93] INFO: max: attack effectiveness 55.38461538461539%.\n",
            "2023-10-30 15:45:54,430 md_at_ma.py[line:120] INFO: Mini batch: 854/1450 | training time in 9 minutes, 21 seconds.\n",
            "2023-10-30 15:45:54,430 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0110 | Train accuracy: 84.46%.\n",
            "2023-10-30 15:45:55,197 max.py[line:93] INFO: max: attack effectiveness 46.96969696969697%.\n",
            "2023-10-30 15:45:55,209 md_at_ma.py[line:120] INFO: Mini batch: 855/1450 | training time in 9 minutes, 22 seconds.\n",
            "2023-10-30 15:45:55,209 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0339 | Train accuracy: 86.08%.\n",
            "2023-10-30 15:45:55,944 max.py[line:93] INFO: max: attack effectiveness 44.61538461538462%.\n",
            "2023-10-30 15:45:55,956 md_at_ma.py[line:120] INFO: Mini batch: 856/1450 | training time in 9 minutes, 22 seconds.\n",
            "2023-10-30 15:45:55,957 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0177 | Train accuracy: 87.56%.\n",
            "2023-10-30 15:45:56,734 max.py[line:93] INFO: max: attack effectiveness 53.52112676056338%.\n",
            "2023-10-30 15:45:56,747 md_at_ma.py[line:120] INFO: Mini batch: 857/1450 | training time in 9 minutes, 23 seconds.\n",
            "2023-10-30 15:45:56,747 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0140 | Train accuracy: 82.91%.\n",
            "2023-10-30 15:45:57,236 max.py[line:93] INFO: max: attack effectiveness 40.625%.\n",
            "2023-10-30 15:45:57,245 md_at_ma.py[line:120] INFO: Mini batch: 858/1450 | training time in 9 minutes, 24 seconds.\n",
            "2023-10-30 15:45:57,245 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0176 | Train accuracy: 89.58%.\n",
            "2023-10-30 15:45:58,010 max.py[line:93] INFO: max: attack effectiveness 46.26865671641791%.\n",
            "2023-10-30 15:45:58,022 md_at_ma.py[line:120] INFO: Mini batch: 859/1450 | training time in 9 minutes, 24 seconds.\n",
            "2023-10-30 15:45:58,022 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0118 | Train accuracy: 87.18%.\n",
            "2023-10-30 15:45:58,508 max.py[line:93] INFO: max: attack effectiveness 46.875%.\n",
            "2023-10-30 15:45:58,517 md_at_ma.py[line:120] INFO: Mini batch: 860/1450 | training time in 9 minutes, 25 seconds.\n",
            "2023-10-30 15:45:58,517 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0225 | Train accuracy: 84.90%.\n",
            "2023-10-30 15:45:59,334 max.py[line:93] INFO: max: attack effectiveness 55.4054054054054%.\n",
            "2023-10-30 15:45:59,346 md_at_ma.py[line:120] INFO: Mini batch: 861/1450 | training time in 9 minutes, 26 seconds.\n",
            "2023-10-30 15:45:59,346 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0417 | Train accuracy: 81.68%.\n",
            "2023-10-30 15:46:00,117 max.py[line:93] INFO: max: attack effectiveness 46.3768115942029%.\n",
            "2023-10-30 15:46:00,129 md_at_ma.py[line:120] INFO: Mini batch: 862/1450 | training time in 9 minutes, 27 seconds.\n",
            "2023-10-30 15:46:00,129 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0294 | Train accuracy: 85.28%.\n",
            "2023-10-30 15:46:00,954 max.py[line:93] INFO: max: attack effectiveness 50.66666666666667%.\n",
            "2023-10-30 15:46:00,966 md_at_ma.py[line:120] INFO: Mini batch: 863/1450 | training time in 9 minutes, 27 seconds.\n",
            "2023-10-30 15:46:00,966 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0345 | Train accuracy: 82.76%.\n",
            "2023-10-30 15:46:01,738 max.py[line:93] INFO: max: attack effectiveness 48.529411764705884%.\n",
            "2023-10-30 15:46:01,750 md_at_ma.py[line:120] INFO: Mini batch: 864/1450 | training time in 9 minutes, 28 seconds.\n",
            "2023-10-30 15:46:01,750 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0253 | Train accuracy: 86.22%.\n",
            "2023-10-30 15:46:02,339 max.py[line:93] INFO: max: attack effectiveness 50.847457627118644%.\n",
            "2023-10-30 15:46:02,347 md_at_ma.py[line:120] INFO: Mini batch: 865/1450 | training time in 9 minutes, 29 seconds.\n",
            "2023-10-30 15:46:02,348 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0309 | Train accuracy: 86.10%.\n",
            "2023-10-30 15:46:03,170 max.py[line:93] INFO: max: attack effectiveness 46.666666666666664%.\n",
            "2023-10-30 15:46:03,182 md_at_ma.py[line:120] INFO: Mini batch: 866/1450 | training time in 9 minutes, 29 seconds.\n",
            "2023-10-30 15:46:03,183 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0175 | Train accuracy: 85.22%.\n",
            "2023-10-30 15:46:03,958 max.py[line:93] INFO: max: attack effectiveness 50.72463768115942%.\n",
            "2023-10-30 15:46:03,970 md_at_ma.py[line:120] INFO: Mini batch: 867/1450 | training time in 9 minutes, 30 seconds.\n",
            "2023-10-30 15:46:03,971 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0156 | Train accuracy: 87.31%.\n",
            "2023-10-30 15:46:04,464 max.py[line:93] INFO: max: attack effectiveness 39.0625%.\n",
            "2023-10-30 15:46:04,473 md_at_ma.py[line:120] INFO: Mini batch: 868/1450 | training time in 9 minutes, 31 seconds.\n",
            "2023-10-30 15:46:04,473 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0341 | Train accuracy: 88.54%.\n",
            "2023-10-30 15:46:04,960 max.py[line:93] INFO: max: attack effectiveness 43.54838709677419%.\n",
            "2023-10-30 15:46:04,969 md_at_ma.py[line:120] INFO: Mini batch: 869/1450 | training time in 9 minutes, 31 seconds.\n",
            "2023-10-30 15:46:04,969 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0132 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:46:05,369 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:46:05,374 md_at_ma.py[line:120] INFO: Mini batch: 870/1450 | training time in 9 minutes, 32 seconds.\n",
            "2023-10-30 15:46:05,374 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0044 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:46:05,403 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0216 | Train accuracy: 85.47\n",
            "2023-10-30 15:46:07,574 max.py[line:93] INFO: max: attack effectiveness 60.15625%.\n",
            "2023-10-30 15:46:08,519 max.py[line:93] INFO: max: attack effectiveness 61.71875%.\n",
            "2023-10-30 15:46:09,435 max.py[line:93] INFO: max: attack effectiveness 64.0625%.\n",
            "2023-10-30 15:46:10,390 max.py[line:93] INFO: max: attack effectiveness 53.90625%.\n",
            "2023-10-30 15:46:10,980 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:46:11,613 md_at_ma.py[line:165] INFO: \tVal accuracy 67.46% with accuracy 38.71% under attack.\n",
            "2023-10-30 15:46:11,613 md_at_ma.py[line:167] INFO: \tModel select at epoch 28 with validation accuracy 67.68% and accuracy 38.89% under attack.\n",
            "2023-10-30 15:46:12,448 max.py[line:93] INFO: max: attack effectiveness 45.45454545454545%.\n",
            "2023-10-30 15:46:12,461 md_at_ma.py[line:120] INFO: Mini batch: 871/1450 | training time in 9 minutes, 32 seconds.\n",
            "2023-10-30 15:46:12,461 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0343 | Train accuracy: 86.08%.\n",
            "2023-10-30 15:46:12,945 max.py[line:93] INFO: max: attack effectiveness 53.96825396825397%.\n",
            "2023-10-30 15:46:12,954 md_at_ma.py[line:120] INFO: Mini batch: 872/1450 | training time in 9 minutes, 33 seconds.\n",
            "2023-10-30 15:46:12,954 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0242 | Train accuracy: 85.34%.\n",
            "2023-10-30 15:46:13,719 max.py[line:93] INFO: max: attack effectiveness 45.45454545454545%.\n",
            "2023-10-30 15:46:13,731 md_at_ma.py[line:120] INFO: Mini batch: 873/1450 | training time in 9 minutes, 34 seconds.\n",
            "2023-10-30 15:46:13,731 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0300 | Train accuracy: 85.57%.\n",
            "2023-10-30 15:46:14,504 max.py[line:93] INFO: max: attack effectiveness 52.85714285714286%.\n",
            "2023-10-30 15:46:14,516 md_at_ma.py[line:120] INFO: Mini batch: 874/1450 | training time in 9 minutes, 34 seconds.\n",
            "2023-10-30 15:46:14,517 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0110 | Train accuracy: 85.35%.\n",
            "2023-10-30 15:46:15,298 max.py[line:93] INFO: max: attack effectiveness 57.74647887323944%.\n",
            "2023-10-30 15:46:15,310 md_at_ma.py[line:120] INFO: Mini batch: 875/1450 | training time in 9 minutes, 35 seconds.\n",
            "2023-10-30 15:46:15,310 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0242 | Train accuracy: 79.40%.\n",
            "2023-10-30 15:46:16,134 max.py[line:93] INFO: max: attack effectiveness 60.526315789473685%.\n",
            "2023-10-30 15:46:16,146 md_at_ma.py[line:120] INFO: Mini batch: 876/1450 | training time in 9 minutes, 36 seconds.\n",
            "2023-10-30 15:46:16,146 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0173 | Train accuracy: 79.41%.\n",
            "2023-10-30 15:46:16,633 max.py[line:93] INFO: max: attack effectiveness 65.57377049180327%.\n",
            "2023-10-30 15:46:16,643 md_at_ma.py[line:120] INFO: Mini batch: 877/1450 | training time in 9 minutes, 36 seconds.\n",
            "2023-10-30 15:46:16,643 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0165 | Train accuracy: 80.95%.\n",
            "2023-10-30 15:46:17,450 max.py[line:93] INFO: max: attack effectiveness 56.52173913043478%.\n",
            "2023-10-30 15:46:17,463 md_at_ma.py[line:120] INFO: Mini batch: 878/1450 | training time in 9 minutes, 37 seconds.\n",
            "2023-10-30 15:46:17,463 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0298 | Train accuracy: 80.71%.\n",
            "2023-10-30 15:46:17,990 max.py[line:93] INFO: max: attack effectiveness 62.903225806451616%.\n",
            "2023-10-30 15:46:17,999 md_at_ma.py[line:120] INFO: Mini batch: 879/1450 | training time in 9 minutes, 38 seconds.\n",
            "2023-10-30 15:46:18,000 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0220 | Train accuracy: 81.05%.\n",
            "2023-10-30 15:46:18,629 max.py[line:93] INFO: max: attack effectiveness 60.0%.\n",
            "2023-10-30 15:46:18,638 md_at_ma.py[line:120] INFO: Mini batch: 880/1450 | training time in 9 minutes, 38 seconds.\n",
            "2023-10-30 15:46:18,638 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0299 | Train accuracy: 78.72%.\n",
            "2023-10-30 15:46:19,243 max.py[line:93] INFO: max: attack effectiveness 42.592592592592595%.\n",
            "2023-10-30 15:46:19,252 md_at_ma.py[line:120] INFO: Mini batch: 881/1450 | training time in 9 minutes, 39 seconds.\n",
            "2023-10-30 15:46:19,252 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0173 | Train accuracy: 88.46%.\n",
            "2023-10-30 15:46:19,752 max.py[line:93] INFO: max: attack effectiveness 53.96825396825397%.\n",
            "2023-10-30 15:46:19,761 md_at_ma.py[line:120] INFO: Mini batch: 882/1450 | training time in 9 minutes, 39 seconds.\n",
            "2023-10-30 15:46:19,761 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0207 | Train accuracy: 84.29%.\n",
            "2023-10-30 15:46:20,495 max.py[line:93] INFO: max: attack effectiveness 56.92307692307692%.\n",
            "2023-10-30 15:46:20,507 md_at_ma.py[line:120] INFO: Mini batch: 883/1450 | training time in 9 minutes, 40 seconds.\n",
            "2023-10-30 15:46:20,507 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0149 | Train accuracy: 84.46%.\n",
            "2023-10-30 15:46:21,273 max.py[line:93] INFO: max: attack effectiveness 46.96969696969697%.\n",
            "2023-10-30 15:46:21,285 md_at_ma.py[line:120] INFO: Mini batch: 884/1450 | training time in 9 minutes, 41 seconds.\n",
            "2023-10-30 15:46:21,285 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0419 | Train accuracy: 85.57%.\n",
            "2023-10-30 15:46:22,022 max.py[line:93] INFO: max: attack effectiveness 41.53846153846154%.\n",
            "2023-10-30 15:46:22,034 md_at_ma.py[line:120] INFO: Mini batch: 885/1450 | training time in 9 minutes, 42 seconds.\n",
            "2023-10-30 15:46:22,035 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0240 | Train accuracy: 87.05%.\n",
            "2023-10-30 15:46:22,813 max.py[line:93] INFO: max: attack effectiveness 53.52112676056338%.\n",
            "2023-10-30 15:46:22,826 md_at_ma.py[line:120] INFO: Mini batch: 886/1450 | training time in 9 minutes, 42 seconds.\n",
            "2023-10-30 15:46:22,826 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0134 | Train accuracy: 83.42%.\n",
            "2023-10-30 15:46:23,315 max.py[line:93] INFO: max: attack effectiveness 40.625%.\n",
            "2023-10-30 15:46:23,324 md_at_ma.py[line:120] INFO: Mini batch: 887/1450 | training time in 9 minutes, 43 seconds.\n",
            "2023-10-30 15:46:23,324 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0174 | Train accuracy: 88.54%.\n",
            "2023-10-30 15:46:24,096 max.py[line:93] INFO: max: attack effectiveness 46.26865671641791%.\n",
            "2023-10-30 15:46:24,108 md_at_ma.py[line:120] INFO: Mini batch: 888/1450 | training time in 9 minutes, 44 seconds.\n",
            "2023-10-30 15:46:24,108 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0173 | Train accuracy: 87.69%.\n",
            "2023-10-30 15:46:24,597 max.py[line:93] INFO: max: attack effectiveness 43.75%.\n",
            "2023-10-30 15:46:24,606 md_at_ma.py[line:120] INFO: Mini batch: 889/1450 | training time in 9 minutes, 44 seconds.\n",
            "2023-10-30 15:46:24,606 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0185 | Train accuracy: 87.50%.\n",
            "2023-10-30 15:46:25,427 max.py[line:93] INFO: max: attack effectiveness 51.35135135135135%.\n",
            "2023-10-30 15:46:25,440 md_at_ma.py[line:120] INFO: Mini batch: 890/1450 | training time in 9 minutes, 45 seconds.\n",
            "2023-10-30 15:46:25,440 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0361 | Train accuracy: 81.19%.\n",
            "2023-10-30 15:46:26,214 max.py[line:93] INFO: max: attack effectiveness 42.028985507246375%.\n",
            "2023-10-30 15:46:26,226 md_at_ma.py[line:120] INFO: Mini batch: 891/1450 | training time in 9 minutes, 46 seconds.\n",
            "2023-10-30 15:46:26,226 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0235 | Train accuracy: 86.29%.\n",
            "2023-10-30 15:46:27,056 max.py[line:93] INFO: max: attack effectiveness 48.0%.\n",
            "2023-10-30 15:46:27,068 md_at_ma.py[line:120] INFO: Mini batch: 892/1450 | training time in 9 minutes, 47 seconds.\n",
            "2023-10-30 15:46:27,069 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0260 | Train accuracy: 81.28%.\n",
            "2023-10-30 15:46:27,837 max.py[line:93] INFO: max: attack effectiveness 48.529411764705884%.\n",
            "2023-10-30 15:46:27,849 md_at_ma.py[line:120] INFO: Mini batch: 893/1450 | training time in 9 minutes, 47 seconds.\n",
            "2023-10-30 15:46:27,849 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0237 | Train accuracy: 83.67%.\n",
            "2023-10-30 15:46:28,448 max.py[line:93] INFO: max: attack effectiveness 49.152542372881356%.\n",
            "2023-10-30 15:46:28,457 md_at_ma.py[line:120] INFO: Mini batch: 894/1450 | training time in 9 minutes, 48 seconds.\n",
            "2023-10-30 15:46:28,457 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0305 | Train accuracy: 85.03%.\n",
            "2023-10-30 15:46:29,280 max.py[line:93] INFO: max: attack effectiveness 45.33333333333333%.\n",
            "2023-10-30 15:46:29,292 md_at_ma.py[line:120] INFO: Mini batch: 895/1450 | training time in 9 minutes, 49 seconds.\n",
            "2023-10-30 15:46:29,292 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0167 | Train accuracy: 82.76%.\n",
            "2023-10-30 15:46:30,080 max.py[line:93] INFO: max: attack effectiveness 53.62318840579711%.\n",
            "2023-10-30 15:46:30,093 md_at_ma.py[line:120] INFO: Mini batch: 896/1450 | training time in 9 minutes, 50 seconds.\n",
            "2023-10-30 15:46:30,093 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0199 | Train accuracy: 84.26%.\n",
            "2023-10-30 15:46:30,590 max.py[line:93] INFO: max: attack effectiveness 35.9375%.\n",
            "2023-10-30 15:46:30,599 md_at_ma.py[line:120] INFO: Mini batch: 897/1450 | training time in 9 minutes, 50 seconds.\n",
            "2023-10-30 15:46:30,600 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0214 | Train accuracy: 89.58%.\n",
            "2023-10-30 15:46:31,098 max.py[line:93] INFO: max: attack effectiveness 45.16129032258064%.\n",
            "2023-10-30 15:46:31,108 md_at_ma.py[line:120] INFO: Mini batch: 898/1450 | training time in 9 minutes, 51 seconds.\n",
            "2023-10-30 15:46:31,108 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0116 | Train accuracy: 87.37%.\n",
            "2023-10-30 15:46:31,504 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:46:31,508 md_at_ma.py[line:120] INFO: Mini batch: 899/1450 | training time in 9 minutes, 51 seconds.\n",
            "2023-10-30 15:46:31,508 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0118 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:46:31,541 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0223 | Train accuracy: 84.50\n",
            "2023-10-30 15:46:33,697 max.py[line:93] INFO: max: attack effectiveness 58.59375%.\n",
            "2023-10-30 15:46:34,655 max.py[line:93] INFO: max: attack effectiveness 59.375%.\n",
            "2023-10-30 15:46:35,620 max.py[line:93] INFO: max: attack effectiveness 59.375%.\n",
            "2023-10-30 15:46:36,597 max.py[line:93] INFO: max: attack effectiveness 53.125%.\n",
            "2023-10-30 15:46:37,242 max.py[line:93] INFO: max: attack effectiveness 78.26086956521739%.\n",
            "2023-10-30 15:46:37,993 md_at_ma.py[line:165] INFO: \tVal accuracy 68.37% with accuracy 40.68% under attack.\n",
            "2023-10-30 15:46:37,993 md_at_ma.py[line:167] INFO: \tModel select at epoch 31 with validation accuracy 68.37% and accuracy 40.68% under attack.\n",
            "2023-10-30 15:46:38,867 max.py[line:93] INFO: max: attack effectiveness 45.45454545454545%.\n",
            "2023-10-30 15:46:38,880 md_at_ma.py[line:120] INFO: Mini batch: 900/1450 | training time in 9 minutes, 52 seconds.\n",
            "2023-10-30 15:46:38,880 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0194 | Train accuracy: 85.57%.\n",
            "2023-10-30 15:46:39,372 max.py[line:93] INFO: max: attack effectiveness 50.79365079365079%.\n",
            "2023-10-30 15:46:39,380 md_at_ma.py[line:120] INFO: Mini batch: 901/1450 | training time in 9 minutes, 52 seconds.\n",
            "2023-10-30 15:46:39,381 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0251 | Train accuracy: 83.77%.\n",
            "2023-10-30 15:46:40,145 max.py[line:93] INFO: max: attack effectiveness 45.45454545454545%.\n",
            "2023-10-30 15:46:40,157 md_at_ma.py[line:120] INFO: Mini batch: 902/1450 | training time in 9 minutes, 53 seconds.\n",
            "2023-10-30 15:46:40,158 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0881 | Train accuracy: 85.57%.\n",
            "2023-10-30 15:46:40,934 max.py[line:93] INFO: max: attack effectiveness 47.14285714285714%.\n",
            "2023-10-30 15:46:40,946 md_at_ma.py[line:120] INFO: Mini batch: 903/1450 | training time in 9 minutes, 54 seconds.\n",
            "2023-10-30 15:46:40,946 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0131 | Train accuracy: 85.86%.\n",
            "2023-10-30 15:46:41,726 max.py[line:93] INFO: max: attack effectiveness 53.52112676056338%.\n",
            "2023-10-30 15:46:41,738 md_at_ma.py[line:120] INFO: Mini batch: 904/1450 | training time in 9 minutes, 54 seconds.\n",
            "2023-10-30 15:46:41,738 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0144 | Train accuracy: 82.91%.\n",
            "2023-10-30 15:46:42,575 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:46:42,587 md_at_ma.py[line:120] INFO: Mini batch: 905/1450 | training time in 9 minutes, 55 seconds.\n",
            "2023-10-30 15:46:42,587 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0138 | Train accuracy: 82.35%.\n",
            "2023-10-30 15:46:43,074 max.py[line:93] INFO: max: attack effectiveness 47.540983606557376%.\n",
            "2023-10-30 15:46:43,084 md_at_ma.py[line:120] INFO: Mini batch: 906/1450 | training time in 9 minutes, 56 seconds.\n",
            "2023-10-30 15:46:43,084 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0167 | Train accuracy: 86.24%.\n",
            "2023-10-30 15:46:43,865 max.py[line:93] INFO: max: attack effectiveness 44.927536231884055%.\n",
            "2023-10-30 15:46:43,877 md_at_ma.py[line:120] INFO: Mini batch: 907/1450 | training time in 9 minutes, 57 seconds.\n",
            "2023-10-30 15:46:43,878 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0140 | Train accuracy: 88.32%.\n",
            "2023-10-30 15:46:44,413 max.py[line:93] INFO: max: attack effectiveness 40.32258064516129%.\n",
            "2023-10-30 15:46:44,422 md_at_ma.py[line:120] INFO: Mini batch: 908/1450 | training time in 9 minutes, 57 seconds.\n",
            "2023-10-30 15:46:44,422 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0200 | Train accuracy: 87.89%.\n",
            "2023-10-30 15:46:45,034 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:46:45,043 md_at_ma.py[line:120] INFO: Mini batch: 909/1450 | training time in 9 minutes, 58 seconds.\n",
            "2023-10-30 15:46:45,043 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0183 | Train accuracy: 85.64%.\n",
            "2023-10-30 15:46:45,655 max.py[line:93] INFO: max: attack effectiveness 37.03703703703704%.\n",
            "2023-10-30 15:46:45,664 md_at_ma.py[line:120] INFO: Mini batch: 910/1450 | training time in 9 minutes, 58 seconds.\n",
            "2023-10-30 15:46:45,664 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0108 | Train accuracy: 88.46%.\n",
            "2023-10-30 15:46:46,150 max.py[line:93] INFO: max: attack effectiveness 50.79365079365079%.\n",
            "2023-10-30 15:46:46,159 md_at_ma.py[line:120] INFO: Mini batch: 911/1450 | training time in 9 minutes, 59 seconds.\n",
            "2023-10-30 15:46:46,159 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0195 | Train accuracy: 84.82%.\n",
            "2023-10-30 15:46:46,897 max.py[line:93] INFO: max: attack effectiveness 52.307692307692314%.\n",
            "2023-10-30 15:46:46,909 md_at_ma.py[line:120] INFO: Mini batch: 912/1450 | training time in 9 minutes, 59 seconds.\n",
            "2023-10-30 15:46:46,909 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0141 | Train accuracy: 83.94%.\n",
            "2023-10-30 15:46:47,682 max.py[line:93] INFO: max: attack effectiveness 45.45454545454545%.\n",
            "2023-10-30 15:46:47,694 md_at_ma.py[line:120] INFO: Mini batch: 913/1450 | training time in 10 minutes, 0 seconds.\n",
            "2023-10-30 15:46:47,695 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0438 | Train accuracy: 85.05%.\n",
            "2023-10-30 15:46:48,427 max.py[line:93] INFO: max: attack effectiveness 43.07692307692308%.\n",
            "2023-10-30 15:46:48,440 md_at_ma.py[line:120] INFO: Mini batch: 914/1450 | training time in 10 minutes, 1 seconds.\n",
            "2023-10-30 15:46:48,440 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0138 | Train accuracy: 88.60%.\n",
            "2023-10-30 15:46:49,228 max.py[line:93] INFO: max: attack effectiveness 52.112676056338024%.\n",
            "2023-10-30 15:46:49,240 md_at_ma.py[line:120] INFO: Mini batch: 915/1450 | training time in 10 minutes, 2 seconds.\n",
            "2023-10-30 15:46:49,240 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0119 | Train accuracy: 81.91%.\n",
            "2023-10-30 15:46:49,725 max.py[line:93] INFO: max: attack effectiveness 37.5%.\n",
            "2023-10-30 15:46:49,734 md_at_ma.py[line:120] INFO: Mini batch: 916/1450 | training time in 10 minutes, 2 seconds.\n",
            "2023-10-30 15:46:49,734 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0137 | Train accuracy: 86.46%.\n",
            "2023-10-30 15:46:50,510 max.py[line:93] INFO: max: attack effectiveness 41.7910447761194%.\n",
            "2023-10-30 15:46:50,523 md_at_ma.py[line:120] INFO: Mini batch: 917/1450 | training time in 10 minutes, 3 seconds.\n",
            "2023-10-30 15:46:50,523 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0115 | Train accuracy: 85.64%.\n",
            "2023-10-30 15:46:51,010 max.py[line:93] INFO: max: attack effectiveness 46.875%.\n",
            "2023-10-30 15:46:51,018 md_at_ma.py[line:120] INFO: Mini batch: 918/1450 | training time in 10 minutes, 3 seconds.\n",
            "2023-10-30 15:46:51,019 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0141 | Train accuracy: 85.42%.\n",
            "2023-10-30 15:46:51,838 max.py[line:93] INFO: max: attack effectiveness 52.702702702702695%.\n",
            "2023-10-30 15:46:51,850 md_at_ma.py[line:120] INFO: Mini batch: 919/1450 | training time in 10 minutes, 4 seconds.\n",
            "2023-10-30 15:46:51,850 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0272 | Train accuracy: 81.19%.\n",
            "2023-10-30 15:46:52,626 max.py[line:93] INFO: max: attack effectiveness 44.927536231884055%.\n",
            "2023-10-30 15:46:52,638 md_at_ma.py[line:120] INFO: Mini batch: 920/1450 | training time in 10 minutes, 5 seconds.\n",
            "2023-10-30 15:46:52,638 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0120 | Train accuracy: 86.29%.\n",
            "2023-10-30 15:46:53,460 max.py[line:93] INFO: max: attack effectiveness 54.666666666666664%.\n",
            "2023-10-30 15:46:53,472 md_at_ma.py[line:120] INFO: Mini batch: 921/1450 | training time in 10 minutes, 6 seconds.\n",
            "2023-10-30 15:46:53,472 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0153 | Train accuracy: 81.77%.\n",
            "2023-10-30 15:46:54,241 max.py[line:93] INFO: max: attack effectiveness 51.470588235294116%.\n",
            "2023-10-30 15:46:54,253 md_at_ma.py[line:120] INFO: Mini batch: 922/1450 | training time in 10 minutes, 7 seconds.\n",
            "2023-10-30 15:46:54,253 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0119 | Train accuracy: 82.14%.\n",
            "2023-10-30 15:46:54,845 max.py[line:93] INFO: max: attack effectiveness 47.45762711864407%.\n",
            "2023-10-30 15:46:54,854 md_at_ma.py[line:120] INFO: Mini batch: 923/1450 | training time in 10 minutes, 7 seconds.\n",
            "2023-10-30 15:46:54,854 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0300 | Train accuracy: 87.70%.\n",
            "2023-10-30 15:46:55,681 max.py[line:93] INFO: max: attack effectiveness 49.333333333333336%.\n",
            "2023-10-30 15:46:55,693 md_at_ma.py[line:120] INFO: Mini batch: 924/1450 | training time in 10 minutes, 8 seconds.\n",
            "2023-10-30 15:46:55,693 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0088 | Train accuracy: 89.16%.\n",
            "2023-10-30 15:46:56,472 max.py[line:93] INFO: max: attack effectiveness 52.17391304347826%.\n",
            "2023-10-30 15:46:56,485 md_at_ma.py[line:120] INFO: Mini batch: 925/1450 | training time in 10 minutes, 9 seconds.\n",
            "2023-10-30 15:46:56,485 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0128 | Train accuracy: 85.79%.\n",
            "2023-10-30 15:46:56,986 max.py[line:93] INFO: max: attack effectiveness 35.9375%.\n",
            "2023-10-30 15:46:56,995 md_at_ma.py[line:120] INFO: Mini batch: 926/1450 | training time in 10 minutes, 9 seconds.\n",
            "2023-10-30 15:46:56,996 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0307 | Train accuracy: 90.10%.\n",
            "2023-10-30 15:46:57,489 max.py[line:93] INFO: max: attack effectiveness 43.54838709677419%.\n",
            "2023-10-30 15:46:57,498 md_at_ma.py[line:120] INFO: Mini batch: 927/1450 | training time in 10 minutes, 10 seconds.\n",
            "2023-10-30 15:46:57,498 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0253 | Train accuracy: 85.79%.\n",
            "2023-10-30 15:46:57,913 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:46:57,917 md_at_ma.py[line:120] INFO: Mini batch: 928/1450 | training time in 10 minutes, 10 seconds.\n",
            "2023-10-30 15:46:57,917 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0064 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:46:57,957 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0199 | Train accuracy: 85.65\n",
            "2023-10-30 15:46:59,990 max.py[line:93] INFO: max: attack effectiveness 59.375%.\n",
            "2023-10-30 15:47:00,982 max.py[line:93] INFO: max: attack effectiveness 58.59375%.\n",
            "2023-10-30 15:47:01,919 max.py[line:93] INFO: max: attack effectiveness 60.15625%.\n",
            "2023-10-30 15:47:02,815 max.py[line:93] INFO: max: attack effectiveness 52.34375%.\n",
            "2023-10-30 15:47:03,459 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:47:04,198 md_at_ma.py[line:165] INFO: \tVal accuracy 68.77% with accuracy 40.86% under attack.\n",
            "2023-10-30 15:47:04,199 md_at_ma.py[line:167] INFO: \tModel select at epoch 32 with validation accuracy 68.77% and accuracy 40.86% under attack.\n",
            "2023-10-30 15:47:05,086 max.py[line:93] INFO: max: attack effectiveness 42.42424242424242%.\n",
            "2023-10-30 15:47:05,099 md_at_ma.py[line:120] INFO: Mini batch: 929/1450 | training time in 10 minutes, 11 seconds.\n",
            "2023-10-30 15:47:05,099 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0230 | Train accuracy: 86.08%.\n",
            "2023-10-30 15:47:05,592 max.py[line:93] INFO: max: attack effectiveness 49.2063492063492%.\n",
            "2023-10-30 15:47:05,601 md_at_ma.py[line:120] INFO: Mini batch: 930/1450 | training time in 10 minutes, 11 seconds.\n",
            "2023-10-30 15:47:05,601 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0294 | Train accuracy: 85.86%.\n",
            "2023-10-30 15:47:06,368 max.py[line:93] INFO: max: attack effectiveness 45.45454545454545%.\n",
            "2023-10-30 15:47:06,380 md_at_ma.py[line:120] INFO: Mini batch: 931/1450 | training time in 10 minutes, 12 seconds.\n",
            "2023-10-30 15:47:06,380 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1041 | Train accuracy: 86.60%.\n",
            "2023-10-30 15:47:07,156 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:47:07,168 md_at_ma.py[line:120] INFO: Mini batch: 932/1450 | training time in 10 minutes, 13 seconds.\n",
            "2023-10-30 15:47:07,169 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0112 | Train accuracy: 86.36%.\n",
            "2023-10-30 15:47:07,943 max.py[line:93] INFO: max: attack effectiveness 52.112676056338024%.\n",
            "2023-10-30 15:47:07,956 md_at_ma.py[line:120] INFO: Mini batch: 933/1450 | training time in 10 minutes, 14 seconds.\n",
            "2023-10-30 15:47:07,956 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0185 | Train accuracy: 81.91%.\n",
            "2023-10-30 15:47:08,781 max.py[line:93] INFO: max: attack effectiveness 51.31578947368421%.\n",
            "2023-10-30 15:47:08,793 md_at_ma.py[line:120] INFO: Mini batch: 934/1450 | training time in 10 minutes, 15 seconds.\n",
            "2023-10-30 15:47:08,793 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0130 | Train accuracy: 85.29%.\n",
            "2023-10-30 15:47:09,291 max.py[line:93] INFO: max: attack effectiveness 50.81967213114754%.\n",
            "2023-10-30 15:47:09,302 md_at_ma.py[line:120] INFO: Mini batch: 935/1450 | training time in 10 minutes, 15 seconds.\n",
            "2023-10-30 15:47:09,302 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0141 | Train accuracy: 84.13%.\n",
            "2023-10-30 15:47:10,107 max.py[line:93] INFO: max: attack effectiveness 49.275362318840585%.\n",
            "2023-10-30 15:47:10,120 md_at_ma.py[line:120] INFO: Mini batch: 936/1450 | training time in 10 minutes, 16 seconds.\n",
            "2023-10-30 15:47:10,120 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0261 | Train accuracy: 82.74%.\n",
            "2023-10-30 15:47:10,622 max.py[line:93] INFO: max: attack effectiveness 53.2258064516129%.\n",
            "2023-10-30 15:47:10,631 md_at_ma.py[line:120] INFO: Mini batch: 937/1450 | training time in 10 minutes, 16 seconds.\n",
            "2023-10-30 15:47:10,631 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0167 | Train accuracy: 83.68%.\n",
            "2023-10-30 15:47:11,254 max.py[line:93] INFO: max: attack effectiveness 68.33333333333333%.\n",
            "2023-10-30 15:47:11,263 md_at_ma.py[line:120] INFO: Mini batch: 938/1450 | training time in 10 minutes, 17 seconds.\n",
            "2023-10-30 15:47:11,263 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0286 | Train accuracy: 79.79%.\n",
            "2023-10-30 15:47:11,868 max.py[line:93] INFO: max: attack effectiveness 64.81481481481481%.\n",
            "2023-10-30 15:47:11,877 md_at_ma.py[line:120] INFO: Mini batch: 939/1450 | training time in 10 minutes, 18 seconds.\n",
            "2023-10-30 15:47:11,877 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0222 | Train accuracy: 83.52%.\n",
            "2023-10-30 15:47:12,381 max.py[line:93] INFO: max: attack effectiveness 76.19047619047619%.\n",
            "2023-10-30 15:47:12,390 md_at_ma.py[line:120] INFO: Mini batch: 940/1450 | training time in 10 minutes, 18 seconds.\n",
            "2023-10-30 15:47:12,390 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0183 | Train accuracy: 80.10%.\n",
            "2023-10-30 15:47:13,122 max.py[line:93] INFO: max: attack effectiveness 53.84615384615385%.\n",
            "2023-10-30 15:47:13,134 md_at_ma.py[line:120] INFO: Mini batch: 941/1450 | training time in 10 minutes, 19 seconds.\n",
            "2023-10-30 15:47:13,134 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0114 | Train accuracy: 85.49%.\n",
            "2023-10-30 15:47:13,903 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:47:13,915 md_at_ma.py[line:120] INFO: Mini batch: 942/1450 | training time in 10 minutes, 20 seconds.\n",
            "2023-10-30 15:47:13,915 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0403 | Train accuracy: 85.57%.\n",
            "2023-10-30 15:47:14,652 max.py[line:93] INFO: max: attack effectiveness 43.07692307692308%.\n",
            "2023-10-30 15:47:14,664 md_at_ma.py[line:120] INFO: Mini batch: 943/1450 | training time in 10 minutes, 20 seconds.\n",
            "2023-10-30 15:47:14,664 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0138 | Train accuracy: 87.05%.\n",
            "2023-10-30 15:47:15,442 max.py[line:93] INFO: max: attack effectiveness 57.74647887323944%.\n",
            "2023-10-30 15:47:15,455 md_at_ma.py[line:120] INFO: Mini batch: 944/1450 | training time in 10 minutes, 21 seconds.\n",
            "2023-10-30 15:47:15,455 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0128 | Train accuracy: 81.91%.\n",
            "2023-10-30 15:47:15,942 max.py[line:93] INFO: max: attack effectiveness 40.625%.\n",
            "2023-10-30 15:47:15,951 md_at_ma.py[line:120] INFO: Mini batch: 945/1450 | training time in 10 minutes, 22 seconds.\n",
            "2023-10-30 15:47:15,951 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0116 | Train accuracy: 86.98%.\n",
            "2023-10-30 15:47:16,718 max.py[line:93] INFO: max: attack effectiveness 44.776119402985074%.\n",
            "2023-10-30 15:47:16,730 md_at_ma.py[line:120] INFO: Mini batch: 946/1450 | training time in 10 minutes, 22 seconds.\n",
            "2023-10-30 15:47:16,730 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0091 | Train accuracy: 86.67%.\n",
            "2023-10-30 15:47:17,216 max.py[line:93] INFO: max: attack effectiveness 51.5625%.\n",
            "2023-10-30 15:47:17,225 md_at_ma.py[line:120] INFO: Mini batch: 947/1450 | training time in 10 minutes, 23 seconds.\n",
            "2023-10-30 15:47:17,225 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0147 | Train accuracy: 83.85%.\n",
            "2023-10-30 15:47:18,044 max.py[line:93] INFO: max: attack effectiveness 56.75675675675676%.\n",
            "2023-10-30 15:47:18,056 md_at_ma.py[line:120] INFO: Mini batch: 948/1450 | training time in 10 minutes, 24 seconds.\n",
            "2023-10-30 15:47:18,057 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0315 | Train accuracy: 80.69%.\n",
            "2023-10-30 15:47:18,831 max.py[line:93] INFO: max: attack effectiveness 47.82608695652174%.\n",
            "2023-10-30 15:47:18,843 md_at_ma.py[line:120] INFO: Mini batch: 949/1450 | training time in 10 minutes, 24 seconds.\n",
            "2023-10-30 15:47:18,843 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0174 | Train accuracy: 84.77%.\n",
            "2023-10-30 15:47:19,668 max.py[line:93] INFO: max: attack effectiveness 53.333333333333336%.\n",
            "2023-10-30 15:47:19,680 md_at_ma.py[line:120] INFO: Mini batch: 950/1450 | training time in 10 minutes, 25 seconds.\n",
            "2023-10-30 15:47:19,681 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0148 | Train accuracy: 84.24%.\n",
            "2023-10-30 15:47:20,456 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:47:20,468 md_at_ma.py[line:120] INFO: Mini batch: 951/1450 | training time in 10 minutes, 26 seconds.\n",
            "2023-10-30 15:47:20,469 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0160 | Train accuracy: 83.67%.\n",
            "2023-10-30 15:47:21,055 max.py[line:93] INFO: max: attack effectiveness 47.45762711864407%.\n",
            "2023-10-30 15:47:21,064 md_at_ma.py[line:120] INFO: Mini batch: 952/1450 | training time in 10 minutes, 27 seconds.\n",
            "2023-10-30 15:47:21,064 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0251 | Train accuracy: 85.56%.\n",
            "2023-10-30 15:47:21,888 max.py[line:93] INFO: max: attack effectiveness 45.33333333333333%.\n",
            "2023-10-30 15:47:21,900 md_at_ma.py[line:120] INFO: Mini batch: 953/1450 | training time in 10 minutes, 27 seconds.\n",
            "2023-10-30 15:47:21,900 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0149 | Train accuracy: 87.19%.\n",
            "2023-10-30 15:47:22,679 max.py[line:93] INFO: max: attack effectiveness 50.72463768115942%.\n",
            "2023-10-30 15:47:22,691 md_at_ma.py[line:120] INFO: Mini batch: 954/1450 | training time in 10 minutes, 28 seconds.\n",
            "2023-10-30 15:47:22,691 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0127 | Train accuracy: 88.32%.\n",
            "2023-10-30 15:47:23,183 max.py[line:93] INFO: max: attack effectiveness 37.5%.\n",
            "2023-10-30 15:47:23,192 md_at_ma.py[line:120] INFO: Mini batch: 955/1450 | training time in 10 minutes, 29 seconds.\n",
            "2023-10-30 15:47:23,192 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0199 | Train accuracy: 89.06%.\n",
            "2023-10-30 15:47:23,679 max.py[line:93] INFO: max: attack effectiveness 41.935483870967744%.\n",
            "2023-10-30 15:47:23,689 md_at_ma.py[line:120] INFO: Mini batch: 956/1450 | training time in 10 minutes, 29 seconds.\n",
            "2023-10-30 15:47:23,689 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0093 | Train accuracy: 90.00%.\n",
            "2023-10-30 15:47:24,085 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:47:24,089 md_at_ma.py[line:120] INFO: Mini batch: 957/1450 | training time in 10 minutes, 30 seconds.\n",
            "2023-10-30 15:47:24,089 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0041 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:47:24,119 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0209 | Train accuracy: 85.05\n",
            "2023-10-30 15:47:26,161 max.py[line:93] INFO: max: attack effectiveness 58.59375%.\n",
            "2023-10-30 15:47:27,071 max.py[line:93] INFO: max: attack effectiveness 57.03125%.\n",
            "2023-10-30 15:47:28,027 max.py[line:93] INFO: max: attack effectiveness 58.59375%.\n",
            "2023-10-30 15:47:28,950 max.py[line:93] INFO: max: attack effectiveness 53.125%.\n",
            "2023-10-30 15:47:29,530 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:47:30,250 md_at_ma.py[line:165] INFO: \tVal accuracy 68.79% with accuracy 41.58% under attack.\n",
            "2023-10-30 15:47:30,250 md_at_ma.py[line:167] INFO: \tModel select at epoch 33 with validation accuracy 68.79% and accuracy 41.58% under attack.\n",
            "2023-10-30 15:47:31,127 max.py[line:93] INFO: max: attack effectiveness 43.93939393939394%.\n",
            "2023-10-30 15:47:31,140 md_at_ma.py[line:120] INFO: Mini batch: 958/1450 | training time in 10 minutes, 30 seconds.\n",
            "2023-10-30 15:47:31,140 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0275 | Train accuracy: 87.63%.\n",
            "2023-10-30 15:47:31,631 max.py[line:93] INFO: max: attack effectiveness 52.38095238095239%.\n",
            "2023-10-30 15:47:31,640 md_at_ma.py[line:120] INFO: Mini batch: 959/1450 | training time in 10 minutes, 31 seconds.\n",
            "2023-10-30 15:47:31,640 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0189 | Train accuracy: 83.77%.\n",
            "2023-10-30 15:47:32,406 max.py[line:93] INFO: max: attack effectiveness 45.45454545454545%.\n",
            "2023-10-30 15:47:32,418 md_at_ma.py[line:120] INFO: Mini batch: 960/1450 | training time in 10 minutes, 32 seconds.\n",
            "2023-10-30 15:47:32,419 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1516 | Train accuracy: 86.08%.\n",
            "2023-10-30 15:47:33,197 max.py[line:93] INFO: max: attack effectiveness 47.14285714285714%.\n",
            "2023-10-30 15:47:33,209 md_at_ma.py[line:120] INFO: Mini batch: 961/1450 | training time in 10 minutes, 32 seconds.\n",
            "2023-10-30 15:47:33,209 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0104 | Train accuracy: 86.87%.\n",
            "2023-10-30 15:47:33,986 max.py[line:93] INFO: max: attack effectiveness 50.70422535211267%.\n",
            "2023-10-30 15:47:33,999 md_at_ma.py[line:120] INFO: Mini batch: 962/1450 | training time in 10 minutes, 33 seconds.\n",
            "2023-10-30 15:47:33,999 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0162 | Train accuracy: 86.93%.\n",
            "2023-10-30 15:47:34,823 max.py[line:93] INFO: max: attack effectiveness 48.68421052631579%.\n",
            "2023-10-30 15:47:34,836 md_at_ma.py[line:120] INFO: Mini batch: 963/1450 | training time in 10 minutes, 34 seconds.\n",
            "2023-10-30 15:47:34,836 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0145 | Train accuracy: 84.31%.\n",
            "2023-10-30 15:47:35,331 max.py[line:93] INFO: max: attack effectiveness 44.26229508196721%.\n",
            "2023-10-30 15:47:35,342 md_at_ma.py[line:120] INFO: Mini batch: 964/1450 | training time in 10 minutes, 34 seconds.\n",
            "2023-10-30 15:47:35,342 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0101 | Train accuracy: 88.89%.\n",
            "2023-10-30 15:47:36,141 max.py[line:93] INFO: max: attack effectiveness 43.47826086956522%.\n",
            "2023-10-30 15:47:36,153 md_at_ma.py[line:120] INFO: Mini batch: 965/1450 | training time in 10 minutes, 35 seconds.\n",
            "2023-10-30 15:47:36,154 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0144 | Train accuracy: 87.31%.\n",
            "2023-10-30 15:47:36,660 max.py[line:93] INFO: max: attack effectiveness 37.096774193548384%.\n",
            "2023-10-30 15:47:36,669 md_at_ma.py[line:120] INFO: Mini batch: 966/1450 | training time in 10 minutes, 36 seconds.\n",
            "2023-10-30 15:47:36,669 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0084 | Train accuracy: 91.58%.\n",
            "2023-10-30 15:47:37,187 max.py[line:93] INFO: max: attack effectiveness 51.66666666666667%.\n",
            "2023-10-30 15:47:37,196 md_at_ma.py[line:120] INFO: Mini batch: 967/1450 | training time in 10 minutes, 36 seconds.\n",
            "2023-10-30 15:47:37,196 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0222 | Train accuracy: 82.45%.\n",
            "2023-10-30 15:47:37,807 max.py[line:93] INFO: max: attack effectiveness 46.2962962962963%.\n",
            "2023-10-30 15:47:37,816 md_at_ma.py[line:120] INFO: Mini batch: 968/1450 | training time in 10 minutes, 37 seconds.\n",
            "2023-10-30 15:47:37,817 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0172 | Train accuracy: 85.16%.\n",
            "2023-10-30 15:47:38,313 max.py[line:93] INFO: max: attack effectiveness 65.07936507936508%.\n",
            "2023-10-30 15:47:38,322 md_at_ma.py[line:120] INFO: Mini batch: 969/1450 | training time in 10 minutes, 37 seconds.\n",
            "2023-10-30 15:47:38,322 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0198 | Train accuracy: 82.20%.\n",
            "2023-10-30 15:47:39,079 max.py[line:93] INFO: max: attack effectiveness 70.76923076923077%.\n",
            "2023-10-30 15:47:39,091 md_at_ma.py[line:120] INFO: Mini batch: 970/1450 | training time in 10 minutes, 38 seconds.\n",
            "2023-10-30 15:47:39,091 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0143 | Train accuracy: 79.27%.\n",
            "2023-10-30 15:47:39,856 max.py[line:93] INFO: max: attack effectiveness 75.75757575757575%.\n",
            "2023-10-30 15:47:39,868 md_at_ma.py[line:120] INFO: Mini batch: 971/1450 | training time in 10 minutes, 39 seconds.\n",
            "2023-10-30 15:47:39,868 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0513 | Train accuracy: 77.32%.\n",
            "2023-10-30 15:47:40,603 max.py[line:93] INFO: max: attack effectiveness 64.61538461538461%.\n",
            "2023-10-30 15:47:40,615 md_at_ma.py[line:120] INFO: Mini batch: 972/1450 | training time in 10 minutes, 40 seconds.\n",
            "2023-10-30 15:47:40,615 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0389 | Train accuracy: 81.35%.\n",
            "2023-10-30 15:47:41,392 max.py[line:93] INFO: max: attack effectiveness 59.154929577464785%.\n",
            "2023-10-30 15:47:41,404 md_at_ma.py[line:120] INFO: Mini batch: 973/1450 | training time in 10 minutes, 40 seconds.\n",
            "2023-10-30 15:47:41,404 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0204 | Train accuracy: 79.40%.\n",
            "2023-10-30 15:47:41,894 max.py[line:93] INFO: max: attack effectiveness 42.1875%.\n",
            "2023-10-30 15:47:41,903 md_at_ma.py[line:120] INFO: Mini batch: 974/1450 | training time in 10 minutes, 41 seconds.\n",
            "2023-10-30 15:47:41,903 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0191 | Train accuracy: 81.77%.\n",
            "2023-10-30 15:47:42,670 max.py[line:93] INFO: max: attack effectiveness 44.776119402985074%.\n",
            "2023-10-30 15:47:42,682 md_at_ma.py[line:120] INFO: Mini batch: 975/1450 | training time in 10 minutes, 42 seconds.\n",
            "2023-10-30 15:47:42,682 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0206 | Train accuracy: 81.54%.\n",
            "2023-10-30 15:47:43,172 max.py[line:93] INFO: max: attack effectiveness 45.3125%.\n",
            "2023-10-30 15:47:43,181 md_at_ma.py[line:120] INFO: Mini batch: 976/1450 | training time in 10 minutes, 42 seconds.\n",
            "2023-10-30 15:47:43,181 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0158 | Train accuracy: 84.90%.\n",
            "2023-10-30 15:47:44,003 max.py[line:93] INFO: max: attack effectiveness 51.35135135135135%.\n",
            "2023-10-30 15:47:44,015 md_at_ma.py[line:120] INFO: Mini batch: 977/1450 | training time in 10 minutes, 43 seconds.\n",
            "2023-10-30 15:47:44,015 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0312 | Train accuracy: 82.18%.\n",
            "2023-10-30 15:47:44,786 max.py[line:93] INFO: max: attack effectiveness 42.028985507246375%.\n",
            "2023-10-30 15:47:44,798 md_at_ma.py[line:120] INFO: Mini batch: 978/1450 | training time in 10 minutes, 44 seconds.\n",
            "2023-10-30 15:47:44,798 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0115 | Train accuracy: 86.29%.\n",
            "2023-10-30 15:47:45,625 max.py[line:93] INFO: max: attack effectiveness 49.333333333333336%.\n",
            "2023-10-30 15:47:45,637 md_at_ma.py[line:120] INFO: Mini batch: 979/1450 | training time in 10 minutes, 44 seconds.\n",
            "2023-10-30 15:47:45,638 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0169 | Train accuracy: 82.76%.\n",
            "2023-10-30 15:47:46,407 max.py[line:93] INFO: max: attack effectiveness 48.529411764705884%.\n",
            "2023-10-30 15:47:46,419 md_at_ma.py[line:120] INFO: Mini batch: 980/1450 | training time in 10 minutes, 45 seconds.\n",
            "2023-10-30 15:47:46,419 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0110 | Train accuracy: 85.71%.\n",
            "2023-10-30 15:47:47,013 max.py[line:93] INFO: max: attack effectiveness 47.45762711864407%.\n",
            "2023-10-30 15:47:47,022 md_at_ma.py[line:120] INFO: Mini batch: 981/1450 | training time in 10 minutes, 46 seconds.\n",
            "2023-10-30 15:47:47,022 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0200 | Train accuracy: 87.17%.\n",
            "2023-10-30 15:47:47,844 max.py[line:93] INFO: max: attack effectiveness 45.33333333333333%.\n",
            "2023-10-30 15:47:47,856 md_at_ma.py[line:120] INFO: Mini batch: 982/1450 | training time in 10 minutes, 47 seconds.\n",
            "2023-10-30 15:47:47,857 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0143 | Train accuracy: 83.25%.\n",
            "2023-10-30 15:47:48,632 max.py[line:93] INFO: max: attack effectiveness 50.72463768115942%.\n",
            "2023-10-30 15:47:48,644 md_at_ma.py[line:120] INFO: Mini batch: 983/1450 | training time in 10 minutes, 47 seconds.\n",
            "2023-10-30 15:47:48,645 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0145 | Train accuracy: 83.25%.\n",
            "2023-10-30 15:47:49,137 max.py[line:93] INFO: max: attack effectiveness 39.0625%.\n",
            "2023-10-30 15:47:49,147 md_at_ma.py[line:120] INFO: Mini batch: 984/1450 | training time in 10 minutes, 48 seconds.\n",
            "2023-10-30 15:47:49,147 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0158 | Train accuracy: 92.19%.\n",
            "2023-10-30 15:47:49,646 max.py[line:93] INFO: max: attack effectiveness 43.54838709677419%.\n",
            "2023-10-30 15:47:49,656 md_at_ma.py[line:120] INFO: Mini batch: 985/1450 | training time in 10 minutes, 48 seconds.\n",
            "2023-10-30 15:47:49,656 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0158 | Train accuracy: 87.89%.\n",
            "2023-10-30 15:47:50,047 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:47:50,052 md_at_ma.py[line:120] INFO: Mini batch: 986/1450 | training time in 10 minutes, 49 seconds.\n",
            "2023-10-30 15:47:50,052 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0050 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:47:50,088 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0230 | Train accuracy: 84.79\n",
            "2023-10-30 15:47:52,262 max.py[line:93] INFO: max: attack effectiveness 58.59375%.\n",
            "2023-10-30 15:47:53,234 max.py[line:93] INFO: max: attack effectiveness 58.59375%.\n",
            "2023-10-30 15:47:54,162 max.py[line:93] INFO: max: attack effectiveness 59.375%.\n",
            "2023-10-30 15:47:55,127 max.py[line:93] INFO: max: attack effectiveness 53.90625%.\n",
            "2023-10-30 15:47:55,780 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:47:56,555 md_at_ma.py[line:165] INFO: \tVal accuracy 68.54% with accuracy 40.86% under attack.\n",
            "2023-10-30 15:47:56,555 md_at_ma.py[line:167] INFO: \tModel select at epoch 33 with validation accuracy 68.79% and accuracy 41.58% under attack.\n",
            "2023-10-30 15:47:57,438 max.py[line:93] INFO: max: attack effectiveness 42.42424242424242%.\n",
            "2023-10-30 15:47:57,451 md_at_ma.py[line:120] INFO: Mini batch: 987/1450 | training time in 10 minutes, 50 seconds.\n",
            "2023-10-30 15:47:57,451 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0219 | Train accuracy: 86.60%.\n",
            "2023-10-30 15:47:57,955 max.py[line:93] INFO: max: attack effectiveness 52.38095238095239%.\n",
            "2023-10-30 15:47:57,964 md_at_ma.py[line:120] INFO: Mini batch: 988/1450 | training time in 10 minutes, 50 seconds.\n",
            "2023-10-30 15:47:57,965 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0633 | Train accuracy: 84.29%.\n",
            "2023-10-30 15:47:58,731 max.py[line:93] INFO: max: attack effectiveness 45.45454545454545%.\n",
            "2023-10-30 15:47:58,743 md_at_ma.py[line:120] INFO: Mini batch: 989/1450 | training time in 10 minutes, 51 seconds.\n",
            "2023-10-30 15:47:58,744 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0140 | Train accuracy: 89.18%.\n",
            "2023-10-30 15:47:59,522 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:47:59,534 md_at_ma.py[line:120] INFO: Mini batch: 990/1450 | training time in 10 minutes, 52 seconds.\n",
            "2023-10-30 15:47:59,534 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0092 | Train accuracy: 85.35%.\n",
            "2023-10-30 15:48:00,315 max.py[line:93] INFO: max: attack effectiveness 61.97183098591549%.\n",
            "2023-10-30 15:48:00,328 md_at_ma.py[line:120] INFO: Mini batch: 991/1450 | training time in 10 minutes, 52 seconds.\n",
            "2023-10-30 15:48:00,328 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0135 | Train accuracy: 82.91%.\n",
            "2023-10-30 15:48:01,160 max.py[line:93] INFO: max: attack effectiveness 56.57894736842105%.\n",
            "2023-10-30 15:48:01,172 md_at_ma.py[line:120] INFO: Mini batch: 992/1450 | training time in 10 minutes, 53 seconds.\n",
            "2023-10-30 15:48:01,172 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0269 | Train accuracy: 80.39%.\n",
            "2023-10-30 15:48:01,656 max.py[line:93] INFO: max: attack effectiveness 52.459016393442624%.\n",
            "2023-10-30 15:48:01,665 md_at_ma.py[line:120] INFO: Mini batch: 993/1450 | training time in 10 minutes, 54 seconds.\n",
            "2023-10-30 15:48:01,665 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0147 | Train accuracy: 83.60%.\n",
            "2023-10-30 15:48:02,448 max.py[line:93] INFO: max: attack effectiveness 53.62318840579711%.\n",
            "2023-10-30 15:48:02,461 md_at_ma.py[line:120] INFO: Mini batch: 994/1450 | training time in 10 minutes, 54 seconds.\n",
            "2023-10-30 15:48:02,461 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0292 | Train accuracy: 83.76%.\n",
            "2023-10-30 15:48:02,969 max.py[line:93] INFO: max: attack effectiveness 48.38709677419355%.\n",
            "2023-10-30 15:48:02,978 md_at_ma.py[line:120] INFO: Mini batch: 995/1450 | training time in 10 minutes, 55 seconds.\n",
            "2023-10-30 15:48:02,978 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0302 | Train accuracy: 87.37%.\n",
            "2023-10-30 15:48:03,462 max.py[line:93] INFO: max: attack effectiveness 55.00000000000001%.\n",
            "2023-10-30 15:48:03,471 md_at_ma.py[line:120] INFO: Mini batch: 996/1450 | training time in 10 minutes, 55 seconds.\n",
            "2023-10-30 15:48:03,471 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0216 | Train accuracy: 86.17%.\n",
            "2023-10-30 15:48:04,073 max.py[line:93] INFO: max: attack effectiveness 40.74074074074074%.\n",
            "2023-10-30 15:48:04,082 md_at_ma.py[line:120] INFO: Mini batch: 997/1450 | training time in 10 minutes, 56 seconds.\n",
            "2023-10-30 15:48:04,083 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0118 | Train accuracy: 89.01%.\n",
            "2023-10-30 15:48:04,603 max.py[line:93] INFO: max: attack effectiveness 53.96825396825397%.\n",
            "2023-10-30 15:48:04,612 md_at_ma.py[line:120] INFO: Mini batch: 998/1450 | training time in 10 minutes, 56 seconds.\n",
            "2023-10-30 15:48:04,612 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0225 | Train accuracy: 85.86%.\n",
            "2023-10-30 15:48:05,375 max.py[line:93] INFO: max: attack effectiveness 55.38461538461539%.\n",
            "2023-10-30 15:48:05,387 md_at_ma.py[line:120] INFO: Mini batch: 999/1450 | training time in 10 minutes, 57 seconds.\n",
            "2023-10-30 15:48:05,387 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0105 | Train accuracy: 86.53%.\n",
            "2023-10-30 15:48:06,154 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:48:06,166 md_at_ma.py[line:120] INFO: Mini batch: 1000/1450 | training time in 10 minutes, 58 seconds.\n",
            "2023-10-30 15:48:06,166 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0465 | Train accuracy: 86.08%.\n",
            "2023-10-30 15:48:06,903 max.py[line:93] INFO: max: attack effectiveness 41.53846153846154%.\n",
            "2023-10-30 15:48:06,916 md_at_ma.py[line:120] INFO: Mini batch: 1001/1450 | training time in 10 minutes, 59 seconds.\n",
            "2023-10-30 15:48:06,916 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0153 | Train accuracy: 88.08%.\n",
            "2023-10-30 15:48:07,696 max.py[line:93] INFO: max: attack effectiveness 53.52112676056338%.\n",
            "2023-10-30 15:48:07,708 md_at_ma.py[line:120] INFO: Mini batch: 1002/1450 | training time in 10 minutes, 59 seconds.\n",
            "2023-10-30 15:48:07,708 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0114 | Train accuracy: 83.92%.\n",
            "2023-10-30 15:48:08,196 max.py[line:93] INFO: max: attack effectiveness 40.625%.\n",
            "2023-10-30 15:48:08,205 md_at_ma.py[line:120] INFO: Mini batch: 1003/1450 | training time in 11 minutes, 0 seconds.\n",
            "2023-10-30 15:48:08,205 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0111 | Train accuracy: 88.02%.\n",
            "2023-10-30 15:48:08,974 max.py[line:93] INFO: max: attack effectiveness 44.776119402985074%.\n",
            "2023-10-30 15:48:08,986 md_at_ma.py[line:120] INFO: Mini batch: 1004/1450 | training time in 11 minutes, 1 seconds.\n",
            "2023-10-30 15:48:08,986 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0098 | Train accuracy: 87.18%.\n",
            "2023-10-30 15:48:09,476 max.py[line:93] INFO: max: attack effectiveness 51.5625%.\n",
            "2023-10-30 15:48:09,485 md_at_ma.py[line:120] INFO: Mini batch: 1005/1450 | training time in 11 minutes, 1 seconds.\n",
            "2023-10-30 15:48:09,485 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0121 | Train accuracy: 84.38%.\n",
            "2023-10-30 15:48:10,302 max.py[line:93] INFO: max: attack effectiveness 55.4054054054054%.\n",
            "2023-10-30 15:48:10,315 md_at_ma.py[line:120] INFO: Mini batch: 1006/1450 | training time in 11 minutes, 2 seconds.\n",
            "2023-10-30 15:48:10,315 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0268 | Train accuracy: 80.69%.\n",
            "2023-10-30 15:48:11,087 max.py[line:93] INFO: max: attack effectiveness 46.3768115942029%.\n",
            "2023-10-30 15:48:11,099 md_at_ma.py[line:120] INFO: Mini batch: 1007/1450 | training time in 11 minutes, 3 seconds.\n",
            "2023-10-30 15:48:11,100 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0109 | Train accuracy: 86.29%.\n",
            "2023-10-30 15:48:11,925 max.py[line:93] INFO: max: attack effectiveness 53.333333333333336%.\n",
            "2023-10-30 15:48:11,937 md_at_ma.py[line:120] INFO: Mini batch: 1008/1450 | training time in 11 minutes, 4 seconds.\n",
            "2023-10-30 15:48:11,938 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0208 | Train accuracy: 83.74%.\n",
            "2023-10-30 15:48:12,707 max.py[line:93] INFO: max: attack effectiveness 48.529411764705884%.\n",
            "2023-10-30 15:48:12,719 md_at_ma.py[line:120] INFO: Mini batch: 1009/1450 | training time in 11 minutes, 4 seconds.\n",
            "2023-10-30 15:48:12,719 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0116 | Train accuracy: 86.22%.\n",
            "2023-10-30 15:48:13,304 max.py[line:93] INFO: max: attack effectiveness 49.152542372881356%.\n",
            "2023-10-30 15:48:13,313 md_at_ma.py[line:120] INFO: Mini batch: 1010/1450 | training time in 11 minutes, 5 seconds.\n",
            "2023-10-30 15:48:13,313 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0177 | Train accuracy: 88.24%.\n",
            "2023-10-30 15:48:14,137 max.py[line:93] INFO: max: attack effectiveness 46.666666666666664%.\n",
            "2023-10-30 15:48:14,150 md_at_ma.py[line:120] INFO: Mini batch: 1011/1450 | training time in 11 minutes, 6 seconds.\n",
            "2023-10-30 15:48:14,150 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0095 | Train accuracy: 84.73%.\n",
            "2023-10-30 15:48:14,927 max.py[line:93] INFO: max: attack effectiveness 50.72463768115942%.\n",
            "2023-10-30 15:48:14,940 md_at_ma.py[line:120] INFO: Mini batch: 1012/1450 | training time in 11 minutes, 7 seconds.\n",
            "2023-10-30 15:48:14,940 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0144 | Train accuracy: 82.74%.\n",
            "2023-10-30 15:48:15,431 max.py[line:93] INFO: max: attack effectiveness 39.0625%.\n",
            "2023-10-30 15:48:15,440 md_at_ma.py[line:120] INFO: Mini batch: 1013/1450 | training time in 11 minutes, 7 seconds.\n",
            "2023-10-30 15:48:15,441 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0231 | Train accuracy: 89.58%.\n",
            "2023-10-30 15:48:15,936 max.py[line:93] INFO: max: attack effectiveness 41.935483870967744%.\n",
            "2023-10-30 15:48:15,945 md_at_ma.py[line:120] INFO: Mini batch: 1014/1450 | training time in 11 minutes, 8 seconds.\n",
            "2023-10-30 15:48:15,945 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0105 | Train accuracy: 87.89%.\n",
            "2023-10-30 15:48:16,342 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:48:16,346 md_at_ma.py[line:120] INFO: Mini batch: 1015/1450 | training time in 11 minutes, 8 seconds.\n",
            "2023-10-30 15:48:16,346 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0054 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:48:16,383 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0188 | Train accuracy: 85.80\n",
            "2023-10-30 15:48:18,552 max.py[line:93] INFO: max: attack effectiveness 57.8125%.\n",
            "2023-10-30 15:48:19,633 max.py[line:93] INFO: max: attack effectiveness 58.59375%.\n",
            "2023-10-30 15:48:20,612 max.py[line:93] INFO: max: attack effectiveness 58.59375%.\n",
            "2023-10-30 15:48:21,557 max.py[line:93] INFO: max: attack effectiveness 51.5625%.\n",
            "2023-10-30 15:48:22,179 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:48:22,743 md_at_ma.py[line:165] INFO: \tVal accuracy 68.64% with accuracy 41.76% under attack.\n",
            "2023-10-30 15:48:22,743 md_at_ma.py[line:167] INFO: \tModel select at epoch 33 with validation accuracy 68.79% and accuracy 41.58% under attack.\n",
            "2023-10-30 15:48:23,624 max.py[line:93] INFO: max: attack effectiveness 42.42424242424242%.\n",
            "2023-10-30 15:48:23,637 md_at_ma.py[line:120] INFO: Mini batch: 1016/1450 | training time in 11 minutes, 9 seconds.\n",
            "2023-10-30 15:48:23,637 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0169 | Train accuracy: 86.08%.\n",
            "2023-10-30 15:48:24,121 max.py[line:93] INFO: max: attack effectiveness 47.61904761904761%.\n",
            "2023-10-30 15:48:24,129 md_at_ma.py[line:120] INFO: Mini batch: 1017/1450 | training time in 11 minutes, 9 seconds.\n",
            "2023-10-30 15:48:24,130 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0754 | Train accuracy: 85.34%.\n",
            "2023-10-30 15:48:24,895 max.py[line:93] INFO: max: attack effectiveness 45.45454545454545%.\n",
            "2023-10-30 15:48:24,907 md_at_ma.py[line:120] INFO: Mini batch: 1018/1450 | training time in 11 minutes, 10 seconds.\n",
            "2023-10-30 15:48:24,907 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.1354 | Train accuracy: 85.05%.\n",
            "2023-10-30 15:48:25,686 max.py[line:93] INFO: max: attack effectiveness 48.57142857142857%.\n",
            "2023-10-30 15:48:25,698 md_at_ma.py[line:120] INFO: Mini batch: 1019/1450 | training time in 11 minutes, 11 seconds.\n",
            "2023-10-30 15:48:25,698 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0096 | Train accuracy: 86.87%.\n",
            "2023-10-30 15:48:26,473 max.py[line:93] INFO: max: attack effectiveness 49.29577464788733%.\n",
            "2023-10-30 15:48:26,485 md_at_ma.py[line:120] INFO: Mini batch: 1020/1450 | training time in 11 minutes, 11 seconds.\n",
            "2023-10-30 15:48:26,485 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0123 | Train accuracy: 83.42%.\n",
            "2023-10-30 15:48:27,318 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:48:27,330 md_at_ma.py[line:120] INFO: Mini batch: 1021/1450 | training time in 11 minutes, 12 seconds.\n",
            "2023-10-30 15:48:27,330 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0117 | Train accuracy: 85.78%.\n",
            "2023-10-30 15:48:27,816 max.py[line:93] INFO: max: attack effectiveness 44.26229508196721%.\n",
            "2023-10-30 15:48:27,825 md_at_ma.py[line:120] INFO: Mini batch: 1022/1450 | training time in 11 minutes, 13 seconds.\n",
            "2023-10-30 15:48:27,825 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0108 | Train accuracy: 88.36%.\n",
            "2023-10-30 15:48:28,603 max.py[line:93] INFO: max: attack effectiveness 43.47826086956522%.\n",
            "2023-10-30 15:48:28,615 md_at_ma.py[line:120] INFO: Mini batch: 1023/1450 | training time in 11 minutes, 14 seconds.\n",
            "2023-10-30 15:48:28,615 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0126 | Train accuracy: 87.82%.\n",
            "2023-10-30 15:48:29,112 max.py[line:93] INFO: max: attack effectiveness 37.096774193548384%.\n",
            "2023-10-30 15:48:29,121 md_at_ma.py[line:120] INFO: Mini batch: 1024/1450 | training time in 11 minutes, 14 seconds.\n",
            "2023-10-30 15:48:29,121 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0090 | Train accuracy: 88.42%.\n",
            "2023-10-30 15:48:29,638 max.py[line:93] INFO: max: attack effectiveness 53.333333333333336%.\n",
            "2023-10-30 15:48:29,647 md_at_ma.py[line:120] INFO: Mini batch: 1025/1450 | training time in 11 minutes, 15 seconds.\n",
            "2023-10-30 15:48:29,648 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0203 | Train accuracy: 86.70%.\n",
            "2023-10-30 15:48:30,217 max.py[line:93] INFO: max: attack effectiveness 44.44444444444444%.\n",
            "2023-10-30 15:48:30,226 md_at_ma.py[line:120] INFO: Mini batch: 1026/1450 | training time in 11 minutes, 15 seconds.\n",
            "2023-10-30 15:48:30,226 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0100 | Train accuracy: 89.56%.\n",
            "2023-10-30 15:48:30,756 max.py[line:93] INFO: max: attack effectiveness 55.55555555555556%.\n",
            "2023-10-30 15:48:30,765 md_at_ma.py[line:120] INFO: Mini batch: 1027/1450 | training time in 11 minutes, 16 seconds.\n",
            "2023-10-30 15:48:30,766 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0156 | Train accuracy: 83.77%.\n",
            "2023-10-30 15:48:31,535 max.py[line:93] INFO: max: attack effectiveness 53.84615384615385%.\n",
            "2023-10-30 15:48:31,547 md_at_ma.py[line:120] INFO: Mini batch: 1028/1450 | training time in 11 minutes, 16 seconds.\n",
            "2023-10-30 15:48:31,548 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0087 | Train accuracy: 88.60%.\n",
            "2023-10-30 15:48:32,313 max.py[line:93] INFO: max: attack effectiveness 53.03030303030303%.\n",
            "2023-10-30 15:48:32,325 md_at_ma.py[line:120] INFO: Mini batch: 1029/1450 | training time in 11 minutes, 17 seconds.\n",
            "2023-10-30 15:48:32,325 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0377 | Train accuracy: 84.02%.\n",
            "2023-10-30 15:48:33,058 max.py[line:93] INFO: max: attack effectiveness 43.07692307692308%.\n",
            "2023-10-30 15:48:33,070 md_at_ma.py[line:120] INFO: Mini batch: 1030/1450 | training time in 11 minutes, 18 seconds.\n",
            "2023-10-30 15:48:33,070 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0111 | Train accuracy: 88.60%.\n",
            "2023-10-30 15:48:33,847 max.py[line:93] INFO: max: attack effectiveness 46.478873239436616%.\n",
            "2023-10-30 15:48:33,859 md_at_ma.py[line:120] INFO: Mini batch: 1031/1450 | training time in 11 minutes, 19 seconds.\n",
            "2023-10-30 15:48:33,859 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0131 | Train accuracy: 85.93%.\n",
            "2023-10-30 15:48:34,346 max.py[line:93] INFO: max: attack effectiveness 35.9375%.\n",
            "2023-10-30 15:48:34,354 md_at_ma.py[line:120] INFO: Mini batch: 1032/1450 | training time in 11 minutes, 19 seconds.\n",
            "2023-10-30 15:48:34,355 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0141 | Train accuracy: 89.06%.\n",
            "2023-10-30 15:48:35,123 max.py[line:93] INFO: max: attack effectiveness 41.7910447761194%.\n",
            "2023-10-30 15:48:35,135 md_at_ma.py[line:120] INFO: Mini batch: 1033/1450 | training time in 11 minutes, 20 seconds.\n",
            "2023-10-30 15:48:35,135 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0119 | Train accuracy: 87.18%.\n",
            "2023-10-30 15:48:35,620 max.py[line:93] INFO: max: attack effectiveness 46.875%.\n",
            "2023-10-30 15:48:35,629 md_at_ma.py[line:120] INFO: Mini batch: 1034/1450 | training time in 11 minutes, 20 seconds.\n",
            "2023-10-30 15:48:35,629 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0109 | Train accuracy: 87.50%.\n",
            "2023-10-30 15:48:36,450 max.py[line:93] INFO: max: attack effectiveness 54.054054054054056%.\n",
            "2023-10-30 15:48:36,462 md_at_ma.py[line:120] INFO: Mini batch: 1035/1450 | training time in 11 minutes, 21 seconds.\n",
            "2023-10-30 15:48:36,462 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0303 | Train accuracy: 81.68%.\n",
            "2023-10-30 15:48:37,239 max.py[line:93] INFO: max: attack effectiveness 43.47826086956522%.\n",
            "2023-10-30 15:48:37,252 md_at_ma.py[line:120] INFO: Mini batch: 1036/1450 | training time in 11 minutes, 22 seconds.\n",
            "2023-10-30 15:48:37,252 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0115 | Train accuracy: 87.31%.\n",
            "2023-10-30 15:48:38,078 max.py[line:93] INFO: max: attack effectiveness 53.333333333333336%.\n",
            "2023-10-30 15:48:38,090 md_at_ma.py[line:120] INFO: Mini batch: 1037/1450 | training time in 11 minutes, 23 seconds.\n",
            "2023-10-30 15:48:38,090 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0187 | Train accuracy: 83.74%.\n",
            "2023-10-30 15:48:38,862 max.py[line:93] INFO: max: attack effectiveness 48.529411764705884%.\n",
            "2023-10-30 15:48:38,874 md_at_ma.py[line:120] INFO: Mini batch: 1038/1450 | training time in 11 minutes, 24 seconds.\n",
            "2023-10-30 15:48:38,875 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0112 | Train accuracy: 83.67%.\n",
            "2023-10-30 15:48:39,468 max.py[line:93] INFO: max: attack effectiveness 50.847457627118644%.\n",
            "2023-10-30 15:48:39,477 md_at_ma.py[line:120] INFO: Mini batch: 1039/1450 | training time in 11 minutes, 24 seconds.\n",
            "2023-10-30 15:48:39,477 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0263 | Train accuracy: 85.56%.\n",
            "2023-10-30 15:48:40,300 max.py[line:93] INFO: max: attack effectiveness 52.0%.\n",
            "2023-10-30 15:48:40,312 md_at_ma.py[line:120] INFO: Mini batch: 1040/1450 | training time in 11 minutes, 25 seconds.\n",
            "2023-10-30 15:48:40,312 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0129 | Train accuracy: 82.76%.\n",
            "2023-10-30 15:48:41,084 max.py[line:93] INFO: max: attack effectiveness 50.72463768115942%.\n",
            "2023-10-30 15:48:41,096 md_at_ma.py[line:120] INFO: Mini batch: 1041/1450 | training time in 11 minutes, 26 seconds.\n",
            "2023-10-30 15:48:41,096 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0144 | Train accuracy: 84.26%.\n",
            "2023-10-30 15:48:41,597 max.py[line:93] INFO: max: attack effectiveness 37.5%.\n",
            "2023-10-30 15:48:41,606 md_at_ma.py[line:120] INFO: Mini batch: 1042/1450 | training time in 11 minutes, 26 seconds.\n",
            "2023-10-30 15:48:41,607 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0268 | Train accuracy: 89.58%.\n",
            "2023-10-30 15:48:42,092 max.py[line:93] INFO: max: attack effectiveness 41.935483870967744%.\n",
            "2023-10-30 15:48:42,101 md_at_ma.py[line:120] INFO: Mini batch: 1043/1450 | training time in 11 minutes, 27 seconds.\n",
            "2023-10-30 15:48:42,101 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0091 | Train accuracy: 88.95%.\n",
            "2023-10-30 15:48:42,494 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:48:42,499 md_at_ma.py[line:120] INFO: Mini batch: 1044/1450 | training time in 11 minutes, 27 seconds.\n",
            "2023-10-30 15:48:42,499 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0062 | Train accuracy: 84.21%.\n",
            "2023-10-30 15:48:42,530 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0212 | Train accuracy: 86.20\n",
            "2023-10-30 15:48:44,974 max.py[line:93] INFO: max: attack effectiveness 57.8125%.\n",
            "2023-10-30 15:48:46,051 max.py[line:93] INFO: max: attack effectiveness 55.46875%.\n",
            "2023-10-30 15:48:46,946 max.py[line:93] INFO: max: attack effectiveness 57.8125%.\n",
            "2023-10-30 15:48:47,959 max.py[line:93] INFO: max: attack effectiveness 52.34375%.\n",
            "2023-10-30 15:48:48,548 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:48:49,333 md_at_ma.py[line:165] INFO: \tVal accuracy 68.99% with accuracy 42.47% under attack.\n",
            "2023-10-30 15:48:49,334 md_at_ma.py[line:167] INFO: \tModel select at epoch 36 with validation accuracy 68.99% and accuracy 42.47% under attack.\n",
            "2023-10-30 15:48:50,203 max.py[line:93] INFO: max: attack effectiveness 43.93939393939394%.\n",
            "2023-10-30 15:48:50,216 md_at_ma.py[line:120] INFO: Mini batch: 1045/1450 | training time in 11 minutes, 28 seconds.\n",
            "2023-10-30 15:48:50,216 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0205 | Train accuracy: 87.63%.\n",
            "2023-10-30 15:48:50,706 max.py[line:93] INFO: max: attack effectiveness 44.44444444444444%.\n",
            "2023-10-30 15:48:50,715 md_at_ma.py[line:120] INFO: Mini batch: 1046/1450 | training time in 11 minutes, 28 seconds.\n",
            "2023-10-30 15:48:50,715 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0343 | Train accuracy: 86.39%.\n",
            "2023-10-30 15:48:51,484 max.py[line:93] INFO: max: attack effectiveness 43.93939393939394%.\n",
            "2023-10-30 15:48:51,496 md_at_ma.py[line:120] INFO: Mini batch: 1047/1450 | training time in 11 minutes, 29 seconds.\n",
            "2023-10-30 15:48:51,496 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0166 | Train accuracy: 87.11%.\n",
            "2023-10-30 15:48:52,269 max.py[line:93] INFO: max: attack effectiveness 47.14285714285714%.\n",
            "2023-10-30 15:48:52,281 md_at_ma.py[line:120] INFO: Mini batch: 1048/1450 | training time in 11 minutes, 30 seconds.\n",
            "2023-10-30 15:48:52,281 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0104 | Train accuracy: 85.86%.\n",
            "2023-10-30 15:48:53,056 max.py[line:93] INFO: max: attack effectiveness 50.70422535211267%.\n",
            "2023-10-30 15:48:53,068 md_at_ma.py[line:120] INFO: Mini batch: 1049/1450 | training time in 11 minutes, 31 seconds.\n",
            "2023-10-30 15:48:53,068 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0147 | Train accuracy: 84.42%.\n",
            "2023-10-30 15:48:53,892 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:48:53,904 md_at_ma.py[line:120] INFO: Mini batch: 1050/1450 | training time in 11 minutes, 31 seconds.\n",
            "2023-10-30 15:48:53,904 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0099 | Train accuracy: 87.75%.\n",
            "2023-10-30 15:48:54,382 max.py[line:93] INFO: max: attack effectiveness 44.26229508196721%.\n",
            "2023-10-30 15:48:54,391 md_at_ma.py[line:120] INFO: Mini batch: 1051/1450 | training time in 11 minutes, 32 seconds.\n",
            "2023-10-30 15:48:54,391 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0097 | Train accuracy: 89.95%.\n",
            "2023-10-30 15:48:55,177 max.py[line:93] INFO: max: attack effectiveness 42.028985507246375%.\n",
            "2023-10-30 15:48:55,189 md_at_ma.py[line:120] INFO: Mini batch: 1052/1450 | training time in 11 minutes, 33 seconds.\n",
            "2023-10-30 15:48:55,190 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0131 | Train accuracy: 87.31%.\n",
            "2023-10-30 15:48:55,683 max.py[line:93] INFO: max: attack effectiveness 45.16129032258064%.\n",
            "2023-10-30 15:48:55,692 md_at_ma.py[line:120] INFO: Mini batch: 1053/1450 | training time in 11 minutes, 33 seconds.\n",
            "2023-10-30 15:48:55,692 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0114 | Train accuracy: 90.00%.\n",
            "2023-10-30 15:48:56,187 max.py[line:93] INFO: max: attack effectiveness 51.66666666666667%.\n",
            "2023-10-30 15:48:56,196 md_at_ma.py[line:120] INFO: Mini batch: 1054/1450 | training time in 11 minutes, 34 seconds.\n",
            "2023-10-30 15:48:56,197 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0195 | Train accuracy: 86.70%.\n",
            "2023-10-30 15:48:56,768 max.py[line:93] INFO: max: attack effectiveness 40.74074074074074%.\n",
            "2023-10-30 15:48:56,777 md_at_ma.py[line:120] INFO: Mini batch: 1055/1450 | training time in 11 minutes, 34 seconds.\n",
            "2023-10-30 15:48:56,777 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0110 | Train accuracy: 89.56%.\n",
            "2023-10-30 15:48:57,278 max.py[line:93] INFO: max: attack effectiveness 53.96825396825397%.\n",
            "2023-10-30 15:48:57,287 md_at_ma.py[line:120] INFO: Mini batch: 1056/1450 | training time in 11 minutes, 35 seconds.\n",
            "2023-10-30 15:48:57,287 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0100 | Train accuracy: 89.53%.\n",
            "2023-10-30 15:48:58,047 max.py[line:93] INFO: max: attack effectiveness 55.38461538461539%.\n",
            "2023-10-30 15:48:58,059 md_at_ma.py[line:120] INFO: Mini batch: 1057/1450 | training time in 11 minutes, 35 seconds.\n",
            "2023-10-30 15:48:58,060 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0111 | Train accuracy: 84.97%.\n",
            "2023-10-30 15:48:58,824 max.py[line:93] INFO: max: attack effectiveness 46.96969696969697%.\n",
            "2023-10-30 15:48:58,836 md_at_ma.py[line:120] INFO: Mini batch: 1058/1450 | training time in 11 minutes, 36 seconds.\n",
            "2023-10-30 15:48:58,836 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0453 | Train accuracy: 87.11%.\n",
            "2023-10-30 15:48:59,577 max.py[line:93] INFO: max: attack effectiveness 43.07692307692308%.\n",
            "2023-10-30 15:48:59,589 md_at_ma.py[line:120] INFO: Mini batch: 1059/1450 | training time in 11 minutes, 37 seconds.\n",
            "2023-10-30 15:48:59,590 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0106 | Train accuracy: 90.16%.\n",
            "2023-10-30 15:49:00,365 max.py[line:93] INFO: max: attack effectiveness 53.52112676056338%.\n",
            "2023-10-30 15:49:00,378 md_at_ma.py[line:120] INFO: Mini batch: 1060/1450 | training time in 11 minutes, 38 seconds.\n",
            "2023-10-30 15:49:00,378 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0115 | Train accuracy: 83.42%.\n",
            "2023-10-30 15:49:00,870 max.py[line:93] INFO: max: attack effectiveness 35.9375%.\n",
            "2023-10-30 15:49:00,879 md_at_ma.py[line:120] INFO: Mini batch: 1061/1450 | training time in 11 minutes, 38 seconds.\n",
            "2023-10-30 15:49:00,880 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0099 | Train accuracy: 91.15%.\n",
            "2023-10-30 15:49:01,654 max.py[line:93] INFO: max: attack effectiveness 38.80597014925373%.\n",
            "2023-10-30 15:49:01,666 md_at_ma.py[line:120] INFO: Mini batch: 1062/1450 | training time in 11 minutes, 39 seconds.\n",
            "2023-10-30 15:49:01,667 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0096 | Train accuracy: 88.72%.\n",
            "2023-10-30 15:49:02,158 max.py[line:93] INFO: max: attack effectiveness 45.3125%.\n",
            "2023-10-30 15:49:02,167 md_at_ma.py[line:120] INFO: Mini batch: 1063/1450 | training time in 11 minutes, 39 seconds.\n",
            "2023-10-30 15:49:02,167 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0125 | Train accuracy: 88.54%.\n",
            "2023-10-30 15:49:02,987 max.py[line:93] INFO: max: attack effectiveness 51.35135135135135%.\n",
            "2023-10-30 15:49:03,000 md_at_ma.py[line:120] INFO: Mini batch: 1064/1450 | training time in 11 minutes, 40 seconds.\n",
            "2023-10-30 15:49:03,000 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0203 | Train accuracy: 83.66%.\n",
            "2023-10-30 15:49:03,771 max.py[line:93] INFO: max: attack effectiveness 39.130434782608695%.\n",
            "2023-10-30 15:49:03,783 md_at_ma.py[line:120] INFO: Mini batch: 1065/1450 | training time in 11 minutes, 41 seconds.\n",
            "2023-10-30 15:49:03,783 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0111 | Train accuracy: 87.82%.\n",
            "2023-10-30 15:49:04,607 max.py[line:93] INFO: max: attack effectiveness 49.333333333333336%.\n",
            "2023-10-30 15:49:04,619 md_at_ma.py[line:120] INFO: Mini batch: 1066/1450 | training time in 11 minutes, 42 seconds.\n",
            "2023-10-30 15:49:04,619 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0165 | Train accuracy: 82.76%.\n",
            "2023-10-30 15:49:05,406 max.py[line:93] INFO: max: attack effectiveness 48.529411764705884%.\n",
            "2023-10-30 15:49:05,419 md_at_ma.py[line:120] INFO: Mini batch: 1067/1450 | training time in 11 minutes, 43 seconds.\n",
            "2023-10-30 15:49:05,419 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0119 | Train accuracy: 83.16%.\n",
            "2023-10-30 15:49:06,031 max.py[line:93] INFO: max: attack effectiveness 45.76271186440678%.\n",
            "2023-10-30 15:49:06,040 md_at_ma.py[line:120] INFO: Mini batch: 1068/1450 | training time in 11 minutes, 43 seconds.\n",
            "2023-10-30 15:49:06,040 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0329 | Train accuracy: 85.56%.\n",
            "2023-10-30 15:49:06,862 max.py[line:93] INFO: max: attack effectiveness 45.33333333333333%.\n",
            "2023-10-30 15:49:06,874 md_at_ma.py[line:120] INFO: Mini batch: 1069/1450 | training time in 11 minutes, 44 seconds.\n",
            "2023-10-30 15:49:06,874 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0200 | Train accuracy: 84.24%.\n",
            "2023-10-30 15:49:07,647 max.py[line:93] INFO: max: attack effectiveness 49.275362318840585%.\n",
            "2023-10-30 15:49:07,659 md_at_ma.py[line:120] INFO: Mini batch: 1070/1450 | training time in 11 minutes, 45 seconds.\n",
            "2023-10-30 15:49:07,660 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0155 | Train accuracy: 84.77%.\n",
            "2023-10-30 15:49:08,166 max.py[line:93] INFO: max: attack effectiveness 34.375%.\n",
            "2023-10-30 15:49:08,175 md_at_ma.py[line:120] INFO: Mini batch: 1071/1450 | training time in 11 minutes, 45 seconds.\n",
            "2023-10-30 15:49:08,175 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0250 | Train accuracy: 89.58%.\n",
            "2023-10-30 15:49:08,661 max.py[line:93] INFO: max: attack effectiveness 37.096774193548384%.\n",
            "2023-10-30 15:49:08,670 md_at_ma.py[line:120] INFO: Mini batch: 1072/1450 | training time in 11 minutes, 46 seconds.\n",
            "2023-10-30 15:49:08,670 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0122 | Train accuracy: 88.95%.\n",
            "2023-10-30 15:49:09,064 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:49:09,068 md_at_ma.py[line:120] INFO: Mini batch: 1073/1450 | training time in 11 minutes, 46 seconds.\n",
            "2023-10-30 15:49:09,068 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0082 | Train accuracy: 94.74%.\n",
            "2023-10-30 15:49:09,099 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0160 | Train accuracy: 87.29\n",
            "2023-10-30 15:49:11,519 max.py[line:93] INFO: max: attack effectiveness 53.125%.\n",
            "2023-10-30 15:49:12,576 max.py[line:93] INFO: max: attack effectiveness 56.25%.\n",
            "2023-10-30 15:49:13,500 max.py[line:93] INFO: max: attack effectiveness 56.25%.\n",
            "2023-10-30 15:49:14,418 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:49:15,110 max.py[line:93] INFO: max: attack effectiveness 71.73913043478261%.\n",
            "2023-10-30 15:49:15,792 md_at_ma.py[line:165] INFO: \tVal accuracy 70.04% with accuracy 44.62% under attack.\n",
            "2023-10-30 15:49:15,792 md_at_ma.py[line:167] INFO: \tModel select at epoch 37 with validation accuracy 70.04% and accuracy 44.62% under attack.\n",
            "2023-10-30 15:49:16,670 max.py[line:93] INFO: max: attack effectiveness 39.39393939393939%.\n",
            "2023-10-30 15:49:16,682 md_at_ma.py[line:120] INFO: Mini batch: 1074/1450 | training time in 11 minutes, 47 seconds.\n",
            "2023-10-30 15:49:16,683 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0296 | Train accuracy: 87.63%.\n",
            "2023-10-30 15:49:17,172 max.py[line:93] INFO: max: attack effectiveness 47.61904761904761%.\n",
            "2023-10-30 15:49:17,181 md_at_ma.py[line:120] INFO: Mini batch: 1075/1450 | training time in 11 minutes, 47 seconds.\n",
            "2023-10-30 15:49:17,181 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0291 | Train accuracy: 85.86%.\n",
            "2023-10-30 15:49:17,953 max.py[line:93] INFO: max: attack effectiveness 43.93939393939394%.\n",
            "2023-10-30 15:49:17,965 md_at_ma.py[line:120] INFO: Mini batch: 1076/1450 | training time in 11 minutes, 48 seconds.\n",
            "2023-10-30 15:49:17,965 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0331 | Train accuracy: 86.08%.\n",
            "2023-10-30 15:49:18,739 max.py[line:93] INFO: max: attack effectiveness 45.714285714285715%.\n",
            "2023-10-30 15:49:18,751 md_at_ma.py[line:120] INFO: Mini batch: 1077/1450 | training time in 11 minutes, 49 seconds.\n",
            "2023-10-30 15:49:18,751 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0132 | Train accuracy: 84.85%.\n",
            "2023-10-30 15:49:19,532 max.py[line:93] INFO: max: attack effectiveness 47.88732394366197%.\n",
            "2023-10-30 15:49:19,544 md_at_ma.py[line:120] INFO: Mini batch: 1078/1450 | training time in 11 minutes, 50 seconds.\n",
            "2023-10-30 15:49:19,544 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0288 | Train accuracy: 83.92%.\n",
            "2023-10-30 15:49:20,370 max.py[line:93] INFO: max: attack effectiveness 51.31578947368421%.\n",
            "2023-10-30 15:49:20,382 md_at_ma.py[line:120] INFO: Mini batch: 1079/1450 | training time in 11 minutes, 51 seconds.\n",
            "2023-10-30 15:49:20,382 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0146 | Train accuracy: 84.31%.\n",
            "2023-10-30 15:49:20,864 max.py[line:93] INFO: max: attack effectiveness 42.62295081967213%.\n",
            "2023-10-30 15:49:20,873 md_at_ma.py[line:120] INFO: Mini batch: 1080/1450 | training time in 11 minutes, 51 seconds.\n",
            "2023-10-30 15:49:20,873 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0170 | Train accuracy: 88.36%.\n",
            "2023-10-30 15:49:21,654 max.py[line:93] INFO: max: attack effectiveness 43.47826086956522%.\n",
            "2023-10-30 15:49:21,666 md_at_ma.py[line:120] INFO: Mini batch: 1081/1450 | training time in 11 minutes, 52 seconds.\n",
            "2023-10-30 15:49:21,666 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0177 | Train accuracy: 85.79%.\n",
            "2023-10-30 15:49:22,171 max.py[line:93] INFO: max: attack effectiveness 35.483870967741936%.\n",
            "2023-10-30 15:49:22,180 md_at_ma.py[line:120] INFO: Mini batch: 1082/1450 | training time in 11 minutes, 52 seconds.\n",
            "2023-10-30 15:49:22,180 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0180 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:49:22,668 max.py[line:93] INFO: max: attack effectiveness 48.333333333333336%.\n",
            "2023-10-30 15:49:22,677 md_at_ma.py[line:120] INFO: Mini batch: 1083/1450 | training time in 11 minutes, 53 seconds.\n",
            "2023-10-30 15:49:22,678 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0295 | Train accuracy: 86.70%.\n",
            "2023-10-30 15:49:23,276 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:49:23,285 md_at_ma.py[line:120] INFO: Mini batch: 1084/1450 | training time in 11 minutes, 53 seconds.\n",
            "2023-10-30 15:49:23,286 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0136 | Train accuracy: 91.76%.\n",
            "2023-10-30 15:49:23,802 max.py[line:93] INFO: max: attack effectiveness 46.03174603174603%.\n",
            "2023-10-30 15:49:23,811 md_at_ma.py[line:120] INFO: Mini batch: 1085/1450 | training time in 11 minutes, 54 seconds.\n",
            "2023-10-30 15:49:23,812 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0116 | Train accuracy: 84.82%.\n",
            "2023-10-30 15:49:24,576 max.py[line:93] INFO: max: attack effectiveness 49.23076923076923%.\n",
            "2023-10-30 15:49:24,589 md_at_ma.py[line:120] INFO: Mini batch: 1086/1450 | training time in 11 minutes, 55 seconds.\n",
            "2023-10-30 15:49:24,589 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0083 | Train accuracy: 88.60%.\n",
            "2023-10-30 15:49:25,353 max.py[line:93] INFO: max: attack effectiveness 45.45454545454545%.\n",
            "2023-10-30 15:49:25,365 md_at_ma.py[line:120] INFO: Mini batch: 1087/1450 | training time in 11 minutes, 55 seconds.\n",
            "2023-10-30 15:49:25,366 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0318 | Train accuracy: 85.57%.\n",
            "2023-10-30 15:49:26,103 max.py[line:93] INFO: max: attack effectiveness 40.0%.\n",
            "2023-10-30 15:49:26,115 md_at_ma.py[line:120] INFO: Mini batch: 1088/1450 | training time in 11 minutes, 56 seconds.\n",
            "2023-10-30 15:49:26,116 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0229 | Train accuracy: 89.64%.\n",
            "2023-10-30 15:49:26,894 max.py[line:93] INFO: max: attack effectiveness 53.52112676056338%.\n",
            "2023-10-30 15:49:26,906 md_at_ma.py[line:120] INFO: Mini batch: 1089/1450 | training time in 11 minutes, 57 seconds.\n",
            "2023-10-30 15:49:26,907 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0109 | Train accuracy: 85.93%.\n",
            "2023-10-30 15:49:27,395 max.py[line:93] INFO: max: attack effectiveness 40.625%.\n",
            "2023-10-30 15:49:27,404 md_at_ma.py[line:120] INFO: Mini batch: 1090/1450 | training time in 11 minutes, 57 seconds.\n",
            "2023-10-30 15:49:27,404 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0088 | Train accuracy: 89.58%.\n",
            "2023-10-30 15:49:28,172 max.py[line:93] INFO: max: attack effectiveness 41.7910447761194%.\n",
            "2023-10-30 15:49:28,184 md_at_ma.py[line:120] INFO: Mini batch: 1091/1450 | training time in 11 minutes, 58 seconds.\n",
            "2023-10-30 15:49:28,184 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0075 | Train accuracy: 87.69%.\n",
            "2023-10-30 15:49:28,667 max.py[line:93] INFO: max: attack effectiveness 46.875%.\n",
            "2023-10-30 15:49:28,676 md_at_ma.py[line:120] INFO: Mini batch: 1092/1450 | training time in 11 minutes, 59 seconds.\n",
            "2023-10-30 15:49:28,676 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0105 | Train accuracy: 85.94%.\n",
            "2023-10-30 15:49:29,493 max.py[line:93] INFO: max: attack effectiveness 56.75675675675676%.\n",
            "2023-10-30 15:49:29,505 md_at_ma.py[line:120] INFO: Mini batch: 1093/1450 | training time in 11 minutes, 59 seconds.\n",
            "2023-10-30 15:49:29,506 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0290 | Train accuracy: 80.20%.\n",
            "2023-10-30 15:49:30,283 max.py[line:93] INFO: max: attack effectiveness 49.275362318840585%.\n",
            "2023-10-30 15:49:30,295 md_at_ma.py[line:120] INFO: Mini batch: 1094/1450 | training time in 12 minutes, 0 seconds.\n",
            "2023-10-30 15:49:30,296 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0122 | Train accuracy: 83.25%.\n",
            "2023-10-30 15:49:31,122 max.py[line:93] INFO: max: attack effectiveness 54.666666666666664%.\n",
            "2023-10-30 15:49:31,134 md_at_ma.py[line:120] INFO: Mini batch: 1095/1450 | training time in 12 minutes, 1 seconds.\n",
            "2023-10-30 15:49:31,135 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0137 | Train accuracy: 83.25%.\n",
            "2023-10-30 15:49:31,902 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:49:31,914 md_at_ma.py[line:120] INFO: Mini batch: 1096/1450 | training time in 12 minutes, 2 seconds.\n",
            "2023-10-30 15:49:31,914 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0086 | Train accuracy: 84.69%.\n",
            "2023-10-30 15:49:32,502 max.py[line:93] INFO: max: attack effectiveness 54.23728813559322%.\n",
            "2023-10-30 15:49:32,510 md_at_ma.py[line:120] INFO: Mini batch: 1097/1450 | training time in 12 minutes, 2 seconds.\n",
            "2023-10-30 15:49:32,511 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0257 | Train accuracy: 86.63%.\n",
            "2023-10-30 15:49:33,333 max.py[line:93] INFO: max: attack effectiveness 50.66666666666667%.\n",
            "2023-10-30 15:49:33,345 md_at_ma.py[line:120] INFO: Mini batch: 1098/1450 | training time in 12 minutes, 3 seconds.\n",
            "2023-10-30 15:49:33,345 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0123 | Train accuracy: 82.27%.\n",
            "2023-10-30 15:49:34,125 max.py[line:93] INFO: max: attack effectiveness 49.275362318840585%.\n",
            "2023-10-30 15:49:34,138 md_at_ma.py[line:120] INFO: Mini batch: 1099/1450 | training time in 12 minutes, 4 seconds.\n",
            "2023-10-30 15:49:34,139 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0105 | Train accuracy: 86.29%.\n",
            "2023-10-30 15:49:34,632 max.py[line:93] INFO: max: attack effectiveness 37.5%.\n",
            "2023-10-30 15:49:34,641 md_at_ma.py[line:120] INFO: Mini batch: 1100/1450 | training time in 12 minutes, 5 seconds.\n",
            "2023-10-30 15:49:34,641 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0250 | Train accuracy: 89.58%.\n",
            "2023-10-30 15:49:35,126 max.py[line:93] INFO: max: attack effectiveness 45.16129032258064%.\n",
            "2023-10-30 15:49:35,136 md_at_ma.py[line:120] INFO: Mini batch: 1101/1450 | training time in 12 minutes, 5 seconds.\n",
            "2023-10-30 15:49:35,136 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0270 | Train accuracy: 90.00%.\n",
            "2023-10-30 15:49:35,532 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:49:35,536 md_at_ma.py[line:120] INFO: Mini batch: 1102/1450 | training time in 12 minutes, 5 seconds.\n",
            "2023-10-30 15:49:35,536 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0155 | Train accuracy: 84.21%.\n",
            "2023-10-30 15:49:35,581 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0185 | Train accuracy: 86.31\n",
            "2023-10-30 15:49:37,810 max.py[line:93] INFO: max: attack effectiveness 60.9375%.\n",
            "2023-10-30 15:49:39,002 max.py[line:93] INFO: max: attack effectiveness 57.03125%.\n",
            "2023-10-30 15:49:39,904 max.py[line:93] INFO: max: attack effectiveness 59.375%.\n",
            "2023-10-30 15:49:40,797 max.py[line:93] INFO: max: attack effectiveness 53.125%.\n",
            "2023-10-30 15:49:41,441 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:49:42,110 md_at_ma.py[line:165] INFO: \tVal accuracy 68.42% with accuracy 40.86% under attack.\n",
            "2023-10-30 15:49:42,110 md_at_ma.py[line:167] INFO: \tModel select at epoch 37 with validation accuracy 70.04% and accuracy 44.62% under attack.\n",
            "2023-10-30 15:49:43,009 max.py[line:93] INFO: max: attack effectiveness 43.93939393939394%.\n",
            "2023-10-30 15:49:43,022 md_at_ma.py[line:120] INFO: Mini batch: 1103/1450 | training time in 12 minutes, 6 seconds.\n",
            "2023-10-30 15:49:43,022 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0200 | Train accuracy: 85.57%.\n",
            "2023-10-30 15:49:43,513 max.py[line:93] INFO: max: attack effectiveness 49.2063492063492%.\n",
            "2023-10-30 15:49:43,522 md_at_ma.py[line:120] INFO: Mini batch: 1104/1450 | training time in 12 minutes, 7 seconds.\n",
            "2023-10-30 15:49:43,522 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0176 | Train accuracy: 85.86%.\n",
            "2023-10-30 15:49:44,292 max.py[line:93] INFO: max: attack effectiveness 43.93939393939394%.\n",
            "2023-10-30 15:49:44,305 md_at_ma.py[line:120] INFO: Mini batch: 1105/1450 | training time in 12 minutes, 7 seconds.\n",
            "2023-10-30 15:49:44,305 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0197 | Train accuracy: 86.08%.\n",
            "2023-10-30 15:49:45,085 max.py[line:93] INFO: max: attack effectiveness 47.14285714285714%.\n",
            "2023-10-30 15:49:45,097 md_at_ma.py[line:120] INFO: Mini batch: 1106/1450 | training time in 12 minutes, 8 seconds.\n",
            "2023-10-30 15:49:45,097 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0109 | Train accuracy: 85.86%.\n",
            "2023-10-30 15:49:45,875 max.py[line:93] INFO: max: attack effectiveness 50.70422535211267%.\n",
            "2023-10-30 15:49:45,887 md_at_ma.py[line:120] INFO: Mini batch: 1107/1450 | training time in 12 minutes, 9 seconds.\n",
            "2023-10-30 15:49:45,888 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0137 | Train accuracy: 83.42%.\n",
            "2023-10-30 15:49:46,720 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:49:46,733 md_at_ma.py[line:120] INFO: Mini batch: 1108/1450 | training time in 12 minutes, 10 seconds.\n",
            "2023-10-30 15:49:46,733 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0135 | Train accuracy: 86.27%.\n",
            "2023-10-30 15:49:47,211 max.py[line:93] INFO: max: attack effectiveness 40.98360655737705%.\n",
            "2023-10-30 15:49:47,220 md_at_ma.py[line:120] INFO: Mini batch: 1109/1450 | training time in 12 minutes, 10 seconds.\n",
            "2023-10-30 15:49:47,220 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0250 | Train accuracy: 89.95%.\n",
            "2023-10-30 15:49:48,011 max.py[line:93] INFO: max: attack effectiveness 42.028985507246375%.\n",
            "2023-10-30 15:49:48,024 md_at_ma.py[line:120] INFO: Mini batch: 1110/1450 | training time in 12 minutes, 11 seconds.\n",
            "2023-10-30 15:49:48,024 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0208 | Train accuracy: 88.32%.\n",
            "2023-10-30 15:49:48,549 max.py[line:93] INFO: max: attack effectiveness 33.87096774193548%.\n",
            "2023-10-30 15:49:48,558 md_at_ma.py[line:120] INFO: Mini batch: 1111/1450 | training time in 12 minutes, 12 seconds.\n",
            "2023-10-30 15:49:48,558 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0212 | Train accuracy: 90.00%.\n",
            "2023-10-30 15:49:49,057 max.py[line:93] INFO: max: attack effectiveness 48.333333333333336%.\n",
            "2023-10-30 15:49:49,066 md_at_ma.py[line:120] INFO: Mini batch: 1112/1450 | training time in 12 minutes, 12 seconds.\n",
            "2023-10-30 15:49:49,066 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0256 | Train accuracy: 85.11%.\n",
            "2023-10-30 15:49:49,668 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:49:49,677 md_at_ma.py[line:120] INFO: Mini batch: 1113/1450 | training time in 12 minutes, 13 seconds.\n",
            "2023-10-30 15:49:49,677 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0110 | Train accuracy: 90.11%.\n",
            "2023-10-30 15:49:50,178 max.py[line:93] INFO: max: attack effectiveness 50.79365079365079%.\n",
            "2023-10-30 15:49:50,187 md_at_ma.py[line:120] INFO: Mini batch: 1114/1450 | training time in 12 minutes, 13 seconds.\n",
            "2023-10-30 15:49:50,187 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0101 | Train accuracy: 85.34%.\n",
            "2023-10-30 15:49:50,953 max.py[line:93] INFO: max: attack effectiveness 52.307692307692314%.\n",
            "2023-10-30 15:49:50,965 md_at_ma.py[line:120] INFO: Mini batch: 1115/1450 | training time in 12 minutes, 14 seconds.\n",
            "2023-10-30 15:49:50,965 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0091 | Train accuracy: 85.49%.\n",
            "2023-10-30 15:49:51,736 max.py[line:93] INFO: max: attack effectiveness 48.484848484848484%.\n",
            "2023-10-30 15:49:51,748 md_at_ma.py[line:120] INFO: Mini batch: 1116/1450 | training time in 12 minutes, 15 seconds.\n",
            "2023-10-30 15:49:51,748 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0222 | Train accuracy: 86.08%.\n",
            "2023-10-30 15:49:52,485 max.py[line:93] INFO: max: attack effectiveness 41.53846153846154%.\n",
            "2023-10-30 15:49:52,497 md_at_ma.py[line:120] INFO: Mini batch: 1117/1450 | training time in 12 minutes, 15 seconds.\n",
            "2023-10-30 15:49:52,497 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0130 | Train accuracy: 88.60%.\n",
            "2023-10-30 15:49:53,272 max.py[line:93] INFO: max: attack effectiveness 46.478873239436616%.\n",
            "2023-10-30 15:49:53,285 md_at_ma.py[line:120] INFO: Mini batch: 1118/1450 | training time in 12 minutes, 16 seconds.\n",
            "2023-10-30 15:49:53,285 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0119 | Train accuracy: 86.93%.\n",
            "2023-10-30 15:49:53,769 max.py[line:93] INFO: max: attack effectiveness 35.9375%.\n",
            "2023-10-30 15:49:53,778 md_at_ma.py[line:120] INFO: Mini batch: 1119/1450 | training time in 12 minutes, 17 seconds.\n",
            "2023-10-30 15:49:53,778 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0087 | Train accuracy: 89.58%.\n",
            "2023-10-30 15:49:54,545 max.py[line:93] INFO: max: attack effectiveness 41.7910447761194%.\n",
            "2023-10-30 15:49:54,557 md_at_ma.py[line:120] INFO: Mini batch: 1120/1450 | training time in 12 minutes, 17 seconds.\n",
            "2023-10-30 15:49:54,557 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0086 | Train accuracy: 88.21%.\n",
            "2023-10-30 15:49:55,043 max.py[line:93] INFO: max: attack effectiveness 45.3125%.\n",
            "2023-10-30 15:49:55,052 md_at_ma.py[line:120] INFO: Mini batch: 1121/1450 | training time in 12 minutes, 18 seconds.\n",
            "2023-10-30 15:49:55,052 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0155 | Train accuracy: 87.50%.\n",
            "2023-10-30 15:49:55,873 max.py[line:93] INFO: max: attack effectiveness 51.35135135135135%.\n",
            "2023-10-30 15:49:55,885 md_at_ma.py[line:120] INFO: Mini batch: 1122/1450 | training time in 12 minutes, 19 seconds.\n",
            "2023-10-30 15:49:55,885 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0223 | Train accuracy: 82.67%.\n",
            "2023-10-30 15:49:56,659 max.py[line:93] INFO: max: attack effectiveness 40.57971014492754%.\n",
            "2023-10-30 15:49:56,672 md_at_ma.py[line:120] INFO: Mini batch: 1123/1450 | training time in 12 minutes, 19 seconds.\n",
            "2023-10-30 15:49:56,672 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0085 | Train accuracy: 87.31%.\n",
            "2023-10-30 15:49:57,497 max.py[line:93] INFO: max: attack effectiveness 48.0%.\n",
            "2023-10-30 15:49:57,510 md_at_ma.py[line:120] INFO: Mini batch: 1124/1450 | training time in 12 minutes, 20 seconds.\n",
            "2023-10-30 15:49:57,510 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0115 | Train accuracy: 84.73%.\n",
            "2023-10-30 15:49:58,279 max.py[line:93] INFO: max: attack effectiveness 48.529411764705884%.\n",
            "2023-10-30 15:49:58,291 md_at_ma.py[line:120] INFO: Mini batch: 1125/1450 | training time in 12 minutes, 21 seconds.\n",
            "2023-10-30 15:49:58,291 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0077 | Train accuracy: 87.24%.\n",
            "2023-10-30 15:49:58,880 max.py[line:93] INFO: max: attack effectiveness 47.45762711864407%.\n",
            "2023-10-30 15:49:58,889 md_at_ma.py[line:120] INFO: Mini batch: 1126/1450 | training time in 12 minutes, 22 seconds.\n",
            "2023-10-30 15:49:58,890 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0258 | Train accuracy: 87.17%.\n",
            "2023-10-30 15:49:59,711 max.py[line:93] INFO: max: attack effectiveness 45.33333333333333%.\n",
            "2023-10-30 15:49:59,723 md_at_ma.py[line:120] INFO: Mini batch: 1127/1450 | training time in 12 minutes, 22 seconds.\n",
            "2023-10-30 15:49:59,723 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0078 | Train accuracy: 86.70%.\n",
            "2023-10-30 15:50:00,499 max.py[line:93] INFO: max: attack effectiveness 49.275362318840585%.\n",
            "2023-10-30 15:50:00,512 md_at_ma.py[line:120] INFO: Mini batch: 1128/1450 | training time in 12 minutes, 23 seconds.\n",
            "2023-10-30 15:50:00,512 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0095 | Train accuracy: 85.79%.\n",
            "2023-10-30 15:50:01,003 max.py[line:93] INFO: max: attack effectiveness 37.5%.\n",
            "2023-10-30 15:50:01,012 md_at_ma.py[line:120] INFO: Mini batch: 1129/1450 | training time in 12 minutes, 24 seconds.\n",
            "2023-10-30 15:50:01,012 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0195 | Train accuracy: 90.62%.\n",
            "2023-10-30 15:50:01,499 max.py[line:93] INFO: max: attack effectiveness 40.32258064516129%.\n",
            "2023-10-30 15:50:01,508 md_at_ma.py[line:120] INFO: Mini batch: 1130/1450 | training time in 12 minutes, 24 seconds.\n",
            "2023-10-30 15:50:01,508 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0194 | Train accuracy: 92.11%.\n",
            "2023-10-30 15:50:01,901 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:50:01,905 md_at_ma.py[line:120] INFO: Mini batch: 1131/1450 | training time in 12 minutes, 25 seconds.\n",
            "2023-10-30 15:50:01,905 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0065 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:50:01,947 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0151 | Train accuracy: 87.18\n",
            "2023-10-30 15:50:04,168 max.py[line:93] INFO: max: attack effectiveness 59.375%.\n",
            "2023-10-30 15:50:05,249 max.py[line:93] INFO: max: attack effectiveness 55.46875%.\n",
            "2023-10-30 15:50:06,153 max.py[line:93] INFO: max: attack effectiveness 59.375%.\n",
            "2023-10-30 15:50:07,060 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:50:07,659 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:50:08,364 md_at_ma.py[line:165] INFO: \tVal accuracy 69.29% with accuracy 42.29% under attack.\n",
            "2023-10-30 15:50:08,364 md_at_ma.py[line:167] INFO: \tModel select at epoch 37 with validation accuracy 70.04% and accuracy 44.62% under attack.\n",
            "2023-10-30 15:50:09,260 max.py[line:93] INFO: max: attack effectiveness 43.93939393939394%.\n",
            "2023-10-30 15:50:09,273 md_at_ma.py[line:120] INFO: Mini batch: 1132/1450 | training time in 12 minutes, 25 seconds.\n",
            "2023-10-30 15:50:09,273 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0146 | Train accuracy: 87.63%.\n",
            "2023-10-30 15:50:09,760 max.py[line:93] INFO: max: attack effectiveness 49.2063492063492%.\n",
            "2023-10-30 15:50:09,770 md_at_ma.py[line:120] INFO: Mini batch: 1133/1450 | training time in 12 minutes, 26 seconds.\n",
            "2023-10-30 15:50:09,770 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0160 | Train accuracy: 86.39%.\n",
            "2023-10-30 15:50:10,541 max.py[line:93] INFO: max: attack effectiveness 45.45454545454545%.\n",
            "2023-10-30 15:50:10,554 md_at_ma.py[line:120] INFO: Mini batch: 1134/1450 | training time in 12 minutes, 27 seconds.\n",
            "2023-10-30 15:50:10,554 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0179 | Train accuracy: 85.57%.\n",
            "2023-10-30 15:50:11,335 max.py[line:93] INFO: max: attack effectiveness 48.57142857142857%.\n",
            "2023-10-30 15:50:11,348 md_at_ma.py[line:120] INFO: Mini batch: 1135/1450 | training time in 12 minutes, 27 seconds.\n",
            "2023-10-30 15:50:11,348 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0100 | Train accuracy: 84.85%.\n",
            "2023-10-30 15:50:12,125 max.py[line:93] INFO: max: attack effectiveness 49.29577464788733%.\n",
            "2023-10-30 15:50:12,137 md_at_ma.py[line:120] INFO: Mini batch: 1136/1450 | training time in 12 minutes, 28 seconds.\n",
            "2023-10-30 15:50:12,137 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0126 | Train accuracy: 85.93%.\n",
            "2023-10-30 15:50:12,960 max.py[line:93] INFO: max: attack effectiveness 44.73684210526316%.\n",
            "2023-10-30 15:50:12,972 md_at_ma.py[line:120] INFO: Mini batch: 1137/1450 | training time in 12 minutes, 29 seconds.\n",
            "2023-10-30 15:50:12,972 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0110 | Train accuracy: 86.76%.\n",
            "2023-10-30 15:50:13,455 max.py[line:93] INFO: max: attack effectiveness 40.98360655737705%.\n",
            "2023-10-30 15:50:13,464 md_at_ma.py[line:120] INFO: Mini batch: 1138/1450 | training time in 12 minutes, 29 seconds.\n",
            "2023-10-30 15:50:13,464 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0126 | Train accuracy: 89.42%.\n",
            "2023-10-30 15:50:14,243 max.py[line:93] INFO: max: attack effectiveness 42.028985507246375%.\n",
            "2023-10-30 15:50:14,255 md_at_ma.py[line:120] INFO: Mini batch: 1139/1450 | training time in 12 minutes, 30 seconds.\n",
            "2023-10-30 15:50:14,255 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0191 | Train accuracy: 86.29%.\n",
            "2023-10-30 15:50:14,765 max.py[line:93] INFO: max: attack effectiveness 33.87096774193548%.\n",
            "2023-10-30 15:50:14,774 md_at_ma.py[line:120] INFO: Mini batch: 1140/1450 | training time in 12 minutes, 31 seconds.\n",
            "2023-10-30 15:50:14,775 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0085 | Train accuracy: 93.16%.\n",
            "2023-10-30 15:50:15,267 max.py[line:93] INFO: max: attack effectiveness 46.666666666666664%.\n",
            "2023-10-30 15:50:15,276 md_at_ma.py[line:120] INFO: Mini batch: 1141/1450 | training time in 12 minutes, 31 seconds.\n",
            "2023-10-30 15:50:15,276 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0220 | Train accuracy: 85.64%.\n",
            "2023-10-30 15:50:15,856 max.py[line:93] INFO: max: attack effectiveness 37.03703703703704%.\n",
            "2023-10-30 15:50:15,865 md_at_ma.py[line:120] INFO: Mini batch: 1142/1450 | training time in 12 minutes, 32 seconds.\n",
            "2023-10-30 15:50:15,865 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0122 | Train accuracy: 91.21%.\n",
            "2023-10-30 15:50:16,387 max.py[line:93] INFO: max: attack effectiveness 47.61904761904761%.\n",
            "2023-10-30 15:50:16,396 md_at_ma.py[line:120] INFO: Mini batch: 1143/1450 | training time in 12 minutes, 32 seconds.\n",
            "2023-10-30 15:50:16,396 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0127 | Train accuracy: 86.91%.\n",
            "2023-10-30 15:50:17,157 max.py[line:93] INFO: max: attack effectiveness 46.15384615384615%.\n",
            "2023-10-30 15:50:17,169 md_at_ma.py[line:120] INFO: Mini batch: 1144/1450 | training time in 12 minutes, 33 seconds.\n",
            "2023-10-30 15:50:17,169 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0091 | Train accuracy: 88.08%.\n",
            "2023-10-30 15:50:17,935 max.py[line:93] INFO: max: attack effectiveness 42.42424242424242%.\n",
            "2023-10-30 15:50:17,947 md_at_ma.py[line:120] INFO: Mini batch: 1145/1450 | training time in 12 minutes, 34 seconds.\n",
            "2023-10-30 15:50:17,947 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0460 | Train accuracy: 87.63%.\n",
            "2023-10-30 15:50:18,680 max.py[line:93] INFO: max: attack effectiveness 36.92307692307693%.\n",
            "2023-10-30 15:50:18,692 md_at_ma.py[line:120] INFO: Mini batch: 1146/1450 | training time in 12 minutes, 35 seconds.\n",
            "2023-10-30 15:50:18,692 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0125 | Train accuracy: 89.12%.\n",
            "2023-10-30 15:50:19,466 max.py[line:93] INFO: max: attack effectiveness 46.478873239436616%.\n",
            "2023-10-30 15:50:19,479 md_at_ma.py[line:120] INFO: Mini batch: 1147/1450 | training time in 12 minutes, 35 seconds.\n",
            "2023-10-30 15:50:19,479 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0159 | Train accuracy: 85.43%.\n",
            "2023-10-30 15:50:19,963 max.py[line:93] INFO: max: attack effectiveness 35.9375%.\n",
            "2023-10-30 15:50:19,971 md_at_ma.py[line:120] INFO: Mini batch: 1148/1450 | training time in 12 minutes, 36 seconds.\n",
            "2023-10-30 15:50:19,972 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0102 | Train accuracy: 90.10%.\n",
            "2023-10-30 15:50:20,741 max.py[line:93] INFO: max: attack effectiveness 41.7910447761194%.\n",
            "2023-10-30 15:50:20,753 md_at_ma.py[line:120] INFO: Mini batch: 1149/1450 | training time in 12 minutes, 37 seconds.\n",
            "2023-10-30 15:50:20,753 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0091 | Train accuracy: 89.23%.\n",
            "2023-10-30 15:50:21,239 max.py[line:93] INFO: max: attack effectiveness 45.3125%.\n",
            "2023-10-30 15:50:21,247 md_at_ma.py[line:120] INFO: Mini batch: 1150/1450 | training time in 12 minutes, 37 seconds.\n",
            "2023-10-30 15:50:21,248 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0122 | Train accuracy: 85.94%.\n",
            "2023-10-30 15:50:22,066 max.py[line:93] INFO: max: attack effectiveness 52.702702702702695%.\n",
            "2023-10-30 15:50:22,078 md_at_ma.py[line:120] INFO: Mini batch: 1151/1450 | training time in 12 minutes, 38 seconds.\n",
            "2023-10-30 15:50:22,078 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0260 | Train accuracy: 83.17%.\n",
            "2023-10-30 15:50:22,851 max.py[line:93] INFO: max: attack effectiveness 43.47826086956522%.\n",
            "2023-10-30 15:50:22,863 md_at_ma.py[line:120] INFO: Mini batch: 1152/1450 | training time in 12 minutes, 39 seconds.\n",
            "2023-10-30 15:50:22,863 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0184 | Train accuracy: 86.80%.\n",
            "2023-10-30 15:50:23,687 max.py[line:93] INFO: max: attack effectiveness 52.0%.\n",
            "2023-10-30 15:50:23,699 md_at_ma.py[line:120] INFO: Mini batch: 1153/1450 | training time in 12 minutes, 39 seconds.\n",
            "2023-10-30 15:50:23,699 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0118 | Train accuracy: 83.25%.\n",
            "2023-10-30 15:50:24,468 max.py[line:93] INFO: max: attack effectiveness 48.529411764705884%.\n",
            "2023-10-30 15:50:24,480 md_at_ma.py[line:120] INFO: Mini batch: 1154/1450 | training time in 12 minutes, 40 seconds.\n",
            "2023-10-30 15:50:24,480 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0068 | Train accuracy: 85.71%.\n",
            "2023-10-30 15:50:25,065 max.py[line:93] INFO: max: attack effectiveness 50.847457627118644%.\n",
            "2023-10-30 15:50:25,074 md_at_ma.py[line:120] INFO: Mini batch: 1155/1450 | training time in 12 minutes, 41 seconds.\n",
            "2023-10-30 15:50:25,074 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0267 | Train accuracy: 88.77%.\n",
            "2023-10-30 15:50:25,899 max.py[line:93] INFO: max: attack effectiveness 46.666666666666664%.\n",
            "2023-10-30 15:50:25,911 md_at_ma.py[line:120] INFO: Mini batch: 1156/1450 | training time in 12 minutes, 42 seconds.\n",
            "2023-10-30 15:50:25,911 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0068 | Train accuracy: 85.71%.\n",
            "2023-10-30 15:50:26,689 max.py[line:93] INFO: max: attack effectiveness 50.72463768115942%.\n",
            "2023-10-30 15:50:26,701 md_at_ma.py[line:120] INFO: Mini batch: 1157/1450 | training time in 12 minutes, 42 seconds.\n",
            "2023-10-30 15:50:26,702 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0125 | Train accuracy: 85.28%.\n",
            "2023-10-30 15:50:27,190 max.py[line:93] INFO: max: attack effectiveness 34.375%.\n",
            "2023-10-30 15:50:27,199 md_at_ma.py[line:120] INFO: Mini batch: 1158/1450 | training time in 12 minutes, 43 seconds.\n",
            "2023-10-30 15:50:27,200 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0236 | Train accuracy: 92.71%.\n",
            "2023-10-30 15:50:27,691 max.py[line:93] INFO: max: attack effectiveness 41.935483870967744%.\n",
            "2023-10-30 15:50:27,700 md_at_ma.py[line:120] INFO: Mini batch: 1159/1450 | training time in 12 minutes, 43 seconds.\n",
            "2023-10-30 15:50:27,701 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0085 | Train accuracy: 88.95%.\n",
            "2023-10-30 15:50:28,105 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:50:28,110 md_at_ma.py[line:120] INFO: Mini batch: 1160/1450 | training time in 12 minutes, 44 seconds.\n",
            "2023-10-30 15:50:28,110 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0094 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:50:28,156 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0150 | Train accuracy: 87.42\n",
            "2023-10-30 15:50:30,391 max.py[line:93] INFO: max: attack effectiveness 57.03125%.\n",
            "2023-10-30 15:50:31,419 max.py[line:93] INFO: max: attack effectiveness 57.03125%.\n",
            "2023-10-30 15:50:32,337 max.py[line:93] INFO: max: attack effectiveness 59.375%.\n",
            "2023-10-30 15:50:33,226 max.py[line:93] INFO: max: attack effectiveness 50.78125%.\n",
            "2023-10-30 15:50:33,779 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:50:34,394 md_at_ma.py[line:165] INFO: \tVal accuracy 68.98% with accuracy 42.29% under attack.\n",
            "2023-10-30 15:50:34,394 md_at_ma.py[line:167] INFO: \tModel select at epoch 37 with validation accuracy 70.04% and accuracy 44.62% under attack.\n",
            "2023-10-30 15:50:35,254 max.py[line:93] INFO: max: attack effectiveness 45.45454545454545%.\n",
            "2023-10-30 15:50:35,267 md_at_ma.py[line:120] INFO: Mini batch: 1161/1450 | training time in 12 minutes, 45 seconds.\n",
            "2023-10-30 15:50:35,267 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0118 | Train accuracy: 87.63%.\n",
            "2023-10-30 15:50:35,754 max.py[line:93] INFO: max: attack effectiveness 47.61904761904761%.\n",
            "2023-10-30 15:50:35,763 md_at_ma.py[line:120] INFO: Mini batch: 1162/1450 | training time in 12 minutes, 45 seconds.\n",
            "2023-10-30 15:50:35,763 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0105 | Train accuracy: 88.48%.\n",
            "2023-10-30 15:50:36,538 max.py[line:93] INFO: max: attack effectiveness 45.45454545454545%.\n",
            "2023-10-30 15:50:36,550 md_at_ma.py[line:120] INFO: Mini batch: 1163/1450 | training time in 12 minutes, 46 seconds.\n",
            "2023-10-30 15:50:36,550 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0108 | Train accuracy: 88.14%.\n",
            "2023-10-30 15:50:37,327 max.py[line:93] INFO: max: attack effectiveness 48.57142857142857%.\n",
            "2023-10-30 15:50:37,340 md_at_ma.py[line:120] INFO: Mini batch: 1164/1450 | training time in 12 minutes, 47 seconds.\n",
            "2023-10-30 15:50:37,340 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0116 | Train accuracy: 89.39%.\n",
            "2023-10-30 15:50:38,112 max.py[line:93] INFO: max: attack effectiveness 49.29577464788733%.\n",
            "2023-10-30 15:50:38,125 md_at_ma.py[line:120] INFO: Mini batch: 1165/1450 | training time in 12 minutes, 47 seconds.\n",
            "2023-10-30 15:50:38,125 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0149 | Train accuracy: 84.42%.\n",
            "2023-10-30 15:50:38,953 max.py[line:93] INFO: max: attack effectiveness 46.05263157894737%.\n",
            "2023-10-30 15:50:38,965 md_at_ma.py[line:120] INFO: Mini batch: 1166/1450 | training time in 12 minutes, 48 seconds.\n",
            "2023-10-30 15:50:38,965 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0087 | Train accuracy: 84.80%.\n",
            "2023-10-30 15:50:39,445 max.py[line:93] INFO: max: attack effectiveness 40.98360655737705%.\n",
            "2023-10-30 15:50:39,453 md_at_ma.py[line:120] INFO: Mini batch: 1167/1450 | training time in 12 minutes, 49 seconds.\n",
            "2023-10-30 15:50:39,454 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0114 | Train accuracy: 88.36%.\n",
            "2023-10-30 15:50:40,235 max.py[line:93] INFO: max: attack effectiveness 42.028985507246375%.\n",
            "2023-10-30 15:50:40,248 md_at_ma.py[line:120] INFO: Mini batch: 1168/1450 | training time in 12 minutes, 49 seconds.\n",
            "2023-10-30 15:50:40,248 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0119 | Train accuracy: 88.32%.\n",
            "2023-10-30 15:50:40,765 max.py[line:93] INFO: max: attack effectiveness 33.87096774193548%.\n",
            "2023-10-30 15:50:40,774 md_at_ma.py[line:120] INFO: Mini batch: 1169/1450 | training time in 12 minutes, 50 seconds.\n",
            "2023-10-30 15:50:40,774 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0097 | Train accuracy: 91.05%.\n",
            "2023-10-30 15:50:41,269 max.py[line:93] INFO: max: attack effectiveness 45.0%.\n",
            "2023-10-30 15:50:41,278 md_at_ma.py[line:120] INFO: Mini batch: 1170/1450 | training time in 12 minutes, 50 seconds.\n",
            "2023-10-30 15:50:41,278 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0163 | Train accuracy: 87.23%.\n",
            "2023-10-30 15:50:41,846 max.py[line:93] INFO: max: attack effectiveness 31.48148148148148%.\n",
            "2023-10-30 15:50:41,855 md_at_ma.py[line:120] INFO: Mini batch: 1171/1450 | training time in 12 minutes, 51 seconds.\n",
            "2023-10-30 15:50:41,856 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0145 | Train accuracy: 92.31%.\n",
            "2023-10-30 15:50:42,381 max.py[line:93] INFO: max: attack effectiveness 47.61904761904761%.\n",
            "2023-10-30 15:50:42,390 md_at_ma.py[line:120] INFO: Mini batch: 1172/1450 | training time in 12 minutes, 51 seconds.\n",
            "2023-10-30 15:50:42,391 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0134 | Train accuracy: 89.01%.\n",
            "2023-10-30 15:50:43,150 max.py[line:93] INFO: max: attack effectiveness 46.15384615384615%.\n",
            "2023-10-30 15:50:43,162 md_at_ma.py[line:120] INFO: Mini batch: 1173/1450 | training time in 12 minutes, 52 seconds.\n",
            "2023-10-30 15:50:43,162 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0097 | Train accuracy: 88.08%.\n",
            "2023-10-30 15:50:43,932 max.py[line:93] INFO: max: attack effectiveness 42.42424242424242%.\n",
            "2023-10-30 15:50:43,944 md_at_ma.py[line:120] INFO: Mini batch: 1174/1450 | training time in 12 minutes, 53 seconds.\n",
            "2023-10-30 15:50:43,944 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0347 | Train accuracy: 90.72%.\n",
            "2023-10-30 15:50:44,682 max.py[line:93] INFO: max: attack effectiveness 36.92307692307693%.\n",
            "2023-10-30 15:50:44,694 md_at_ma.py[line:120] INFO: Mini batch: 1175/1450 | training time in 12 minutes, 54 seconds.\n",
            "2023-10-30 15:50:44,694 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0111 | Train accuracy: 89.12%.\n",
            "2023-10-30 15:50:45,469 max.py[line:93] INFO: max: attack effectiveness 45.07042253521127%.\n",
            "2023-10-30 15:50:45,481 md_at_ma.py[line:120] INFO: Mini batch: 1176/1450 | training time in 12 minutes, 54 seconds.\n",
            "2023-10-30 15:50:45,481 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0204 | Train accuracy: 85.93%.\n",
            "2023-10-30 15:50:45,967 max.py[line:93] INFO: max: attack effectiveness 34.375%.\n",
            "2023-10-30 15:50:45,976 md_at_ma.py[line:120] INFO: Mini batch: 1177/1450 | training time in 12 minutes, 55 seconds.\n",
            "2023-10-30 15:50:45,976 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0069 | Train accuracy: 90.62%.\n",
            "2023-10-30 15:50:46,746 max.py[line:93] INFO: max: attack effectiveness 40.298507462686565%.\n",
            "2023-10-30 15:50:46,758 md_at_ma.py[line:120] INFO: Mini batch: 1178/1450 | training time in 12 minutes, 56 seconds.\n",
            "2023-10-30 15:50:46,758 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0081 | Train accuracy: 88.21%.\n",
            "2023-10-30 15:50:47,246 max.py[line:93] INFO: max: attack effectiveness 45.3125%.\n",
            "2023-10-30 15:50:47,255 md_at_ma.py[line:120] INFO: Mini batch: 1179/1450 | training time in 12 minutes, 56 seconds.\n",
            "2023-10-30 15:50:47,255 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0146 | Train accuracy: 85.94%.\n",
            "2023-10-30 15:50:48,078 max.py[line:93] INFO: max: attack effectiveness 52.702702702702695%.\n",
            "2023-10-30 15:50:48,091 md_at_ma.py[line:120] INFO: Mini batch: 1180/1450 | training time in 12 minutes, 57 seconds.\n",
            "2023-10-30 15:50:48,091 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0228 | Train accuracy: 83.17%.\n",
            "2023-10-30 15:50:48,863 max.py[line:93] INFO: max: attack effectiveness 39.130434782608695%.\n",
            "2023-10-30 15:50:48,875 md_at_ma.py[line:120] INFO: Mini batch: 1181/1450 | training time in 12 minutes, 58 seconds.\n",
            "2023-10-30 15:50:48,875 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0123 | Train accuracy: 87.31%.\n",
            "2023-10-30 15:50:49,698 max.py[line:93] INFO: max: attack effectiveness 49.333333333333336%.\n",
            "2023-10-30 15:50:49,711 md_at_ma.py[line:120] INFO: Mini batch: 1182/1450 | training time in 12 minutes, 59 seconds.\n",
            "2023-10-30 15:50:49,711 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0162 | Train accuracy: 84.73%.\n",
            "2023-10-30 15:50:50,480 max.py[line:93] INFO: max: attack effectiveness 48.529411764705884%.\n",
            "2023-10-30 15:50:50,492 md_at_ma.py[line:120] INFO: Mini batch: 1183/1450 | training time in 12 minutes, 59 seconds.\n",
            "2023-10-30 15:50:50,492 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0085 | Train accuracy: 85.20%.\n",
            "2023-10-30 15:50:51,079 max.py[line:93] INFO: max: attack effectiveness 42.3728813559322%.\n",
            "2023-10-30 15:50:51,087 md_at_ma.py[line:120] INFO: Mini batch: 1184/1450 | training time in 13 minutes, 0 seconds.\n",
            "2023-10-30 15:50:51,088 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0214 | Train accuracy: 91.44%.\n",
            "2023-10-30 15:50:51,912 max.py[line:93] INFO: max: attack effectiveness 45.33333333333333%.\n",
            "2023-10-30 15:50:51,924 md_at_ma.py[line:120] INFO: Mini batch: 1185/1450 | training time in 13 minutes, 1 seconds.\n",
            "2023-10-30 15:50:51,925 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0171 | Train accuracy: 86.21%.\n",
            "2023-10-30 15:50:52,700 max.py[line:93] INFO: max: attack effectiveness 46.3768115942029%.\n",
            "2023-10-30 15:50:52,712 md_at_ma.py[line:120] INFO: Mini batch: 1186/1450 | training time in 13 minutes, 2 seconds.\n",
            "2023-10-30 15:50:52,712 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0089 | Train accuracy: 87.31%.\n",
            "2023-10-30 15:50:53,211 max.py[line:93] INFO: max: attack effectiveness 35.9375%.\n",
            "2023-10-30 15:50:53,220 md_at_ma.py[line:120] INFO: Mini batch: 1187/1450 | training time in 13 minutes, 2 seconds.\n",
            "2023-10-30 15:50:53,221 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0242 | Train accuracy: 90.10%.\n",
            "2023-10-30 15:50:53,716 max.py[line:93] INFO: max: attack effectiveness 41.935483870967744%.\n",
            "2023-10-30 15:50:53,725 md_at_ma.py[line:120] INFO: Mini batch: 1188/1450 | training time in 13 minutes, 3 seconds.\n",
            "2023-10-30 15:50:53,725 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0079 | Train accuracy: 87.89%.\n",
            "2023-10-30 15:50:54,118 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:50:54,122 md_at_ma.py[line:120] INFO: Mini batch: 1189/1450 | training time in 13 minutes, 3 seconds.\n",
            "2023-10-30 15:50:54,122 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0508 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:50:54,165 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0152 | Train accuracy: 87.95\n",
            "2023-10-30 15:50:56,381 max.py[line:93] INFO: max: attack effectiveness 57.8125%.\n",
            "2023-10-30 15:50:57,403 max.py[line:93] INFO: max: attack effectiveness 55.46875%.\n",
            "2023-10-30 15:50:58,302 max.py[line:93] INFO: max: attack effectiveness 57.8125%.\n",
            "2023-10-30 15:50:59,213 max.py[line:93] INFO: max: attack effectiveness 52.34375%.\n",
            "2023-10-30 15:50:59,861 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:51:00,533 md_at_ma.py[line:165] INFO: \tVal accuracy 69.42% with accuracy 42.47% under attack.\n",
            "2023-10-30 15:51:00,533 md_at_ma.py[line:167] INFO: \tModel select at epoch 37 with validation accuracy 70.04% and accuracy 44.62% under attack.\n",
            "2023-10-30 15:51:01,405 max.py[line:93] INFO: max: attack effectiveness 43.93939393939394%.\n",
            "2023-10-30 15:51:01,418 md_at_ma.py[line:120] INFO: Mini batch: 1190/1450 | training time in 13 minutes, 4 seconds.\n",
            "2023-10-30 15:51:01,418 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0210 | Train accuracy: 87.63%.\n",
            "2023-10-30 15:51:01,917 max.py[line:93] INFO: max: attack effectiveness 49.2063492063492%.\n",
            "2023-10-30 15:51:01,926 md_at_ma.py[line:120] INFO: Mini batch: 1191/1450 | training time in 13 minutes, 4 seconds.\n",
            "2023-10-30 15:51:01,926 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0338 | Train accuracy: 83.77%.\n",
            "2023-10-30 15:51:02,692 max.py[line:93] INFO: max: attack effectiveness 45.45454545454545%.\n",
            "2023-10-30 15:51:02,704 md_at_ma.py[line:120] INFO: Mini batch: 1192/1450 | training time in 13 minutes, 5 seconds.\n",
            "2023-10-30 15:51:02,705 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0384 | Train accuracy: 86.08%.\n",
            "2023-10-30 15:51:03,476 max.py[line:93] INFO: max: attack effectiveness 45.714285714285715%.\n",
            "2023-10-30 15:51:03,488 md_at_ma.py[line:120] INFO: Mini batch: 1193/1450 | training time in 13 minutes, 6 seconds.\n",
            "2023-10-30 15:51:03,489 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0408 | Train accuracy: 86.36%.\n",
            "2023-10-30 15:51:04,263 max.py[line:93] INFO: max: attack effectiveness 50.70422535211267%.\n",
            "2023-10-30 15:51:04,275 md_at_ma.py[line:120] INFO: Mini batch: 1194/1450 | training time in 13 minutes, 6 seconds.\n",
            "2023-10-30 15:51:04,276 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0485 | Train accuracy: 82.91%.\n",
            "2023-10-30 15:51:05,099 max.py[line:93] INFO: max: attack effectiveness 47.368421052631575%.\n",
            "2023-10-30 15:51:05,111 md_at_ma.py[line:120] INFO: Mini batch: 1195/1450 | training time in 13 minutes, 7 seconds.\n",
            "2023-10-30 15:51:05,112 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0391 | Train accuracy: 83.82%.\n",
            "2023-10-30 15:51:05,598 max.py[line:93] INFO: max: attack effectiveness 40.98360655737705%.\n",
            "2023-10-30 15:51:05,607 md_at_ma.py[line:120] INFO: Mini batch: 1196/1450 | training time in 13 minutes, 8 seconds.\n",
            "2023-10-30 15:51:05,607 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0369 | Train accuracy: 86.77%.\n",
            "2023-10-30 15:51:06,389 max.py[line:93] INFO: max: attack effectiveness 39.130434782608695%.\n",
            "2023-10-30 15:51:06,402 md_at_ma.py[line:120] INFO: Mini batch: 1197/1450 | training time in 13 minutes, 9 seconds.\n",
            "2023-10-30 15:51:06,402 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0311 | Train accuracy: 87.31%.\n",
            "2023-10-30 15:51:06,907 max.py[line:93] INFO: max: attack effectiveness 30.64516129032258%.\n",
            "2023-10-30 15:51:06,916 md_at_ma.py[line:120] INFO: Mini batch: 1198/1450 | training time in 13 minutes, 9 seconds.\n",
            "2023-10-30 15:51:06,916 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0511 | Train accuracy: 90.53%.\n",
            "2023-10-30 15:51:07,432 max.py[line:93] INFO: max: attack effectiveness 45.0%.\n",
            "2023-10-30 15:51:07,441 md_at_ma.py[line:120] INFO: Mini batch: 1199/1450 | training time in 13 minutes, 10 seconds.\n",
            "2023-10-30 15:51:07,441 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0355 | Train accuracy: 87.23%.\n",
            "2023-10-30 15:51:08,048 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:51:08,057 md_at_ma.py[line:120] INFO: Mini batch: 1200/1450 | training time in 13 minutes, 10 seconds.\n",
            "2023-10-30 15:51:08,057 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0192 | Train accuracy: 91.21%.\n",
            "2023-10-30 15:51:08,582 max.py[line:93] INFO: max: attack effectiveness 53.96825396825397%.\n",
            "2023-10-30 15:51:08,595 md_at_ma.py[line:120] INFO: Mini batch: 1201/1450 | training time in 13 minutes, 11 seconds.\n",
            "2023-10-30 15:51:08,595 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0177 | Train accuracy: 86.91%.\n",
            "2023-10-30 15:51:09,332 max.py[line:93] INFO: max: attack effectiveness 55.38461538461539%.\n",
            "2023-10-30 15:51:09,344 md_at_ma.py[line:120] INFO: Mini batch: 1202/1450 | training time in 13 minutes, 11 seconds.\n",
            "2023-10-30 15:51:09,344 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0282 | Train accuracy: 81.87%.\n",
            "2023-10-30 15:51:10,110 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:51:10,122 md_at_ma.py[line:120] INFO: Mini batch: 1203/1450 | training time in 13 minutes, 12 seconds.\n",
            "2023-10-30 15:51:10,122 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0231 | Train accuracy: 85.05%.\n",
            "2023-10-30 15:51:10,616 max.py[line:93] INFO: max: attack effectiveness 49.23076923076923%.\n",
            "2023-10-30 15:51:10,628 md_at_ma.py[line:120] INFO: Mini batch: 1204/1450 | training time in 13 minutes, 13 seconds.\n",
            "2023-10-30 15:51:10,628 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0346 | Train accuracy: 86.01%.\n",
            "2023-10-30 15:51:11,403 max.py[line:93] INFO: max: attack effectiveness 57.74647887323944%.\n",
            "2023-10-30 15:51:11,415 md_at_ma.py[line:120] INFO: Mini batch: 1205/1450 | training time in 13 minutes, 13 seconds.\n",
            "2023-10-30 15:51:11,415 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0244 | Train accuracy: 82.41%.\n",
            "2023-10-30 15:51:11,905 max.py[line:93] INFO: max: attack effectiveness 48.4375%.\n",
            "2023-10-30 15:51:11,913 md_at_ma.py[line:120] INFO: Mini batch: 1206/1450 | training time in 13 minutes, 14 seconds.\n",
            "2023-10-30 15:51:11,914 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0191 | Train accuracy: 85.94%.\n",
            "2023-10-30 15:51:12,681 max.py[line:93] INFO: max: attack effectiveness 44.776119402985074%.\n",
            "2023-10-30 15:51:12,694 md_at_ma.py[line:120] INFO: Mini batch: 1207/1450 | training time in 13 minutes, 15 seconds.\n",
            "2023-10-30 15:51:12,694 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0131 | Train accuracy: 86.15%.\n",
            "2023-10-30 15:51:13,176 max.py[line:93] INFO: max: attack effectiveness 53.125%.\n",
            "2023-10-30 15:51:13,185 md_at_ma.py[line:120] INFO: Mini batch: 1208/1450 | training time in 13 minutes, 15 seconds.\n",
            "2023-10-30 15:51:13,185 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0164 | Train accuracy: 86.46%.\n",
            "2023-10-30 15:51:14,003 max.py[line:93] INFO: max: attack effectiveness 56.75675675675676%.\n",
            "2023-10-30 15:51:14,015 md_at_ma.py[line:120] INFO: Mini batch: 1209/1450 | training time in 13 minutes, 16 seconds.\n",
            "2023-10-30 15:51:14,016 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0276 | Train accuracy: 80.20%.\n",
            "2023-10-30 15:51:14,787 max.py[line:93] INFO: max: attack effectiveness 49.275362318840585%.\n",
            "2023-10-30 15:51:14,799 md_at_ma.py[line:120] INFO: Mini batch: 1210/1450 | training time in 13 minutes, 17 seconds.\n",
            "2023-10-30 15:51:14,799 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0106 | Train accuracy: 84.26%.\n",
            "2023-10-30 15:51:15,628 max.py[line:93] INFO: max: attack effectiveness 57.333333333333336%.\n",
            "2023-10-30 15:51:15,641 md_at_ma.py[line:120] INFO: Mini batch: 1211/1450 | training time in 13 minutes, 18 seconds.\n",
            "2023-10-30 15:51:15,641 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0205 | Train accuracy: 79.80%.\n",
            "2023-10-30 15:51:16,409 max.py[line:93] INFO: max: attack effectiveness 54.41176470588235%.\n",
            "2023-10-30 15:51:16,421 md_at_ma.py[line:120] INFO: Mini batch: 1212/1450 | training time in 13 minutes, 18 seconds.\n",
            "2023-10-30 15:51:16,421 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0254 | Train accuracy: 83.16%.\n",
            "2023-10-30 15:51:17,013 max.py[line:93] INFO: max: attack effectiveness 66.10169491525424%.\n",
            "2023-10-30 15:51:17,022 md_at_ma.py[line:120] INFO: Mini batch: 1213/1450 | training time in 13 minutes, 19 seconds.\n",
            "2023-10-30 15:51:17,022 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0426 | Train accuracy: 80.21%.\n",
            "2023-10-30 15:51:17,842 max.py[line:93] INFO: max: attack effectiveness 65.33333333333333%.\n",
            "2023-10-30 15:51:17,854 md_at_ma.py[line:120] INFO: Mini batch: 1214/1450 | training time in 13 minutes, 20 seconds.\n",
            "2023-10-30 15:51:17,855 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0274 | Train accuracy: 79.31%.\n",
            "2023-10-30 15:51:18,621 max.py[line:93] INFO: max: attack effectiveness 62.31884057971014%.\n",
            "2023-10-30 15:51:18,633 md_at_ma.py[line:120] INFO: Mini batch: 1215/1450 | training time in 13 minutes, 20 seconds.\n",
            "2023-10-30 15:51:18,633 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0467 | Train accuracy: 80.20%.\n",
            "2023-10-30 15:51:19,130 max.py[line:93] INFO: max: attack effectiveness 48.4375%.\n",
            "2023-10-30 15:51:19,139 md_at_ma.py[line:120] INFO: Mini batch: 1216/1450 | training time in 13 minutes, 21 seconds.\n",
            "2023-10-30 15:51:19,139 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0203 | Train accuracy: 85.94%.\n",
            "2023-10-30 15:51:19,625 max.py[line:93] INFO: max: attack effectiveness 46.774193548387096%.\n",
            "2023-10-30 15:51:19,634 md_at_ma.py[line:120] INFO: Mini batch: 1217/1450 | training time in 13 minutes, 21 seconds.\n",
            "2023-10-30 15:51:19,634 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0133 | Train accuracy: 86.84%.\n",
            "2023-10-30 15:51:20,036 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:51:20,040 md_at_ma.py[line:120] INFO: Mini batch: 1218/1450 | training time in 13 minutes, 22 seconds.\n",
            "2023-10-30 15:51:20,040 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.5859 | Train accuracy: 84.21%.\n",
            "2023-10-30 15:51:20,077 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0480 | Train accuracy: 84.78\n",
            "2023-10-30 15:51:22,458 max.py[line:93] INFO: max: attack effectiveness 71.09375%.\n",
            "2023-10-30 15:51:23,498 max.py[line:93] INFO: max: attack effectiveness 71.09375%.\n",
            "2023-10-30 15:51:24,402 max.py[line:93] INFO: max: attack effectiveness 69.53125%.\n",
            "2023-10-30 15:51:25,295 max.py[line:93] INFO: max: attack effectiveness 65.625%.\n",
            "2023-10-30 15:51:25,869 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:51:26,599 md_at_ma.py[line:165] INFO: \tVal accuracy 63.25% with accuracy 30.11% under attack.\n",
            "2023-10-30 15:51:26,599 md_at_ma.py[line:167] INFO: \tModel select at epoch 37 with validation accuracy 70.04% and accuracy 44.62% under attack.\n",
            "2023-10-30 15:51:27,446 max.py[line:93] INFO: max: attack effectiveness 59.09090909090909%.\n",
            "2023-10-30 15:51:27,459 md_at_ma.py[line:120] INFO: Mini batch: 1219/1450 | training time in 13 minutes, 23 seconds.\n",
            "2023-10-30 15:51:27,459 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0608 | Train accuracy: 80.93%.\n",
            "2023-10-30 15:51:27,950 max.py[line:93] INFO: max: attack effectiveness 68.25396825396825%.\n",
            "2023-10-30 15:51:27,959 md_at_ma.py[line:120] INFO: Mini batch: 1220/1450 | training time in 13 minutes, 23 seconds.\n",
            "2023-10-30 15:51:27,959 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0615 | Train accuracy: 79.58%.\n",
            "2023-10-30 15:51:28,729 max.py[line:93] INFO: max: attack effectiveness 56.060606060606055%.\n",
            "2023-10-30 15:51:28,741 md_at_ma.py[line:120] INFO: Mini batch: 1221/1450 | training time in 13 minutes, 24 seconds.\n",
            "2023-10-30 15:51:28,741 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0402 | Train accuracy: 84.54%.\n",
            "2023-10-30 15:51:29,511 max.py[line:93] INFO: max: attack effectiveness 67.14285714285714%.\n",
            "2023-10-30 15:51:29,524 md_at_ma.py[line:120] INFO: Mini batch: 1222/1450 | training time in 13 minutes, 25 seconds.\n",
            "2023-10-30 15:51:29,524 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0373 | Train accuracy: 80.30%.\n",
            "2023-10-30 15:51:30,302 max.py[line:93] INFO: max: attack effectiveness 74.64788732394366%.\n",
            "2023-10-30 15:51:30,314 md_at_ma.py[line:120] INFO: Mini batch: 1223/1450 | training time in 13 minutes, 25 seconds.\n",
            "2023-10-30 15:51:30,315 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0411 | Train accuracy: 76.88%.\n",
            "2023-10-30 15:51:31,144 max.py[line:93] INFO: max: attack effectiveness 63.1578947368421%.\n",
            "2023-10-30 15:51:31,156 md_at_ma.py[line:120] INFO: Mini batch: 1224/1450 | training time in 13 minutes, 26 seconds.\n",
            "2023-10-30 15:51:31,156 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0352 | Train accuracy: 79.90%.\n",
            "2023-10-30 15:51:31,634 max.py[line:93] INFO: max: attack effectiveness 59.01639344262295%.\n",
            "2023-10-30 15:51:31,643 md_at_ma.py[line:120] INFO: Mini batch: 1225/1450 | training time in 13 minutes, 27 seconds.\n",
            "2023-10-30 15:51:31,643 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0299 | Train accuracy: 83.07%.\n",
            "2023-10-30 15:51:32,429 max.py[line:93] INFO: max: attack effectiveness 55.072463768115945%.\n",
            "2023-10-30 15:51:32,441 md_at_ma.py[line:120] INFO: Mini batch: 1226/1450 | training time in 13 minutes, 27 seconds.\n",
            "2023-10-30 15:51:32,442 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0378 | Train accuracy: 83.25%.\n",
            "2023-10-30 15:51:32,929 max.py[line:93] INFO: max: attack effectiveness 48.38709677419355%.\n",
            "2023-10-30 15:51:32,938 md_at_ma.py[line:120] INFO: Mini batch: 1227/1450 | training time in 13 minutes, 28 seconds.\n",
            "2023-10-30 15:51:32,938 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0273 | Train accuracy: 90.53%.\n",
            "2023-10-30 15:51:33,428 max.py[line:93] INFO: max: attack effectiveness 65.0%.\n",
            "2023-10-30 15:51:33,437 md_at_ma.py[line:120] INFO: Mini batch: 1228/1450 | training time in 13 minutes, 28 seconds.\n",
            "2023-10-30 15:51:33,438 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0387 | Train accuracy: 80.32%.\n",
            "2023-10-30 15:51:34,037 max.py[line:93] INFO: max: attack effectiveness 46.2962962962963%.\n",
            "2023-10-30 15:51:34,046 md_at_ma.py[line:120] INFO: Mini batch: 1229/1450 | training time in 13 minutes, 29 seconds.\n",
            "2023-10-30 15:51:34,046 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0354 | Train accuracy: 87.91%.\n",
            "2023-10-30 15:51:34,581 max.py[line:93] INFO: max: attack effectiveness 58.730158730158735%.\n",
            "2023-10-30 15:51:34,590 md_at_ma.py[line:120] INFO: Mini batch: 1230/1450 | training time in 13 minutes, 29 seconds.\n",
            "2023-10-30 15:51:34,590 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0361 | Train accuracy: 82.20%.\n",
            "2023-10-30 15:51:35,356 max.py[line:93] INFO: max: attack effectiveness 64.61538461538461%.\n",
            "2023-10-30 15:51:35,368 md_at_ma.py[line:120] INFO: Mini batch: 1231/1450 | training time in 13 minutes, 30 seconds.\n",
            "2023-10-30 15:51:35,368 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0298 | Train accuracy: 80.83%.\n",
            "2023-10-30 15:51:36,134 max.py[line:93] INFO: max: attack effectiveness 53.03030303030303%.\n",
            "2023-10-30 15:51:36,146 md_at_ma.py[line:120] INFO: Mini batch: 1232/1450 | training time in 13 minutes, 31 seconds.\n",
            "2023-10-30 15:51:36,146 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0750 | Train accuracy: 84.54%.\n",
            "2023-10-30 15:51:36,640 max.py[line:93] INFO: max: attack effectiveness 49.23076923076923%.\n",
            "2023-10-30 15:51:36,652 md_at_ma.py[line:120] INFO: Mini batch: 1233/1450 | training time in 13 minutes, 31 seconds.\n",
            "2023-10-30 15:51:36,652 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0333 | Train accuracy: 86.53%.\n",
            "2023-10-30 15:51:37,428 max.py[line:93] INFO: max: attack effectiveness 63.38028169014085%.\n",
            "2023-10-30 15:51:37,440 md_at_ma.py[line:120] INFO: Mini batch: 1234/1450 | training time in 13 minutes, 32 seconds.\n",
            "2023-10-30 15:51:37,440 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0447 | Train accuracy: 77.89%.\n",
            "2023-10-30 15:51:37,926 max.py[line:93] INFO: max: attack effectiveness 45.3125%.\n",
            "2023-10-30 15:51:37,935 md_at_ma.py[line:120] INFO: Mini batch: 1235/1450 | training time in 13 minutes, 33 seconds.\n",
            "2023-10-30 15:51:37,935 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0187 | Train accuracy: 86.46%.\n",
            "2023-10-30 15:51:38,704 max.py[line:93] INFO: max: attack effectiveness 50.74626865671642%.\n",
            "2023-10-30 15:51:38,716 md_at_ma.py[line:120] INFO: Mini batch: 1236/1450 | training time in 13 minutes, 34 seconds.\n",
            "2023-10-30 15:51:38,716 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0650 | Train accuracy: 83.08%.\n",
            "2023-10-30 15:51:39,208 max.py[line:93] INFO: max: attack effectiveness 57.8125%.\n",
            "2023-10-30 15:51:39,217 md_at_ma.py[line:120] INFO: Mini batch: 1237/1450 | training time in 13 minutes, 34 seconds.\n",
            "2023-10-30 15:51:39,217 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0374 | Train accuracy: 82.81%.\n",
            "2023-10-30 15:51:40,035 max.py[line:93] INFO: max: attack effectiveness 58.108108108108105%.\n",
            "2023-10-30 15:51:40,048 md_at_ma.py[line:120] INFO: Mini batch: 1238/1450 | training time in 13 minutes, 35 seconds.\n",
            "2023-10-30 15:51:40,048 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0492 | Train accuracy: 82.18%.\n",
            "2023-10-30 15:51:40,833 max.py[line:93] INFO: max: attack effectiveness 44.927536231884055%.\n",
            "2023-10-30 15:51:40,845 md_at_ma.py[line:120] INFO: Mini batch: 1239/1450 | training time in 13 minutes, 36 seconds.\n",
            "2023-10-30 15:51:40,845 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0307 | Train accuracy: 84.77%.\n",
            "2023-10-30 15:51:41,674 max.py[line:93] INFO: max: attack effectiveness 53.333333333333336%.\n",
            "2023-10-30 15:51:41,686 md_at_ma.py[line:120] INFO: Mini batch: 1240/1450 | training time in 13 minutes, 36 seconds.\n",
            "2023-10-30 15:51:41,686 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0543 | Train accuracy: 84.73%.\n",
            "2023-10-30 15:51:42,460 max.py[line:93] INFO: max: attack effectiveness 48.529411764705884%.\n",
            "2023-10-30 15:51:42,472 md_at_ma.py[line:120] INFO: Mini batch: 1241/1450 | training time in 13 minutes, 37 seconds.\n",
            "2023-10-30 15:51:42,473 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0690 | Train accuracy: 84.18%.\n",
            "2023-10-30 15:51:43,061 max.py[line:93] INFO: max: attack effectiveness 54.23728813559322%.\n",
            "2023-10-30 15:51:43,070 md_at_ma.py[line:120] INFO: Mini batch: 1242/1450 | training time in 13 minutes, 38 seconds.\n",
            "2023-10-30 15:51:43,070 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0693 | Train accuracy: 82.89%.\n",
            "2023-10-30 15:51:43,893 max.py[line:93] INFO: max: attack effectiveness 56.00000000000001%.\n",
            "2023-10-30 15:51:43,905 md_at_ma.py[line:120] INFO: Mini batch: 1243/1450 | training time in 13 minutes, 39 seconds.\n",
            "2023-10-30 15:51:43,906 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0559 | Train accuracy: 80.79%.\n",
            "2023-10-30 15:51:44,675 max.py[line:93] INFO: max: attack effectiveness 55.072463768115945%.\n",
            "2023-10-30 15:51:44,687 md_at_ma.py[line:120] INFO: Mini batch: 1244/1450 | training time in 13 minutes, 39 seconds.\n",
            "2023-10-30 15:51:44,687 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0356 | Train accuracy: 81.73%.\n",
            "2023-10-30 15:51:45,177 max.py[line:93] INFO: max: attack effectiveness 45.3125%.\n",
            "2023-10-30 15:51:45,186 md_at_ma.py[line:120] INFO: Mini batch: 1245/1450 | training time in 13 minutes, 40 seconds.\n",
            "2023-10-30 15:51:45,186 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0245 | Train accuracy: 87.50%.\n",
            "2023-10-30 15:51:45,670 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:51:45,679 md_at_ma.py[line:120] INFO: Mini batch: 1246/1450 | training time in 13 minutes, 40 seconds.\n",
            "2023-10-30 15:51:45,680 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0344 | Train accuracy: 84.74%.\n",
            "2023-10-30 15:51:46,070 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:51:46,074 md_at_ma.py[line:120] INFO: Mini batch: 1247/1450 | training time in 13 minutes, 41 seconds.\n",
            "2023-10-30 15:51:46,074 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0149 | Train accuracy: 94.74%.\n",
            "2023-10-30 15:51:46,115 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0422 | Train accuracy: 83.44\n",
            "2023-10-30 15:51:48,392 max.py[line:93] INFO: max: attack effectiveness 70.3125%.\n",
            "2023-10-30 15:51:49,454 max.py[line:93] INFO: max: attack effectiveness 68.75%.\n",
            "2023-10-30 15:51:50,447 max.py[line:93] INFO: max: attack effectiveness 70.3125%.\n",
            "2023-10-30 15:51:51,361 max.py[line:93] INFO: max: attack effectiveness 66.40625%.\n",
            "2023-10-30 15:51:52,018 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:51:52,651 md_at_ma.py[line:165] INFO: \tVal accuracy 63.61% with accuracy 30.47% under attack.\n",
            "2023-10-30 15:51:52,651 md_at_ma.py[line:167] INFO: \tModel select at epoch 37 with validation accuracy 70.04% and accuracy 44.62% under attack.\n",
            "2023-10-30 15:51:53,508 max.py[line:93] INFO: max: attack effectiveness 56.060606060606055%.\n",
            "2023-10-30 15:51:53,522 md_at_ma.py[line:120] INFO: Mini batch: 1248/1450 | training time in 13 minutes, 41 seconds.\n",
            "2023-10-30 15:51:53,522 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0424 | Train accuracy: 81.96%.\n",
            "2023-10-30 15:51:54,006 max.py[line:93] INFO: max: attack effectiveness 65.07936507936508%.\n",
            "2023-10-30 15:51:54,015 md_at_ma.py[line:120] INFO: Mini batch: 1249/1450 | training time in 13 minutes, 42 seconds.\n",
            "2023-10-30 15:51:54,015 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0382 | Train accuracy: 82.20%.\n",
            "2023-10-30 15:51:54,780 max.py[line:93] INFO: max: attack effectiveness 53.03030303030303%.\n",
            "2023-10-30 15:51:54,792 md_at_ma.py[line:120] INFO: Mini batch: 1250/1450 | training time in 13 minutes, 43 seconds.\n",
            "2023-10-30 15:51:54,792 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0256 | Train accuracy: 84.02%.\n",
            "2023-10-30 15:51:55,566 max.py[line:93] INFO: max: attack effectiveness 61.42857142857143%.\n",
            "2023-10-30 15:51:55,578 md_at_ma.py[line:120] INFO: Mini batch: 1251/1450 | training time in 13 minutes, 43 seconds.\n",
            "2023-10-30 15:51:55,579 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0278 | Train accuracy: 79.80%.\n",
            "2023-10-30 15:51:56,360 max.py[line:93] INFO: max: attack effectiveness 60.56338028169014%.\n",
            "2023-10-30 15:51:56,372 md_at_ma.py[line:120] INFO: Mini batch: 1252/1450 | training time in 13 minutes, 44 seconds.\n",
            "2023-10-30 15:51:56,372 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0294 | Train accuracy: 80.90%.\n",
            "2023-10-30 15:51:57,205 max.py[line:93] INFO: max: attack effectiveness 63.1578947368421%.\n",
            "2023-10-30 15:51:57,217 md_at_ma.py[line:120] INFO: Mini batch: 1253/1450 | training time in 13 minutes, 45 seconds.\n",
            "2023-10-30 15:51:57,217 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0248 | Train accuracy: 78.92%.\n",
            "2023-10-30 15:51:57,694 max.py[line:93] INFO: max: attack effectiveness 57.377049180327866%.\n",
            "2023-10-30 15:51:57,703 md_at_ma.py[line:120] INFO: Mini batch: 1254/1450 | training time in 13 minutes, 46 seconds.\n",
            "2023-10-30 15:51:57,704 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0236 | Train accuracy: 83.07%.\n",
            "2023-10-30 15:51:58,490 max.py[line:93] INFO: max: attack effectiveness 52.17391304347826%.\n",
            "2023-10-30 15:51:58,502 md_at_ma.py[line:120] INFO: Mini batch: 1255/1450 | training time in 13 minutes, 46 seconds.\n",
            "2023-10-30 15:51:58,502 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0190 | Train accuracy: 85.79%.\n",
            "2023-10-30 15:51:59,014 max.py[line:93] INFO: max: attack effectiveness 45.16129032258064%.\n",
            "2023-10-30 15:51:59,023 md_at_ma.py[line:120] INFO: Mini batch: 1256/1450 | training time in 13 minutes, 47 seconds.\n",
            "2023-10-30 15:51:59,023 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0130 | Train accuracy: 87.89%.\n",
            "2023-10-30 15:51:59,512 max.py[line:93] INFO: max: attack effectiveness 65.0%.\n",
            "2023-10-30 15:51:59,522 md_at_ma.py[line:120] INFO: Mini batch: 1257/1450 | training time in 13 minutes, 47 seconds.\n",
            "2023-10-30 15:51:59,523 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0302 | Train accuracy: 83.51%.\n",
            "2023-10-30 15:52:00,115 max.py[line:93] INFO: max: attack effectiveness 42.592592592592595%.\n",
            "2023-10-30 15:52:00,124 md_at_ma.py[line:120] INFO: Mini batch: 1258/1450 | training time in 13 minutes, 48 seconds.\n",
            "2023-10-30 15:52:00,124 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0158 | Train accuracy: 89.01%.\n",
            "2023-10-30 15:52:00,647 max.py[line:93] INFO: max: attack effectiveness 55.55555555555556%.\n",
            "2023-10-30 15:52:00,656 md_at_ma.py[line:120] INFO: Mini batch: 1259/1450 | training time in 13 minutes, 48 seconds.\n",
            "2023-10-30 15:52:00,656 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0153 | Train accuracy: 84.29%.\n",
            "2023-10-30 15:52:01,398 max.py[line:93] INFO: max: attack effectiveness 58.46153846153847%.\n",
            "2023-10-30 15:52:01,410 md_at_ma.py[line:120] INFO: Mini batch: 1260/1450 | training time in 13 minutes, 49 seconds.\n",
            "2023-10-30 15:52:01,411 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0131 | Train accuracy: 86.53%.\n",
            "2023-10-30 15:52:02,175 max.py[line:93] INFO: max: attack effectiveness 48.484848484848484%.\n",
            "2023-10-30 15:52:02,187 md_at_ma.py[line:120] INFO: Mini batch: 1261/1450 | training time in 13 minutes, 50 seconds.\n",
            "2023-10-30 15:52:02,187 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0346 | Train accuracy: 85.57%.\n",
            "2023-10-30 15:52:02,926 max.py[line:93] INFO: max: attack effectiveness 44.61538461538462%.\n",
            "2023-10-30 15:52:02,939 md_at_ma.py[line:120] INFO: Mini batch: 1262/1450 | training time in 13 minutes, 51 seconds.\n",
            "2023-10-30 15:52:02,939 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0175 | Train accuracy: 86.01%.\n",
            "2023-10-30 15:52:03,713 max.py[line:93] INFO: max: attack effectiveness 60.56338028169014%.\n",
            "2023-10-30 15:52:03,725 md_at_ma.py[line:120] INFO: Mini batch: 1263/1450 | training time in 13 minutes, 51 seconds.\n",
            "2023-10-30 15:52:03,726 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0147 | Train accuracy: 82.41%.\n",
            "2023-10-30 15:52:04,212 max.py[line:93] INFO: max: attack effectiveness 45.3125%.\n",
            "2023-10-30 15:52:04,222 md_at_ma.py[line:120] INFO: Mini batch: 1264/1450 | training time in 13 minutes, 52 seconds.\n",
            "2023-10-30 15:52:04,222 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0129 | Train accuracy: 86.46%.\n",
            "2023-10-30 15:52:04,990 max.py[line:93] INFO: max: attack effectiveness 46.26865671641791%.\n",
            "2023-10-30 15:52:05,002 md_at_ma.py[line:120] INFO: Mini batch: 1265/1450 | training time in 13 minutes, 53 seconds.\n",
            "2023-10-30 15:52:05,002 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.2144 | Train accuracy: 84.10%.\n",
            "2023-10-30 15:52:05,495 max.py[line:93] INFO: max: attack effectiveness 53.125%.\n",
            "2023-10-30 15:52:05,504 md_at_ma.py[line:120] INFO: Mini batch: 1266/1450 | training time in 13 minutes, 53 seconds.\n",
            "2023-10-30 15:52:05,504 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0164 | Train accuracy: 85.42%.\n",
            "2023-10-30 15:52:06,323 max.py[line:93] INFO: max: attack effectiveness 55.4054054054054%.\n",
            "2023-10-30 15:52:06,336 md_at_ma.py[line:120] INFO: Mini batch: 1267/1450 | training time in 13 minutes, 54 seconds.\n",
            "2023-10-30 15:52:06,336 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0352 | Train accuracy: 82.18%.\n",
            "2023-10-30 15:52:07,108 max.py[line:93] INFO: max: attack effectiveness 52.17391304347826%.\n",
            "2023-10-30 15:52:07,120 md_at_ma.py[line:120] INFO: Mini batch: 1268/1450 | training time in 13 minutes, 55 seconds.\n",
            "2023-10-30 15:52:07,120 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0231 | Train accuracy: 83.76%.\n",
            "2023-10-30 15:52:07,946 max.py[line:93] INFO: max: attack effectiveness 53.333333333333336%.\n",
            "2023-10-30 15:52:07,958 md_at_ma.py[line:120] INFO: Mini batch: 1269/1450 | training time in 13 minutes, 56 seconds.\n",
            "2023-10-30 15:52:07,958 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0264 | Train accuracy: 81.77%.\n",
            "2023-10-30 15:52:08,728 max.py[line:93] INFO: max: attack effectiveness 51.470588235294116%.\n",
            "2023-10-30 15:52:08,740 md_at_ma.py[line:120] INFO: Mini batch: 1270/1450 | training time in 13 minutes, 56 seconds.\n",
            "2023-10-30 15:52:08,740 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0202 | Train accuracy: 84.18%.\n",
            "2023-10-30 15:52:09,333 max.py[line:93] INFO: max: attack effectiveness 55.932203389830505%.\n",
            "2023-10-30 15:52:09,342 md_at_ma.py[line:120] INFO: Mini batch: 1271/1450 | training time in 13 minutes, 57 seconds.\n",
            "2023-10-30 15:52:09,342 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0383 | Train accuracy: 84.49%.\n",
            "2023-10-30 15:52:10,164 max.py[line:93] INFO: max: attack effectiveness 49.333333333333336%.\n",
            "2023-10-30 15:52:10,176 md_at_ma.py[line:120] INFO: Mini batch: 1272/1450 | training time in 13 minutes, 58 seconds.\n",
            "2023-10-30 15:52:10,177 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0211 | Train accuracy: 81.77%.\n",
            "2023-10-30 15:52:10,945 max.py[line:93] INFO: max: attack effectiveness 55.072463768115945%.\n",
            "2023-10-30 15:52:10,957 md_at_ma.py[line:120] INFO: Mini batch: 1273/1450 | training time in 13 minutes, 58 seconds.\n",
            "2023-10-30 15:52:10,957 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0216 | Train accuracy: 82.74%.\n",
            "2023-10-30 15:52:11,458 max.py[line:93] INFO: max: attack effectiveness 40.625%.\n",
            "2023-10-30 15:52:11,467 md_at_ma.py[line:120] INFO: Mini batch: 1274/1450 | training time in 13 minutes, 59 seconds.\n",
            "2023-10-30 15:52:11,467 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0218 | Train accuracy: 88.02%.\n",
            "2023-10-30 15:52:11,961 max.py[line:93] INFO: max: attack effectiveness 43.54838709677419%.\n",
            "2023-10-30 15:52:11,970 md_at_ma.py[line:120] INFO: Mini batch: 1275/1450 | training time in 13 minutes, 59 seconds.\n",
            "2023-10-30 15:52:11,971 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0168 | Train accuracy: 86.32%.\n",
            "2023-10-30 15:52:12,364 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:52:12,368 md_at_ma.py[line:120] INFO: Mini batch: 1276/1450 | training time in 14 minutes, 0 seconds.\n",
            "2023-10-30 15:52:12,368 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0341 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:52:12,401 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0306 | Train accuracy: 84.23\n",
            "2023-10-30 15:52:14,711 max.py[line:93] INFO: max: attack effectiveness 59.375%.\n",
            "2023-10-30 15:52:15,643 max.py[line:93] INFO: max: attack effectiveness 60.9375%.\n",
            "2023-10-30 15:52:16,580 max.py[line:93] INFO: max: attack effectiveness 64.0625%.\n",
            "2023-10-30 15:52:17,592 max.py[line:93] INFO: max: attack effectiveness 55.46875%.\n",
            "2023-10-30 15:52:18,295 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:52:18,941 md_at_ma.py[line:165] INFO: \tVal accuracy 67.62% with accuracy 38.71% under attack.\n",
            "2023-10-30 15:52:18,941 md_at_ma.py[line:167] INFO: \tModel select at epoch 37 with validation accuracy 70.04% and accuracy 44.62% under attack.\n",
            "2023-10-30 15:52:19,798 max.py[line:93] INFO: max: attack effectiveness 45.45454545454545%.\n",
            "2023-10-30 15:52:19,811 md_at_ma.py[line:120] INFO: Mini batch: 1277/1450 | training time in 14 minutes, 1 seconds.\n",
            "2023-10-30 15:52:19,811 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0269 | Train accuracy: 84.54%.\n",
            "2023-10-30 15:52:20,295 max.py[line:93] INFO: max: attack effectiveness 55.55555555555556%.\n",
            "2023-10-30 15:52:20,304 md_at_ma.py[line:120] INFO: Mini batch: 1278/1450 | training time in 14 minutes, 1 seconds.\n",
            "2023-10-30 15:52:20,304 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0258 | Train accuracy: 84.82%.\n",
            "2023-10-30 15:52:21,071 max.py[line:93] INFO: max: attack effectiveness 48.484848484848484%.\n",
            "2023-10-30 15:52:21,083 md_at_ma.py[line:120] INFO: Mini batch: 1279/1450 | training time in 14 minutes, 2 seconds.\n",
            "2023-10-30 15:52:21,083 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0282 | Train accuracy: 86.60%.\n",
            "2023-10-30 15:52:21,858 max.py[line:93] INFO: max: attack effectiveness 52.85714285714286%.\n",
            "2023-10-30 15:52:21,870 md_at_ma.py[line:120] INFO: Mini batch: 1280/1450 | training time in 14 minutes, 3 seconds.\n",
            "2023-10-30 15:52:21,870 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0201 | Train accuracy: 82.83%.\n",
            "2023-10-30 15:52:22,645 max.py[line:93] INFO: max: attack effectiveness 54.929577464788736%.\n",
            "2023-10-30 15:52:22,657 md_at_ma.py[line:120] INFO: Mini batch: 1281/1450 | training time in 14 minutes, 3 seconds.\n",
            "2023-10-30 15:52:22,657 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0251 | Train accuracy: 81.41%.\n",
            "2023-10-30 15:52:23,483 max.py[line:93] INFO: max: attack effectiveness 53.94736842105263%.\n",
            "2023-10-30 15:52:23,495 md_at_ma.py[line:120] INFO: Mini batch: 1282/1450 | training time in 14 minutes, 4 seconds.\n",
            "2023-10-30 15:52:23,495 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0197 | Train accuracy: 81.37%.\n",
            "2023-10-30 15:52:23,974 max.py[line:93] INFO: max: attack effectiveness 47.540983606557376%.\n",
            "2023-10-30 15:52:23,983 md_at_ma.py[line:120] INFO: Mini batch: 1283/1450 | training time in 14 minutes, 5 seconds.\n",
            "2023-10-30 15:52:23,983 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0201 | Train accuracy: 87.30%.\n",
            "2023-10-30 15:52:24,758 max.py[line:93] INFO: max: attack effectiveness 46.3768115942029%.\n",
            "2023-10-30 15:52:24,770 md_at_ma.py[line:120] INFO: Mini batch: 1284/1450 | training time in 14 minutes, 5 seconds.\n",
            "2023-10-30 15:52:24,770 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0215 | Train accuracy: 84.77%.\n",
            "2023-10-30 15:52:25,259 max.py[line:93] INFO: max: attack effectiveness 38.70967741935484%.\n",
            "2023-10-30 15:52:25,268 md_at_ma.py[line:120] INFO: Mini batch: 1285/1450 | training time in 14 minutes, 6 seconds.\n",
            "2023-10-30 15:52:25,269 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0152 | Train accuracy: 88.42%.\n",
            "2023-10-30 15:52:25,779 max.py[line:93] INFO: max: attack effectiveness 58.333333333333336%.\n",
            "2023-10-30 15:52:25,788 md_at_ma.py[line:120] INFO: Mini batch: 1286/1450 | training time in 14 minutes, 6 seconds.\n",
            "2023-10-30 15:52:25,789 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0335 | Train accuracy: 82.98%.\n",
            "2023-10-30 15:52:26,382 max.py[line:93] INFO: max: attack effectiveness 38.88888888888889%.\n",
            "2023-10-30 15:52:26,391 md_at_ma.py[line:120] INFO: Mini batch: 1287/1450 | training time in 14 minutes, 7 seconds.\n",
            "2023-10-30 15:52:26,391 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0119 | Train accuracy: 89.56%.\n",
            "2023-10-30 15:52:26,922 max.py[line:93] INFO: max: attack effectiveness 52.38095238095239%.\n",
            "2023-10-30 15:52:26,931 md_at_ma.py[line:120] INFO: Mini batch: 1288/1450 | training time in 14 minutes, 8 seconds.\n",
            "2023-10-30 15:52:26,932 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0114 | Train accuracy: 87.43%.\n",
            "2023-10-30 15:52:27,705 max.py[line:93] INFO: max: attack effectiveness 50.76923076923077%.\n",
            "2023-10-30 15:52:27,717 md_at_ma.py[line:120] INFO: Mini batch: 1289/1450 | training time in 14 minutes, 8 seconds.\n",
            "2023-10-30 15:52:27,718 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0096 | Train accuracy: 86.01%.\n",
            "2023-10-30 15:52:28,489 max.py[line:93] INFO: max: attack effectiveness 45.45454545454545%.\n",
            "2023-10-30 15:52:28,501 md_at_ma.py[line:120] INFO: Mini batch: 1290/1450 | training time in 14 minutes, 9 seconds.\n",
            "2023-10-30 15:52:28,502 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0175 | Train accuracy: 87.11%.\n",
            "2023-10-30 15:52:29,234 max.py[line:93] INFO: max: attack effectiveness 41.53846153846154%.\n",
            "2023-10-30 15:52:29,247 md_at_ma.py[line:120] INFO: Mini batch: 1291/1450 | training time in 14 minutes, 10 seconds.\n",
            "2023-10-30 15:52:29,247 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0108 | Train accuracy: 87.05%.\n",
            "2023-10-30 15:52:30,025 max.py[line:93] INFO: max: attack effectiveness 49.29577464788733%.\n",
            "2023-10-30 15:52:30,037 md_at_ma.py[line:120] INFO: Mini batch: 1292/1450 | training time in 14 minutes, 11 seconds.\n",
            "2023-10-30 15:52:30,037 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0125 | Train accuracy: 85.43%.\n",
            "2023-10-30 15:52:30,521 max.py[line:93] INFO: max: attack effectiveness 37.5%.\n",
            "2023-10-30 15:52:30,530 md_at_ma.py[line:120] INFO: Mini batch: 1293/1450 | training time in 14 minutes, 11 seconds.\n",
            "2023-10-30 15:52:30,530 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0124 | Train accuracy: 89.06%.\n",
            "2023-10-30 15:52:31,303 max.py[line:93] INFO: max: attack effectiveness 41.7910447761194%.\n",
            "2023-10-30 15:52:31,315 md_at_ma.py[line:120] INFO: Mini batch: 1294/1450 | training time in 14 minutes, 12 seconds.\n",
            "2023-10-30 15:52:31,316 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0434 | Train accuracy: 87.69%.\n",
            "2023-10-30 15:52:31,799 max.py[line:93] INFO: max: attack effectiveness 43.75%.\n",
            "2023-10-30 15:52:31,808 md_at_ma.py[line:120] INFO: Mini batch: 1295/1450 | training time in 14 minutes, 12 seconds.\n",
            "2023-10-30 15:52:31,808 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0126 | Train accuracy: 88.54%.\n",
            "2023-10-30 15:52:32,630 max.py[line:93] INFO: max: attack effectiveness 52.702702702702695%.\n",
            "2023-10-30 15:52:32,642 md_at_ma.py[line:120] INFO: Mini batch: 1296/1450 | training time in 14 minutes, 13 seconds.\n",
            "2023-10-30 15:52:32,643 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0154 | Train accuracy: 84.65%.\n",
            "2023-10-30 15:52:33,415 max.py[line:93] INFO: max: attack effectiveness 43.47826086956522%.\n",
            "2023-10-30 15:52:33,427 md_at_ma.py[line:120] INFO: Mini batch: 1297/1450 | training time in 14 minutes, 14 seconds.\n",
            "2023-10-30 15:52:33,427 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0144 | Train accuracy: 84.77%.\n",
            "2023-10-30 15:52:34,250 max.py[line:93] INFO: max: attack effectiveness 52.0%.\n",
            "2023-10-30 15:52:34,262 md_at_ma.py[line:120] INFO: Mini batch: 1298/1450 | training time in 14 minutes, 15 seconds.\n",
            "2023-10-30 15:52:34,262 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0121 | Train accuracy: 82.27%.\n",
            "2023-10-30 15:52:35,033 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:52:35,045 md_at_ma.py[line:120] INFO: Mini batch: 1299/1450 | training time in 14 minutes, 15 seconds.\n",
            "2023-10-30 15:52:35,046 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0098 | Train accuracy: 84.18%.\n",
            "2023-10-30 15:52:35,630 max.py[line:93] INFO: max: attack effectiveness 52.54237288135594%.\n",
            "2023-10-30 15:52:35,639 md_at_ma.py[line:120] INFO: Mini batch: 1300/1450 | training time in 14 minutes, 16 seconds.\n",
            "2023-10-30 15:52:35,639 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0315 | Train accuracy: 86.63%.\n",
            "2023-10-30 15:52:36,461 max.py[line:93] INFO: max: attack effectiveness 50.66666666666667%.\n",
            "2023-10-30 15:52:36,473 md_at_ma.py[line:120] INFO: Mini batch: 1301/1450 | training time in 14 minutes, 17 seconds.\n",
            "2023-10-30 15:52:36,473 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0147 | Train accuracy: 80.79%.\n",
            "2023-10-30 15:52:37,246 max.py[line:93] INFO: max: attack effectiveness 53.62318840579711%.\n",
            "2023-10-30 15:52:37,258 md_at_ma.py[line:120] INFO: Mini batch: 1302/1450 | training time in 14 minutes, 18 seconds.\n",
            "2023-10-30 15:52:37,258 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0166 | Train accuracy: 81.73%.\n",
            "2023-10-30 15:52:37,749 max.py[line:93] INFO: max: attack effectiveness 42.1875%.\n",
            "2023-10-30 15:52:37,758 md_at_ma.py[line:120] INFO: Mini batch: 1303/1450 | training time in 14 minutes, 18 seconds.\n",
            "2023-10-30 15:52:37,758 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0162 | Train accuracy: 86.46%.\n",
            "2023-10-30 15:52:38,252 max.py[line:93] INFO: max: attack effectiveness 41.935483870967744%.\n",
            "2023-10-30 15:52:38,261 md_at_ma.py[line:120] INFO: Mini batch: 1304/1450 | training time in 14 minutes, 19 seconds.\n",
            "2023-10-30 15:52:38,261 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0114 | Train accuracy: 86.32%.\n",
            "2023-10-30 15:52:38,653 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:52:38,658 md_at_ma.py[line:120] INFO: Mini batch: 1305/1450 | training time in 14 minutes, 19 seconds.\n",
            "2023-10-30 15:52:38,658 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0118 | Train accuracy: 84.21%.\n",
            "2023-10-30 15:52:38,702 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0184 | Train accuracy: 85.34\n",
            "2023-10-30 15:52:41,225 max.py[line:93] INFO: max: attack effectiveness 59.375%.\n",
            "2023-10-30 15:52:42,278 max.py[line:93] INFO: max: attack effectiveness 57.8125%.\n",
            "2023-10-30 15:52:43,228 max.py[line:93] INFO: max: attack effectiveness 59.375%.\n",
            "2023-10-30 15:52:44,155 max.py[line:93] INFO: max: attack effectiveness 53.125%.\n",
            "2023-10-30 15:52:44,807 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:52:45,465 md_at_ma.py[line:165] INFO: \tVal accuracy 68.82% with accuracy 41.04% under attack.\n",
            "2023-10-30 15:52:45,465 md_at_ma.py[line:167] INFO: \tModel select at epoch 37 with validation accuracy 70.04% and accuracy 44.62% under attack.\n",
            "2023-10-30 15:52:46,356 max.py[line:93] INFO: max: attack effectiveness 43.93939393939394%.\n",
            "2023-10-30 15:52:46,369 md_at_ma.py[line:120] INFO: Mini batch: 1306/1450 | training time in 14 minutes, 20 seconds.\n",
            "2023-10-30 15:52:46,369 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0133 | Train accuracy: 87.11%.\n",
            "2023-10-30 15:52:46,860 max.py[line:93] INFO: max: attack effectiveness 49.2063492063492%.\n",
            "2023-10-30 15:52:46,869 md_at_ma.py[line:120] INFO: Mini batch: 1307/1450 | training time in 14 minutes, 20 seconds.\n",
            "2023-10-30 15:52:46,869 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0146 | Train accuracy: 88.48%.\n",
            "2023-10-30 15:52:47,643 max.py[line:93] INFO: max: attack effectiveness 45.45454545454545%.\n",
            "2023-10-30 15:52:47,655 md_at_ma.py[line:120] INFO: Mini batch: 1308/1450 | training time in 14 minutes, 21 seconds.\n",
            "2023-10-30 15:52:47,655 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0141 | Train accuracy: 87.11%.\n",
            "2023-10-30 15:52:48,429 max.py[line:93] INFO: max: attack effectiveness 47.14285714285714%.\n",
            "2023-10-30 15:52:48,442 md_at_ma.py[line:120] INFO: Mini batch: 1309/1450 | training time in 14 minutes, 22 seconds.\n",
            "2023-10-30 15:52:48,442 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0150 | Train accuracy: 87.37%.\n",
            "2023-10-30 15:52:49,221 max.py[line:93] INFO: max: attack effectiveness 49.29577464788733%.\n",
            "2023-10-30 15:52:49,233 md_at_ma.py[line:120] INFO: Mini batch: 1310/1450 | training time in 14 minutes, 23 seconds.\n",
            "2023-10-30 15:52:49,233 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0171 | Train accuracy: 84.42%.\n",
            "2023-10-30 15:52:50,059 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:52:50,071 md_at_ma.py[line:120] INFO: Mini batch: 1311/1450 | training time in 14 minutes, 23 seconds.\n",
            "2023-10-30 15:52:50,072 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0198 | Train accuracy: 84.80%.\n",
            "2023-10-30 15:52:50,551 max.py[line:93] INFO: max: attack effectiveness 39.34426229508197%.\n",
            "2023-10-30 15:52:50,560 md_at_ma.py[line:120] INFO: Mini batch: 1312/1450 | training time in 14 minutes, 24 seconds.\n",
            "2023-10-30 15:52:50,560 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0141 | Train accuracy: 88.36%.\n",
            "2023-10-30 15:52:51,339 max.py[line:93] INFO: max: attack effectiveness 42.028985507246375%.\n",
            "2023-10-30 15:52:51,351 md_at_ma.py[line:120] INFO: Mini batch: 1313/1450 | training time in 14 minutes, 25 seconds.\n",
            "2023-10-30 15:52:51,351 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0161 | Train accuracy: 87.82%.\n",
            "2023-10-30 15:52:51,888 max.py[line:93] INFO: max: attack effectiveness 37.096774193548384%.\n",
            "2023-10-30 15:52:51,897 md_at_ma.py[line:120] INFO: Mini batch: 1314/1450 | training time in 14 minutes, 25 seconds.\n",
            "2023-10-30 15:52:51,897 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0161 | Train accuracy: 90.53%.\n",
            "2023-10-30 15:52:52,427 max.py[line:93] INFO: max: attack effectiveness 48.333333333333336%.\n",
            "2023-10-30 15:52:52,436 md_at_ma.py[line:120] INFO: Mini batch: 1315/1450 | training time in 14 minutes, 26 seconds.\n",
            "2023-10-30 15:52:52,437 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0298 | Train accuracy: 87.77%.\n",
            "2023-10-30 15:52:53,036 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:52:53,045 md_at_ma.py[line:120] INFO: Mini batch: 1316/1450 | training time in 14 minutes, 26 seconds.\n",
            "2023-10-30 15:52:53,046 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0134 | Train accuracy: 90.66%.\n",
            "2023-10-30 15:52:53,538 max.py[line:93] INFO: max: attack effectiveness 47.61904761904761%.\n",
            "2023-10-30 15:52:53,547 md_at_ma.py[line:120] INFO: Mini batch: 1317/1450 | training time in 14 minutes, 27 seconds.\n",
            "2023-10-30 15:52:53,547 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0117 | Train accuracy: 86.91%.\n",
            "2023-10-30 15:52:54,290 max.py[line:93] INFO: max: attack effectiveness 50.76923076923077%.\n",
            "2023-10-30 15:52:54,302 md_at_ma.py[line:120] INFO: Mini batch: 1318/1450 | training time in 14 minutes, 28 seconds.\n",
            "2023-10-30 15:52:54,302 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0182 | Train accuracy: 85.49%.\n",
            "2023-10-30 15:52:55,068 max.py[line:93] INFO: max: attack effectiveness 43.93939393939394%.\n",
            "2023-10-30 15:52:55,080 md_at_ma.py[line:120] INFO: Mini batch: 1319/1450 | training time in 14 minutes, 28 seconds.\n",
            "2023-10-30 15:52:55,080 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0199 | Train accuracy: 86.08%.\n",
            "2023-10-30 15:52:55,815 max.py[line:93] INFO: max: attack effectiveness 40.0%.\n",
            "2023-10-30 15:52:55,828 md_at_ma.py[line:120] INFO: Mini batch: 1320/1450 | training time in 14 minutes, 29 seconds.\n",
            "2023-10-30 15:52:55,828 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0115 | Train accuracy: 89.12%.\n",
            "2023-10-30 15:52:56,603 max.py[line:93] INFO: max: attack effectiveness 47.88732394366197%.\n",
            "2023-10-30 15:52:56,615 md_at_ma.py[line:120] INFO: Mini batch: 1321/1450 | training time in 14 minutes, 30 seconds.\n",
            "2023-10-30 15:52:56,615 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0112 | Train accuracy: 84.92%.\n",
            "2023-10-30 15:52:57,102 max.py[line:93] INFO: max: attack effectiveness 35.9375%.\n",
            "2023-10-30 15:52:57,111 md_at_ma.py[line:120] INFO: Mini batch: 1322/1450 | training time in 14 minutes, 30 seconds.\n",
            "2023-10-30 15:52:57,111 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0099 | Train accuracy: 89.58%.\n",
            "2023-10-30 15:52:57,879 max.py[line:93] INFO: max: attack effectiveness 41.7910447761194%.\n",
            "2023-10-30 15:52:57,891 md_at_ma.py[line:120] INFO: Mini batch: 1323/1450 | training time in 14 minutes, 31 seconds.\n",
            "2023-10-30 15:52:57,892 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0667 | Train accuracy: 90.26%.\n",
            "2023-10-30 15:52:58,375 max.py[line:93] INFO: max: attack effectiveness 42.1875%.\n",
            "2023-10-30 15:52:58,384 md_at_ma.py[line:120] INFO: Mini batch: 1324/1450 | training time in 14 minutes, 31 seconds.\n",
            "2023-10-30 15:52:58,384 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0088 | Train accuracy: 88.54%.\n",
            "2023-10-30 15:52:59,207 max.py[line:93] INFO: max: attack effectiveness 52.702702702702695%.\n",
            "2023-10-30 15:52:59,219 md_at_ma.py[line:120] INFO: Mini batch: 1325/1450 | training time in 14 minutes, 32 seconds.\n",
            "2023-10-30 15:52:59,219 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0129 | Train accuracy: 84.65%.\n",
            "2023-10-30 15:52:59,991 max.py[line:93] INFO: max: attack effectiveness 40.57971014492754%.\n",
            "2023-10-30 15:53:00,003 md_at_ma.py[line:120] INFO: Mini batch: 1326/1450 | training time in 14 minutes, 33 seconds.\n",
            "2023-10-30 15:53:00,003 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0078 | Train accuracy: 87.82%.\n",
            "2023-10-30 15:53:00,829 max.py[line:93] INFO: max: attack effectiveness 50.66666666666667%.\n",
            "2023-10-30 15:53:00,841 md_at_ma.py[line:120] INFO: Mini batch: 1327/1450 | training time in 14 minutes, 34 seconds.\n",
            "2023-10-30 15:53:00,842 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0131 | Train accuracy: 83.25%.\n",
            "2023-10-30 15:53:01,612 max.py[line:93] INFO: max: attack effectiveness 48.529411764705884%.\n",
            "2023-10-30 15:53:01,624 md_at_ma.py[line:120] INFO: Mini batch: 1328/1450 | training time in 14 minutes, 35 seconds.\n",
            "2023-10-30 15:53:01,624 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0089 | Train accuracy: 86.22%.\n",
            "2023-10-30 15:53:02,213 max.py[line:93] INFO: max: attack effectiveness 42.3728813559322%.\n",
            "2023-10-30 15:53:02,221 md_at_ma.py[line:120] INFO: Mini batch: 1329/1450 | training time in 14 minutes, 35 seconds.\n",
            "2023-10-30 15:53:02,222 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0276 | Train accuracy: 86.10%.\n",
            "2023-10-30 15:53:03,044 max.py[line:93] INFO: max: attack effectiveness 45.33333333333333%.\n",
            "2023-10-30 15:53:03,057 md_at_ma.py[line:120] INFO: Mini batch: 1330/1450 | training time in 14 minutes, 36 seconds.\n",
            "2023-10-30 15:53:03,057 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0095 | Train accuracy: 88.18%.\n",
            "2023-10-30 15:53:03,825 max.py[line:93] INFO: max: attack effectiveness 49.275362318840585%.\n",
            "2023-10-30 15:53:03,837 md_at_ma.py[line:120] INFO: Mini batch: 1331/1450 | training time in 14 minutes, 37 seconds.\n",
            "2023-10-30 15:53:03,837 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0135 | Train accuracy: 85.28%.\n",
            "2023-10-30 15:53:04,339 max.py[line:93] INFO: max: attack effectiveness 37.5%.\n",
            "2023-10-30 15:53:04,348 md_at_ma.py[line:120] INFO: Mini batch: 1332/1450 | training time in 14 minutes, 37 seconds.\n",
            "2023-10-30 15:53:04,348 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0268 | Train accuracy: 85.42%.\n",
            "2023-10-30 15:53:04,839 max.py[line:93] INFO: max: attack effectiveness 41.935483870967744%.\n",
            "2023-10-30 15:53:04,848 md_at_ma.py[line:120] INFO: Mini batch: 1333/1450 | training time in 14 minutes, 38 seconds.\n",
            "2023-10-30 15:53:04,848 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0082 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:53:05,244 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:53:05,249 md_at_ma.py[line:120] INFO: Mini batch: 1334/1450 | training time in 14 minutes, 38 seconds.\n",
            "2023-10-30 15:53:05,250 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0035 | Train accuracy: 94.74%.\n",
            "2023-10-30 15:53:05,291 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0163 | Train accuracy: 87.46\n",
            "2023-10-30 15:53:07,708 max.py[line:93] INFO: max: attack effectiveness 59.375%.\n",
            "2023-10-30 15:53:08,822 max.py[line:93] INFO: max: attack effectiveness 57.03125%.\n",
            "2023-10-30 15:53:09,826 max.py[line:93] INFO: max: attack effectiveness 59.375%.\n",
            "2023-10-30 15:53:10,735 max.py[line:93] INFO: max: attack effectiveness 53.90625%.\n",
            "2023-10-30 15:53:11,397 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:53:12,075 md_at_ma.py[line:165] INFO: \tVal accuracy 68.94% with accuracy 41.04% under attack.\n",
            "2023-10-30 15:53:12,075 md_at_ma.py[line:167] INFO: \tModel select at epoch 37 with validation accuracy 70.04% and accuracy 44.62% under attack.\n",
            "2023-10-30 15:53:12,962 max.py[line:93] INFO: max: attack effectiveness 45.45454545454545%.\n",
            "2023-10-30 15:53:12,975 md_at_ma.py[line:120] INFO: Mini batch: 1335/1450 | training time in 14 minutes, 39 seconds.\n",
            "2023-10-30 15:53:12,975 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0116 | Train accuracy: 87.63%.\n",
            "2023-10-30 15:53:13,456 max.py[line:93] INFO: max: attack effectiveness 52.38095238095239%.\n",
            "2023-10-30 15:53:13,465 md_at_ma.py[line:120] INFO: Mini batch: 1336/1450 | training time in 14 minutes, 39 seconds.\n",
            "2023-10-30 15:53:13,465 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0103 | Train accuracy: 89.01%.\n",
            "2023-10-30 15:53:14,232 max.py[line:93] INFO: max: attack effectiveness 45.45454545454545%.\n",
            "2023-10-30 15:53:14,244 md_at_ma.py[line:120] INFO: Mini batch: 1337/1450 | training time in 14 minutes, 40 seconds.\n",
            "2023-10-30 15:53:14,245 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0094 | Train accuracy: 88.66%.\n",
            "2023-10-30 15:53:15,016 max.py[line:93] INFO: max: attack effectiveness 47.14285714285714%.\n",
            "2023-10-30 15:53:15,028 md_at_ma.py[line:120] INFO: Mini batch: 1338/1450 | training time in 14 minutes, 41 seconds.\n",
            "2023-10-30 15:53:15,028 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0079 | Train accuracy: 87.37%.\n",
            "2023-10-30 15:53:15,804 max.py[line:93] INFO: max: attack effectiveness 50.70422535211267%.\n",
            "2023-10-30 15:53:15,816 md_at_ma.py[line:120] INFO: Mini batch: 1339/1450 | training time in 14 minutes, 42 seconds.\n",
            "2023-10-30 15:53:15,817 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0111 | Train accuracy: 82.41%.\n",
            "2023-10-30 15:53:16,648 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:53:16,660 md_at_ma.py[line:120] INFO: Mini batch: 1340/1450 | training time in 14 minutes, 43 seconds.\n",
            "2023-10-30 15:53:16,660 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0096 | Train accuracy: 83.33%.\n",
            "2023-10-30 15:53:17,138 max.py[line:93] INFO: max: attack effectiveness 37.704918032786885%.\n",
            "2023-10-30 15:53:17,147 md_at_ma.py[line:120] INFO: Mini batch: 1341/1450 | training time in 14 minutes, 43 seconds.\n",
            "2023-10-30 15:53:17,147 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0096 | Train accuracy: 91.01%.\n",
            "2023-10-30 15:53:17,934 max.py[line:93] INFO: max: attack effectiveness 42.028985507246375%.\n",
            "2023-10-30 15:53:17,947 md_at_ma.py[line:120] INFO: Mini batch: 1342/1450 | training time in 14 minutes, 44 seconds.\n",
            "2023-10-30 15:53:17,947 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0134 | Train accuracy: 88.32%.\n",
            "2023-10-30 15:53:18,465 max.py[line:93] INFO: max: attack effectiveness 32.25806451612903%.\n",
            "2023-10-30 15:53:18,474 md_at_ma.py[line:120] INFO: Mini batch: 1343/1450 | training time in 14 minutes, 44 seconds.\n",
            "2023-10-30 15:53:18,474 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0087 | Train accuracy: 92.63%.\n",
            "2023-10-30 15:53:18,996 max.py[line:93] INFO: max: attack effectiveness 43.333333333333336%.\n",
            "2023-10-30 15:53:19,005 md_at_ma.py[line:120] INFO: Mini batch: 1344/1450 | training time in 14 minutes, 45 seconds.\n",
            "2023-10-30 15:53:19,005 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0219 | Train accuracy: 87.23%.\n",
            "2023-10-30 15:53:19,604 max.py[line:93] INFO: max: attack effectiveness 29.629629629629626%.\n",
            "2023-10-30 15:53:19,614 md_at_ma.py[line:120] INFO: Mini batch: 1345/1450 | training time in 14 minutes, 45 seconds.\n",
            "2023-10-30 15:53:19,615 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0152 | Train accuracy: 95.05%.\n",
            "2023-10-30 15:53:20,138 max.py[line:93] INFO: max: attack effectiveness 42.857142857142854%.\n",
            "2023-10-30 15:53:20,147 md_at_ma.py[line:120] INFO: Mini batch: 1346/1450 | training time in 14 minutes, 46 seconds.\n",
            "2023-10-30 15:53:20,147 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0159 | Train accuracy: 88.48%.\n",
            "2023-10-30 15:53:20,913 max.py[line:93] INFO: max: attack effectiveness 49.23076923076923%.\n",
            "2023-10-30 15:53:20,925 md_at_ma.py[line:120] INFO: Mini batch: 1347/1450 | training time in 14 minutes, 47 seconds.\n",
            "2023-10-30 15:53:20,925 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0076 | Train accuracy: 87.56%.\n",
            "2023-10-30 15:53:21,696 max.py[line:93] INFO: max: attack effectiveness 43.93939393939394%.\n",
            "2023-10-30 15:53:21,708 md_at_ma.py[line:120] INFO: Mini batch: 1348/1450 | training time in 14 minutes, 47 seconds.\n",
            "2023-10-30 15:53:21,709 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0331 | Train accuracy: 88.14%.\n",
            "2023-10-30 15:53:22,443 max.py[line:93] INFO: max: attack effectiveness 36.92307692307693%.\n",
            "2023-10-30 15:53:22,455 md_at_ma.py[line:120] INFO: Mini batch: 1349/1450 | training time in 14 minutes, 48 seconds.\n",
            "2023-10-30 15:53:22,456 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0091 | Train accuracy: 90.16%.\n",
            "2023-10-30 15:53:23,233 max.py[line:93] INFO: max: attack effectiveness 45.07042253521127%.\n",
            "2023-10-30 15:53:23,245 md_at_ma.py[line:120] INFO: Mini batch: 1350/1450 | training time in 14 minutes, 49 seconds.\n",
            "2023-10-30 15:53:23,245 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0194 | Train accuracy: 84.42%.\n",
            "2023-10-30 15:53:23,737 max.py[line:93] INFO: max: attack effectiveness 35.9375%.\n",
            "2023-10-30 15:53:23,745 md_at_ma.py[line:120] INFO: Mini batch: 1351/1450 | training time in 14 minutes, 49 seconds.\n",
            "2023-10-30 15:53:23,746 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0108 | Train accuracy: 89.06%.\n",
            "2023-10-30 15:53:24,514 max.py[line:93] INFO: max: attack effectiveness 41.7910447761194%.\n",
            "2023-10-30 15:53:24,526 md_at_ma.py[line:120] INFO: Mini batch: 1352/1450 | training time in 14 minutes, 50 seconds.\n",
            "2023-10-30 15:53:24,526 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0837 | Train accuracy: 88.72%.\n",
            "2023-10-30 15:53:25,014 max.py[line:93] INFO: max: attack effectiveness 43.75%.\n",
            "2023-10-30 15:53:25,023 md_at_ma.py[line:120] INFO: Mini batch: 1353/1450 | training time in 14 minutes, 51 seconds.\n",
            "2023-10-30 15:53:25,023 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0123 | Train accuracy: 87.50%.\n",
            "2023-10-30 15:53:25,847 max.py[line:93] INFO: max: attack effectiveness 52.702702702702695%.\n",
            "2023-10-30 15:53:25,859 md_at_ma.py[line:120] INFO: Mini batch: 1354/1450 | training time in 14 minutes, 52 seconds.\n",
            "2023-10-30 15:53:25,859 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0259 | Train accuracy: 82.18%.\n",
            "2023-10-30 15:53:26,633 max.py[line:93] INFO: max: attack effectiveness 40.57971014492754%.\n",
            "2023-10-30 15:53:26,645 md_at_ma.py[line:120] INFO: Mini batch: 1355/1450 | training time in 14 minutes, 52 seconds.\n",
            "2023-10-30 15:53:26,646 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0128 | Train accuracy: 87.31%.\n",
            "2023-10-30 15:53:27,469 max.py[line:93] INFO: max: attack effectiveness 52.0%.\n",
            "2023-10-30 15:53:27,481 md_at_ma.py[line:120] INFO: Mini batch: 1356/1450 | training time in 14 minutes, 53 seconds.\n",
            "2023-10-30 15:53:27,481 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0177 | Train accuracy: 86.21%.\n",
            "2023-10-30 15:53:28,251 max.py[line:93] INFO: max: attack effectiveness 48.529411764705884%.\n",
            "2023-10-30 15:53:28,263 md_at_ma.py[line:120] INFO: Mini batch: 1357/1450 | training time in 14 minutes, 54 seconds.\n",
            "2023-10-30 15:53:28,263 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0142 | Train accuracy: 84.18%.\n",
            "2023-10-30 15:53:28,851 max.py[line:93] INFO: max: attack effectiveness 42.3728813559322%.\n",
            "2023-10-30 15:53:28,860 md_at_ma.py[line:120] INFO: Mini batch: 1358/1450 | training time in 14 minutes, 54 seconds.\n",
            "2023-10-30 15:53:28,860 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0257 | Train accuracy: 87.70%.\n",
            "2023-10-30 15:53:29,683 max.py[line:93] INFO: max: attack effectiveness 45.33333333333333%.\n",
            "2023-10-30 15:53:29,695 md_at_ma.py[line:120] INFO: Mini batch: 1359/1450 | training time in 14 minutes, 55 seconds.\n",
            "2023-10-30 15:53:29,695 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0112 | Train accuracy: 83.74%.\n",
            "2023-10-30 15:53:30,472 max.py[line:93] INFO: max: attack effectiveness 52.17391304347826%.\n",
            "2023-10-30 15:53:30,484 md_at_ma.py[line:120] INFO: Mini batch: 1360/1450 | training time in 14 minutes, 56 seconds.\n",
            "2023-10-30 15:53:30,484 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0151 | Train accuracy: 84.77%.\n",
            "2023-10-30 15:53:30,976 max.py[line:93] INFO: max: attack effectiveness 37.5%.\n",
            "2023-10-30 15:53:30,985 md_at_ma.py[line:120] INFO: Mini batch: 1361/1450 | training time in 14 minutes, 57 seconds.\n",
            "2023-10-30 15:53:30,985 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0200 | Train accuracy: 89.06%.\n",
            "2023-10-30 15:53:31,488 max.py[line:93] INFO: max: attack effectiveness 45.16129032258064%.\n",
            "2023-10-30 15:53:31,497 md_at_ma.py[line:120] INFO: Mini batch: 1362/1450 | training time in 14 minutes, 57 seconds.\n",
            "2023-10-30 15:53:31,497 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0116 | Train accuracy: 84.74%.\n",
            "2023-10-30 15:53:31,951 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:53:31,960 md_at_ma.py[line:120] INFO: Mini batch: 1363/1450 | training time in 14 minutes, 58 seconds.\n",
            "2023-10-30 15:53:31,963 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0098 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:53:32,001 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0167 | Train accuracy: 87.45\n",
            "2023-10-30 15:53:34,555 max.py[line:93] INFO: max: attack effectiveness 53.125%.\n",
            "2023-10-30 15:53:35,614 max.py[line:93] INFO: max: attack effectiveness 54.6875%.\n",
            "2023-10-30 15:53:36,512 max.py[line:93] INFO: max: attack effectiveness 57.8125%.\n",
            "2023-10-30 15:53:37,383 max.py[line:93] INFO: max: attack effectiveness 53.125%.\n",
            "2023-10-30 15:53:38,082 max.py[line:93] INFO: max: attack effectiveness 71.73913043478261%.\n",
            "2023-10-30 15:53:38,749 md_at_ma.py[line:165] INFO: \tVal accuracy 69.67% with accuracy 43.91% under attack.\n",
            "2023-10-30 15:53:38,749 md_at_ma.py[line:167] INFO: \tModel select at epoch 37 with validation accuracy 70.04% and accuracy 44.62% under attack.\n",
            "2023-10-30 15:53:39,616 max.py[line:93] INFO: max: attack effectiveness 45.45454545454545%.\n",
            "2023-10-30 15:53:39,629 md_at_ma.py[line:120] INFO: Mini batch: 1364/1450 | training time in 14 minutes, 58 seconds.\n",
            "2023-10-30 15:53:39,629 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0149 | Train accuracy: 85.57%.\n",
            "2023-10-30 15:53:40,122 max.py[line:93] INFO: max: attack effectiveness 47.61904761904761%.\n",
            "2023-10-30 15:53:40,131 md_at_ma.py[line:120] INFO: Mini batch: 1365/1450 | training time in 14 minutes, 59 seconds.\n",
            "2023-10-30 15:53:40,132 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0179 | Train accuracy: 84.82%.\n",
            "2023-10-30 15:53:40,900 max.py[line:93] INFO: max: attack effectiveness 43.93939393939394%.\n",
            "2023-10-30 15:53:40,912 md_at_ma.py[line:120] INFO: Mini batch: 1366/1450 | training time in 15 minutes, 0 seconds.\n",
            "2023-10-30 15:53:40,912 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0130 | Train accuracy: 86.60%.\n",
            "2023-10-30 15:53:41,689 max.py[line:93] INFO: max: attack effectiveness 47.14285714285714%.\n",
            "2023-10-30 15:53:41,701 md_at_ma.py[line:120] INFO: Mini batch: 1367/1450 | training time in 15 minutes, 0 seconds.\n",
            "2023-10-30 15:53:41,701 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0116 | Train accuracy: 86.87%.\n",
            "2023-10-30 15:53:42,476 max.py[line:93] INFO: max: attack effectiveness 49.29577464788733%.\n",
            "2023-10-30 15:53:42,488 md_at_ma.py[line:120] INFO: Mini batch: 1368/1450 | training time in 15 minutes, 1 seconds.\n",
            "2023-10-30 15:53:42,489 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0130 | Train accuracy: 83.42%.\n",
            "2023-10-30 15:53:43,312 max.py[line:93] INFO: max: attack effectiveness 48.68421052631579%.\n",
            "2023-10-30 15:53:43,324 md_at_ma.py[line:120] INFO: Mini batch: 1369/1450 | training time in 15 minutes, 2 seconds.\n",
            "2023-10-30 15:53:43,325 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0119 | Train accuracy: 85.29%.\n",
            "2023-10-30 15:53:43,803 max.py[line:93] INFO: max: attack effectiveness 37.704918032786885%.\n",
            "2023-10-30 15:53:43,812 md_at_ma.py[line:120] INFO: Mini batch: 1370/1450 | training time in 15 minutes, 2 seconds.\n",
            "2023-10-30 15:53:43,812 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0127 | Train accuracy: 87.83%.\n",
            "2023-10-30 15:53:44,590 max.py[line:93] INFO: max: attack effectiveness 40.57971014492754%.\n",
            "2023-10-30 15:53:44,605 md_at_ma.py[line:120] INFO: Mini batch: 1371/1450 | training time in 15 minutes, 3 seconds.\n",
            "2023-10-30 15:53:44,605 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0166 | Train accuracy: 87.31%.\n",
            "2023-10-30 15:53:45,139 max.py[line:93] INFO: max: attack effectiveness 33.87096774193548%.\n",
            "2023-10-30 15:53:45,149 md_at_ma.py[line:120] INFO: Mini batch: 1372/1450 | training time in 15 minutes, 4 seconds.\n",
            "2023-10-30 15:53:45,149 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0193 | Train accuracy: 90.00%.\n",
            "2023-10-30 15:53:45,679 max.py[line:93] INFO: max: attack effectiveness 46.666666666666664%.\n",
            "2023-10-30 15:53:45,688 md_at_ma.py[line:120] INFO: Mini batch: 1373/1450 | training time in 15 minutes, 4 seconds.\n",
            "2023-10-30 15:53:45,688 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0280 | Train accuracy: 86.17%.\n",
            "2023-10-30 15:53:46,295 max.py[line:93] INFO: max: attack effectiveness 31.48148148148148%.\n",
            "2023-10-30 15:53:46,304 md_at_ma.py[line:120] INFO: Mini batch: 1374/1450 | training time in 15 minutes, 5 seconds.\n",
            "2023-10-30 15:53:46,305 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0150 | Train accuracy: 91.76%.\n",
            "2023-10-30 15:53:46,850 max.py[line:93] INFO: max: attack effectiveness 47.61904761904761%.\n",
            "2023-10-30 15:53:46,859 md_at_ma.py[line:120] INFO: Mini batch: 1375/1450 | training time in 15 minutes, 5 seconds.\n",
            "2023-10-30 15:53:46,860 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0133 | Train accuracy: 87.43%.\n",
            "2023-10-30 15:53:47,612 max.py[line:93] INFO: max: attack effectiveness 49.23076923076923%.\n",
            "2023-10-30 15:53:47,624 md_at_ma.py[line:120] INFO: Mini batch: 1376/1450 | training time in 15 minutes, 6 seconds.\n",
            "2023-10-30 15:53:47,625 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0074 | Train accuracy: 86.01%.\n",
            "2023-10-30 15:53:48,392 max.py[line:93] INFO: max: attack effectiveness 40.909090909090914%.\n",
            "2023-10-30 15:53:48,404 md_at_ma.py[line:120] INFO: Mini batch: 1377/1450 | training time in 15 minutes, 7 seconds.\n",
            "2023-10-30 15:53:48,404 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0349 | Train accuracy: 89.18%.\n",
            "2023-10-30 15:53:49,138 max.py[line:93] INFO: max: attack effectiveness 38.46153846153847%.\n",
            "2023-10-30 15:53:49,150 md_at_ma.py[line:120] INFO: Mini batch: 1378/1450 | training time in 15 minutes, 8 seconds.\n",
            "2023-10-30 15:53:49,150 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0135 | Train accuracy: 88.60%.\n",
            "2023-10-30 15:53:49,928 max.py[line:93] INFO: max: attack effectiveness 40.845070422535215%.\n",
            "2023-10-30 15:53:49,940 md_at_ma.py[line:120] INFO: Mini batch: 1379/1450 | training time in 15 minutes, 8 seconds.\n",
            "2023-10-30 15:53:49,941 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0089 | Train accuracy: 88.94%.\n",
            "2023-10-30 15:53:50,430 max.py[line:93] INFO: max: attack effectiveness 34.375%.\n",
            "2023-10-30 15:53:50,439 md_at_ma.py[line:120] INFO: Mini batch: 1380/1450 | training time in 15 minutes, 9 seconds.\n",
            "2023-10-30 15:53:50,439 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0087 | Train accuracy: 90.62%.\n",
            "2023-10-30 15:53:51,206 max.py[line:93] INFO: max: attack effectiveness 38.80597014925373%.\n",
            "2023-10-30 15:53:51,218 md_at_ma.py[line:120] INFO: Mini batch: 1381/1450 | training time in 15 minutes, 10 seconds.\n",
            "2023-10-30 15:53:51,219 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0506 | Train accuracy: 86.67%.\n",
            "2023-10-30 15:53:51,704 max.py[line:93] INFO: max: attack effectiveness 42.1875%.\n",
            "2023-10-30 15:53:51,713 md_at_ma.py[line:120] INFO: Mini batch: 1382/1450 | training time in 15 minutes, 10 seconds.\n",
            "2023-10-30 15:53:51,713 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0121 | Train accuracy: 88.54%.\n",
            "2023-10-30 15:53:52,540 max.py[line:93] INFO: max: attack effectiveness 51.35135135135135%.\n",
            "2023-10-30 15:53:52,552 md_at_ma.py[line:120] INFO: Mini batch: 1383/1450 | training time in 15 minutes, 11 seconds.\n",
            "2023-10-30 15:53:52,552 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0157 | Train accuracy: 83.66%.\n",
            "2023-10-30 15:53:53,324 max.py[line:93] INFO: max: attack effectiveness 40.57971014492754%.\n",
            "2023-10-30 15:53:53,336 md_at_ma.py[line:120] INFO: Mini batch: 1384/1450 | training time in 15 minutes, 12 seconds.\n",
            "2023-10-30 15:53:53,336 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0111 | Train accuracy: 87.82%.\n",
            "2023-10-30 15:53:54,159 max.py[line:93] INFO: max: attack effectiveness 48.0%.\n",
            "2023-10-30 15:53:54,171 md_at_ma.py[line:120] INFO: Mini batch: 1385/1450 | training time in 15 minutes, 12 seconds.\n",
            "2023-10-30 15:53:54,171 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0152 | Train accuracy: 83.74%.\n",
            "2023-10-30 15:53:54,940 max.py[line:93] INFO: max: attack effectiveness 48.529411764705884%.\n",
            "2023-10-30 15:53:54,953 md_at_ma.py[line:120] INFO: Mini batch: 1386/1450 | training time in 15 minutes, 13 seconds.\n",
            "2023-10-30 15:53:54,953 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0158 | Train accuracy: 84.69%.\n",
            "2023-10-30 15:53:55,543 max.py[line:93] INFO: max: attack effectiveness 40.67796610169492%.\n",
            "2023-10-30 15:53:55,552 md_at_ma.py[line:120] INFO: Mini batch: 1387/1450 | training time in 15 minutes, 14 seconds.\n",
            "2023-10-30 15:53:55,552 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0245 | Train accuracy: 87.17%.\n",
            "2023-10-30 15:53:56,377 max.py[line:93] INFO: max: attack effectiveness 45.33333333333333%.\n",
            "2023-10-30 15:53:56,389 md_at_ma.py[line:120] INFO: Mini batch: 1388/1450 | training time in 15 minutes, 15 seconds.\n",
            "2023-10-30 15:53:56,389 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0109 | Train accuracy: 84.24%.\n",
            "2023-10-30 15:53:57,166 max.py[line:93] INFO: max: attack effectiveness 50.72463768115942%.\n",
            "2023-10-30 15:53:57,178 md_at_ma.py[line:120] INFO: Mini batch: 1389/1450 | training time in 15 minutes, 15 seconds.\n",
            "2023-10-30 15:53:57,178 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0143 | Train accuracy: 84.26%.\n",
            "2023-10-30 15:53:57,673 max.py[line:93] INFO: max: attack effectiveness 37.5%.\n",
            "2023-10-30 15:53:57,682 md_at_ma.py[line:120] INFO: Mini batch: 1390/1450 | training time in 15 minutes, 16 seconds.\n",
            "2023-10-30 15:53:57,682 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0163 | Train accuracy: 89.06%.\n",
            "2023-10-30 15:53:58,180 max.py[line:93] INFO: max: attack effectiveness 40.32258064516129%.\n",
            "2023-10-30 15:53:58,190 md_at_ma.py[line:120] INFO: Mini batch: 1391/1450 | training time in 15 minutes, 16 seconds.\n",
            "2023-10-30 15:53:58,190 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0178 | Train accuracy: 88.95%.\n",
            "2023-10-30 15:53:58,591 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:53:58,595 md_at_ma.py[line:120] INFO: Mini batch: 1392/1450 | training time in 15 minutes, 17 seconds.\n",
            "2023-10-30 15:53:58,595 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0144 | Train accuracy: 94.74%.\n",
            "2023-10-30 15:53:58,633 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0165 | Train accuracy: 87.24\n",
            "2023-10-30 15:54:00,885 max.py[line:93] INFO: max: attack effectiveness 57.8125%.\n",
            "2023-10-30 15:54:02,002 max.py[line:93] INFO: max: attack effectiveness 54.6875%.\n",
            "2023-10-30 15:54:02,948 max.py[line:93] INFO: max: attack effectiveness 58.59375%.\n",
            "2023-10-30 15:54:03,884 max.py[line:93] INFO: max: attack effectiveness 50.0%.\n",
            "2023-10-30 15:54:04,565 max.py[line:93] INFO: max: attack effectiveness 76.08695652173914%.\n",
            "2023-10-30 15:54:05,156 md_at_ma.py[line:165] INFO: \tVal accuracy 69.57% with accuracy 43.01% under attack.\n",
            "2023-10-30 15:54:05,156 md_at_ma.py[line:167] INFO: \tModel select at epoch 37 with validation accuracy 70.04% and accuracy 44.62% under attack.\n",
            "2023-10-30 15:54:06,035 max.py[line:93] INFO: max: attack effectiveness 42.42424242424242%.\n",
            "2023-10-30 15:54:06,048 md_at_ma.py[line:120] INFO: Mini batch: 1393/1450 | training time in 15 minutes, 18 seconds.\n",
            "2023-10-30 15:54:06,048 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0131 | Train accuracy: 86.08%.\n",
            "2023-10-30 15:54:06,535 max.py[line:93] INFO: max: attack effectiveness 46.03174603174603%.\n",
            "2023-10-30 15:54:06,544 md_at_ma.py[line:120] INFO: Mini batch: 1394/1450 | training time in 15 minutes, 18 seconds.\n",
            "2023-10-30 15:54:06,544 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0100 | Train accuracy: 90.58%.\n",
            "2023-10-30 15:54:07,313 max.py[line:93] INFO: max: attack effectiveness 43.93939393939394%.\n",
            "2023-10-30 15:54:07,325 md_at_ma.py[line:120] INFO: Mini batch: 1395/1450 | training time in 15 minutes, 19 seconds.\n",
            "2023-10-30 15:54:07,325 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0106 | Train accuracy: 88.14%.\n",
            "2023-10-30 15:54:08,102 max.py[line:93] INFO: max: attack effectiveness 44.285714285714285%.\n",
            "2023-10-30 15:54:08,114 md_at_ma.py[line:120] INFO: Mini batch: 1396/1450 | training time in 15 minutes, 20 seconds.\n",
            "2023-10-30 15:54:08,115 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0127 | Train accuracy: 87.88%.\n",
            "2023-10-30 15:54:08,893 max.py[line:93] INFO: max: attack effectiveness 45.07042253521127%.\n",
            "2023-10-30 15:54:08,905 md_at_ma.py[line:120] INFO: Mini batch: 1397/1450 | training time in 15 minutes, 20 seconds.\n",
            "2023-10-30 15:54:08,905 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0165 | Train accuracy: 88.94%.\n",
            "2023-10-30 15:54:09,737 max.py[line:93] INFO: max: attack effectiveness 46.05263157894737%.\n",
            "2023-10-30 15:54:09,750 md_at_ma.py[line:120] INFO: Mini batch: 1398/1450 | training time in 15 minutes, 21 seconds.\n",
            "2023-10-30 15:54:09,750 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0139 | Train accuracy: 83.82%.\n",
            "2023-10-30 15:54:10,235 max.py[line:93] INFO: max: attack effectiveness 37.704918032786885%.\n",
            "2023-10-30 15:54:10,244 md_at_ma.py[line:120] INFO: Mini batch: 1399/1450 | training time in 15 minutes, 22 seconds.\n",
            "2023-10-30 15:54:10,245 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0169 | Train accuracy: 89.42%.\n",
            "2023-10-30 15:54:11,030 max.py[line:93] INFO: max: attack effectiveness 37.68115942028986%.\n",
            "2023-10-30 15:54:11,042 md_at_ma.py[line:120] INFO: Mini batch: 1400/1450 | training time in 15 minutes, 22 seconds.\n",
            "2023-10-30 15:54:11,042 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0148 | Train accuracy: 90.36%.\n",
            "2023-10-30 15:54:11,583 max.py[line:93] INFO: max: attack effectiveness 30.64516129032258%.\n",
            "2023-10-30 15:54:11,592 md_at_ma.py[line:120] INFO: Mini batch: 1401/1450 | training time in 15 minutes, 23 seconds.\n",
            "2023-10-30 15:54:11,592 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0126 | Train accuracy: 91.05%.\n",
            "2023-10-30 15:54:12,104 max.py[line:93] INFO: max: attack effectiveness 41.66666666666667%.\n",
            "2023-10-30 15:54:12,113 md_at_ma.py[line:120] INFO: Mini batch: 1402/1450 | training time in 15 minutes, 23 seconds.\n",
            "2023-10-30 15:54:12,114 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0232 | Train accuracy: 87.23%.\n",
            "2023-10-30 15:54:12,678 max.py[line:93] INFO: max: attack effectiveness 29.629629629629626%.\n",
            "2023-10-30 15:54:12,687 md_at_ma.py[line:120] INFO: Mini batch: 1403/1450 | training time in 15 minutes, 24 seconds.\n",
            "2023-10-30 15:54:12,688 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0104 | Train accuracy: 91.76%.\n",
            "2023-10-30 15:54:13,210 max.py[line:93] INFO: max: attack effectiveness 42.857142857142854%.\n",
            "2023-10-30 15:54:13,219 md_at_ma.py[line:120] INFO: Mini batch: 1404/1450 | training time in 15 minutes, 25 seconds.\n",
            "2023-10-30 15:54:13,220 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0102 | Train accuracy: 88.48%.\n",
            "2023-10-30 15:54:13,980 max.py[line:93] INFO: max: attack effectiveness 44.61538461538462%.\n",
            "2023-10-30 15:54:13,992 md_at_ma.py[line:120] INFO: Mini batch: 1405/1450 | training time in 15 minutes, 25 seconds.\n",
            "2023-10-30 15:54:13,992 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0084 | Train accuracy: 89.12%.\n",
            "2023-10-30 15:54:14,759 max.py[line:93] INFO: max: attack effectiveness 40.909090909090914%.\n",
            "2023-10-30 15:54:14,771 md_at_ma.py[line:120] INFO: Mini batch: 1406/1450 | training time in 15 minutes, 26 seconds.\n",
            "2023-10-30 15:54:14,771 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0229 | Train accuracy: 88.14%.\n",
            "2023-10-30 15:54:15,504 max.py[line:93] INFO: max: attack effectiveness 36.92307692307693%.\n",
            "2023-10-30 15:54:15,516 md_at_ma.py[line:120] INFO: Mini batch: 1407/1450 | training time in 15 minutes, 27 seconds.\n",
            "2023-10-30 15:54:15,516 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0209 | Train accuracy: 88.60%.\n",
            "2023-10-30 15:54:16,292 max.py[line:93] INFO: max: attack effectiveness 45.07042253521127%.\n",
            "2023-10-30 15:54:16,304 md_at_ma.py[line:120] INFO: Mini batch: 1408/1450 | training time in 15 minutes, 28 seconds.\n",
            "2023-10-30 15:54:16,304 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0122 | Train accuracy: 85.43%.\n",
            "2023-10-30 15:54:16,791 max.py[line:93] INFO: max: attack effectiveness 35.9375%.\n",
            "2023-10-30 15:54:16,800 md_at_ma.py[line:120] INFO: Mini batch: 1409/1450 | training time in 15 minutes, 28 seconds.\n",
            "2023-10-30 15:54:16,800 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0140 | Train accuracy: 89.58%.\n",
            "2023-10-30 15:54:17,568 max.py[line:93] INFO: max: attack effectiveness 41.7910447761194%.\n",
            "2023-10-30 15:54:17,580 md_at_ma.py[line:120] INFO: Mini batch: 1410/1450 | training time in 15 minutes, 29 seconds.\n",
            "2023-10-30 15:54:17,580 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0110 | Train accuracy: 88.72%.\n",
            "2023-10-30 15:54:18,066 max.py[line:93] INFO: max: attack effectiveness 42.1875%.\n",
            "2023-10-30 15:54:18,074 md_at_ma.py[line:120] INFO: Mini batch: 1411/1450 | training time in 15 minutes, 29 seconds.\n",
            "2023-10-30 15:54:18,075 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0113 | Train accuracy: 88.54%.\n",
            "2023-10-30 15:54:18,897 max.py[line:93] INFO: max: attack effectiveness 51.35135135135135%.\n",
            "2023-10-30 15:54:18,909 md_at_ma.py[line:120] INFO: Mini batch: 1412/1450 | training time in 15 minutes, 30 seconds.\n",
            "2023-10-30 15:54:18,909 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0169 | Train accuracy: 83.17%.\n",
            "2023-10-30 15:54:19,683 max.py[line:93] INFO: max: attack effectiveness 39.130434782608695%.\n",
            "2023-10-30 15:54:19,695 md_at_ma.py[line:120] INFO: Mini batch: 1413/1450 | training time in 15 minutes, 31 seconds.\n",
            "2023-10-30 15:54:19,695 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0101 | Train accuracy: 87.82%.\n",
            "2023-10-30 15:54:20,520 max.py[line:93] INFO: max: attack effectiveness 48.0%.\n",
            "2023-10-30 15:54:20,532 md_at_ma.py[line:120] INFO: Mini batch: 1414/1450 | training time in 15 minutes, 32 seconds.\n",
            "2023-10-30 15:54:20,532 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0177 | Train accuracy: 83.74%.\n",
            "2023-10-30 15:54:21,303 max.py[line:93] INFO: max: attack effectiveness 48.529411764705884%.\n",
            "2023-10-30 15:54:21,315 md_at_ma.py[line:120] INFO: Mini batch: 1415/1450 | training time in 15 minutes, 32 seconds.\n",
            "2023-10-30 15:54:21,315 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0071 | Train accuracy: 87.76%.\n",
            "2023-10-30 15:54:21,902 max.py[line:93] INFO: max: attack effectiveness 40.67796610169492%.\n",
            "2023-10-30 15:54:21,910 md_at_ma.py[line:120] INFO: Mini batch: 1416/1450 | training time in 15 minutes, 33 seconds.\n",
            "2023-10-30 15:54:21,911 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0277 | Train accuracy: 89.84%.\n",
            "2023-10-30 15:54:22,734 max.py[line:93] INFO: max: attack effectiveness 45.33333333333333%.\n",
            "2023-10-30 15:54:22,746 md_at_ma.py[line:120] INFO: Mini batch: 1417/1450 | training time in 15 minutes, 34 seconds.\n",
            "2023-10-30 15:54:22,746 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0093 | Train accuracy: 86.70%.\n",
            "2023-10-30 15:54:23,517 max.py[line:93] INFO: max: attack effectiveness 44.927536231884055%.\n",
            "2023-10-30 15:54:23,529 md_at_ma.py[line:120] INFO: Mini batch: 1418/1450 | training time in 15 minutes, 35 seconds.\n",
            "2023-10-30 15:54:23,530 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0166 | Train accuracy: 86.29%.\n",
            "2023-10-30 15:54:24,024 max.py[line:93] INFO: max: attack effectiveness 34.375%.\n",
            "2023-10-30 15:54:24,033 md_at_ma.py[line:120] INFO: Mini batch: 1419/1450 | training time in 15 minutes, 35 seconds.\n",
            "2023-10-30 15:54:24,033 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0187 | Train accuracy: 91.15%.\n",
            "2023-10-30 15:54:24,524 max.py[line:93] INFO: max: attack effectiveness 40.32258064516129%.\n",
            "2023-10-30 15:54:24,533 md_at_ma.py[line:120] INFO: Mini batch: 1420/1450 | training time in 15 minutes, 36 seconds.\n",
            "2023-10-30 15:54:24,533 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0084 | Train accuracy: 88.42%.\n",
            "2023-10-30 15:54:24,934 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:54:24,938 md_at_ma.py[line:120] INFO: Mini batch: 1421/1450 | training time in 15 minutes, 36 seconds.\n",
            "2023-10-30 15:54:24,939 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0075 | Train accuracy: 94.74%.\n",
            "2023-10-30 15:54:24,970 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0140 | Train accuracy: 88.33\n",
            "2023-10-30 15:54:27,409 max.py[line:93] INFO: max: attack effectiveness 52.34375%.\n",
            "2023-10-30 15:54:28,451 max.py[line:93] INFO: max: attack effectiveness 53.90625%.\n",
            "2023-10-30 15:54:29,373 max.py[line:93] INFO: max: attack effectiveness 57.03125%.\n",
            "2023-10-30 15:54:30,328 max.py[line:93] INFO: max: attack effectiveness 50.78125%.\n",
            "2023-10-30 15:54:30,916 max.py[line:93] INFO: max: attack effectiveness 71.73913043478261%.\n",
            "2023-10-30 15:54:31,653 md_at_ma.py[line:165] INFO: \tVal accuracy 70.6% with accuracy 44.98% under attack.\n",
            "2023-10-30 15:54:31,653 md_at_ma.py[line:167] INFO: \tModel select at epoch 49 with validation accuracy 70.6% and accuracy 44.98% under attack.\n",
            "2023-10-30 15:54:32,547 max.py[line:93] INFO: max: attack effectiveness 40.909090909090914%.\n",
            "2023-10-30 15:54:32,560 md_at_ma.py[line:120] INFO: Mini batch: 1422/1450 | training time in 15 minutes, 37 seconds.\n",
            "2023-10-30 15:54:32,560 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0123 | Train accuracy: 88.14%.\n",
            "2023-10-30 15:54:33,050 max.py[line:93] INFO: max: attack effectiveness 49.2063492063492%.\n",
            "2023-10-30 15:54:33,059 md_at_ma.py[line:120] INFO: Mini batch: 1423/1450 | training time in 15 minutes, 37 seconds.\n",
            "2023-10-30 15:54:33,059 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0170 | Train accuracy: 85.34%.\n",
            "2023-10-30 15:54:33,826 max.py[line:93] INFO: max: attack effectiveness 43.93939393939394%.\n",
            "2023-10-30 15:54:33,838 md_at_ma.py[line:120] INFO: Mini batch: 1424/1450 | training time in 15 minutes, 38 seconds.\n",
            "2023-10-30 15:54:33,838 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0147 | Train accuracy: 87.63%.\n",
            "2023-10-30 15:54:34,619 max.py[line:93] INFO: max: attack effectiveness 45.714285714285715%.\n",
            "2023-10-30 15:54:34,631 md_at_ma.py[line:120] INFO: Mini batch: 1425/1450 | training time in 15 minutes, 39 seconds.\n",
            "2023-10-30 15:54:34,631 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0113 | Train accuracy: 87.37%.\n",
            "2023-10-30 15:54:35,413 max.py[line:93] INFO: max: attack effectiveness 46.478873239436616%.\n",
            "2023-10-30 15:54:35,425 md_at_ma.py[line:120] INFO: Mini batch: 1426/1450 | training time in 15 minutes, 40 seconds.\n",
            "2023-10-30 15:54:35,425 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0101 | Train accuracy: 85.43%.\n",
            "2023-10-30 15:54:36,271 max.py[line:93] INFO: max: attack effectiveness 47.368421052631575%.\n",
            "2023-10-30 15:54:36,283 md_at_ma.py[line:120] INFO: Mini batch: 1427/1450 | training time in 15 minutes, 40 seconds.\n",
            "2023-10-30 15:54:36,283 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0112 | Train accuracy: 86.76%.\n",
            "2023-10-30 15:54:36,762 max.py[line:93] INFO: max: attack effectiveness 37.704918032786885%.\n",
            "2023-10-30 15:54:36,771 md_at_ma.py[line:120] INFO: Mini batch: 1428/1450 | training time in 15 minutes, 41 seconds.\n",
            "2023-10-30 15:54:36,771 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0110 | Train accuracy: 88.89%.\n",
            "2023-10-30 15:54:37,553 max.py[line:93] INFO: max: attack effectiveness 39.130434782608695%.\n",
            "2023-10-30 15:54:37,566 md_at_ma.py[line:120] INFO: Mini batch: 1429/1450 | training time in 15 minutes, 42 seconds.\n",
            "2023-10-30 15:54:37,566 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0135 | Train accuracy: 89.34%.\n",
            "2023-10-30 15:54:38,094 max.py[line:93] INFO: max: attack effectiveness 30.64516129032258%.\n",
            "2023-10-30 15:54:38,103 md_at_ma.py[line:120] INFO: Mini batch: 1430/1450 | training time in 15 minutes, 42 seconds.\n",
            "2023-10-30 15:54:38,103 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0130 | Train accuracy: 91.58%.\n",
            "2023-10-30 15:54:38,618 max.py[line:93] INFO: max: attack effectiveness 41.66666666666667%.\n",
            "2023-10-30 15:54:38,627 md_at_ma.py[line:120] INFO: Mini batch: 1431/1450 | training time in 15 minutes, 43 seconds.\n",
            "2023-10-30 15:54:38,628 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0207 | Train accuracy: 90.43%.\n",
            "2023-10-30 15:54:39,228 max.py[line:93] INFO: max: attack effectiveness 27.77777777777778%.\n",
            "2023-10-30 15:54:39,237 md_at_ma.py[line:120] INFO: Mini batch: 1432/1450 | training time in 15 minutes, 43 seconds.\n",
            "2023-10-30 15:54:39,237 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0111 | Train accuracy: 92.86%.\n",
            "2023-10-30 15:54:39,769 max.py[line:93] INFO: max: attack effectiveness 42.857142857142854%.\n",
            "2023-10-30 15:54:39,778 md_at_ma.py[line:120] INFO: Mini batch: 1433/1450 | training time in 15 minutes, 44 seconds.\n",
            "2023-10-30 15:54:39,778 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0116 | Train accuracy: 89.01%.\n",
            "2023-10-30 15:54:40,539 max.py[line:93] INFO: max: attack effectiveness 46.15384615384615%.\n",
            "2023-10-30 15:54:40,551 md_at_ma.py[line:120] INFO: Mini batch: 1434/1450 | training time in 15 minutes, 44 seconds.\n",
            "2023-10-30 15:54:40,551 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0091 | Train accuracy: 86.53%.\n",
            "2023-10-30 15:54:41,320 max.py[line:93] INFO: max: attack effectiveness 40.909090909090914%.\n",
            "2023-10-30 15:54:41,332 md_at_ma.py[line:120] INFO: Mini batch: 1435/1450 | training time in 15 minutes, 45 seconds.\n",
            "2023-10-30 15:54:41,332 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0289 | Train accuracy: 87.11%.\n",
            "2023-10-30 15:54:42,065 max.py[line:93] INFO: max: attack effectiveness 35.38461538461539%.\n",
            "2023-10-30 15:54:42,078 md_at_ma.py[line:120] INFO: Mini batch: 1436/1450 | training time in 15 minutes, 46 seconds.\n",
            "2023-10-30 15:54:42,078 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0113 | Train accuracy: 91.19%.\n",
            "2023-10-30 15:54:42,858 max.py[line:93] INFO: max: attack effectiveness 45.07042253521127%.\n",
            "2023-10-30 15:54:42,870 md_at_ma.py[line:120] INFO: Mini batch: 1437/1450 | training time in 15 minutes, 47 seconds.\n",
            "2023-10-30 15:54:42,870 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0103 | Train accuracy: 88.44%.\n",
            "2023-10-30 15:54:43,354 max.py[line:93] INFO: max: attack effectiveness 34.375%.\n",
            "2023-10-30 15:54:43,363 md_at_ma.py[line:120] INFO: Mini batch: 1438/1450 | training time in 15 minutes, 47 seconds.\n",
            "2023-10-30 15:54:43,363 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0082 | Train accuracy: 90.62%.\n",
            "2023-10-30 15:54:44,134 max.py[line:93] INFO: max: attack effectiveness 40.298507462686565%.\n",
            "2023-10-30 15:54:44,146 md_at_ma.py[line:120] INFO: Mini batch: 1439/1450 | training time in 15 minutes, 48 seconds.\n",
            "2023-10-30 15:54:44,146 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0081 | Train accuracy: 91.28%.\n",
            "2023-10-30 15:54:44,630 max.py[line:93] INFO: max: attack effectiveness 42.1875%.\n",
            "2023-10-30 15:54:44,639 md_at_ma.py[line:120] INFO: Mini batch: 1440/1450 | training time in 15 minutes, 48 seconds.\n",
            "2023-10-30 15:54:44,639 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0108 | Train accuracy: 87.50%.\n",
            "2023-10-30 15:54:45,461 max.py[line:93] INFO: max: attack effectiveness 51.35135135135135%.\n",
            "2023-10-30 15:54:45,473 md_at_ma.py[line:120] INFO: Mini batch: 1441/1450 | training time in 15 minutes, 49 seconds.\n",
            "2023-10-30 15:54:45,473 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0148 | Train accuracy: 84.16%.\n",
            "2023-10-30 15:54:46,255 max.py[line:93] INFO: max: attack effectiveness 42.028985507246375%.\n",
            "2023-10-30 15:54:46,267 md_at_ma.py[line:120] INFO: Mini batch: 1442/1450 | training time in 15 minutes, 50 seconds.\n",
            "2023-10-30 15:54:46,267 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0105 | Train accuracy: 86.29%.\n",
            "2023-10-30 15:54:47,094 max.py[line:93] INFO: max: attack effectiveness 48.0%.\n",
            "2023-10-30 15:54:47,107 md_at_ma.py[line:120] INFO: Mini batch: 1443/1450 | training time in 15 minutes, 51 seconds.\n",
            "2023-10-30 15:54:47,107 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0150 | Train accuracy: 84.24%.\n",
            "2023-10-30 15:54:47,885 max.py[line:93] INFO: max: attack effectiveness 48.529411764705884%.\n",
            "2023-10-30 15:54:47,897 md_at_ma.py[line:120] INFO: Mini batch: 1444/1450 | training time in 15 minutes, 52 seconds.\n",
            "2023-10-30 15:54:47,897 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0164 | Train accuracy: 85.71%.\n",
            "2023-10-30 15:54:48,484 max.py[line:93] INFO: max: attack effectiveness 42.3728813559322%.\n",
            "2023-10-30 15:54:48,493 md_at_ma.py[line:120] INFO: Mini batch: 1445/1450 | training time in 15 minutes, 52 seconds.\n",
            "2023-10-30 15:54:48,493 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0234 | Train accuracy: 86.63%.\n",
            "2023-10-30 15:54:49,318 max.py[line:93] INFO: max: attack effectiveness 45.33333333333333%.\n",
            "2023-10-30 15:54:49,330 md_at_ma.py[line:120] INFO: Mini batch: 1446/1450 | training time in 15 minutes, 53 seconds.\n",
            "2023-10-30 15:54:49,330 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0098 | Train accuracy: 85.71%.\n",
            "2023-10-30 15:54:50,105 max.py[line:93] INFO: max: attack effectiveness 46.3768115942029%.\n",
            "2023-10-30 15:54:50,117 md_at_ma.py[line:120] INFO: Mini batch: 1447/1450 | training time in 15 minutes, 54 seconds.\n",
            "2023-10-30 15:54:50,118 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0126 | Train accuracy: 86.80%.\n",
            "2023-10-30 15:54:50,622 max.py[line:93] INFO: max: attack effectiveness 35.9375%.\n",
            "2023-10-30 15:54:50,631 md_at_ma.py[line:120] INFO: Mini batch: 1448/1450 | training time in 15 minutes, 54 seconds.\n",
            "2023-10-30 15:54:50,631 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0205 | Train accuracy: 91.15%.\n",
            "2023-10-30 15:54:51,133 max.py[line:93] INFO: max: attack effectiveness 40.32258064516129%.\n",
            "2023-10-30 15:54:51,142 md_at_ma.py[line:120] INFO: Mini batch: 1449/1450 | training time in 15 minutes, 55 seconds.\n",
            "2023-10-30 15:54:51,142 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0084 | Train accuracy: 89.47%.\n",
            "2023-10-30 15:54:51,547 max.py[line:93] INFO: max: attack effectiveness 33.33333333333333%.\n",
            "2023-10-30 15:54:51,551 md_at_ma.py[line:120] INFO: Mini batch: 1450/1450 | training time in 15 minutes, 55 seconds.\n",
            "2023-10-30 15:54:51,552 md_at_ma.py[line:122] INFO: Training loss (batch level): 0.0058 | Train accuracy: 94.74%.\n",
            "2023-10-30 15:54:51,589 md_at_ma.py[line:125] INFO: Training loss (epoch level): 0.0131 | Train accuracy: 88.29\n",
            "2023-10-30 15:54:53,860 max.py[line:93] INFO: max: attack effectiveness 48.4375%.\n",
            "2023-10-30 15:54:54,853 max.py[line:93] INFO: max: attack effectiveness 53.90625%.\n",
            "2023-10-30 15:54:55,784 max.py[line:93] INFO: max: attack effectiveness 54.6875%.\n",
            "2023-10-30 15:54:56,749 max.py[line:93] INFO: max: attack effectiveness 49.21875%.\n",
            "2023-10-30 15:54:57,381 max.py[line:93] INFO: max: attack effectiveness 71.73913043478261%.\n",
            "2023-10-30 15:54:58,105 md_at_ma.py[line:165] INFO: \tVal accuracy 71.3% with accuracy 46.77% under attack.\n",
            "2023-10-30 15:54:58,105 md_at_ma.py[line:167] INFO: \tModel select at epoch 50 with validation accuracy 71.3% and accuracy 46.77% under attack.\n",
            "2023-10-30 15:55:02,020 md_dnn.py[line:165] INFO: The accuracy on the test dataset is 94.74562%\n",
            "2023-10-30 15:55:02,021 md_dnn.py[line:167] INFO: The balanced accuracy on the test dataset is 94.84967%\n",
            "Other evaluation metrics we may need:\n",
            "2023-10-30 15:55:02,024 md_dnn.py[line:180] INFO: False Negative Rate (FNR) is 2.24913%, False Positive Rate (FPR) is 8.05153%, F1 score is 94.71920%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jAcOwLlIHY1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erNp0A5_mW98",
        "outputId": "de53c007-0baf-463c-9d63-c9f74b4a77e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.Max at 0x790930df1780>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6KZfsBWmmr1",
        "outputId": "ee66efc3-7865-4af4-b8ed-5a08ffd2caeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 6693])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_list = [pgdlinf,pgdl2,pgdl1]\n",
        "varepsilon=1e-20\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    loss, done = get_scores(model, x, label)\n",
        "    print(loss.shape)\n",
        "    print(done.shape)\n",
        "pre_loss = loss\n",
        "n, red_n = x.size()[0], x.size()[1:]\n",
        "print(n)\n",
        "print(red_n)\n",
        "red_ind = list(range(2, len(x.size()) + 1))\n",
        "adv_x = x.detach().clone()\n",
        "stop_flag = torch.zeros(n, dtype=torch.bool)\n",
        "for t in range(5):\n",
        "    num_sample_red = n - torch.sum(stop_flag)\n",
        "    if num_sample_red <= 0:\n",
        "        break\n",
        "\n",
        "    red_label = label[~stop_flag]\n",
        "    pertbx = []\n",
        "    for attack in attack_list:\n",
        "        assert 'perturb' in type(attack).__dict__.keys()\n",
        "        if t > 0 and 'use_random' in attack.__dict__.keys():\n",
        "            attack.use_random = False\n",
        "        if 'Orthogonal' in type(attack).__name__:\n",
        "            pertbx.append(attack.perturb(model=model, x=adv_x[~stop_flag], label=red_label))\n",
        "        else:\n",
        "            pertbx.append(attack.perturb(model=model, x=adv_x[~stop_flag], label=red_label,min_lambda_=1e-5,max_lambda_=1e5))\n",
        "\n",
        "    pertbx = torch.vstack(pertbx)\n",
        "    with torch.no_grad():\n",
        "        red_label_ext = torch.cat([red_label] * len(attack_list))\n",
        "        loss, done = get_scores(model, pertbx, red_label_ext)\n",
        "        loss = loss.reshape(len(attack_list), num_sample_red).permute(1, 0)\n",
        "        done = done.reshape(len(attack_list), num_sample_red).permute(1, 0)\n",
        "        print(done)\n",
        "        success_flag = torch.any(done, dim=-1)\n",
        "        print('success_flag : ',success_flag)\n",
        "        done[~torch.any(done, dim=-1)] = 1\n",
        "        print('done : ',done)\n",
        "        print('loss :',loss.shape)\n",
        "        print(torch.min(loss) * (~done).to(torch.float))\n",
        "        print(' (loss * done.to(torch.float)): ', (loss * done.to(torch.float)))\n",
        "        loss = (loss * done.to(torch.float)) + torch.min(loss) * (~done).to(torch.float)\n",
        "        print('loss : ',loss)\n",
        "        pertbx = pertbx.reshape(len(attack_list), num_sample_red, *red_n).permute([1, 0, *red_ind])\n",
        "        print(pertbx.shape)\n",
        "        _, indices = loss.max(dim=-1)\n",
        "        #print(indices.shape)\n",
        "        adv_x[~stop_flag] = pertbx[torch.arange(num_sample_red), indices]\n",
        "        a_loss = loss[torch.arange(num_sample_red), indices]\n",
        "        pre_stop_flag = stop_flag.clone()\n",
        "        stop_flag[~stop_flag] = (torch.abs(pre_loss[~stop_flag] - a_loss) < varepsilon) | success_flag\n",
        "        pre_loss[~pre_stop_flag] = a_loss\n",
        "\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NZZ-fH7i2eO",
        "outputId": "54ced662-7da1-44d9-dc3d-b6f0b9c85800"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5])\n",
            "torch.Size([5])\n",
            "5\n",
            "torch.Size([6693])\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "pgd l1: attack effectiveness 0.000%.\n",
            "tensor([[ True, False, False],\n",
            "        [ True, False, False],\n",
            "        [ True, False, False],\n",
            "        [ True, False, False],\n",
            "        [ True, False, False]])\n",
            "success_flag :  tensor([True, True, True, True, True])\n",
            "done :  tensor([[ True, False, False],\n",
            "        [ True, False, False],\n",
            "        [ True, False, False],\n",
            "        [ True, False, False],\n",
            "        [ True, False, False]])\n",
            "loss : torch.Size([5, 3])\n",
            "tensor([[0.0000, 0.6474, 0.6474],\n",
            "        [0.0000, 0.6474, 0.6474],\n",
            "        [0.0000, 0.6474, 0.6474],\n",
            "        [0.0000, 0.6474, 0.6474],\n",
            "        [0.0000, 0.6474, 0.6474]])\n",
            " (loss * done.to(torch.float)):  tensor([[2.4045, 0.0000, 0.0000],\n",
            "        [2.2561, 0.0000, 0.0000],\n",
            "        [2.4190, 0.0000, 0.0000],\n",
            "        [2.6429, 0.0000, 0.0000],\n",
            "        [2.5728, 0.0000, 0.0000]], dtype=torch.float64)\n",
            "loss :  tensor([[2.4045, 0.6474, 0.6474],\n",
            "        [2.2561, 0.6474, 0.6474],\n",
            "        [2.4190, 0.6474, 0.6474],\n",
            "        [2.6429, 0.6474, 0.6474],\n",
            "        [2.5728, 0.6474, 0.6474]], dtype=torch.float64)\n",
            "torch.Size([5, 3, 6693])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(success_flag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GFeA5yHtx9T",
        "outputId": "aca837f6-be74-446a-9257-99554e48b7a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([True, True, True, True, True])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_scores(model, pertb_x, label):\n",
        "    if hasattr(model, 'is_detector_enabled'):\n",
        "        logits_f, prob_g = model.forward(pertb_x)\n",
        "    else:\n",
        "        logits_f = model.forward(pertb_x)\n",
        "    ce = F.cross_entropy(logits_f, label, reduction='none')\n",
        "    y_pred = logits_f.argmax(1)\n",
        "    if hasattr(model, 'is_detector_enabled') and (not oblivion):\n",
        "        tau = model.get_tau_sample_wise(y_pred)\n",
        "        loss_no_reduction = -prob_g\n",
        "        done = (y_pred != label) & (prob_g <= tau)\n",
        "    else:\n",
        "        loss_no_reduction = ce\n",
        "        done = y_pred != label\n",
        "    return loss_no_reduction, done"
      ],
      "metadata": {
        "id": "HsN_g4cAa1vg"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    with torch.no_grad():\n",
        "        red_label_ext = torch.cat([red_label] * len(self.attack_list))\n",
        "        loss, done = self.get_scores(model, pertbx, red_label_ext)\n",
        "        loss = loss.reshape(len(self.attack_list), num_sample_red).permute(1, 0)\n",
        "        done = done.reshape(len(self.attack_list), num_sample_red).permute(1, 0)\n",
        "        success_flag = torch.any(done, dim=-1)\n",
        "        # for a sample, if there is at least one successful attack, we will select the one with maximum loss;\n",
        "        # while if no attacks evade the victim successful, all perturbed examples are reminded for selection\n",
        "        done[~torch.any(done, dim=-1)] = 1\n",
        "        loss = (loss * done.to(torch.float)) + torch.min(loss) * (~done).to(torch.float)\n",
        "        pertbx = pertbx.reshape(len(self.attack_list), num_sample_red, *red_n).permute([1, 0, *red_ind])\n",
        "        _, indices = loss.max(dim=-1)\n",
        "        adv_x[~stop_flag] = pertbx[torch.arange(num_sample_red), indices]\n",
        "        a_loss = loss[torch.arange(num_sample_red), indices]\n",
        "        pre_stop_flag = stop_flag.clone()\n",
        "        stop_flag[~stop_flag] = (torch.abs(pre_loss[~stop_flag] - a_loss) < self.varepsilon) | success_flag\n",
        "        pre_loss[~pre_stop_flag] = a_loss"
      ],
      "metadata": {
        "id": "XL8VfeMPjpJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pgdlinf.__dict__.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tuSIr3rLLJD",
        "outputId": "d62856bc-dcf5-4b61-fb40-cba4e6ac800d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['norm', 'use_random', 'round_threshold', 'is_attacker', 'lambda_', 'omeag', 'manipulation_x', 'api_flag', 'device', 'perturb'])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(pgdlinf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGTSGoAhdqr8",
        "outputId": "33b04a99-e6cf-4034-9b06-79bb8864edb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "__main__.PGD"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(pgdlinf).__name__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NizOQFdNdc3H",
        "outputId": "cd602d65-38f3-497f-d5aa-43b19b14d39a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PGD'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(pgdl1).__name__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rdu47DVMdiK5",
        "outputId": "3d3c79f4-942a-4e3a-87f3-492e6de884e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PGDl1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "done = torch.tensor(([[1,0,0],[1,1,0],[1,1,1],[0,0,0]]))\n",
        "done.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vU_NJiNQgxaA",
        "outputId": "66e90305-8316-4238-e5b6-4390c0924cf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.any(done, dim=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqTJkWjwgxKc",
        "outputId": "4c9d95df-1054-45c7-f974-f58a0cc7da2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ True,  True,  True, False])"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "done[torch.any(done, dim=-1)]=1\n",
        "done"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaFyT1Gzhwhf",
        "outputId": "0419c4c9-8d3c-4e89-a998-c4c7e0f37b14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1],\n",
              "        [1, 1, 1],\n",
              "        [1, 1, 1],\n",
              "        [0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.min(done) * done"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0U9zY6PiO3A",
        "outputId": "acd2238f-1772-4baf-b6bb-f7a6b29b0e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQYOiHP8LLFj",
        "outputId": "73eed89c-b835-484f-a97b-f4c08fb1d36a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 6693])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(range(2, len(x.size()) + 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2zW5PsRLLAB",
        "outputId": "e6c93e7b-2b8c-4c46-d870-0a6ee9a7d4f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R0DxLH5uEZEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MalwareDetectionDNN(3216,2)\n",
        "#IMPORTANT: model must be double means that its weights must be double for getting float results\n",
        "model = model.double().to(device)\n",
        "#IMPORTANT : we can use pretrain model to check how much pgd attack is effective against normal pretrained model\n",
        "model.load_state_dict(torch.load('/content/malware_detection/MalwareDetectionDNN.pth'))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5e2HDkPD-om",
        "outputId": "c3e802d0-99c3-4400-9f5d-f073e9a9001a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MalwareDetectionDNN(\n",
              "  (nn_model_layer_0): Linear(in_features=3216, out_features=200, bias=True)\n",
              "  (nn_model_layer_1): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (nn_model_layer_2): Linear(in_features=200, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WS2dGm5kDCRu",
        "outputId": "92f58d6a-f869-4e67-fc52-531e7dcf8205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 6693])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(attack.shape)\n",
        "print(torch.sum(x,dim=1))\n",
        "print(torch.sum(attack,dim=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6jYZnksC4DF",
        "outputId": "de6b5dd0-43d4-4657-c6b3-1392573d947f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 6693])\n",
            "tensor([35., 57.])\n",
            "tensor([35., 57.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1PN5wN0ZCmh4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}