{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/lqc/aISM4lgRLLjsjycB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/a_malware/blob/main/Feature_importance_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install androguard\n",
        "!pip install captum\n",
        "\n",
        "import androguard\n",
        "import captum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdWcbQsbDh0u",
        "outputId": "bd651d7a-6086-42e4-94fa-83eebf2c4f0e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting androguard\n",
            "  Downloading androguard-3.3.5-py3-none-any.whl (922 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.4/922.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asn1crypto>=0.24.0 (from androguard)\n",
            "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from androguard) (8.1.7)\n",
            "Collecting colorama (from androguard)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from androguard) (0.18.3)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from androguard) (7.34.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from androguard) (4.9.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from androguard) (3.7.1)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.10/dist-packages (from androguard) (3.2)\n",
            "Requirement already satisfied: pydot>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from androguard) (1.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from androguard) (2.16.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->androguard)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (3.0.39)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (4.8.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot>=1.4.1->androguard) (3.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (2.8.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->androguard) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->androguard) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->androguard) (0.2.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->androguard) (1.16.0)\n",
            "Installing collected packages: asn1crypto, jedi, colorama, androguard\n",
            "Successfully installed androguard-3.3.5 asn1crypto-1.5.1 colorama-0.4.6 jedi-0.19.1\n",
            "Collecting captum\n",
            "  Downloading captum-0.6.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from captum) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from captum) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from captum) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->captum) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->captum) (1.3.0)\n",
            "Installing collected packages: captum\n",
            "Successfully installed captum-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eRx10YoAiFg",
        "outputId": "d6067fc2-931c-4481-93c5-ab1aca42a712"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "Cloning into 'malware_detection'...\n",
            "remote: Enumerating objects: 16028, done.\u001b[K\n",
            "remote: Counting objects: 100% (2180/2180), done.\u001b[K\n",
            "remote: Compressing objects: 100% (163/163), done.\u001b[K\n",
            "remote: Total 16028 (delta 2017), reused 2165 (delta 2003), pack-reused 13848\u001b[K\n",
            "Receiving objects: 100% (16028/16028), 249.84 MiB | 11.98 MiB/s, done.\n",
            "Resolving deltas: 100% (12947/12947), done.\n",
            "Updating files: 100% (141/141), done.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import os.path as path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "!git clone https://github.com/mostafa-ja/malware_detection.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "# our sharable address : https://drive.google.com/file/d/1-MPYbRTFn_zH3rybfAYihHuIjq2XSiI5/view?usp=sharing\n",
        "download_link = 'https://drive.google.com/uc?id=1-MPYbRTFn_zH3rybfAYihHuIjq2XSiI5'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "nBAlbafmmMfq",
        "outputId": "874b4249-5bfe-4d8e-c464-92853575a860"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-MPYbRTFn_zH3rybfAYihHuIjq2XSiI5\n",
            "To: /content/naive_data.zip\n",
            "100%|██████████| 143M/143M [00:03<00:00, 38.6MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/naive_data.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://drive.google.com/uc?id=1--gjFTkAJUW74RXWE4anJ5wssV7K_VAo'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "LWrVkcPVjjzg",
        "outputId": "4bf59c1f-4a24-48b4-e442-b56b5ac756fc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1--gjFTkAJUW74RXWE4anJ5wssV7K_VAo\n",
            "To: /content/train_dataset.pt\n",
            "100%|██████████| 97.4M/97.4M [00:01<00:00, 55.8MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/train_dataset.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://drive.google.com/uc?id=1-2NnBk3YKauGTGK8DfQHBxrLrYyTxNsp'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "P3KZMz42m4c1",
        "outputId": "c6a7b81c-a73a-4eda-d41c-e9f0a424e815"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-2NnBk3YKauGTGK8DfQHBxrLrYyTxNsp\n",
            "To: /content/validation_dataset.pt\n",
            "100%|██████████| 32.5M/32.5M [00:00<00:00, 71.6MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/validation_dataset.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://drive.google.com/uc?id=1-4PhQGYHpMXrCcxcgMadgPPA4S-9yluX'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "9vo-g1RHm46G",
        "outputId": "d22c8ad4-94a7-47bd-f819-650eecc19f35"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-4PhQGYHpMXrCcxcgMadgPPA4S-9yluX\n",
            "To: /content/test_dataset.pt\n",
            "100%|██████████| 32.5M/32.5M [00:00<00:00, 115MB/s] \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/test_dataset.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/train_dataset.pt /content/malware_detection/datasets\n",
        "!cp /content/validation_dataset.pt /content/malware_detection/datasets\n",
        "!cp /content/test_dataset.pt /content/malware_detection/datasets"
      ],
      "metadata": {
        "id": "ml8RC85unN-m"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "\n",
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, samples):\n",
        "        self.samples = [(torch.tensor(data, dtype=torch.float32), label) for data, label in samples]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.samples[index]"
      ],
      "metadata": {
        "id": "a4E-Kgs2AoJG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MalwareDetectionDNN(nn.Module):\n",
        "    def __init__(self, input_size, n_classes, device='cpu', name='DNN', dense_hidden_units=[200, 200], dropout=0.6, smooth=False):\n",
        "        \"\"\"\n",
        "        Construct malware detector\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        @param input_size: Integer, the dimentionality number of input vector\n",
        "        @param n_classes: Integer, the number of classes, n=2\n",
        "        @param device: String, 'cpu' or 'cuda'\n",
        "        @param name: String, model name\n",
        "        \"\"\"\n",
        "        super(MalwareDetectionDNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.n_classes = n_classes\n",
        "        self.name = name\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.smooth = smooth\n",
        "        self.dense_hidden_units = dense_hidden_units\n",
        "\n",
        "        self.dense_layers = []\n",
        "        if len(self.dense_hidden_units) >= 1:\n",
        "            self.dense_layers.append(nn.Linear(self.input_size, self.dense_hidden_units[0]))\n",
        "        else:\n",
        "            raise ValueError(\"Expect at least one hidden layer.\")\n",
        "        for i in range(len(self.dense_hidden_units[0:-1])):\n",
        "            self.dense_layers.append(nn.Linear(self.dense_hidden_units[i],  # start from idx=1\n",
        "                                               self.dense_hidden_units[i + 1]))\n",
        "        self.dense_layers.append(nn.Linear(self.dense_hidden_units[-1], self.n_classes))\n",
        "\n",
        "        # registration\n",
        "        for idx_i, dense_layer in enumerate(self.dense_layers):\n",
        "            self.add_module('nn_model_layer_{}'.format(idx_i), dense_layer)\n",
        "\n",
        "        if self.smooth:\n",
        "            self.activation_func = F.selu  # partial(F.elu, alpha=self.alpha_)\n",
        "        else:\n",
        "            self.activation_func = F.relu\n",
        "\n",
        "        self.model_save_path = path.join('/content/malware_detection/save/drebin/md_dnn'+ '_' + self.name,'model.pth')\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Go through the neural network\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        @param x: 2D tensor, feature representation\n",
        "        \"\"\"\n",
        "        for dense_layer in self.dense_layers[:-1]:\n",
        "            x = self.activation_func(dense_layer(x))\n",
        "\n",
        "        latent_representation = F.dropout(x, self.dropout, training=self.training)\n",
        "        logits = self.dense_layers[-1](latent_representation)\n",
        "        return logits\n",
        "\n",
        "    def customize_loss(self, logits, gt_labels, representation = None, mini_batch_idx=None):\n",
        "        return F.cross_entropy(logits, gt_labels)\n",
        "\n",
        "    # for predict pertubed malicious and create a y_true same size for theam\n",
        "    def inference_batch_wise(self, x):\n",
        "        \"\"\"\n",
        "        support malware samples solely\n",
        "        \"\"\"\n",
        "        assert isinstance(x, torch.Tensor)\n",
        "        logit = self.forward(x)\n",
        "        return torch.softmax(logit, dim=-1).detach().cpu().numpy(), np.ones((logit.size()[0],))\n",
        "\n",
        "    def inference(self, test_data_producer):\n",
        "        confidences = []\n",
        "        gt_labels = []\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            for x, y in test_data_producer: # for large dataset we have to consider test dataset with batches\n",
        "                x, y = x.double().to(device), y.long().to(device)\n",
        "                logits = self.forward(x)\n",
        "                confidences.append(F.softmax(logits, dim=-1))\n",
        "                gt_labels.append(y)\n",
        "        confidences = torch.vstack(confidences) #[[1,2,3],[4,5,6]] > below each other\n",
        "        gt_labels = torch.cat(gt_labels, dim=0) #[[1,2,3],[4,5,6]] > [1,2,3,4,5,6]\n",
        "        return confidences, gt_labels\n",
        "\n",
        "\n",
        "    def predict(self, test_data_producer, indicator_masking=True):\n",
        "        \"\"\"\n",
        "        predict labels and conduct evaluation\n",
        "\n",
        "        Parameters\n",
        "        --------\n",
        "        @param test_data_producer, torch.DataLoader\n",
        "        \"\"\"\n",
        "        # evaluation\n",
        "        confidence, y_true = self.inference(test_data_producer)\n",
        "        y_pred = confidence.argmax(1).cpu().numpy()\n",
        "        y_true = y_true.cpu().numpy()\n",
        "        from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, balanced_accuracy_score\n",
        "        accuracy = accuracy_score(y_true, y_pred)\n",
        "        b_accuracy = balanced_accuracy_score(y_true, y_pred)\n",
        "        print(\"The accuracy on the test dataset is {:.5f}%\".format(accuracy * 100))\n",
        "        print(\"The balanced accuracy on the test dataset is {:.5f}%\".format(b_accuracy * 100))\n",
        "\n",
        "\n",
        "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "        fpr = fp / float(tn + fp)\n",
        "        fnr = fn / float(tp + fn)\n",
        "        f1 = f1_score(y_true, y_pred, average='binary')\n",
        "\n",
        "        print(\"Other evaluation metrics we may need:\")\n",
        "        print(\"False Negative Rate (FNR) is {:.5f}%, False Positive Rate (FPR) is {:.5f}%, F1 score is {:.5f}%\".format(fnr * 100, fpr * 100, f1 * 100))\n",
        "\n"
      ],
      "metadata": {
        "id": "IBNqn_OEAuV-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torch.load('/content/malware_detection/datasets/train_dataset.pt')\n",
        "train_Loader = data.DataLoader(train_dataset, batch_size=128, shuffle=False)\n",
        "validation_dataset = torch.load('/content/malware_detection/datasets/validation_dataset.pt')\n",
        "validation_Loader = data.DataLoader(validation_dataset, batch_size=128, shuffle=False)\n",
        "test_dataset = torch.load('/content/malware_detection/datasets/test_dataset.pt')\n",
        "test_Loader = data.DataLoader(test_dataset, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "DbK8x6j3GjSl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples,labels = next(iter(test_Loader))"
      ],
      "metadata": {
        "id": "r_2qgKQHGihF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(samples.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1eUGCXEGieM",
        "outputId": "04a21f0e-8dd9-48f2-b18f-a04df2d6a55e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 6693])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = MalwareDetectionDNN(6693,2)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hqvTvma7DHx",
        "outputId": "b1da5ab1-7e82-42ee-e7cb-4f45dbef3e28"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MalwareDetectionDNN(\n",
              "  (nn_model_layer_0): Linear(in_features=6693, out_features=200, bias=True)\n",
              "  (nn_model_layer_1): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (nn_model_layer_2): Linear(in_features=200, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(model, input_size=(6693,))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRPJV6Qc7ZtU",
        "outputId": "7320225d-7dc2-4458-e3d6-6d9422ef411b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 200]       1,338,800\n",
            "            Linear-2                  [-1, 200]          40,200\n",
            "            Linear-3                    [-1, 2]             402\n",
            "================================================================\n",
            "Total params: 1,379,402\n",
            "Trainable params: 1,379,402\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.03\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 5.26\n",
            "Estimated Total Size (MB): 5.29\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr =0.005\n",
        "weight_decay = 0.\n",
        "epochs = 50\n",
        "dropout=0.6\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "best_avg_acc = 0.\n",
        "best_epoch = 0\n",
        "total_time = 0.\n",
        "nbatches = len(train_Loader)\n",
        "for i in range(epochs):\n",
        "    model.train()\n",
        "    losses, accuracies = [], []\n",
        "    for idx_batch, (x_train, y_train) in enumerate(train_Loader):\n",
        "        x_train = x_train.to(device)\n",
        "        y_train = y_train.long().to(device)\n",
        "        start_time = time.time()\n",
        "        optimizer.zero_grad()\n",
        "        logits = model.forward(x_train)\n",
        "        loss_train = loss_fn(logits, y_train)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        total_time = total_time + time.time() - start_time\n",
        "        acc_train = (logits.argmax(1) == y_train).sum().item()\n",
        "        acc_train /= x_train.size()[0]\n",
        "        mins, secs = int(total_time / 60), int(total_time % 60)\n",
        "        losses.append(loss_train.item())\n",
        "        accuracies.append(acc_train)\n",
        "\n",
        "        if True:\n",
        "            print(f'Mini batch: {i * nbatches + idx_batch + 1}/{epochs * nbatches} | training time in {mins:.0f} minutes, {secs} seconds.')\n",
        "            print(f'Training loss (batch level): {losses[-1]:.4f} | Train accuracy: {acc_train * 100:.2f}')\n",
        "\n",
        "    model.eval()\n",
        "    avg_acc_val = []\n",
        "    with torch.no_grad():\n",
        "        for x_val, y_val in validation_Loader:\n",
        "            x_val = x_val.to(device)\n",
        "            y_val = y_val.long().to(device)\n",
        "            logits = model.forward(x_val)\n",
        "            acc_val = (logits.argmax(1) == y_val).sum().item()\n",
        "            acc_val /= x_val.size()[0]\n",
        "            avg_acc_val.append(acc_val)\n",
        "        avg_acc_val = np.mean(avg_acc_val)\n",
        "\n",
        "    if avg_acc_val >= best_avg_acc:\n",
        "        best_avg_acc = avg_acc_val\n",
        "        best_epoch = i\n",
        "        torch.save(model.state_dict(), 'model.pth')\n",
        "\n",
        "    if True:\n",
        "        print(f'Training loss (epoch level): {np.mean(losses):.4f} | Train accuracy: {np.mean(accuracies) * 100:.2f}')\n",
        "        print(f'Validation accuracy: {avg_acc_val * 100:.2f} | The best validation accuracy: {best_avg_acc * 100:.2f} at epoch: {best_epoch}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIinm5gH7Zqk",
        "outputId": "98e284e0-ce95-4e71-fe2e-3c70852d9762"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mini batch: 1/1450 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.6910 | Train accuracy: 53.91\n",
            "Mini batch: 2/1450 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.6050 | Train accuracy: 71.88\n",
            "Mini batch: 3/1450 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.4919 | Train accuracy: 78.12\n",
            "Mini batch: 4/1450 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.4460 | Train accuracy: 85.94\n",
            "Mini batch: 5/1450 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.3912 | Train accuracy: 82.03\n",
            "Mini batch: 6/1450 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.2586 | Train accuracy: 89.06\n",
            "Mini batch: 7/1450 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.1812 | Train accuracy: 94.53\n",
            "Mini batch: 8/1450 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.3227 | Train accuracy: 91.41\n",
            "Mini batch: 9/1450 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.1413 | Train accuracy: 94.53\n",
            "Mini batch: 10/1450 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.1363 | Train accuracy: 96.09\n",
            "Mini batch: 11/1450 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.1079 | Train accuracy: 96.88\n",
            "Mini batch: 12/1450 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.1577 | Train accuracy: 94.53\n",
            "Mini batch: 13/1450 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.1803 | Train accuracy: 95.31\n",
            "Mini batch: 14/1450 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.1122 | Train accuracy: 95.31\n",
            "Mini batch: 15/1450 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.1364 | Train accuracy: 95.31\n",
            "Mini batch: 16/1450 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.2408 | Train accuracy: 93.75\n",
            "Mini batch: 17/1450 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.1116 | Train accuracy: 94.53\n",
            "Mini batch: 18/1450 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.2425 | Train accuracy: 94.53\n",
            "Mini batch: 19/1450 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.2757 | Train accuracy: 94.53\n",
            "Mini batch: 20/1450 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.2675 | Train accuracy: 91.41\n",
            "Mini batch: 21/1450 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.2448 | Train accuracy: 92.97\n",
            "Mini batch: 22/1450 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.1474 | Train accuracy: 96.09\n",
            "Mini batch: 23/1450 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.1604 | Train accuracy: 94.53\n",
            "Mini batch: 24/1450 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.1831 | Train accuracy: 94.53\n",
            "Mini batch: 25/1450 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.1033 | Train accuracy: 96.09\n",
            "Mini batch: 26/1450 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.1384 | Train accuracy: 93.75\n",
            "Mini batch: 27/1450 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.2336 | Train accuracy: 92.19\n",
            "Mini batch: 28/1450 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.1773 | Train accuracy: 95.31\n",
            "Mini batch: 29/1450 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.2293 | Train accuracy: 92.31\n",
            "Training loss (epoch level): 0.2454 | Train accuracy: 90.74\n",
            "Validation accuracy: 95.43 | The best validation accuracy: 95.43 at epoch: 0\n",
            "Mini batch: 30/1450 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.1093 | Train accuracy: 96.09\n",
            "Mini batch: 31/1450 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.1350 | Train accuracy: 96.88\n",
            "Mini batch: 32/1450 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0924 | Train accuracy: 96.88\n",
            "Mini batch: 33/1450 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.1115 | Train accuracy: 95.31\n",
            "Mini batch: 34/1450 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0990 | Train accuracy: 95.31\n",
            "Mini batch: 35/1450 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0612 | Train accuracy: 97.66\n",
            "Mini batch: 36/1450 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0228 | Train accuracy: 100.00\n",
            "Mini batch: 37/1450 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.1289 | Train accuracy: 97.66\n",
            "Mini batch: 38/1450 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0661 | Train accuracy: 97.66\n",
            "Mini batch: 39/1450 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0966 | Train accuracy: 96.88\n",
            "Mini batch: 40/1450 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0942 | Train accuracy: 96.88\n",
            "Mini batch: 41/1450 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0675 | Train accuracy: 98.44\n",
            "Mini batch: 42/1450 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0512 | Train accuracy: 96.88\n",
            "Mini batch: 43/1450 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0696 | Train accuracy: 96.88\n",
            "Mini batch: 44/1450 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0723 | Train accuracy: 97.66\n",
            "Mini batch: 45/1450 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0707 | Train accuracy: 97.66\n",
            "Mini batch: 46/1450 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0473 | Train accuracy: 97.66\n",
            "Mini batch: 47/1450 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.1581 | Train accuracy: 96.09\n",
            "Mini batch: 48/1450 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.1621 | Train accuracy: 95.31\n",
            "Mini batch: 49/1450 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.1141 | Train accuracy: 96.88\n",
            "Mini batch: 50/1450 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0766 | Train accuracy: 97.66\n",
            "Mini batch: 51/1450 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0794 | Train accuracy: 96.09\n",
            "Mini batch: 52/1450 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0660 | Train accuracy: 97.66\n",
            "Mini batch: 53/1450 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.1344 | Train accuracy: 96.88\n",
            "Mini batch: 54/1450 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0286 | Train accuracy: 99.22\n",
            "Mini batch: 55/1450 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.1118 | Train accuracy: 96.09\n",
            "Mini batch: 56/1450 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0720 | Train accuracy: 97.66\n",
            "Mini batch: 57/1450 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0736 | Train accuracy: 98.44\n",
            "Mini batch: 58/1450 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0281 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0862 | Train accuracy: 97.25\n",
            "Validation accuracy: 96.76 | The best validation accuracy: 96.76 at epoch: 1\n",
            "Mini batch: 59/1450 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0670 | Train accuracy: 96.88\n",
            "Mini batch: 60/1450 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0613 | Train accuracy: 96.88\n",
            "Mini batch: 61/1450 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0384 | Train accuracy: 99.22\n",
            "Mini batch: 62/1450 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0995 | Train accuracy: 95.31\n",
            "Mini batch: 63/1450 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0717 | Train accuracy: 96.88\n",
            "Mini batch: 64/1450 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0386 | Train accuracy: 99.22\n",
            "Mini batch: 65/1450 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0084 | Train accuracy: 100.00\n",
            "Mini batch: 66/1450 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0790 | Train accuracy: 97.66\n",
            "Mini batch: 67/1450 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0251 | Train accuracy: 98.44\n",
            "Mini batch: 68/1450 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0316 | Train accuracy: 98.44\n",
            "Mini batch: 69/1450 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0269 | Train accuracy: 99.22\n",
            "Mini batch: 70/1450 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0973 | Train accuracy: 98.44\n",
            "Mini batch: 71/1450 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0330 | Train accuracy: 98.44\n",
            "Mini batch: 72/1450 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0491 | Train accuracy: 98.44\n",
            "Mini batch: 73/1450 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0500 | Train accuracy: 99.22\n",
            "Mini batch: 74/1450 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0266 | Train accuracy: 99.22\n",
            "Mini batch: 75/1450 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0253 | Train accuracy: 99.22\n",
            "Mini batch: 76/1450 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0922 | Train accuracy: 97.66\n",
            "Mini batch: 77/1450 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.1541 | Train accuracy: 96.88\n",
            "Mini batch: 78/1450 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0944 | Train accuracy: 97.66\n",
            "Mini batch: 79/1450 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0441 | Train accuracy: 99.22\n",
            "Mini batch: 80/1450 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0546 | Train accuracy: 98.44\n",
            "Mini batch: 81/1450 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.1352 | Train accuracy: 93.75\n",
            "Mini batch: 82/1450 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.1049 | Train accuracy: 97.66\n",
            "Mini batch: 83/1450 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0195 | Train accuracy: 99.22\n",
            "Mini batch: 84/1450 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.1002 | Train accuracy: 96.88\n",
            "Mini batch: 85/1450 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.1010 | Train accuracy: 95.31\n",
            "Mini batch: 86/1450 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0712 | Train accuracy: 96.09\n",
            "Mini batch: 87/1450 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0067 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0623 | Train accuracy: 97.93\n",
            "Validation accuracy: 96.97 | The best validation accuracy: 96.97 at epoch: 2\n",
            "Mini batch: 88/1450 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0621 | Train accuracy: 96.88\n",
            "Mini batch: 89/1450 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0401 | Train accuracy: 100.00\n",
            "Mini batch: 90/1450 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0562 | Train accuracy: 98.44\n",
            "Mini batch: 91/1450 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0878 | Train accuracy: 96.88\n",
            "Mini batch: 92/1450 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0846 | Train accuracy: 96.88\n",
            "Mini batch: 93/1450 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0346 | Train accuracy: 98.44\n",
            "Mini batch: 94/1450 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0172 | Train accuracy: 100.00\n",
            "Mini batch: 95/1450 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0804 | Train accuracy: 98.44\n",
            "Mini batch: 96/1450 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0427 | Train accuracy: 99.22\n",
            "Mini batch: 97/1450 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0395 | Train accuracy: 98.44\n",
            "Mini batch: 98/1450 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0371 | Train accuracy: 99.22\n",
            "Mini batch: 99/1450 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0481 | Train accuracy: 98.44\n",
            "Mini batch: 100/1450 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0276 | Train accuracy: 99.22\n",
            "Mini batch: 101/1450 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0121 | Train accuracy: 100.00\n",
            "Mini batch: 102/1450 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0572 | Train accuracy: 99.22\n",
            "Mini batch: 103/1450 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0602 | Train accuracy: 97.66\n",
            "Mini batch: 104/1450 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0130 | Train accuracy: 100.00\n",
            "Mini batch: 105/1450 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.1090 | Train accuracy: 96.88\n",
            "Mini batch: 106/1450 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0714 | Train accuracy: 97.66\n",
            "Mini batch: 107/1450 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.1352 | Train accuracy: 96.09\n",
            "Mini batch: 108/1450 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0095 | Train accuracy: 100.00\n",
            "Mini batch: 109/1450 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0460 | Train accuracy: 98.44\n",
            "Mini batch: 110/1450 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0162 | Train accuracy: 100.00\n",
            "Mini batch: 111/1450 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0889 | Train accuracy: 96.88\n",
            "Mini batch: 112/1450 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0125 | Train accuracy: 100.00\n",
            "Mini batch: 113/1450 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0734 | Train accuracy: 97.66\n",
            "Mini batch: 114/1450 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0618 | Train accuracy: 98.44\n",
            "Mini batch: 115/1450 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0163 | Train accuracy: 100.00\n",
            "Mini batch: 116/1450 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0075 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0499 | Train accuracy: 98.60\n",
            "Validation accuracy: 97.05 | The best validation accuracy: 97.05 at epoch: 3\n",
            "Mini batch: 117/1450 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0766 | Train accuracy: 97.66\n",
            "Mini batch: 118/1450 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0465 | Train accuracy: 96.88\n",
            "Mini batch: 119/1450 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0272 | Train accuracy: 99.22\n",
            "Mini batch: 120/1450 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0400 | Train accuracy: 99.22\n",
            "Mini batch: 121/1450 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0415 | Train accuracy: 98.44\n",
            "Mini batch: 122/1450 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0401 | Train accuracy: 98.44\n",
            "Mini batch: 123/1450 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0435 | Train accuracy: 98.44\n",
            "Mini batch: 124/1450 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0412 | Train accuracy: 99.22\n",
            "Mini batch: 125/1450 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0374 | Train accuracy: 97.66\n",
            "Mini batch: 126/1450 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0218 | Train accuracy: 99.22\n",
            "Mini batch: 127/1450 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0179 | Train accuracy: 99.22\n",
            "Mini batch: 128/1450 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0284 | Train accuracy: 99.22\n",
            "Mini batch: 129/1450 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0102 | Train accuracy: 100.00\n",
            "Mini batch: 130/1450 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0059 | Train accuracy: 100.00\n",
            "Mini batch: 131/1450 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0699 | Train accuracy: 98.44\n",
            "Mini batch: 132/1450 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0174 | Train accuracy: 99.22\n",
            "Mini batch: 133/1450 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0047 | Train accuracy: 100.00\n",
            "Mini batch: 134/1450 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0645 | Train accuracy: 98.44\n",
            "Mini batch: 135/1450 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0522 | Train accuracy: 98.44\n",
            "Mini batch: 136/1450 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.1029 | Train accuracy: 98.44\n",
            "Mini batch: 137/1450 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0212 | Train accuracy: 99.22\n",
            "Mini batch: 138/1450 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0095 | Train accuracy: 100.00\n",
            "Mini batch: 139/1450 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0164 | Train accuracy: 100.00\n",
            "Mini batch: 140/1450 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0412 | Train accuracy: 99.22\n",
            "Mini batch: 141/1450 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0053 | Train accuracy: 100.00\n",
            "Mini batch: 142/1450 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0465 | Train accuracy: 99.22\n",
            "Mini batch: 143/1450 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0230 | Train accuracy: 100.00\n",
            "Mini batch: 144/1450 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0083 | Train accuracy: 100.00\n",
            "Mini batch: 145/1450 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0029 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0333 | Train accuracy: 99.08\n",
            "Validation accuracy: 97.37 | The best validation accuracy: 97.37 at epoch: 4\n",
            "Mini batch: 146/1450 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0373 | Train accuracy: 99.22\n",
            "Mini batch: 147/1450 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0121 | Train accuracy: 100.00\n",
            "Mini batch: 148/1450 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0155 | Train accuracy: 99.22\n",
            "Mini batch: 149/1450 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0552 | Train accuracy: 99.22\n",
            "Mini batch: 150/1450 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0408 | Train accuracy: 99.22\n",
            "Mini batch: 151/1450 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0066 | Train accuracy: 100.00\n",
            "Mini batch: 152/1450 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0244 | Train accuracy: 99.22\n",
            "Mini batch: 153/1450 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0276 | Train accuracy: 99.22\n",
            "Mini batch: 154/1450 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0142 | Train accuracy: 100.00\n",
            "Mini batch: 155/1450 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0243 | Train accuracy: 99.22\n",
            "Mini batch: 156/1450 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0089 | Train accuracy: 100.00\n",
            "Mini batch: 157/1450 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0587 | Train accuracy: 98.44\n",
            "Mini batch: 158/1450 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0028 | Train accuracy: 100.00\n",
            "Mini batch: 159/1450 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0063 | Train accuracy: 100.00\n",
            "Mini batch: 160/1450 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0364 | Train accuracy: 98.44\n",
            "Mini batch: 161/1450 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0156 | Train accuracy: 100.00\n",
            "Mini batch: 162/1450 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0066 | Train accuracy: 100.00\n",
            "Mini batch: 163/1450 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0406 | Train accuracy: 98.44\n",
            "Mini batch: 164/1450 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0457 | Train accuracy: 98.44\n",
            "Mini batch: 165/1450 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0957 | Train accuracy: 98.44\n",
            "Mini batch: 166/1450 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0023 | Train accuracy: 100.00\n",
            "Mini batch: 167/1450 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0084 | Train accuracy: 100.00\n",
            "Mini batch: 168/1450 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0187 | Train accuracy: 100.00\n",
            "Mini batch: 169/1450 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0443 | Train accuracy: 97.66\n",
            "Mini batch: 170/1450 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0052 | Train accuracy: 100.00\n",
            "Mini batch: 171/1450 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0387 | Train accuracy: 99.22\n",
            "Mini batch: 172/1450 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0072 | Train accuracy: 100.00\n",
            "Mini batch: 173/1450 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0094 | Train accuracy: 100.00\n",
            "Mini batch: 174/1450 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0020 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0245 | Train accuracy: 99.43\n",
            "Validation accuracy: 97.13 | The best validation accuracy: 97.37 at epoch: 4\n",
            "Mini batch: 175/1450 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0409 | Train accuracy: 98.44\n",
            "Mini batch: 176/1450 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0231 | Train accuracy: 99.22\n",
            "Mini batch: 177/1450 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0055 | Train accuracy: 100.00\n",
            "Mini batch: 178/1450 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0597 | Train accuracy: 97.66\n",
            "Mini batch: 179/1450 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0305 | Train accuracy: 99.22\n",
            "Mini batch: 180/1450 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0263 | Train accuracy: 99.22\n",
            "Mini batch: 181/1450 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0070 | Train accuracy: 100.00\n",
            "Mini batch: 182/1450 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0290 | Train accuracy: 99.22\n",
            "Mini batch: 183/1450 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0076 | Train accuracy: 100.00\n",
            "Mini batch: 184/1450 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0388 | Train accuracy: 98.44\n",
            "Mini batch: 185/1450 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0403 | Train accuracy: 99.22\n",
            "Mini batch: 186/1450 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0784 | Train accuracy: 97.66\n",
            "Mini batch: 187/1450 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0111 | Train accuracy: 100.00\n",
            "Mini batch: 188/1450 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0191 | Train accuracy: 99.22\n",
            "Mini batch: 189/1450 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0180 | Train accuracy: 99.22\n",
            "Mini batch: 190/1450 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0157 | Train accuracy: 98.44\n",
            "Mini batch: 191/1450 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0049 | Train accuracy: 100.00\n",
            "Mini batch: 192/1450 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0631 | Train accuracy: 97.66\n",
            "Mini batch: 193/1450 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0895 | Train accuracy: 96.09\n",
            "Mini batch: 194/1450 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0708 | Train accuracy: 98.44\n",
            "Mini batch: 195/1450 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0089 | Train accuracy: 99.22\n",
            "Mini batch: 196/1450 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0233 | Train accuracy: 99.22\n",
            "Mini batch: 197/1450 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0259 | Train accuracy: 99.22\n",
            "Mini batch: 198/1450 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0328 | Train accuracy: 98.44\n",
            "Mini batch: 199/1450 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0077 | Train accuracy: 100.00\n",
            "Mini batch: 200/1450 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0332 | Train accuracy: 99.22\n",
            "Mini batch: 201/1450 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0116 | Train accuracy: 100.00\n",
            "Mini batch: 202/1450 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0099 | Train accuracy: 100.00\n",
            "Mini batch: 203/1450 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0013 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0288 | Train accuracy: 99.06\n",
            "Validation accuracy: 97.13 | The best validation accuracy: 97.37 at epoch: 4\n",
            "Mini batch: 204/1450 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0436 | Train accuracy: 98.44\n",
            "Mini batch: 205/1450 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0129 | Train accuracy: 100.00\n",
            "Mini batch: 206/1450 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0049 | Train accuracy: 100.00\n",
            "Mini batch: 207/1450 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0274 | Train accuracy: 99.22\n",
            "Mini batch: 208/1450 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0296 | Train accuracy: 99.22\n",
            "Mini batch: 209/1450 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0470 | Train accuracy: 99.22\n",
            "Mini batch: 210/1450 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0110 | Train accuracy: 100.00\n",
            "Mini batch: 211/1450 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0354 | Train accuracy: 98.44\n",
            "Mini batch: 212/1450 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0051 | Train accuracy: 100.00\n",
            "Mini batch: 213/1450 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0307 | Train accuracy: 98.44\n",
            "Mini batch: 214/1450 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0226 | Train accuracy: 99.22\n",
            "Mini batch: 215/1450 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0281 | Train accuracy: 99.22\n",
            "Mini batch: 216/1450 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0040 | Train accuracy: 100.00\n",
            "Mini batch: 217/1450 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0058 | Train accuracy: 100.00\n",
            "Mini batch: 218/1450 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0183 | Train accuracy: 99.22\n",
            "Mini batch: 219/1450 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0296 | Train accuracy: 99.22\n",
            "Mini batch: 220/1450 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 221/1450 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0364 | Train accuracy: 99.22\n",
            "Mini batch: 222/1450 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0546 | Train accuracy: 98.44\n",
            "Mini batch: 223/1450 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.1758 | Train accuracy: 96.09\n",
            "Mini batch: 224/1450 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0014 | Train accuracy: 100.00\n",
            "Mini batch: 225/1450 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0052 | Train accuracy: 100.00\n",
            "Mini batch: 226/1450 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0052 | Train accuracy: 100.00\n",
            "Mini batch: 227/1450 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0416 | Train accuracy: 99.22\n",
            "Mini batch: 228/1450 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0074 | Train accuracy: 100.00\n",
            "Mini batch: 229/1450 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0973 | Train accuracy: 96.88\n",
            "Mini batch: 230/1450 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0246 | Train accuracy: 100.00\n",
            "Mini batch: 231/1450 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0129 | Train accuracy: 100.00\n",
            "Mini batch: 232/1450 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0044 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0284 | Train accuracy: 99.30\n",
            "Validation accuracy: 97.21 | The best validation accuracy: 97.37 at epoch: 4\n",
            "Mini batch: 233/1450 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0647 | Train accuracy: 96.88\n",
            "Mini batch: 234/1450 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0224 | Train accuracy: 99.22\n",
            "Mini batch: 235/1450 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0269 | Train accuracy: 98.44\n",
            "Mini batch: 236/1450 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0359 | Train accuracy: 98.44\n",
            "Mini batch: 237/1450 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0274 | Train accuracy: 98.44\n",
            "Mini batch: 238/1450 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0169 | Train accuracy: 99.22\n",
            "Mini batch: 239/1450 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0059 | Train accuracy: 100.00\n",
            "Mini batch: 240/1450 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0175 | Train accuracy: 99.22\n",
            "Mini batch: 241/1450 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0083 | Train accuracy: 100.00\n",
            "Mini batch: 242/1450 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0243 | Train accuracy: 99.22\n",
            "Mini batch: 243/1450 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0166 | Train accuracy: 100.00\n",
            "Mini batch: 244/1450 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0361 | Train accuracy: 99.22\n",
            "Mini batch: 245/1450 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0083 | Train accuracy: 100.00\n",
            "Mini batch: 246/1450 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0321 | Train accuracy: 99.22\n",
            "Mini batch: 247/1450 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0227 | Train accuracy: 99.22\n",
            "Mini batch: 248/1450 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0030 | Train accuracy: 100.00\n",
            "Mini batch: 249/1450 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0511 | Train accuracy: 99.22\n",
            "Mini batch: 250/1450 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0320 | Train accuracy: 99.22\n",
            "Mini batch: 251/1450 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0349 | Train accuracy: 98.44\n",
            "Mini batch: 252/1450 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0993 | Train accuracy: 97.66\n",
            "Mini batch: 253/1450 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00\n",
            "Mini batch: 254/1450 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0611 | Train accuracy: 98.44\n",
            "Mini batch: 255/1450 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0033 | Train accuracy: 100.00\n",
            "Mini batch: 256/1450 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0189 | Train accuracy: 99.22\n",
            "Mini batch: 257/1450 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0048 | Train accuracy: 100.00\n",
            "Mini batch: 258/1450 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0393 | Train accuracy: 98.44\n",
            "Mini batch: 259/1450 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0470 | Train accuracy: 98.44\n",
            "Mini batch: 260/1450 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0806 | Train accuracy: 98.44\n",
            "Mini batch: 261/1450 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0862 | Train accuracy: 92.31\n",
            "Training loss (epoch level): 0.0320 | Train accuracy: 98.85\n",
            "Validation accuracy: 96.35 | The best validation accuracy: 97.37 at epoch: 4\n",
            "Mini batch: 262/1450 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0478 | Train accuracy: 99.22\n",
            "Mini batch: 263/1450 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.2589 | Train accuracy: 95.31\n",
            "Mini batch: 264/1450 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.2215 | Train accuracy: 95.31\n",
            "Mini batch: 265/1450 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.1108 | Train accuracy: 94.53\n",
            "Mini batch: 266/1450 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0235 | Train accuracy: 99.22\n",
            "Mini batch: 267/1450 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0242 | Train accuracy: 99.22\n",
            "Mini batch: 268/1450 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0549 | Train accuracy: 97.66\n",
            "Mini batch: 269/1450 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0707 | Train accuracy: 98.44\n",
            "Mini batch: 270/1450 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0564 | Train accuracy: 97.66\n",
            "Mini batch: 271/1450 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0388 | Train accuracy: 99.22\n",
            "Mini batch: 272/1450 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0258 | Train accuracy: 99.22\n",
            "Mini batch: 273/1450 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.1111 | Train accuracy: 98.44\n",
            "Mini batch: 274/1450 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0147 | Train accuracy: 99.22\n",
            "Mini batch: 275/1450 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0483 | Train accuracy: 99.22\n",
            "Mini batch: 276/1450 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0357 | Train accuracy: 98.44\n",
            "Mini batch: 277/1450 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0345 | Train accuracy: 99.22\n",
            "Mini batch: 278/1450 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0130 | Train accuracy: 99.22\n",
            "Mini batch: 279/1450 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0581 | Train accuracy: 98.44\n",
            "Mini batch: 280/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.1143 | Train accuracy: 97.66\n",
            "Mini batch: 281/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0564 | Train accuracy: 98.44\n",
            "Mini batch: 282/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0189 | Train accuracy: 99.22\n",
            "Mini batch: 283/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0194 | Train accuracy: 99.22\n",
            "Mini batch: 284/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0296 | Train accuracy: 99.22\n",
            "Mini batch: 285/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0619 | Train accuracy: 97.66\n",
            "Mini batch: 286/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0039 | Train accuracy: 100.00\n",
            "Mini batch: 287/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0322 | Train accuracy: 99.22\n",
            "Mini batch: 288/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0067 | Train accuracy: 100.00\n",
            "Mini batch: 289/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0135 | Train accuracy: 100.00\n",
            "Mini batch: 290/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0065 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0556 | Train accuracy: 98.55\n",
            "Validation accuracy: 97.83 | The best validation accuracy: 97.83 at epoch: 9\n",
            "Mini batch: 291/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0552 | Train accuracy: 98.44\n",
            "Mini batch: 292/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0107 | Train accuracy: 100.00\n",
            "Mini batch: 293/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0209 | Train accuracy: 99.22\n",
            "Mini batch: 294/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0141 | Train accuracy: 99.22\n",
            "Mini batch: 295/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0209 | Train accuracy: 99.22\n",
            "Mini batch: 296/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0262 | Train accuracy: 97.66\n",
            "Mini batch: 297/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0080 | Train accuracy: 100.00\n",
            "Mini batch: 298/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0566 | Train accuracy: 98.44\n",
            "Mini batch: 299/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0085 | Train accuracy: 100.00\n",
            "Mini batch: 300/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0222 | Train accuracy: 99.22\n",
            "Mini batch: 301/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0129 | Train accuracy: 99.22\n",
            "Mini batch: 302/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0230 | Train accuracy: 99.22\n",
            "Mini batch: 303/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0083 | Train accuracy: 100.00\n",
            "Mini batch: 304/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0111 | Train accuracy: 100.00\n",
            "Mini batch: 305/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0323 | Train accuracy: 98.44\n",
            "Mini batch: 306/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0065 | Train accuracy: 100.00\n",
            "Mini batch: 307/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 308/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0197 | Train accuracy: 98.44\n",
            "Mini batch: 309/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0033 | Train accuracy: 100.00\n",
            "Mini batch: 310/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0541 | Train accuracy: 97.66\n",
            "Mini batch: 311/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0032 | Train accuracy: 100.00\n",
            "Mini batch: 312/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0288 | Train accuracy: 99.22\n",
            "Mini batch: 313/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0019 | Train accuracy: 100.00\n",
            "Mini batch: 314/1450 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0235 | Train accuracy: 99.22\n",
            "Mini batch: 315/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0074 | Train accuracy: 99.22\n",
            "Mini batch: 316/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0432 | Train accuracy: 99.22\n",
            "Mini batch: 317/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0077 | Train accuracy: 100.00\n",
            "Mini batch: 318/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0326 | Train accuracy: 98.44\n",
            "Mini batch: 319/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0195 | Train accuracy: 99.30\n",
            "Validation accuracy: 95.09 | The best validation accuracy: 97.83 at epoch: 9\n",
            "Mini batch: 320/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.1007 | Train accuracy: 96.88\n",
            "Mini batch: 321/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0322 | Train accuracy: 97.66\n",
            "Mini batch: 322/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0042 | Train accuracy: 100.00\n",
            "Mini batch: 323/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0038 | Train accuracy: 100.00\n",
            "Mini batch: 324/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0160 | Train accuracy: 99.22\n",
            "Mini batch: 325/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0438 | Train accuracy: 98.44\n",
            "Mini batch: 326/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0035 | Train accuracy: 100.00\n",
            "Mini batch: 327/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0886 | Train accuracy: 98.44\n",
            "Mini batch: 328/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0191 | Train accuracy: 99.22\n",
            "Mini batch: 329/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0413 | Train accuracy: 97.66\n",
            "Mini batch: 330/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0083 | Train accuracy: 100.00\n",
            "Mini batch: 331/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0063 | Train accuracy: 100.00\n",
            "Mini batch: 332/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0035 | Train accuracy: 100.00\n",
            "Mini batch: 333/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0160 | Train accuracy: 100.00\n",
            "Mini batch: 334/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0324 | Train accuracy: 99.22\n",
            "Mini batch: 335/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0682 | Train accuracy: 97.66\n",
            "Mini batch: 336/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0081 | Train accuracy: 100.00\n",
            "Mini batch: 337/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0470 | Train accuracy: 98.44\n",
            "Mini batch: 338/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0079 | Train accuracy: 100.00\n",
            "Mini batch: 339/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0130 | Train accuracy: 99.22\n",
            "Mini batch: 340/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00\n",
            "Mini batch: 341/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0308 | Train accuracy: 99.22\n",
            "Mini batch: 342/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0105 | Train accuracy: 100.00\n",
            "Mini batch: 343/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0592 | Train accuracy: 98.44\n",
            "Mini batch: 344/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0135 | Train accuracy: 99.22\n",
            "Mini batch: 345/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0411 | Train accuracy: 99.22\n",
            "Mini batch: 346/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0097 | Train accuracy: 100.00\n",
            "Mini batch: 347/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0273 | Train accuracy: 98.44\n",
            "Mini batch: 348/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0261 | Train accuracy: 99.19\n",
            "Validation accuracy: 98.38 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 349/1450 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0101 | Train accuracy: 100.00\n",
            "Mini batch: 350/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0102 | Train accuracy: 99.22\n",
            "Mini batch: 351/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0206 | Train accuracy: 99.22\n",
            "Mini batch: 352/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0271 | Train accuracy: 98.44\n",
            "Mini batch: 353/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0127 | Train accuracy: 100.00\n",
            "Mini batch: 354/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0053 | Train accuracy: 100.00\n",
            "Mini batch: 355/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0094 | Train accuracy: 100.00\n",
            "Mini batch: 356/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0206 | Train accuracy: 99.22\n",
            "Mini batch: 357/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0102 | Train accuracy: 99.22\n",
            "Mini batch: 358/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0106 | Train accuracy: 99.22\n",
            "Mini batch: 359/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0023 | Train accuracy: 100.00\n",
            "Mini batch: 360/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0088 | Train accuracy: 99.22\n",
            "Mini batch: 361/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0081 | Train accuracy: 99.22\n",
            "Mini batch: 362/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0018 | Train accuracy: 100.00\n",
            "Mini batch: 363/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0205 | Train accuracy: 99.22\n",
            "Mini batch: 364/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0033 | Train accuracy: 100.00\n",
            "Mini batch: 365/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 366/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0069 | Train accuracy: 100.00\n",
            "Mini batch: 367/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0017 | Train accuracy: 100.00\n",
            "Mini batch: 368/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0127 | Train accuracy: 99.22\n",
            "Mini batch: 369/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00\n",
            "Mini batch: 370/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0018 | Train accuracy: 100.00\n",
            "Mini batch: 371/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0022 | Train accuracy: 100.00\n",
            "Mini batch: 372/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0285 | Train accuracy: 99.22\n",
            "Mini batch: 373/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0021 | Train accuracy: 100.00\n",
            "Mini batch: 374/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0259 | Train accuracy: 99.22\n",
            "Mini batch: 375/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 376/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00\n",
            "Mini batch: 377/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0092 | Train accuracy: 99.65\n",
            "Validation accuracy: 98.30 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 378/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0038 | Train accuracy: 100.00\n",
            "Mini batch: 379/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0077 | Train accuracy: 99.22\n",
            "Mini batch: 380/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0024 | Train accuracy: 100.00\n",
            "Mini batch: 381/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0045 | Train accuracy: 100.00\n",
            "Mini batch: 382/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0025 | Train accuracy: 100.00\n",
            "Mini batch: 383/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00\n",
            "Mini batch: 384/1450 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0040 | Train accuracy: 100.00\n",
            "Mini batch: 385/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0099 | Train accuracy: 99.22\n",
            "Mini batch: 386/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0013 | Train accuracy: 100.00\n",
            "Mini batch: 387/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0034 | Train accuracy: 100.00\n",
            "Mini batch: 388/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0024 | Train accuracy: 100.00\n",
            "Mini batch: 389/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0015 | Train accuracy: 100.00\n",
            "Mini batch: 390/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00\n",
            "Mini batch: 391/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 392/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0158 | Train accuracy: 99.22\n",
            "Mini batch: 393/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0034 | Train accuracy: 100.00\n",
            "Mini batch: 394/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0018 | Train accuracy: 100.00\n",
            "Mini batch: 395/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0028 | Train accuracy: 100.00\n",
            "Mini batch: 396/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0020 | Train accuracy: 100.00\n",
            "Mini batch: 397/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0251 | Train accuracy: 99.22\n",
            "Mini batch: 398/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 399/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0019 | Train accuracy: 100.00\n",
            "Mini batch: 400/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 401/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0256 | Train accuracy: 99.22\n",
            "Mini batch: 402/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 403/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0316 | Train accuracy: 99.22\n",
            "Mini batch: 404/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 405/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 406/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0054 | Train accuracy: 99.84\n",
            "Validation accuracy: 98.30 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 407/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0050 | Train accuracy: 100.00\n",
            "Mini batch: 408/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0077 | Train accuracy: 99.22\n",
            "Mini batch: 409/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0043 | Train accuracy: 100.00\n",
            "Mini batch: 410/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0030 | Train accuracy: 100.00\n",
            "Mini batch: 411/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0194 | Train accuracy: 99.22\n",
            "Mini batch: 412/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0015 | Train accuracy: 100.00\n",
            "Mini batch: 413/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0060 | Train accuracy: 100.00\n",
            "Mini batch: 414/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0068 | Train accuracy: 100.00\n",
            "Mini batch: 415/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0091 | Train accuracy: 99.22\n",
            "Mini batch: 416/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0069 | Train accuracy: 100.00\n",
            "Mini batch: 417/1450 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0033 | Train accuracy: 100.00\n",
            "Mini batch: 418/1450 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0025 | Train accuracy: 100.00\n",
            "Mini batch: 419/1450 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00\n",
            "Mini batch: 420/1450 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0020 | Train accuracy: 100.00\n",
            "Mini batch: 421/1450 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0085 | Train accuracy: 100.00\n",
            "Mini batch: 422/1450 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0107 | Train accuracy: 99.22\n",
            "Mini batch: 423/1450 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 424/1450 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0048 | Train accuracy: 100.00\n",
            "Mini batch: 425/1450 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00\n",
            "Mini batch: 426/1450 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0105 | Train accuracy: 99.22\n",
            "Mini batch: 427/1450 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 428/1450 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0036 | Train accuracy: 100.00\n",
            "Mini batch: 429/1450 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0019 | Train accuracy: 100.00\n",
            "Mini batch: 430/1450 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0200 | Train accuracy: 99.22\n",
            "Mini batch: 431/1450 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 432/1450 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0378 | Train accuracy: 99.22\n",
            "Mini batch: 433/1450 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00\n",
            "Mini batch: 434/1450 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0025 | Train accuracy: 100.00\n",
            "Mini batch: 435/1450 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0063 | Train accuracy: 99.81\n",
            "Validation accuracy: 97.99 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 436/1450 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0054 | Train accuracy: 100.00\n",
            "Mini batch: 437/1450 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0024 | Train accuracy: 100.00\n",
            "Mini batch: 438/1450 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0017 | Train accuracy: 100.00\n",
            "Mini batch: 439/1450 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0024 | Train accuracy: 100.00\n",
            "Mini batch: 440/1450 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0052 | Train accuracy: 100.00\n",
            "Mini batch: 441/1450 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00\n",
            "Mini batch: 442/1450 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0045 | Train accuracy: 100.00\n",
            "Mini batch: 443/1450 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0039 | Train accuracy: 100.00\n",
            "Mini batch: 444/1450 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0031 | Train accuracy: 100.00\n",
            "Mini batch: 445/1450 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0046 | Train accuracy: 100.00\n",
            "Mini batch: 446/1450 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0018 | Train accuracy: 100.00\n",
            "Mini batch: 447/1450 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0026 | Train accuracy: 100.00\n",
            "Mini batch: 448/1450 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 449/1450 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00\n",
            "Mini batch: 450/1450 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0049 | Train accuracy: 100.00\n",
            "Mini batch: 451/1450 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0049 | Train accuracy: 100.00\n",
            "Mini batch: 452/1450 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0014 | Train accuracy: 100.00\n",
            "Mini batch: 453/1450 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0014 | Train accuracy: 100.00\n",
            "Mini batch: 454/1450 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00\n",
            "Mini batch: 455/1450 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0149 | Train accuracy: 99.22\n",
            "Mini batch: 456/1450 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 457/1450 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00\n",
            "Mini batch: 458/1450 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00\n",
            "Mini batch: 459/1450 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0097 | Train accuracy: 99.22\n",
            "Mini batch: 460/1450 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 461/1450 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0145 | Train accuracy: 99.22\n",
            "Mini batch: 462/1450 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 463/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 464/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0033 | Train accuracy: 99.92\n",
            "Validation accuracy: 97.99 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 465/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0064 | Train accuracy: 99.22\n",
            "Mini batch: 466/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0028 | Train accuracy: 100.00\n",
            "Mini batch: 467/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 468/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 469/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0065 | Train accuracy: 99.22\n",
            "Mini batch: 470/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 471/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00\n",
            "Mini batch: 472/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0059 | Train accuracy: 100.00\n",
            "Mini batch: 473/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 474/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0095 | Train accuracy: 99.22\n",
            "Mini batch: 475/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00\n",
            "Mini batch: 476/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0020 | Train accuracy: 100.00\n",
            "Mini batch: 477/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 478/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 479/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0092 | Train accuracy: 99.22\n",
            "Mini batch: 480/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0016 | Train accuracy: 100.00\n",
            "Mini batch: 481/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 482/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00\n",
            "Mini batch: 483/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00\n",
            "Mini batch: 484/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0221 | Train accuracy: 99.22\n",
            "Mini batch: 485/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 486/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00\n",
            "Mini batch: 487/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 488/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0131 | Train accuracy: 99.22\n",
            "Mini batch: 489/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00\n",
            "Mini batch: 490/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0059 | Train accuracy: 100.00\n",
            "Mini batch: 491/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 492/1450 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 493/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0032 | Train accuracy: 99.84\n",
            "Validation accuracy: 97.99 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 494/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0015 | Train accuracy: 100.00\n",
            "Mini batch: 495/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0032 | Train accuracy: 100.00\n",
            "Mini batch: 496/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 497/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 498/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00\n",
            "Mini batch: 499/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 500/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0028 | Train accuracy: 100.00\n",
            "Mini batch: 501/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0056 | Train accuracy: 100.00\n",
            "Mini batch: 502/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 503/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0037 | Train accuracy: 100.00\n",
            "Mini batch: 504/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00\n",
            "Mini batch: 505/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0015 | Train accuracy: 100.00\n",
            "Mini batch: 506/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 507/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 508/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0014 | Train accuracy: 100.00\n",
            "Mini batch: 509/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00\n",
            "Mini batch: 510/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 511/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 512/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 513/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0052 | Train accuracy: 100.00\n",
            "Mini batch: 514/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0013 | Train accuracy: 100.00\n",
            "Mini batch: 515/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00\n",
            "Mini batch: 516/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 517/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0182 | Train accuracy: 99.22\n",
            "Mini batch: 518/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 519/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0023 | Train accuracy: 100.00\n",
            "Mini batch: 520/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 521/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 522/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0018 | Train accuracy: 99.97\n",
            "Validation accuracy: 98.07 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 523/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0016 | Train accuracy: 100.00\n",
            "Mini batch: 524/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0028 | Train accuracy: 100.00\n",
            "Mini batch: 525/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 526/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 527/1450 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 528/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 529/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0043 | Train accuracy: 100.00\n",
            "Mini batch: 530/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00\n",
            "Mini batch: 531/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0087 | Train accuracy: 99.22\n",
            "Mini batch: 532/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00\n",
            "Mini batch: 533/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0018 | Train accuracy: 100.00\n",
            "Mini batch: 534/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0014 | Train accuracy: 100.00\n",
            "Mini batch: 535/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 536/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 537/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0018 | Train accuracy: 100.00\n",
            "Mini batch: 538/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0065 | Train accuracy: 99.22\n",
            "Mini batch: 539/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00\n",
            "Mini batch: 540/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00\n",
            "Mini batch: 541/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 542/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0320 | Train accuracy: 99.22\n",
            "Mini batch: 543/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0172 | Train accuracy: 99.22\n",
            "Mini batch: 544/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 545/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0241 | Train accuracy: 99.22\n",
            "Mini batch: 546/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0340 | Train accuracy: 99.22\n",
            "Mini batch: 547/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 548/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0275 | Train accuracy: 98.44\n",
            "Mini batch: 549/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0075 | Train accuracy: 100.00\n",
            "Mini batch: 550/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 551/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0061 | Train accuracy: 99.78\n",
            "Validation accuracy: 97.99 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 552/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0269 | Train accuracy: 99.22\n",
            "Mini batch: 553/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0149 | Train accuracy: 99.22\n",
            "Mini batch: 554/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0030 | Train accuracy: 100.00\n",
            "Mini batch: 555/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0041 | Train accuracy: 100.00\n",
            "Mini batch: 556/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0496 | Train accuracy: 99.22\n",
            "Mini batch: 557/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00\n",
            "Mini batch: 558/1450 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0163 | Train accuracy: 99.22\n",
            "Mini batch: 559/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0083 | Train accuracy: 99.22\n",
            "Mini batch: 560/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00\n",
            "Mini batch: 561/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0069 | Train accuracy: 99.22\n",
            "Mini batch: 562/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0051 | Train accuracy: 100.00\n",
            "Mini batch: 563/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0327 | Train accuracy: 99.22\n",
            "Mini batch: 564/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00\n",
            "Mini batch: 565/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0016 | Train accuracy: 100.00\n",
            "Mini batch: 566/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0079 | Train accuracy: 99.22\n",
            "Mini batch: 567/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 568/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 569/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0117 | Train accuracy: 99.22\n",
            "Mini batch: 570/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0176 | Train accuracy: 99.22\n",
            "Mini batch: 571/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0110 | Train accuracy: 99.22\n",
            "Mini batch: 572/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00\n",
            "Mini batch: 573/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00\n",
            "Mini batch: 574/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 575/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0128 | Train accuracy: 99.22\n",
            "Mini batch: 576/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0026 | Train accuracy: 100.00\n",
            "Mini batch: 577/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0030 | Train accuracy: 100.00\n",
            "Mini batch: 578/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 579/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 580/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0083 | Train accuracy: 99.68\n",
            "Validation accuracy: 97.83 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 581/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0252 | Train accuracy: 99.22\n",
            "Mini batch: 582/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0063 | Train accuracy: 99.22\n",
            "Mini batch: 583/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0050 | Train accuracy: 100.00\n",
            "Mini batch: 584/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0069 | Train accuracy: 100.00\n",
            "Mini batch: 585/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00\n",
            "Mini batch: 586/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00\n",
            "Mini batch: 587/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0355 | Train accuracy: 99.22\n",
            "Mini batch: 588/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0061 | Train accuracy: 100.00\n",
            "Mini batch: 589/1450 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0302 | Train accuracy: 99.22\n",
            "Mini batch: 590/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0058 | Train accuracy: 100.00\n",
            "Mini batch: 591/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0014 | Train accuracy: 100.00\n",
            "Mini batch: 592/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0041 | Train accuracy: 100.00\n",
            "Mini batch: 593/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00\n",
            "Mini batch: 594/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 595/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00\n",
            "Mini batch: 596/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00\n",
            "Mini batch: 597/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 598/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0018 | Train accuracy: 100.00\n",
            "Mini batch: 599/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0023 | Train accuracy: 100.00\n",
            "Mini batch: 600/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0422 | Train accuracy: 99.22\n",
            "Mini batch: 601/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00\n",
            "Mini batch: 602/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00\n",
            "Mini batch: 603/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0022 | Train accuracy: 100.00\n",
            "Mini batch: 604/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0265 | Train accuracy: 99.22\n",
            "Mini batch: 605/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0104 | Train accuracy: 99.22\n",
            "Mini batch: 606/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0096 | Train accuracy: 99.22\n",
            "Mini batch: 607/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0013 | Train accuracy: 100.00\n",
            "Mini batch: 608/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00\n",
            "Mini batch: 609/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0079 | Train accuracy: 99.78\n",
            "Validation accuracy: 97.99 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 610/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0177 | Train accuracy: 99.22\n",
            "Mini batch: 611/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0048 | Train accuracy: 100.00\n",
            "Mini batch: 612/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0031 | Train accuracy: 100.00\n",
            "Mini batch: 613/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0058 | Train accuracy: 100.00\n",
            "Mini batch: 614/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0016 | Train accuracy: 100.00\n",
            "Mini batch: 615/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 616/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0032 | Train accuracy: 100.00\n",
            "Mini batch: 617/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0046 | Train accuracy: 100.00\n",
            "Mini batch: 618/1450 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0032 | Train accuracy: 100.00\n",
            "Mini batch: 619/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0030 | Train accuracy: 100.00\n",
            "Mini batch: 620/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00\n",
            "Mini batch: 621/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0111 | Train accuracy: 100.00\n",
            "Mini batch: 622/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00\n",
            "Mini batch: 623/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 624/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0016 | Train accuracy: 100.00\n",
            "Mini batch: 625/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0019 | Train accuracy: 100.00\n",
            "Mini batch: 626/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0014 | Train accuracy: 100.00\n",
            "Mini batch: 627/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00\n",
            "Mini batch: 628/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0013 | Train accuracy: 100.00\n",
            "Mini batch: 629/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0918 | Train accuracy: 99.22\n",
            "Mini batch: 630/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00\n",
            "Mini batch: 631/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 632/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 633/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0512 | Train accuracy: 99.22\n",
            "Mini batch: 634/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 635/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0054 | Train accuracy: 100.00\n",
            "Mini batch: 636/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00\n",
            "Mini batch: 637/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00\n",
            "Mini batch: 638/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0076 | Train accuracy: 99.92\n",
            "Validation accuracy: 98.07 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 639/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0015 | Train accuracy: 100.00\n",
            "Mini batch: 640/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0049 | Train accuracy: 100.00\n",
            "Mini batch: 641/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0036 | Train accuracy: 100.00\n",
            "Mini batch: 642/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00\n",
            "Mini batch: 643/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0029 | Train accuracy: 100.00\n",
            "Mini batch: 644/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 645/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0033 | Train accuracy: 100.00\n",
            "Mini batch: 646/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0051 | Train accuracy: 100.00\n",
            "Mini batch: 647/1450 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00\n",
            "Mini batch: 648/1450 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0031 | Train accuracy: 100.00\n",
            "Mini batch: 649/1450 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00\n",
            "Mini batch: 650/1450 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0013 | Train accuracy: 100.00\n",
            "Mini batch: 651/1450 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 652/1450 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 653/1450 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00\n",
            "Mini batch: 654/1450 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00\n",
            "Mini batch: 655/1450 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 656/1450 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0040 | Train accuracy: 100.00\n",
            "Mini batch: 657/1450 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 658/1450 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0302 | Train accuracy: 99.22\n",
            "Mini batch: 659/1450 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 660/1450 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 661/1450 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 662/1450 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0367 | Train accuracy: 99.22\n",
            "Mini batch: 663/1450 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 664/1450 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0016 | Train accuracy: 100.00\n",
            "Mini batch: 665/1450 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 666/1450 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 667/1450 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0036 | Train accuracy: 99.95\n",
            "Validation accuracy: 97.99 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 668/1450 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0087 | Train accuracy: 99.22\n",
            "Mini batch: 669/1450 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0026 | Train accuracy: 100.00\n",
            "Mini batch: 670/1450 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 671/1450 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00\n",
            "Mini batch: 672/1450 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0077 | Train accuracy: 99.22\n",
            "Mini batch: 673/1450 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 674/1450 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0027 | Train accuracy: 100.00\n",
            "Mini batch: 675/1450 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0057 | Train accuracy: 100.00\n",
            "Mini batch: 676/1450 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 677/1450 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0042 | Train accuracy: 100.00\n",
            "Mini batch: 678/1450 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0038 | Train accuracy: 100.00\n",
            "Mini batch: 679/1450 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 680/1450 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 681/1450 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 682/1450 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0019 | Train accuracy: 100.00\n",
            "Mini batch: 683/1450 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 684/1450 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 685/1450 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 686/1450 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 687/1450 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0207 | Train accuracy: 99.22\n",
            "Mini batch: 688/1450 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 689/1450 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 690/1450 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 691/1450 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0168 | Train accuracy: 99.22\n",
            "Mini batch: 692/1450 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 693/1450 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0013 | Train accuracy: 100.00\n",
            "Mini batch: 694/1450 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 695/1450 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 696/1450 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0028 | Train accuracy: 99.89\n",
            "Validation accuracy: 98.15 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 697/1450 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 698/1450 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0035 | Train accuracy: 100.00\n",
            "Mini batch: 699/1450 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 700/1450 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 701/1450 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 702/1450 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 703/1450 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0035 | Train accuracy: 100.00\n",
            "Mini batch: 704/1450 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0047 | Train accuracy: 100.00\n",
            "Mini batch: 705/1450 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00\n",
            "Mini batch: 706/1450 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0060 | Train accuracy: 100.00\n",
            "Mini batch: 707/1450 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0025 | Train accuracy: 100.00\n",
            "Mini batch: 708/1450 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 709/1450 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 710/1450 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 711/1450 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0033 | Train accuracy: 100.00\n",
            "Mini batch: 712/1450 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 713/1450 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 714/1450 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00\n",
            "Mini batch: 715/1450 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 716/1450 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0088 | Train accuracy: 99.22\n",
            "Mini batch: 717/1450 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 718/1450 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00\n",
            "Mini batch: 719/1450 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 720/1450 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0101 | Train accuracy: 99.22\n",
            "Mini batch: 721/1450 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 722/1450 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 723/1450 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 724/1450 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 725/1450 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0017 | Train accuracy: 99.95\n",
            "Validation accuracy: 98.15 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 726/1450 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0041 | Train accuracy: 100.00\n",
            "Mini batch: 727/1450 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0031 | Train accuracy: 100.00\n",
            "Mini batch: 728/1450 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 729/1450 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 730/1450 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0028 | Train accuracy: 100.00\n",
            "Mini batch: 731/1450 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 732/1450 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0025 | Train accuracy: 100.00\n",
            "Mini batch: 733/1450 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0025 | Train accuracy: 100.00\n",
            "Mini batch: 734/1450 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 735/1450 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0027 | Train accuracy: 100.00\n",
            "Mini batch: 736/1450 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0019 | Train accuracy: 100.00\n",
            "Mini batch: 737/1450 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00\n",
            "Mini batch: 738/1450 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 739/1450 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 740/1450 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0018 | Train accuracy: 100.00\n",
            "Mini batch: 741/1450 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 742/1450 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 743/1450 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 744/1450 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 745/1450 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0183 | Train accuracy: 99.22\n",
            "Mini batch: 746/1450 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 747/1450 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 748/1450 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 749/1450 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0132 | Train accuracy: 99.22\n",
            "Mini batch: 750/1450 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 751/1450 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 752/1450 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 753/1450 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 754/1450 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0020 | Train accuracy: 99.95\n",
            "Validation accuracy: 98.15 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 755/1450 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00\n",
            "Mini batch: 756/1450 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0030 | Train accuracy: 100.00\n",
            "Mini batch: 757/1450 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 758/1450 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 759/1450 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00\n",
            "Mini batch: 760/1450 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 761/1450 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0020 | Train accuracy: 100.00\n",
            "Mini batch: 762/1450 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0025 | Train accuracy: 100.00\n",
            "Mini batch: 763/1450 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 764/1450 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0038 | Train accuracy: 100.00\n",
            "Mini batch: 765/1450 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00\n",
            "Mini batch: 766/1450 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 767/1450 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 768/1450 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 769/1450 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0027 | Train accuracy: 100.00\n",
            "Mini batch: 770/1450 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 771/1450 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 772/1450 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 773/1450 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 774/1450 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0102 | Train accuracy: 99.22\n",
            "Mini batch: 775/1450 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 776/1450 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 777/1450 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 778/1450 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0233 | Train accuracy: 99.22\n",
            "Mini batch: 779/1450 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 780/1450 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 781/1450 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 782/1450 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 783/1450 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0018 | Train accuracy: 99.95\n",
            "Validation accuracy: 98.15 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 784/1450 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 785/1450 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0042 | Train accuracy: 100.00\n",
            "Mini batch: 786/1450 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 787/1450 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 788/1450 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 789/1450 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 790/1450 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0030 | Train accuracy: 100.00\n",
            "Mini batch: 791/1450 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0040 | Train accuracy: 100.00\n",
            "Mini batch: 792/1450 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 793/1450 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0032 | Train accuracy: 100.00\n",
            "Mini batch: 794/1450 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0032 | Train accuracy: 100.00\n",
            "Mini batch: 795/1450 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 796/1450 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 797/1450 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 798/1450 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0019 | Train accuracy: 100.00\n",
            "Mini batch: 799/1450 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 800/1450 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 801/1450 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 802/1450 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 803/1450 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0075 | Train accuracy: 99.22\n",
            "Mini batch: 804/1450 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 805/1450 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 806/1450 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 807/1450 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0139 | Train accuracy: 99.22\n",
            "Mini batch: 808/1450 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 809/1450 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00\n",
            "Mini batch: 810/1450 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 811/1450 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 812/1450 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0015 | Train accuracy: 99.95\n",
            "Validation accuracy: 98.15 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 813/1450 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 814/1450 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0037 | Train accuracy: 100.00\n",
            "Mini batch: 815/1450 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 816/1450 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 817/1450 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 818/1450 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 819/1450 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0044 | Train accuracy: 100.00\n",
            "Mini batch: 820/1450 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0037 | Train accuracy: 100.00\n",
            "Mini batch: 821/1450 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 822/1450 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0047 | Train accuracy: 100.00\n",
            "Mini batch: 823/1450 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0033 | Train accuracy: 100.00\n",
            "Mini batch: 824/1450 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 825/1450 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 826/1450 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 827/1450 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0030 | Train accuracy: 100.00\n",
            "Mini batch: 828/1450 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 829/1450 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 830/1450 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 831/1450 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 832/1450 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0075 | Train accuracy: 99.22\n",
            "Mini batch: 833/1450 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 834/1450 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 835/1450 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 836/1450 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0071 | Train accuracy: 99.22\n",
            "Mini batch: 837/1450 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 838/1450 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00\n",
            "Mini batch: 839/1450 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 840/1450 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 841/1450 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0014 | Train accuracy: 99.95\n",
            "Validation accuracy: 98.15 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 842/1450 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 843/1450 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0020 | Train accuracy: 100.00\n",
            "Mini batch: 844/1450 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 845/1450 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 846/1450 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 847/1450 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 848/1450 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0026 | Train accuracy: 100.00\n",
            "Mini batch: 849/1450 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0029 | Train accuracy: 100.00\n",
            "Mini batch: 850/1450 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 851/1450 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0023 | Train accuracy: 100.00\n",
            "Mini batch: 852/1450 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00\n",
            "Mini batch: 853/1450 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 854/1450 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 855/1450 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 856/1450 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 857/1450 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 858/1450 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 859/1450 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 860/1450 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 861/1450 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0136 | Train accuracy: 99.22\n",
            "Mini batch: 862/1450 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 863/1450 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 864/1450 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 865/1450 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0201 | Train accuracy: 99.22\n",
            "Mini batch: 866/1450 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 867/1450 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00\n",
            "Mini batch: 868/1450 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 869/1450 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 870/1450 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0016 | Train accuracy: 99.95\n",
            "Validation accuracy: 98.07 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 871/1450 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 872/1450 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0047 | Train accuracy: 100.00\n",
            "Mini batch: 873/1450 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 874/1450 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 875/1450 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 876/1450 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 877/1450 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0040 | Train accuracy: 100.00\n",
            "Mini batch: 878/1450 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0055 | Train accuracy: 100.00\n",
            "Mini batch: 879/1450 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 880/1450 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0047 | Train accuracy: 100.00\n",
            "Mini batch: 881/1450 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0051 | Train accuracy: 100.00\n",
            "Mini batch: 882/1450 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 883/1450 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 884/1450 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 885/1450 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0045 | Train accuracy: 100.00\n",
            "Mini batch: 886/1450 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 887/1450 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 888/1450 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 889/1450 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 890/1450 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0067 | Train accuracy: 99.22\n",
            "Mini batch: 891/1450 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 892/1450 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 893/1450 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 894/1450 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0088 | Train accuracy: 99.22\n",
            "Mini batch: 895/1450 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 896/1450 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 897/1450 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 898/1450 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 899/1450 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0016 | Train accuracy: 99.95\n",
            "Validation accuracy: 98.07 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 900/1450 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00\n",
            "Mini batch: 901/1450 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0033 | Train accuracy: 100.00\n",
            "Mini batch: 902/1450 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 903/1450 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 904/1450 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 905/1450 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 906/1450 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0041 | Train accuracy: 100.00\n",
            "Mini batch: 907/1450 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0046 | Train accuracy: 100.00\n",
            "Mini batch: 908/1450 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 909/1450 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0039 | Train accuracy: 100.00\n",
            "Mini batch: 910/1450 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0038 | Train accuracy: 100.00\n",
            "Mini batch: 911/1450 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 912/1450 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 913/1450 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 914/1450 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0048 | Train accuracy: 100.00\n",
            "Mini batch: 915/1450 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00\n",
            "Mini batch: 916/1450 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 917/1450 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 918/1450 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 919/1450 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0079 | Train accuracy: 99.22\n",
            "Mini batch: 920/1450 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 921/1450 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 922/1450 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 923/1450 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0081 | Train accuracy: 99.22\n",
            "Mini batch: 924/1450 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 925/1450 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 926/1450 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 927/1450 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 928/1450 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0015 | Train accuracy: 99.95\n",
            "Validation accuracy: 98.15 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 929/1450 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 930/1450 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0041 | Train accuracy: 100.00\n",
            "Mini batch: 931/1450 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 932/1450 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 933/1450 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 934/1450 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 935/1450 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0031 | Train accuracy: 100.00\n",
            "Mini batch: 936/1450 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0038 | Train accuracy: 100.00\n",
            "Mini batch: 937/1450 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 938/1450 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0039 | Train accuracy: 100.00\n",
            "Mini batch: 939/1450 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0040 | Train accuracy: 100.00\n",
            "Mini batch: 940/1450 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 941/1450 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 942/1450 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 943/1450 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0035 | Train accuracy: 100.00\n",
            "Mini batch: 944/1450 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 945/1450 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 946/1450 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 947/1450 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 948/1450 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0088 | Train accuracy: 99.22\n",
            "Mini batch: 949/1450 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 950/1450 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 951/1450 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 952/1450 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0091 | Train accuracy: 99.22\n",
            "Mini batch: 953/1450 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 954/1450 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 955/1450 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 956/1450 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 957/1450 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0014 | Train accuracy: 99.95\n",
            "Validation accuracy: 98.07 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 958/1450 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 959/1450 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0033 | Train accuracy: 100.00\n",
            "Mini batch: 960/1450 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 961/1450 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 962/1450 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 963/1450 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 964/1450 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0034 | Train accuracy: 100.00\n",
            "Mini batch: 965/1450 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0041 | Train accuracy: 100.00\n",
            "Mini batch: 966/1450 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00\n",
            "Mini batch: 967/1450 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0037 | Train accuracy: 100.00\n",
            "Mini batch: 968/1450 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0038 | Train accuracy: 100.00\n",
            "Mini batch: 969/1450 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 970/1450 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 971/1450 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 972/1450 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0031 | Train accuracy: 100.00\n",
            "Mini batch: 973/1450 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 974/1450 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 975/1450 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 976/1450 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 977/1450 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0083 | Train accuracy: 99.22\n",
            "Mini batch: 978/1450 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 979/1450 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 980/1450 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 981/1450 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0086 | Train accuracy: 99.22\n",
            "Mini batch: 982/1450 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 983/1450 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 984/1450 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 985/1450 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 986/1450 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0014 | Train accuracy: 99.95\n",
            "Validation accuracy: 98.15 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 987/1450 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 988/1450 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0033 | Train accuracy: 100.00\n",
            "Mini batch: 989/1450 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 990/1450 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 991/1450 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00\n",
            "Mini batch: 992/1450 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 993/1450 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0040 | Train accuracy: 100.00\n",
            "Mini batch: 994/1450 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0039 | Train accuracy: 100.00\n",
            "Mini batch: 995/1450 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 996/1450 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0031 | Train accuracy: 100.00\n",
            "Mini batch: 997/1450 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0034 | Train accuracy: 100.00\n",
            "Mini batch: 998/1450 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 999/1450 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1000/1450 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1001/1450 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0031 | Train accuracy: 100.00\n",
            "Mini batch: 1002/1450 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1003/1450 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1004/1450 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1005/1450 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1006/1450 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0095 | Train accuracy: 99.22\n",
            "Mini batch: 1007/1450 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1008/1450 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1009/1450 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1010/1450 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0095 | Train accuracy: 99.22\n",
            "Mini batch: 1011/1450 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1012/1450 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 1013/1450 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1014/1450 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1015/1450 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0014 | Train accuracy: 99.95\n",
            "Validation accuracy: 97.99 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 1016/1450 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1017/1450 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0030 | Train accuracy: 100.00\n",
            "Mini batch: 1018/1450 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1019/1450 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1020/1450 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1021/1450 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1022/1450 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0026 | Train accuracy: 100.00\n",
            "Mini batch: 1023/1450 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0026 | Train accuracy: 100.00\n",
            "Mini batch: 1024/1450 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1025/1450 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0033 | Train accuracy: 100.00\n",
            "Mini batch: 1026/1450 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0019 | Train accuracy: 100.00\n",
            "Mini batch: 1027/1450 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1028/1450 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1029/1450 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1030/1450 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00\n",
            "Mini batch: 1031/1450 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1032/1450 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1033/1450 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1034/1450 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1035/1450 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0137 | Train accuracy: 99.22\n",
            "Mini batch: 1036/1450 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1037/1450 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1038/1450 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1039/1450 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0147 | Train accuracy: 99.22\n",
            "Mini batch: 1040/1450 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1041/1450 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1042/1450 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1043/1450 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1044/1450 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0015 | Train accuracy: 99.95\n",
            "Validation accuracy: 98.07 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 1045/1450 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00\n",
            "Mini batch: 1046/1450 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0029 | Train accuracy: 100.00\n",
            "Mini batch: 1047/1450 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00\n",
            "Mini batch: 1048/1450 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1049/1450 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00\n",
            "Mini batch: 1050/1450 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1051/1450 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0045 | Train accuracy: 100.00\n",
            "Mini batch: 1052/1450 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0032 | Train accuracy: 100.00\n",
            "Mini batch: 1053/1450 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1054/1450 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0039 | Train accuracy: 100.00\n",
            "Mini batch: 1055/1450 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0040 | Train accuracy: 100.00\n",
            "Mini batch: 1056/1450 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 1057/1450 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 1058/1450 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0023 | Train accuracy: 100.00\n",
            "Mini batch: 1059/1450 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0031 | Train accuracy: 100.00\n",
            "Mini batch: 1060/1450 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00\n",
            "Mini batch: 1061/1450 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 1062/1450 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00\n",
            "Mini batch: 1063/1450 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1064/1450 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0105 | Train accuracy: 99.22\n",
            "Mini batch: 1065/1450 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1066/1450 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 1067/1450 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1068/1450 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0145 | Train accuracy: 99.22\n",
            "Mini batch: 1069/1450 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 1070/1450 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1071/1450 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1072/1450 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1073/1450 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0019 | Train accuracy: 99.95\n",
            "Validation accuracy: 97.91 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 1074/1450 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0021 | Train accuracy: 100.00\n",
            "Mini batch: 1075/1450 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0022 | Train accuracy: 100.00\n",
            "Mini batch: 1076/1450 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1077/1450 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1078/1450 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0080 | Train accuracy: 99.22\n",
            "Mini batch: 1079/1450 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1080/1450 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0027 | Train accuracy: 100.00\n",
            "Mini batch: 1081/1450 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0018 | Train accuracy: 100.00\n",
            "Mini batch: 1082/1450 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0313 | Train accuracy: 99.22\n",
            "Mini batch: 1083/1450 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0037 | Train accuracy: 100.00\n",
            "Mini batch: 1084/1450 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 1085/1450 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00\n",
            "Mini batch: 1086/1450 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 1087/1450 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 1088/1450 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0026 | Train accuracy: 100.00\n",
            "Mini batch: 1089/1450 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00\n",
            "Mini batch: 1090/1450 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0060 | Train accuracy: 100.00\n",
            "Mini batch: 1091/1450 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 1092/1450 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1093/1450 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0114 | Train accuracy: 99.22\n",
            "Mini batch: 1094/1450 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 1095/1450 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 1096/1450 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 1097/1450 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0205 | Train accuracy: 99.22\n",
            "Mini batch: 1098/1450 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1099/1450 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 1100/1450 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1101/1450 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 1102/1450 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0033 | Train accuracy: 99.89\n",
            "Validation accuracy: 97.37 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 1103/1450 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0155 | Train accuracy: 99.22\n",
            "Mini batch: 1104/1450 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0024 | Train accuracy: 100.00\n",
            "Mini batch: 1105/1450 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1106/1450 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 1107/1450 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0287 | Train accuracy: 99.22\n",
            "Mini batch: 1108/1450 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1109/1450 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0025 | Train accuracy: 100.00\n",
            "Mini batch: 1110/1450 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0029 | Train accuracy: 100.00\n",
            "Mini batch: 1111/1450 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1112/1450 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0038 | Train accuracy: 100.00\n",
            "Mini batch: 1113/1450 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0027 | Train accuracy: 100.00\n",
            "Mini batch: 1114/1450 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 1115/1450 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 1116/1450 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 1117/1450 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0017 | Train accuracy: 100.00\n",
            "Mini batch: 1118/1450 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1119/1450 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1120/1450 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1121/1450 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1122/1450 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0145 | Train accuracy: 99.22\n",
            "Mini batch: 1123/1450 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1124/1450 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00\n",
            "Mini batch: 1125/1450 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 1126/1450 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0139 | Train accuracy: 99.22\n",
            "Mini batch: 1127/1450 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1128/1450 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0036 | Train accuracy: 100.00\n",
            "Mini batch: 1129/1450 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1130/1450 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1131/1450 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0033 | Train accuracy: 99.89\n",
            "Validation accuracy: 98.15 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 1132/1450 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0024 | Train accuracy: 100.00\n",
            "Mini batch: 1133/1450 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0026 | Train accuracy: 100.00\n",
            "Mini batch: 1134/1450 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 1135/1450 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0020 | Train accuracy: 100.00\n",
            "Mini batch: 1136/1450 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0016 | Train accuracy: 100.00\n",
            "Mini batch: 1137/1450 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 1138/1450 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0032 | Train accuracy: 100.00\n",
            "Mini batch: 1139/1450 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0028 | Train accuracy: 100.00\n",
            "Mini batch: 1140/1450 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00\n",
            "Mini batch: 1141/1450 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0028 | Train accuracy: 100.00\n",
            "Mini batch: 1142/1450 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0032 | Train accuracy: 100.00\n",
            "Mini batch: 1143/1450 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0020 | Train accuracy: 100.00\n",
            "Mini batch: 1144/1450 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1145/1450 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1146/1450 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0033 | Train accuracy: 100.00\n",
            "Mini batch: 1147/1450 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00\n",
            "Mini batch: 1148/1450 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1149/1450 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00\n",
            "Mini batch: 1150/1450 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1151/1450 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0092 | Train accuracy: 99.22\n",
            "Mini batch: 1152/1450 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1153/1450 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 1154/1450 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 1155/1450 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0113 | Train accuracy: 99.22\n",
            "Mini batch: 1156/1450 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 1157/1450 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1158/1450 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1159/1450 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1160/1450 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0017 | Train accuracy: 99.95\n",
            "Validation accuracy: 97.91 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 1161/1450 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 1162/1450 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0032 | Train accuracy: 100.00\n",
            "Mini batch: 1163/1450 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1164/1450 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0048 | Train accuracy: 100.00\n",
            "Mini batch: 1165/1450 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1166/1450 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1167/1450 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0028 | Train accuracy: 100.00\n",
            "Mini batch: 1168/1450 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0027 | Train accuracy: 100.00\n",
            "Mini batch: 1169/1450 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1170/1450 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0027 | Train accuracy: 100.00\n",
            "Mini batch: 1171/1450 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0028 | Train accuracy: 100.00\n",
            "Mini batch: 1172/1450 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0131 | Train accuracy: 98.44\n",
            "Mini batch: 1173/1450 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1174/1450 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1175/1450 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0028 | Train accuracy: 100.00\n",
            "Mini batch: 1176/1450 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 1177/1450 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1178/1450 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 1179/1450 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1180/1450 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0286 | Train accuracy: 99.22\n",
            "Mini batch: 1181/1450 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1182/1450 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 1183/1450 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1184/1450 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0128 | Train accuracy: 99.22\n",
            "Mini batch: 1185/1450 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 1186/1450 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0050 | Train accuracy: 100.00\n",
            "Mini batch: 1187/1450 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1188/1450 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1189/1450 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0029 | Train accuracy: 99.89\n",
            "Validation accuracy: 97.91 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 1190/1450 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0015 | Train accuracy: 100.00\n",
            "Mini batch: 1191/1450 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0017 | Train accuracy: 100.00\n",
            "Mini batch: 1192/1450 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1193/1450 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1194/1450 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00\n",
            "Mini batch: 1195/1450 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1196/1450 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0029 | Train accuracy: 100.00\n",
            "Mini batch: 1197/1450 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0026 | Train accuracy: 100.00\n",
            "Mini batch: 1198/1450 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1199/1450 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0021 | Train accuracy: 100.00\n",
            "Mini batch: 1200/1450 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0026 | Train accuracy: 100.00\n",
            "Mini batch: 1201/1450 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1202/1450 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1203/1450 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1204/1450 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0023 | Train accuracy: 100.00\n",
            "Mini batch: 1205/1450 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0033 | Train accuracy: 100.00\n",
            "Mini batch: 1206/1450 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1207/1450 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1208/1450 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 1209/1450 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0080 | Train accuracy: 99.22\n",
            "Mini batch: 1210/1450 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 1211/1450 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1212/1450 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 1213/1450 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0108 | Train accuracy: 99.22\n",
            "Mini batch: 1214/1450 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 1215/1450 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1216/1450 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1217/1450 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1218/1450 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0014 | Train accuracy: 99.95\n",
            "Validation accuracy: 98.07 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 1219/1450 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1220/1450 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0045 | Train accuracy: 100.00\n",
            "Mini batch: 1221/1450 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 1222/1450 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1223/1450 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00\n",
            "Mini batch: 1224/1450 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1225/1450 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0028 | Train accuracy: 100.00\n",
            "Mini batch: 1226/1450 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0028 | Train accuracy: 100.00\n",
            "Mini batch: 1227/1450 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0030 | Train accuracy: 100.00\n",
            "Mini batch: 1228/1450 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0031 | Train accuracy: 100.00\n",
            "Mini batch: 1229/1450 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0033 | Train accuracy: 100.00\n",
            "Mini batch: 1230/1450 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1231/1450 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1232/1450 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1233/1450 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0022 | Train accuracy: 100.00\n",
            "Mini batch: 1234/1450 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0397 | Train accuracy: 99.22\n",
            "Mini batch: 1235/1450 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 1236/1450 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 1237/1450 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1238/1450 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0156 | Train accuracy: 99.22\n",
            "Mini batch: 1239/1450 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0019 | Train accuracy: 100.00\n",
            "Mini batch: 1240/1450 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00\n",
            "Mini batch: 1241/1450 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 1242/1450 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0101 | Train accuracy: 99.22\n",
            "Mini batch: 1243/1450 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 1244/1450 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 1245/1450 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1246/1450 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 1247/1450 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0032 | Train accuracy: 99.92\n",
            "Validation accuracy: 97.91 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 1248/1450 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1249/1450 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0022 | Train accuracy: 100.00\n",
            "Mini batch: 1250/1450 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1251/1450 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0024 | Train accuracy: 100.00\n",
            "Mini batch: 1252/1450 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 1253/1450 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1254/1450 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0030 | Train accuracy: 100.00\n",
            "Mini batch: 1255/1450 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0028 | Train accuracy: 100.00\n",
            "Mini batch: 1256/1450 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1257/1450 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0027 | Train accuracy: 100.00\n",
            "Mini batch: 1258/1450 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00\n",
            "Mini batch: 1259/1450 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1260/1450 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1261/1450 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1262/1450 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00\n",
            "Mini batch: 1263/1450 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1264/1450 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1265/1450 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1266/1450 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1267/1450 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0186 | Train accuracy: 99.22\n",
            "Mini batch: 1268/1450 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1269/1450 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1270/1450 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1271/1450 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0141 | Train accuracy: 99.22\n",
            "Mini batch: 1272/1450 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1273/1450 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1274/1450 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1275/1450 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1276/1450 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0017 | Train accuracy: 99.95\n",
            "Validation accuracy: 98.15 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 1277/1450 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0028 | Train accuracy: 100.00\n",
            "Mini batch: 1278/1450 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0028 | Train accuracy: 100.00\n",
            "Mini batch: 1279/1450 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1280/1450 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00\n",
            "Mini batch: 1281/1450 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1282/1450 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1283/1450 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0029 | Train accuracy: 100.00\n",
            "Mini batch: 1284/1450 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0073 | Train accuracy: 100.00\n",
            "Mini batch: 1285/1450 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1286/1450 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0026 | Train accuracy: 100.00\n",
            "Mini batch: 1287/1450 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0024 | Train accuracy: 100.00\n",
            "Mini batch: 1288/1450 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00\n",
            "Mini batch: 1289/1450 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1290/1450 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1291/1450 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0038 | Train accuracy: 100.00\n",
            "Mini batch: 1292/1450 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0027 | Train accuracy: 100.00\n",
            "Mini batch: 1293/1450 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1294/1450 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00\n",
            "Mini batch: 1295/1450 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1296/1450 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0090 | Train accuracy: 99.22\n",
            "Mini batch: 1297/1450 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 1298/1450 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1299/1450 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0157 | Train accuracy: 99.22\n",
            "Mini batch: 1300/1450 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0106 | Train accuracy: 99.22\n",
            "Mini batch: 1301/1450 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1302/1450 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1303/1450 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0195 | Train accuracy: 99.22\n",
            "Mini batch: 1304/1450 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 1305/1450 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0029 | Train accuracy: 99.89\n",
            "Validation accuracy: 97.83 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 1306/1450 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0511 | Train accuracy: 99.22\n",
            "Mini batch: 1307/1450 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0059 | Train accuracy: 100.00\n",
            "Mini batch: 1308/1450 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0051 | Train accuracy: 100.00\n",
            "Mini batch: 1309/1450 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0018 | Train accuracy: 100.00\n",
            "Mini batch: 1310/1450 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0197 | Train accuracy: 99.22\n",
            "Mini batch: 1311/1450 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 1312/1450 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0014 | Train accuracy: 100.00\n",
            "Mini batch: 1313/1450 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0211 | Train accuracy: 99.22\n",
            "Mini batch: 1314/1450 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0481 | Train accuracy: 98.44\n",
            "Mini batch: 1315/1450 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0166 | Train accuracy: 99.22\n",
            "Mini batch: 1316/1450 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0198 | Train accuracy: 99.22\n",
            "Mini batch: 1317/1450 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0416 | Train accuracy: 96.88\n",
            "Mini batch: 1318/1450 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1319/1450 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 1320/1450 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0561 | Train accuracy: 99.22\n",
            "Mini batch: 1321/1450 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0214 | Train accuracy: 98.44\n",
            "Mini batch: 1322/1450 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 1323/1450 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0033 | Train accuracy: 100.00\n",
            "Mini batch: 1324/1450 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0687 | Train accuracy: 98.44\n",
            "Mini batch: 1325/1450 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0219 | Train accuracy: 99.22\n",
            "Mini batch: 1326/1450 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0328 | Train accuracy: 98.44\n",
            "Mini batch: 1327/1450 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0019 | Train accuracy: 100.00\n",
            "Mini batch: 1328/1450 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00\n",
            "Mini batch: 1329/1450 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0321 | Train accuracy: 98.44\n",
            "Mini batch: 1330/1450 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0277 | Train accuracy: 99.22\n",
            "Mini batch: 1331/1450 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.1069 | Train accuracy: 98.44\n",
            "Mini batch: 1332/1450 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0093 | Train accuracy: 100.00\n",
            "Mini batch: 1333/1450 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0070 | Train accuracy: 100.00\n",
            "Mini batch: 1334/1450 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.1886 | Train accuracy: 92.31\n",
            "Training loss (epoch level): 0.0280 | Train accuracy: 99.09\n",
            "Validation accuracy: 97.29 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 1335/1450 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0089 | Train accuracy: 100.00\n",
            "Mini batch: 1336/1450 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.2763 | Train accuracy: 94.53\n",
            "Mini batch: 1337/1450 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0227 | Train accuracy: 98.44\n",
            "Mini batch: 1338/1450 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0353 | Train accuracy: 99.22\n",
            "Mini batch: 1339/1450 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0643 | Train accuracy: 97.66\n",
            "Mini batch: 1340/1450 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0044 | Train accuracy: 100.00\n",
            "Mini batch: 1341/1450 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00\n",
            "Mini batch: 1342/1450 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.1341 | Train accuracy: 98.44\n",
            "Mini batch: 1343/1450 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0119 | Train accuracy: 99.22\n",
            "Mini batch: 1344/1450 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0194 | Train accuracy: 99.22\n",
            "Mini batch: 1345/1450 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0219 | Train accuracy: 99.22\n",
            "Mini batch: 1346/1450 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0036 | Train accuracy: 100.00\n",
            "Mini batch: 1347/1450 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0098 | Train accuracy: 99.22\n",
            "Mini batch: 1348/1450 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.2172 | Train accuracy: 94.53\n",
            "Mini batch: 1349/1450 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0155 | Train accuracy: 99.22\n",
            "Mini batch: 1350/1450 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0621 | Train accuracy: 97.66\n",
            "Mini batch: 1351/1450 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0784 | Train accuracy: 98.44\n",
            "Mini batch: 1352/1450 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.3895 | Train accuracy: 92.97\n",
            "Mini batch: 1353/1450 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0562 | Train accuracy: 99.22\n",
            "Mini batch: 1354/1450 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0829 | Train accuracy: 96.88\n",
            "Mini batch: 1355/1450 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.3621 | Train accuracy: 93.75\n",
            "Mini batch: 1356/1450 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.2376 | Train accuracy: 96.09\n",
            "Mini batch: 1357/1450 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0129 | Train accuracy: 99.22\n",
            "Mini batch: 1358/1450 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0604 | Train accuracy: 96.88\n",
            "Mini batch: 1359/1450 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0195 | Train accuracy: 98.44\n",
            "Mini batch: 1360/1450 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.1227 | Train accuracy: 97.66\n",
            "Mini batch: 1361/1450 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0561 | Train accuracy: 97.66\n",
            "Mini batch: 1362/1450 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0866 | Train accuracy: 96.88\n",
            "Mini batch: 1363/1450 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0853 | Train accuracy: 97.95\n",
            "Validation accuracy: 95.40 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 1364/1450 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0282 | Train accuracy: 99.22\n",
            "Mini batch: 1365/1450 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.2425 | Train accuracy: 92.97\n",
            "Mini batch: 1366/1450 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0336 | Train accuracy: 99.22\n",
            "Mini batch: 1367/1450 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0122 | Train accuracy: 100.00\n",
            "Mini batch: 1368/1450 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0443 | Train accuracy: 99.22\n",
            "Mini batch: 1369/1450 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0144 | Train accuracy: 99.22\n",
            "Mini batch: 1370/1450 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0018 | Train accuracy: 100.00\n",
            "Mini batch: 1371/1450 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0856 | Train accuracy: 98.44\n",
            "Mini batch: 1372/1450 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0086 | Train accuracy: 100.00\n",
            "Mini batch: 1373/1450 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0443 | Train accuracy: 98.44\n",
            "Mini batch: 1374/1450 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0086 | Train accuracy: 100.00\n",
            "Mini batch: 1375/1450 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0289 | Train accuracy: 99.22\n",
            "Mini batch: 1376/1450 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0070 | Train accuracy: 100.00\n",
            "Mini batch: 1377/1450 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0266 | Train accuracy: 99.22\n",
            "Mini batch: 1378/1450 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0112 | Train accuracy: 99.22\n",
            "Mini batch: 1379/1450 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0578 | Train accuracy: 96.88\n",
            "Mini batch: 1380/1450 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0091 | Train accuracy: 100.00\n",
            "Mini batch: 1381/1450 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0288 | Train accuracy: 98.44\n",
            "Mini batch: 1382/1450 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0145 | Train accuracy: 99.22\n",
            "Mini batch: 1383/1450 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0471 | Train accuracy: 98.44\n",
            "Mini batch: 1384/1450 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0016 | Train accuracy: 100.00\n",
            "Mini batch: 1385/1450 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0436 | Train accuracy: 98.44\n",
            "Mini batch: 1386/1450 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0061 | Train accuracy: 100.00\n",
            "Mini batch: 1387/1450 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0209 | Train accuracy: 99.22\n",
            "Mini batch: 1388/1450 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0060 | Train accuracy: 100.00\n",
            "Mini batch: 1389/1450 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0054 | Train accuracy: 100.00\n",
            "Mini batch: 1390/1450 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0017 | Train accuracy: 100.00\n",
            "Mini batch: 1391/1450 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0035 | Train accuracy: 100.00\n",
            "Mini batch: 1392/1450 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0038 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0292 | Train accuracy: 99.14\n",
            "Validation accuracy: 97.68 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 1393/1450 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0316 | Train accuracy: 99.22\n",
            "Mini batch: 1394/1450 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0235 | Train accuracy: 98.44\n",
            "Mini batch: 1395/1450 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0122 | Train accuracy: 99.22\n",
            "Mini batch: 1396/1450 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0029 | Train accuracy: 100.00\n",
            "Mini batch: 1397/1450 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0040 | Train accuracy: 100.00\n",
            "Mini batch: 1398/1450 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0156 | Train accuracy: 99.22\n",
            "Mini batch: 1399/1450 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0212 | Train accuracy: 98.44\n",
            "Mini batch: 1400/1450 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0270 | Train accuracy: 99.22\n",
            "Mini batch: 1401/1450 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0326 | Train accuracy: 98.44\n",
            "Mini batch: 1402/1450 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0041 | Train accuracy: 100.00\n",
            "Mini batch: 1403/1450 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0013 | Train accuracy: 100.00\n",
            "Mini batch: 1404/1450 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0283 | Train accuracy: 99.22\n",
            "Mini batch: 1405/1450 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0556 | Train accuracy: 98.44\n",
            "Mini batch: 1406/1450 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0013 | Train accuracy: 100.00\n",
            "Mini batch: 1407/1450 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0048 | Train accuracy: 100.00\n",
            "Mini batch: 1408/1450 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0013 | Train accuracy: 100.00\n",
            "Mini batch: 1409/1450 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1410/1450 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0045 | Train accuracy: 100.00\n",
            "Mini batch: 1411/1450 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0308 | Train accuracy: 98.44\n",
            "Mini batch: 1412/1450 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0163 | Train accuracy: 99.22\n",
            "Mini batch: 1413/1450 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 1414/1450 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0381 | Train accuracy: 98.44\n",
            "Mini batch: 1415/1450 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0271 | Train accuracy: 99.22\n",
            "Mini batch: 1416/1450 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0401 | Train accuracy: 98.44\n",
            "Mini batch: 1417/1450 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0026 | Train accuracy: 100.00\n",
            "Mini batch: 1418/1450 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00\n",
            "Mini batch: 1419/1450 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00\n",
            "Mini batch: 1420/1450 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0013 | Train accuracy: 100.00\n",
            "Mini batch: 1421/1450 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0149 | Train accuracy: 99.43\n",
            "Validation accuracy: 98.01 | The best validation accuracy: 98.38 at epoch: 11\n",
            "Mini batch: 1422/1450 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0083 | Train accuracy: 100.00\n",
            "Mini batch: 1423/1450 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0039 | Train accuracy: 100.00\n",
            "Mini batch: 1424/1450 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00\n",
            "Mini batch: 1425/1450 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0176 | Train accuracy: 99.22\n",
            "Mini batch: 1426/1450 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0036 | Train accuracy: 100.00\n",
            "Mini batch: 1427/1450 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 1428/1450 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00\n",
            "Mini batch: 1429/1450 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0231 | Train accuracy: 99.22\n",
            "Mini batch: 1430/1450 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0067 | Train accuracy: 99.22\n",
            "Mini batch: 1431/1450 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0066 | Train accuracy: 100.00\n",
            "Mini batch: 1432/1450 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0035 | Train accuracy: 100.00\n",
            "Mini batch: 1433/1450 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 1434/1450 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1435/1450 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 1436/1450 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0046 | Train accuracy: 100.00\n",
            "Mini batch: 1437/1450 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 1438/1450 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0064 | Train accuracy: 100.00\n",
            "Mini batch: 1439/1450 | training time in 1 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0106 | Train accuracy: 100.00\n",
            "Mini batch: 1440/1450 | training time in 1 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0039 | Train accuracy: 100.00\n",
            "Mini batch: 1441/1450 | training time in 1 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.1064 | Train accuracy: 96.88\n",
            "Mini batch: 1442/1450 | training time in 1 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00\n",
            "Mini batch: 1443/1450 | training time in 1 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 1444/1450 | training time in 1 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0051 | Train accuracy: 100.00\n",
            "Mini batch: 1445/1450 | training time in 1 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0136 | Train accuracy: 99.22\n",
            "Mini batch: 1446/1450 | training time in 1 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0169 | Train accuracy: 99.22\n",
            "Mini batch: 1447/1450 | training time in 1 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0021 | Train accuracy: 100.00\n",
            "Mini batch: 1448/1450 | training time in 1 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0357 | Train accuracy: 99.22\n",
            "Mini batch: 1449/1450 | training time in 1 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0574 | Train accuracy: 97.66\n",
            "Mini batch: 1450/1450 | training time in 1 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0117 | Train accuracy: 99.65\n",
            "Validation accuracy: 97.91 | The best validation accuracy: 98.38 at epoch: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('/content/model.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhkKt7zLwT5z",
        "outputId": "714a89b2-3c4c-44f5-c169-9691122e2b14"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = model(samples)\n",
        "y.argmax(dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qw8QWYDKwT3T",
        "outputId": "7e2baf4a-b217-427a-a0ba-97c60df0e7d9"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1,  ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfOlLYbcwT1D",
        "outputId": "3c4c9f56-b141-457f-ab4f-50a814931138"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from captum.attr import IntegratedGradients\n",
        "model.eval()\n",
        "ig = IntegratedGradients(model)\n"
      ],
      "metadata": {
        "id": "XV8eqRulwTxW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, (x_train, y_train) in enumerate(train_Loader):\n",
        "  attributions = ig.attribute(x_train, target=1)\n",
        "  if idx==0:\n",
        "    res = attributions\n",
        "  else:\n",
        "    res = torch.cat((res, attributions), dim=0)"
      ],
      "metadata": {
        "id": "oj-9Ff-U4OdN"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-5W2dRmW7HOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ushAm705KW8",
        "outputId": "b4b11383-c885-457c-8828-496797a77b6f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3597, 6693])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_index = res.mean(dim=0)\n",
        "features_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv2zn8Gj5Ei6",
        "outputId": "abb43878-46ff-4c78-df9d-9d1cdb9ca208"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.2140e-01,  9.2395e-02,  6.4109e-01,  ...,  1.4022e-04,\n",
              "        -4.4524e-04, -1.3800e-05], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Open and load the Pickle file\n",
        "with open('/content/malware_detection/dataset/drebin/data.vocab', 'rb') as file:\n",
        "    features = pickle.load(file)\n",
        "\n",
        "# Access and use the loaded data\n",
        "print(len(features))  # Example: Print the loaded data\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ed387YtKwTqi",
        "outputId": "83b3595c-94f7-4958-afd5-8b6a25289af8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdcIc1lHzDj_",
        "outputId": "2e826524-7467-4307-b813-0ff5443a2457"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['android.permission.READ_PHONE_STATE',\n",
              " 'android.permission.READ_CONTACTS',\n",
              " 'android.permission.WRITE_EXTERNAL_STORAGE',\n",
              " 'android.permission.ACCESS_FINE_LOCATION',\n",
              " 'android.permission.ACCESS_COARSE_LOCATION']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import_index = features_index.argsort(descending=True)[:20]\n",
        "import_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH-7rMu_zDge",
        "outputId": "aa73a133-9e74-4888-b2e8-b213eb51aeff"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 528,    2,  421,    3,  464,    6, 1233, 1228,  476,   32, 1232,  453,\n",
              "        1230,   36,  434, 1231,  587,  443,   55,  444])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in import_index:\n",
        "  print(features[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yuxGSYK1Z69",
        "outputId": "901c1abd-01f7-46fa-aada-32c1ef5650d7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ljava/lang/Runtime;->exec\n",
            "android.permission.WRITE_EXTERNAL_STORAGE\n",
            "Ljava/lang/Class;->getDeclaredMethod\n",
            "android.permission.ACCESS_FINE_LOCATION\n",
            "Ljava/lang/Runtime;->getRuntime\n",
            "android.permission.READ_EXTERNAL_STORAGE\n",
            "android.permission.READ_LOGS\n",
            "android.permission.MOUNT_UNMOUNT_FILESYSTEMS\n",
            "Landroid/app/ActivityManager;->getRunningTasks\n",
            "android.net.conn.CONNECTIVITY_CHANGE\n",
            "android.permission.SYSTEM_ALERT_WINDOW\n",
            "Ljava/lang/System;->loadLibrary\n",
            "android.permission.GET_TASKS\n",
            "android.intent.action.USER_PRESENT\n",
            "Landroid/widget/VideoView;->start\n",
            "android.permission.WRITE_SETTINGS\n",
            "Landroid/net/wifi/WifiManager;->getConnectionInfo\n",
            "Ljava/lang/reflect/Array;->get\n",
            "android.intent.action.PACKAGE_ADDED\n",
            "Ljava/lang/reflect/Array;->getLength\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from captum.attr import IntegratedGradients\n",
        "\n",
        "def get_import_features(model, train_loader, features, target, num=20):\n",
        "    ig = IntegratedGradients(model)\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize a list to store attributions\n",
        "    attributions_list = []\n",
        "\n",
        "    for x_train, y_train in train_loader:\n",
        "        attributions = ig.attribute(x_train, target=1)\n",
        "        attributions_list.append(attributions)\n",
        "\n",
        "    # Stack the attributions along the first dimension\n",
        "    res = torch.cat(attributions_list, dim=0)\n",
        "\n",
        "    # Calculate the mean along the first dimension\n",
        "    important_features_index = res.mean(dim=0)\n",
        "\n",
        "    # Get the top indices\n",
        "    top_indices = important_features_index.argsort(descending=True)[:num]\n",
        "\n",
        "    for i in top_indices:\n",
        "        print(features[i])\n",
        "\n",
        "# Example usage:\n",
        "# get_import_features(model, train_loader, features, target, num=20)\n"
      ],
      "metadata": {
        "id": "hYIIux5w9x6h"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_import_features(model, train_Loader, features,target=1, num=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7U6x53Q6c9u",
        "outputId": "3bdda328-52ea-4ffa-d25a-e8e5c51171a5"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ljava/lang/Runtime;->exec\n",
            "android.permission.WRITE_EXTERNAL_STORAGE\n",
            "Ljava/lang/Class;->getDeclaredMethod\n",
            "android.permission.ACCESS_FINE_LOCATION\n",
            "Ljava/lang/Runtime;->getRuntime\n",
            "android.permission.READ_EXTERNAL_STORAGE\n",
            "android.permission.READ_LOGS\n",
            "android.permission.MOUNT_UNMOUNT_FILESYSTEMS\n",
            "Landroid/app/ActivityManager;->getRunningTasks\n",
            "android.net.conn.CONNECTIVITY_CHANGE\n",
            "android.permission.SYSTEM_ALERT_WINDOW\n",
            "Ljava/lang/System;->loadLibrary\n",
            "android.permission.GET_TASKS\n",
            "android.intent.action.USER_PRESENT\n",
            "Landroid/widget/VideoView;->start\n",
            "android.permission.WRITE_SETTINGS\n",
            "Landroid/net/wifi/WifiManager;->getConnectionInfo\n",
            "Ljava/lang/reflect/Array;->get\n",
            "android.intent.action.PACKAGE_ADDED\n",
            "Ljava/lang/reflect/Array;->getLength\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_import_features(model, train_Loader, features,target=0, num=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9yma-WB6nfz",
        "outputId": "dd98f95a-228d-4ace-cb7d-97aa777f3ea7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ljava/lang/Runtime;->exec\n",
            "android.permission.WRITE_EXTERNAL_STORAGE\n",
            "Ljava/lang/Class;->getDeclaredMethod\n",
            "android.permission.ACCESS_FINE_LOCATION\n",
            "Ljava/lang/Runtime;->getRuntime\n",
            "android.permission.READ_EXTERNAL_STORAGE\n",
            "android.permission.READ_LOGS\n",
            "android.permission.MOUNT_UNMOUNT_FILESYSTEMS\n",
            "Landroid/app/ActivityManager;->getRunningTasks\n",
            "android.net.conn.CONNECTIVITY_CHANGE\n",
            "android.permission.SYSTEM_ALERT_WINDOW\n",
            "Ljava/lang/System;->loadLibrary\n",
            "android.permission.GET_TASKS\n",
            "android.intent.action.USER_PRESENT\n",
            "Landroid/widget/VideoView;->start\n",
            "android.permission.WRITE_SETTINGS\n",
            "Landroid/net/wifi/WifiManager;->getConnectionInfo\n",
            "Ljava/lang/reflect/Array;->get\n",
            "android.intent.action.PACKAGE_ADDED\n",
            "Ljava/lang/reflect/Array;->getLength\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JCAH3lz_zDZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from captum.attr import IntegratedGradients\n",
        "\n",
        "def get_important_attributes(model, test_data_producer, target_label=1):\n",
        "    \"\"\"\n",
        "    get important attributes by using integrated gradients\n",
        "    \"\"\"\n",
        "    attributions = []\n",
        "    gt_labels = []\n",
        "\n",
        "    def _ig_wrapper(_x):\n",
        "        logits = model.forward(_x)\n",
        "        return F.softmax(logits, dim=-1)\n",
        "    ig = IntegratedGradients(_ig_wrapper)\n",
        "\n",
        "    for i, (x, y) in enumerate(test_data_producer):\n",
        "        x = x.to(device)\n",
        "        y = y.long().to(device)\n",
        "        x.requires_grad = True\n",
        "        baseline = torch.zeros_like(x, dtype=torch.double, device=device)\n",
        "        attribution_bs = ig.attribute(x,\n",
        "                                      baselines=baseline,\n",
        "                                      target=target_label)\n",
        "        print(attribution_bs)\n",
        "        attribution = torch.cat(attribution_bs, dim=1)\n",
        "        attributions.append(attribution.clone().detach().cpu().numpy())\n",
        "        gt_labels.append(y.clone().detach().cpu().numpy())\n",
        "        np.save('./labels', np.concatenate(gt_labels))\n",
        "    return np.vstack(attributions)"
      ],
      "metadata": {
        "id": "E3EM7MxI7Zd5"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_important_attributes(model.double(), test_Loader, target_label=1)"
      ],
      "metadata": {
        "id": "n2bJ1ysm9iK0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "831c48dc-2a2e-49d1-fc2e-6040a9804379"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0028,  0.0260,  0.0665,  ...,  0.0000, -0.0000, -0.0000],\n",
            "        [ 0.0012,  0.0000,  0.0437,  ...,  0.0000, -0.0000, -0.0000],\n",
            "        [-0.0012,  0.0111,  0.0279,  ...,  0.0000, -0.0000, -0.0000],\n",
            "        ...,\n",
            "        [ 0.0005,  0.0177,  0.0462,  ...,  0.0000, -0.0000, -0.0000],\n",
            "        [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
            "        [-0.0011,  0.0102,  0.0255,  ...,  0.0000, -0.0000,  0.0000]],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-1a9f78e2f97b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_important_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_Loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-8de66a6a6c19>\u001b[0m in \u001b[0;36mget_important_attributes\u001b[0;34m(model, test_data_producer, target_label)\u001b[0m\n\u001b[1;32m     23\u001b[0m                                       target=target_label)\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattribution_bs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mattribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattribution_bs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mattributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mgt_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cat() received an invalid combination of arguments - got (Tensor, dim=int), but expected one of:\n * (tuple of Tensors tensors, int dim, *, Tensor out)\n * (tuple of Tensors tensors, name dim, *, Tensor out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "227Y8gEQ9iHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J1xo68M09iEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nuvi7N0w9iBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/malware_detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRRx7oWaDnGY",
        "outputId": "e25e4911-d791-4eb8-d182-57aef9f343c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/malware_detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Projected gradient descent (ascent)."
      ],
      "metadata": {
        "id": "-45R7q66ygAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from core.droidfeature import InverseDroidFeature\n",
        "\n",
        "inverse_feature = InverseDroidFeature()\n",
        "\n",
        "# manipulation_x : removable features\n",
        "manipulation_x = inverse_feature.get_manipulation()\n",
        "manipulation_x = torch.LongTensor(manipulation_x).to(device)\n",
        "\n",
        "# index of vocab which are interdependent\n",
        "omega = inverse_feature.get_interdependent_apis()\n",
        "omega = torch.sum(F.one_hot(torch.tensor(omega), num_classes=len(inverse_feature.vocab)),dim=0).to(device)\n",
        "\n",
        "# a list of vocab length : if the type of feature is api , index of that feature will be true\n",
        "api_flag = inverse_feature.get_api_flag()"
      ],
      "metadata": {
        "id": "sY7SRwnGYixM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZA17YgKOGimw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8OXrRGxBGij9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_perturbation(gradients, adv_features, norm= 'l2'):\n",
        "    # look for allowable position, because only '1--> -' and '0 --> +' are permitted\n",
        "    # api insertion\n",
        "    pos_insertion = (adv_features <= 0.5) * 1 * (adv_features >= 0.)\n",
        "    grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "    # grad4insertion = (gradients > 0) * gradients\n",
        "    # api removal\n",
        "    pos_removal = (adv_features > 0.5) * 1\n",
        "    grad4removal = (gradients < 0) * (pos_removal & manipulation_x) * gradients\n",
        "    gradients = grad4removal + grad4insertion\n",
        "\n",
        "    # norm\n",
        "    if norm == 'linf':\n",
        "        perturbation = torch.sign(gradients)\n",
        "    elif norm == 'l2':\n",
        "        l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "        perturbation = torch.minimum(\n",
        "            torch.tensor(1., dtype=adv_features.dtype, device=adv_features.device),\n",
        "            gradients / l2norm\n",
        "        )\n",
        "    return perturbation"
      ],
      "metadata": {
        "id": "nec2k9xQGibW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.sum(x,dim=-1))\n",
        "adv_x = x\n",
        "grad = torch.randn(x.size())\n",
        "gradients = get_perturbation(grad, adv_x)\n",
        "adv = (abs(gradients[0]/2) > torch.rand_like(x)) * torch.sign(gradients)\n",
        "adv_x = x+adv\n",
        "print(torch.sum(adv_x,dim=-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekVGd6EOrIv4",
        "outputId": "673ab884-bbe0-4879-c321-6abda0a1d02f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([168.,  50.,  30.,  65.,  15.])\n",
            "tensor([187.,  65.,  39.,  83.,  22.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grad = torch.randn(x.size())"
      ],
      "metadata": {
        "id": "-ajksjP-IEQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gradients = get_perturbation(grad, x, norm= 'l2')"
      ],
      "metadata": {
        "id": "B0Y_JuV_JlxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sign(gradients)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcqF6VaDqKo2",
        "outputId": "b6764636-0fe6-41d7-8db4-0254590605aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 1., 0.],\n",
              "        [0., 1., 0.,  ..., 1., 0., 1.],\n",
              "        [0., 1., 0.,  ..., 1., 1., 0.],\n",
              "        [0., 1., 0.,  ..., 0., 1., 1.],\n",
              "        [0., 0., 0.,  ..., 0., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adv = (abs(gradients[0]/4) > torch.rand_like(x))*torch.sign(gradients)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RwO-PorpWK4",
        "outputId": "07def009-2fe7-468b-83ff-44954b9d87a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(26.)"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_perturbation(torch.rand(x.size()), x, norm= 'l2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoFjqKTpJxp9",
        "outputId": "470bc54c-faa7-4387-e4b8-ff6ce0894206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0117, 0.0113, 0.0000,  ..., 0.0208, 0.0022, 0.0164]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parobalities = get_perturbation(torch.rand(x.size()), x, norm= 'l2')"
      ],
      "metadata": {
        "id": "eeIkz4xRY_ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = [i if random.random()<p else 0 for p in parobalities]\n"
      ],
      "metadata": {
        "id": "n87U-dZKY0--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(get_perturbation(torch.rand(x.size()), x, norm= 'l2')==0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iK3fo6E1IpSp",
        "outputId": "814c7f76-e22e-42ce-c130-9fa1dc05488e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(168)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_perturbation(torch.rand(x.size()), x, norm= 'l2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ1KmbozIfmn",
        "outputId": "a0abc0b2-0f2b-4612-8478-0cbc9402526a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0147, 0.0136, 0.0000,  ..., 0.0113, 0.0011, 0.0009]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_x0(x, rounding_threshold=0.5, is_sample=False):\n",
        "    \"\"\"\n",
        "    Helper function to randomly initialize the the inner maximizer algos\n",
        "    randomize such that the functionality is preserved.\n",
        "    :param x: training sample\n",
        "    :param is_sample: flag to sample randomly from feasible area or return just x\n",
        "    :return: randomly sampled feasible version of x\n",
        "    \"\"\"\n",
        "    if is_sample:\n",
        "        rand_x = round_x(torch.rand(x.size()), alpha=rounding_threshold)\n",
        "        if x.is_cuda:\n",
        "            rand_x = rand_x.cuda()\n",
        "        return (rand_x.byte() | x.byte()).double()\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "\n",
        "def round_x(x, alpha=0.5):\n",
        "    \"\"\"\n",
        "    rounds x by thresholding it according to alpha which can be a scalar or vector\n",
        "    :param x:\n",
        "    :param alpha: threshold parameter\n",
        "    :return: a double tensor of 0s and 1s.\n",
        "    \"\"\"\n",
        "    return (x >= alpha).double()"
      ],
      "metadata": {
        "id": "Ye0d01eYuWZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cN4pJEl7u6C4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PGD():\n",
        "    \"\"\"\n",
        "    Projected gradient descent (ascent).\n",
        "\n",
        "    Parameters\n",
        "    ---------\n",
        "    @param norm, 'l2' or 'linf'\n",
        "    @param use_random, Boolean,  whether use random start point\n",
        "    @param rounding_threshold, float, a threshold for rounding real scalars\n",
        "    @param is_attacker, Boolean, play the role of attacker (note: the defender conducts adversarial training)\n",
        "    @param oblivion, Boolean, whether know the adversary indicator or not\n",
        "    @param kappa, attack confidence\n",
        "    @param manipulation_x, manipulations\n",
        "    @param omega, the indices of interdependent apis corresponding to each api\n",
        "    @param device, 'cpu' or 'cuda'\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, norm, use_random=False, rounding_threshold=0.5,\n",
        "                 is_attacker=True, manipulation_x=None, omega=None,api_flag=None, device=None):\n",
        "        super(PGD, self).__init__()\n",
        "        assert norm == 'l1' or norm == 'l2' or norm == 'linf', \"Expect 'l1', 'l2' or 'linf'.\"\n",
        "        self.norm = norm\n",
        "        self.use_random = use_random\n",
        "        self.round_threshold = rounding_threshold\n",
        "        self.is_attacker = is_attacker\n",
        "        self.lambda_ = 1.\n",
        "        self.omeag = omega\n",
        "        self.manipulation_x = manipulation_x\n",
        "        self.api_flag = api_flag\n",
        "        self.device = device\n",
        "    def _perturb(self, model, x, label=None,\n",
        "                 steps=10,\n",
        "                 step_length=1.,\n",
        "                 lambda_=1.,\n",
        "                 ):\n",
        "        \"\"\"\n",
        "        perturb node feature vectors\n",
        "\n",
        "        Parameters\n",
        "        -----------\n",
        "        @param model, a victim model\n",
        "        @param x: torch.FloatTensor, node feature vectors (each represents the occurrences of apis in a graph) with shape [batch_size, vocab_dim]\n",
        "        @param label: torch.LongTensor, ground truth labels\n",
        "        @param steps: Integer, maximum number of iterations\n",
        "        @param step_length: float, the step length in each iteration\n",
        "        @param lambda_, float, penalty factor\n",
        "        \"\"\"\n",
        "        adv_x = x\n",
        "        self.lambda_ = lambda_\n",
        "        model.eval()\n",
        "        loss_natural = 0.\n",
        "        for t in range(steps):\n",
        "            if t == 0 and self.use_random:\n",
        "                adv_x = get_x0(adv_x, rounding_threshold=self.round_threshold, is_sample=True)\n",
        "            var_adv_x = torch.autograd.Variable(adv_x, requires_grad=True)\n",
        "            loss, done = self.get_loss(model, var_adv_x, label, self.lambda_)\n",
        "            if t == 0:\n",
        "                loss_natural = loss\n",
        "            grad = torch.autograd.grad(torch.mean(loss), var_adv_x)[0].detach().data\n",
        "            perturbation = self.get_perturbation(grad, x, adv_x)\n",
        "            adv_x = torch.clamp(adv_x + perturbation * step_length, min=0., max=1.)\n",
        "        # round\n",
        "        if self.norm == 'linf' and (not hasattr(model, 'is_detector_enabled')):\n",
        "            round_threshold = torch.rand(x.size()).to(self.device)\n",
        "        else:\n",
        "            round_threshold = self.round_threshold\n",
        "        adv_x = round_x(adv_x, round_threshold)\n",
        "        loss_adv, _1 = self.get_loss(model, adv_x, label, self.lambda_)\n",
        "        replace_flag = (loss_adv < loss_natural).unsqueeze(1).expand_as(adv_x)\n",
        "        adv_x[replace_flag] = x[replace_flag]\n",
        "        return adv_x\n",
        "\n",
        "    def perturb(self, model, x, label=None,\n",
        "                steps=10,\n",
        "                step_length=1.,\n",
        "                min_lambda_=1e-5,\n",
        "                max_lambda_=1e5,\n",
        "                base=10.,\n",
        "                verbose=False):\n",
        "        \"\"\"\n",
        "        enhance attack\n",
        "        \"\"\"\n",
        "        model.eval()\n",
        "        if hasattr(model, 'is_detector_enabled'):\n",
        "            self.lambda_ = min_lambda_\n",
        "        else:\n",
        "            self.lambda_ = max_lambda_\n",
        "\n",
        "        adv_x = x.detach().clone().to(torch.double)\n",
        "        while self.lambda_ <= max_lambda_:\n",
        "            with torch.no_grad():\n",
        "                _, done = self.get_loss(model, adv_x, label, self.lambda_)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            pert_x = self._perturb(model, adv_x[~done], label[~done],\n",
        "                                   steps,\n",
        "                                   step_length,\n",
        "                                   lambda_=self.lambda_\n",
        "                                   )\n",
        "            adv_x[~done] = pert_x\n",
        "            self.lambda_ *= base\n",
        "        with torch.no_grad():\n",
        "            _, done = self.get_loss(model, adv_x, label, self.lambda_)\n",
        "            print(f\"pgd {self.norm}: attack effectiveness {done.sum().item() / done.size()[0] * 100:.3f}%.\")\n",
        "        return adv_x\n",
        "\n",
        "    def get_perturbation(self, gradients, features, adv_features):\n",
        "        # look for allowable position, because only '1--> -' and '0 --> +' are permitted\n",
        "        # api insertion\n",
        "        pos_insertion = (adv_features <= 0.5) * 1 * (adv_features >= 0.)\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "        # grad4insertion = (gradients > 0) * gradients\n",
        "        # api removal\n",
        "        pos_removal = (adv_features > 0.5) * 1\n",
        "        grad4removal = (gradients < 0) * (pos_removal & self.manipulation_x) * gradients\n",
        "        if self.is_attacker:\n",
        "            # cope with the interdependent apis\n",
        "            checking_nonexist_api = (pos_removal ^ self.omega) & self.omega\n",
        "            grad4removal[:, self.api_flag] += torch.sum(gradients * checking_nonexist_api, dim=-1, keepdim=True)\n",
        "        gradients = grad4removal + grad4insertion\n",
        "\n",
        "        # norm\n",
        "        if self.norm == 'linf':\n",
        "            perturbation = torch.sign(gradients)\n",
        "        elif self.norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = torch.minimum(\n",
        "                torch.tensor(1., dtype=features.dtype, device=features.device),\n",
        "                gradients / l2norm\n",
        "            )\n",
        "            perturbation = torch.where(torch.isnan(perturbation), 0., perturbation)\n",
        "            perturbation = torch.where(torch.isinf(perturbation), 1., perturbation)\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # add the extra perturbation owing to the interdependent apis\n",
        "        if self.norm == 'linf' and self.is_attacker:\n",
        "            perturbation += torch.any(perturbation[:, self.api_flag] < 0, dim=-1,\n",
        "                                      keepdim=True) * checking_nonexist_api\n",
        "        if self.norm == 'l2' and self.is_attacker:\n",
        "            min_val = torch.amin(perturbation, dim=-1, keepdim=True).clamp_(max=0.)\n",
        "            perturbation += (torch.any(perturbation[:, self.api_flag] < 0, dim=-1,\n",
        "                                       keepdim=True) * torch.abs(min_val) * checking_nonexist_api)\n",
        "        return perturbation\n",
        "\n",
        "    def get_loss(self, model, adv_x, label, lambda_=None):\n",
        "        if hasattr(model, 'is_detector_enabled'):\n",
        "            logits_f, prob_g = model.forward(adv_x)\n",
        "        else:\n",
        "            logits_f = model.forward(adv_x)\n",
        "\n",
        "        ce = F.cross_entropy(logits_f, label, reduction='none')\n",
        "        y_pred = logits_f.argmax(1)\n",
        "        if hasattr(model, 'is_detector_enabled') and (not self.oblivion):\n",
        "            assert lambda_ is not None\n",
        "            tau = model.get_tau_sample_wise(y_pred)\n",
        "            if self.is_attacker:\n",
        "                loss_no_reduction = ce + lambda_ * (torch.clamp(tau - prob_g,\n",
        "                                                                max=self.kappa)\n",
        "                                                    )\n",
        "            else:\n",
        "                loss_no_reduction = ce + lambda_ * (tau - prob_g)\n",
        "            done = (y_pred != label) & (prob_g <= tau)\n",
        "        else:\n",
        "            loss_no_reduction = ce\n",
        "            done = y_pred != label\n",
        "        return loss_no_reduction, done"
      ],
      "metadata": {
        "id": "Wd8Q6mNduaya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PGDAdvTraining(object):\n",
        "    \"\"\"adversarial training incorporating pgd attack\n",
        "\n",
        "    Parameters\n",
        "    -------\n",
        "    @param model, Object,  a model to be protected, e.g., MalwareDetector\n",
        "    @attack_model: Object, adversary's model for generating adversarial malware on the feature space\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, attack=None, attack_param=None):\n",
        "        self.model = model\n",
        "        self.attack = attack\n",
        "        self.attack_param = attack_param\n",
        "\n",
        "        self.name = self.model.name\n",
        "        self.model_save_path =  path.join('/content/malware_detection/save/md_at_pgd' + '_' + 'train','model.pth')\n",
        "\n",
        "    def fit(self, train_data_producer, validation_data_producer=None, adv_epochs=45,beta=0.001,lr=0.005,weight_decay=0, verbose=True):\n",
        "        \"\"\"\n",
        "        Applying adversarial train to enhance the malware detector.\n",
        "\n",
        "        Parameters\n",
        "        -------\n",
        "        @param train_data_producer: Object, an dataloader object for producing a batch of training data\n",
        "        @param validation_data_producer: Object, an dataloader object for producing validation dataset\n",
        "        @param epochs: Integer, epochs for adversarial training\n",
        "        @param adv_epochs: Integer, epochs for adversarial training\n",
        "        @param beta: Float, penalty factor for adversarial loss\n",
        "        @param lr: Float, learning rate of Adam optimizer\n",
        "        @param weight_decay: Float, penalty factor, default value 5e-4\n",
        "        @param verbose: Boolean, whether to show verbose info\n",
        "        \"\"\"\n",
        "        optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "        total_time = 0.\n",
        "        nbatches = len(train_data_producer)\n",
        "        best_acc_val = 0.\n",
        "        acc_val_adv_be = 0.\n",
        "        best_epoch = 0\n",
        "        for i in range(adv_epochs):\n",
        "            losses, accuracies = [], []\n",
        "            for idx_batch, (x_batch, y_batch) in enumerate(train_data_producer):\n",
        "                x_batch, y_batch = x_batch.double().to(device), y_batch.long().to(device)\n",
        "                batch_size = x_batch.shape[0]\n",
        "                # make data\n",
        "                mal_x_batch, ben_x_batch, mal_y_batch, ben_y_batch = x_batch[y_batch == 1], x_batch[y_batch == 0], y_batch[y_batch == 1], y_batch[y_batch == 0]\n",
        "                start_time = time.time()\n",
        "                self.model.eval()\n",
        "\n",
        "                adv_x = mal_x_batch\n",
        "                grad = torch.randn(mal_x_batch.size())\n",
        "                gradients = get_perturbation(grad, adv_x)\n",
        "                adv = (abs(gradients[0]/2) > torch.rand_like(mal_x_batch)) * torch.sign(gradients)\n",
        "                pertb_mal_x = mal_x_batch + adv\n",
        "\n",
        "                total_time += time.time() - start_time\n",
        "                x_batch = torch.cat([ben_x_batch, pertb_mal_x], dim=0)\n",
        "                y_batch = torch.cat([ben_y_batch, mal_y_batch])\n",
        "                start_time = time.time()\n",
        "                self.model.train()\n",
        "                optimizer.zero_grad()\n",
        "                logits = self.model.forward(x_batch)\n",
        "                loss_train = self.model.customize_loss(logits,y_batch)\n",
        "\n",
        "                loss_train.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                total_time += time.time() - start_time\n",
        "                mins, secs = int(total_time / 60), int(total_time % 60)\n",
        "                acc_train = (logits.argmax(1) == y_batch).sum().item()\n",
        "                acc_train /= x_batch.size()[0]\n",
        "                accuracies.append(acc_train)\n",
        "                losses.append(loss_train.item())\n",
        "                if verbose:\n",
        "                    print(f'Mini batch: {i * nbatches + idx_batch + 1}/{adv_epochs * nbatches} | training time in {mins:.0f} minutes, {secs} seconds.')\n",
        "                    print(f'Training loss (batch level): {losses[-1]:.4f} | Train accuracy: {acc_train * 100:.2f}%.')\n",
        "            if verbose:\n",
        "                print(f'Training loss (epoch level): {np.mean(losses):.4f} | Train accuracy: {np.mean(accuracies) * 100:.2f}')\n",
        "\n",
        "            # select model\n",
        "            self.model.eval()\n",
        "            # long-time to train (save the model temporally in case of interruption)\n",
        "            self.save_to_disk(i + 1, optimizer, self.model_save_path + '.tmp')\n",
        "\n",
        "            res_val = []\n",
        "            avg_acc_val = []\n",
        "            for x_val, y_val in validation_data_producer:\n",
        "                x_val, y_val = x_val.double().to(device), y_val.long().to(device)\n",
        "                logits = self.model.forward(x_val)\n",
        "                acc_val = (logits.argmax(1) == y_val).sum().item()\n",
        "                acc_val /= x_val.size()[0]\n",
        "                avg_acc_val.append(acc_val)\n",
        "\n",
        "                mal_x_batch, mal_y_batch = x_val[y_val == 1], y_val[y_val == 1]\n",
        "                pertb_mal_x = self.attack.perturb(self.model, mal_x_batch, mal_y_batch,**self.attack_param)\n",
        "                y_cent_batch, x_density_batch = self.model.inference_batch_wise(pertb_mal_x)\n",
        "                y_pred = np.argmax(y_cent_batch, axis=-1)\n",
        "                res_val.append(y_pred == 1.)\n",
        "            assert len(res_val) > 0\n",
        "            res_val = np.concatenate(res_val)\n",
        "            acc_val_adv = np.sum(res_val).astype(float) / res_val.shape[0]\n",
        "            acc_val = (np.mean(avg_acc_val) + acc_val_adv) / 2.\n",
        "            # Owing to we look for a new threshold after each epoch, this hinders the convergence of training.\n",
        "            # We save the model's parameters at last several epochs as a well-trained model may be obtained.\n",
        "            if acc_val >= best_acc_val:\n",
        "                best_acc_val = acc_val\n",
        "                acc_val_adv_be = acc_val_adv\n",
        "                best_epoch = i + 1\n",
        "                self.save_to_disk(best_epoch, optimizer, self.model_save_path)\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"\\tVal accuracy {acc_val * 100:.4}% with accuracy {acc_val_adv * 100:.4}% under attack.\")\n",
        "                print(f\"\\tModel select at epoch {best_epoch} with validation accuracy {best_acc_val * 100:.4}% and accuracy {acc_val_adv_be * 100:.4}% under attack.\")\n",
        "                if hasattr(self.model, 'tau'):\n",
        "                    print(f'The threshold is {self.model.tau}.')\n",
        "\n",
        "    #we define here not in model definition, beacause we need attack.pertube()\n",
        "    #also we must not use \"with no grad\" because we need grad for pertubation\n",
        "    def adv_predict(self, test_data_producer):\n",
        "      res_test = []\n",
        "      for x, y in test_data_producer:\n",
        "          x, y = x.double().to(device), y.long().to(device)\n",
        "\n",
        "          mal_x_batch, mal_y_batch = x[y == 1], y[y == 1]\n",
        "          pertb_mal_x = self.attack.perturb(self.model, mal_x_batch, mal_y_batch,**self.attack_param)\n",
        "          y_cent_batch, x_density_batch = self.model.inference_batch_wise(pertb_mal_x)\n",
        "          y_pred = np.argmax(y_cent_batch, axis=-1)\n",
        "          res_test.append(y_pred == 1.)\n",
        "      assert len(res_test) > 0\n",
        "      res_test = np.concatenate(res_test)\n",
        "      acc_val_adv = np.sum(res_test).astype(float) / res_test.shape[0]\n",
        "      print(f\"\\tadversarial accuracy  {acc_val_adv * 100:.4}% under attack.\")\n",
        "\n",
        "\n",
        "    def load(self):\n",
        "        assert path.exists(self.model_save_path), 'train model first'\n",
        "        ckpt = torch.load(self.model_save_path)\n",
        "        self.model.load_state_dict(ckpt['model'])\n",
        "\n",
        "    def save_to_disk(self, epoch, optimizer, save_path=None):\n",
        "        if not path.exists(save_path):\n",
        "            os.makedirs(path.dirname(save_path), exist_ok = True)\n",
        "        torch.save({'model': self.model.state_dict(),\n",
        "                    'epoch': epoch,\n",
        "                    'optimizer_state_dict': optimizer.state_dict()\n",
        "                    },\n",
        "                   save_path)"
      ],
      "metadata": {
        "id": "4eqeD6NWvqhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying adversarial train to enhance the malware detector."
      ],
      "metadata": {
        "id": "He1Ak73MyYtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torch.load('/content/malware_detection/datasets/train_dataset.pt')\n",
        "train_Loader = data.DataLoader(train_dataset, batch_size=128, shuffle=False)\n",
        "validation_dataset = torch.load('/content/malware_detection/datasets/validation_dataset.pt')\n",
        "validation_Loader = data.DataLoader(validation_dataset, batch_size=10000, shuffle=False)\n",
        "test_dataset = torch.load('/content/malware_detection/datasets/test_dataset.pt')\n",
        "test_Loader = data.DataLoader(test_dataset, batch_size=10000, shuffle=False)"
      ],
      "metadata": {
        "id": "MRAX7j_qywXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('/content/malware_detection/dataset/drebin/data.vocab', 'rb') as file:\n",
        "    loaded_data = pickle.load(file)\n",
        "\n",
        "print(len(loaded_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngwMMct9nohS",
        "outputId": "d7934217-7087-4b13-d89a-7af01de0badc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# norm = 'linf'\n",
        "\n",
        "model = MalwareDetectionDNN(6693,2)\n",
        "model = model.double().to(device)\n",
        "attack = PGD(norm='linf', use_random=False,rounding_threshold=0.5,is_attacker=False,manipulation_x=manipulation_x, omega=omega,api_flag=api_flag,device=device)\n",
        "attack_param = {}\n",
        "max_adv_training_model = PGDAdvTraining(model, attack, attack_param)\n",
        "max_adv_training_model.fit(train_Loader,validation_Loader,adv_epochs=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41DiMLnjfGBG",
        "outputId": "7d99b83c-a4fc-40b1-e7f4-a54eb91a6561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mini batch: 1/870 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.6917 | Train accuracy: 50.78%.\n",
            "Mini batch: 2/870 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.6406 | Train accuracy: 72.66%.\n",
            "Mini batch: 3/870 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.4805 | Train accuracy: 79.69%.\n",
            "Mini batch: 4/870 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.3918 | Train accuracy: 87.50%.\n",
            "Mini batch: 5/870 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.3705 | Train accuracy: 80.47%.\n",
            "Mini batch: 6/870 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.2362 | Train accuracy: 89.06%.\n",
            "Mini batch: 7/870 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.1747 | Train accuracy: 95.31%.\n",
            "Mini batch: 8/870 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.3492 | Train accuracy: 91.41%.\n",
            "Mini batch: 9/870 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.1660 | Train accuracy: 92.97%.\n",
            "Mini batch: 10/870 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0944 | Train accuracy: 95.31%.\n",
            "Mini batch: 11/870 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.1600 | Train accuracy: 93.75%.\n",
            "Mini batch: 12/870 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.1286 | Train accuracy: 96.09%.\n",
            "Mini batch: 13/870 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.1788 | Train accuracy: 93.75%.\n",
            "Mini batch: 14/870 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.1107 | Train accuracy: 94.53%.\n",
            "Mini batch: 15/870 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.1692 | Train accuracy: 96.09%.\n",
            "Mini batch: 16/870 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.1855 | Train accuracy: 95.31%.\n",
            "Mini batch: 17/870 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.1407 | Train accuracy: 95.31%.\n",
            "Mini batch: 18/870 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.3032 | Train accuracy: 93.75%.\n",
            "Mini batch: 19/870 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.3036 | Train accuracy: 93.75%.\n",
            "Mini batch: 20/870 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.1966 | Train accuracy: 94.53%.\n",
            "Mini batch: 21/870 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.2004 | Train accuracy: 93.75%.\n",
            "Mini batch: 22/870 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.1310 | Train accuracy: 94.53%.\n",
            "Mini batch: 23/870 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.1853 | Train accuracy: 93.75%.\n",
            "Mini batch: 24/870 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.1654 | Train accuracy: 96.09%.\n",
            "Mini batch: 25/870 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0681 | Train accuracy: 98.44%.\n",
            "Mini batch: 26/870 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.1035 | Train accuracy: 96.09%.\n",
            "Mini batch: 27/870 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.1469 | Train accuracy: 96.88%.\n",
            "Mini batch: 28/870 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.1581 | Train accuracy: 96.09%.\n",
            "Mini batch: 29/870 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.1247 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.2330 | Train accuracy: 91.30\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 47.21% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 1 with validation accuracy 47.21% and accuracy 0.0% under attack.\n",
            "Mini batch: 30/870 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.1189 | Train accuracy: 96.09%.\n",
            "Mini batch: 31/870 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.1068 | Train accuracy: 96.88%.\n",
            "Mini batch: 32/870 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0649 | Train accuracy: 97.66%.\n",
            "Mini batch: 33/870 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0706 | Train accuracy: 98.44%.\n",
            "Mini batch: 34/870 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.1110 | Train accuracy: 96.09%.\n",
            "Mini batch: 35/870 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0597 | Train accuracy: 98.44%.\n",
            "Mini batch: 36/870 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0189 | Train accuracy: 100.00%.\n",
            "Mini batch: 37/870 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.1320 | Train accuracy: 97.66%.\n",
            "Mini batch: 38/870 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0241 | Train accuracy: 99.22%.\n",
            "Mini batch: 39/870 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0440 | Train accuracy: 98.44%.\n",
            "Mini batch: 40/870 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0515 | Train accuracy: 98.44%.\n",
            "Mini batch: 41/870 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0735 | Train accuracy: 97.66%.\n",
            "Mini batch: 42/870 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0281 | Train accuracy: 99.22%.\n",
            "Mini batch: 43/870 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0384 | Train accuracy: 98.44%.\n",
            "Mini batch: 44/870 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0325 | Train accuracy: 99.22%.\n",
            "Mini batch: 45/870 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0358 | Train accuracy: 99.22%.\n",
            "Mini batch: 46/870 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0238 | Train accuracy: 99.22%.\n",
            "Mini batch: 47/870 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0896 | Train accuracy: 97.66%.\n",
            "Mini batch: 48/870 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.1670 | Train accuracy: 96.09%.\n",
            "Mini batch: 49/870 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.1170 | Train accuracy: 97.66%.\n",
            "Mini batch: 50/870 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0582 | Train accuracy: 97.66%.\n",
            "Mini batch: 51/870 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0877 | Train accuracy: 98.44%.\n",
            "Mini batch: 52/870 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0386 | Train accuracy: 98.44%.\n",
            "Mini batch: 53/870 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0526 | Train accuracy: 98.44%.\n",
            "Mini batch: 54/870 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0301 | Train accuracy: 98.44%.\n",
            "Mini batch: 55/870 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0795 | Train accuracy: 97.66%.\n",
            "Mini batch: 56/870 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0542 | Train accuracy: 97.66%.\n",
            "Mini batch: 57/870 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0414 | Train accuracy: 99.22%.\n",
            "Mini batch: 58/870 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0040 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0639 | Train accuracy: 98.20\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 46.66% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 1 with validation accuracy 47.21% and accuracy 0.0% under attack.\n",
            "Mini batch: 59/870 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0302 | Train accuracy: 99.22%.\n",
            "Mini batch: 60/870 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0240 | Train accuracy: 100.00%.\n",
            "Mini batch: 61/870 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0549 | Train accuracy: 99.22%.\n",
            "Mini batch: 62/870 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0673 | Train accuracy: 97.66%.\n",
            "Mini batch: 63/870 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0661 | Train accuracy: 98.44%.\n",
            "Mini batch: 64/870 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0266 | Train accuracy: 98.44%.\n",
            "Mini batch: 65/870 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0058 | Train accuracy: 100.00%.\n",
            "Mini batch: 66/870 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0649 | Train accuracy: 98.44%.\n",
            "Mini batch: 67/870 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0088 | Train accuracy: 100.00%.\n",
            "Mini batch: 68/870 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0242 | Train accuracy: 99.22%.\n",
            "Mini batch: 69/870 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0271 | Train accuracy: 99.22%.\n",
            "Mini batch: 70/870 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0576 | Train accuracy: 99.22%.\n",
            "Mini batch: 71/870 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0232 | Train accuracy: 98.44%.\n",
            "Mini batch: 72/870 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0184 | Train accuracy: 99.22%.\n",
            "Mini batch: 73/870 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0301 | Train accuracy: 99.22%.\n",
            "Mini batch: 74/870 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0274 | Train accuracy: 98.44%.\n",
            "Mini batch: 75/870 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0309 | Train accuracy: 99.22%.\n",
            "Mini batch: 76/870 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0534 | Train accuracy: 98.44%.\n",
            "Mini batch: 77/870 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.1256 | Train accuracy: 98.44%.\n",
            "Mini batch: 78/870 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0740 | Train accuracy: 98.44%.\n",
            "Mini batch: 79/870 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0279 | Train accuracy: 99.22%.\n",
            "Mini batch: 80/870 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0155 | Train accuracy: 100.00%.\n",
            "Mini batch: 81/870 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0737 | Train accuracy: 96.88%.\n",
            "Mini batch: 82/870 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0597 | Train accuracy: 98.44%.\n",
            "Mini batch: 83/870 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0088 | Train accuracy: 100.00%.\n",
            "Mini batch: 84/870 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0626 | Train accuracy: 98.44%.\n",
            "Mini batch: 85/870 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0263 | Train accuracy: 98.44%.\n",
            "Mini batch: 86/870 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0677 | Train accuracy: 97.66%.\n",
            "Mini batch: 87/870 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0178 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0414 | Train accuracy: 98.90\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 44.33% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 1 with validation accuracy 47.21% and accuracy 0.0% under attack.\n",
            "Mini batch: 88/870 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0231 | Train accuracy: 98.44%.\n",
            "Mini batch: 89/870 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0470 | Train accuracy: 96.88%.\n",
            "Mini batch: 90/870 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0072 | Train accuracy: 100.00%.\n",
            "Mini batch: 91/870 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0103 | Train accuracy: 100.00%.\n",
            "Mini batch: 92/870 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0528 | Train accuracy: 98.44%.\n",
            "Mini batch: 93/870 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0101 | Train accuracy: 100.00%.\n",
            "Mini batch: 94/870 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0226 | Train accuracy: 98.44%.\n",
            "Mini batch: 95/870 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0238 | Train accuracy: 99.22%.\n",
            "Mini batch: 96/870 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0078 | Train accuracy: 100.00%.\n",
            "Mini batch: 97/870 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0061 | Train accuracy: 100.00%.\n",
            "Mini batch: 98/870 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0086 | Train accuracy: 100.00%.\n",
            "Mini batch: 99/870 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.1297 | Train accuracy: 97.66%.\n",
            "Mini batch: 100/870 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0049 | Train accuracy: 100.00%.\n",
            "Mini batch: 101/870 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0555 | Train accuracy: 99.22%.\n",
            "Mini batch: 102/870 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0092 | Train accuracy: 100.00%.\n",
            "Mini batch: 103/870 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0067 | Train accuracy: 100.00%.\n",
            "Mini batch: 104/870 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0017 | Train accuracy: 100.00%.\n",
            "Mini batch: 105/870 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0236 | Train accuracy: 98.44%.\n",
            "Mini batch: 106/870 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0610 | Train accuracy: 98.44%.\n",
            "Mini batch: 107/870 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.1197 | Train accuracy: 96.88%.\n",
            "Mini batch: 108/870 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0116 | Train accuracy: 99.22%.\n",
            "Mini batch: 109/870 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0189 | Train accuracy: 99.22%.\n",
            "Mini batch: 110/870 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0203 | Train accuracy: 99.22%.\n",
            "Mini batch: 111/870 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0191 | Train accuracy: 99.22%.\n",
            "Mini batch: 112/870 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0036 | Train accuracy: 100.00%.\n",
            "Mini batch: 113/870 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0239 | Train accuracy: 99.22%.\n",
            "Mini batch: 114/870 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0206 | Train accuracy: 99.22%.\n",
            "Mini batch: 115/870 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0174 | Train accuracy: 99.22%.\n",
            "Mini batch: 116/870 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0024 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0265 | Train accuracy: 99.19\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 40.83% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 1 with validation accuracy 47.21% and accuracy 0.0% under attack.\n",
            "Mini batch: 117/870 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0514 | Train accuracy: 96.88%.\n",
            "Mini batch: 118/870 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0145 | Train accuracy: 100.00%.\n",
            "Mini batch: 119/870 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0212 | Train accuracy: 99.22%.\n",
            "Mini batch: 120/870 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0125 | Train accuracy: 100.00%.\n",
            "Mini batch: 121/870 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0169 | Train accuracy: 99.22%.\n",
            "Mini batch: 122/870 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0185 | Train accuracy: 99.22%.\n",
            "Mini batch: 123/870 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0441 | Train accuracy: 97.66%.\n",
            "Mini batch: 124/870 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0157 | Train accuracy: 99.22%.\n",
            "Mini batch: 125/870 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0027 | Train accuracy: 100.00%.\n",
            "Mini batch: 126/870 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0701 | Train accuracy: 98.44%.\n",
            "Mini batch: 127/870 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0097 | Train accuracy: 100.00%.\n",
            "Mini batch: 128/870 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0333 | Train accuracy: 98.44%.\n",
            "Mini batch: 129/870 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0073 | Train accuracy: 100.00%.\n",
            "Mini batch: 130/870 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0150 | Train accuracy: 100.00%.\n",
            "Mini batch: 131/870 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0436 | Train accuracy: 96.88%.\n",
            "Mini batch: 132/870 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0253 | Train accuracy: 98.44%.\n",
            "Mini batch: 133/870 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0028 | Train accuracy: 100.00%.\n",
            "Mini batch: 134/870 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0222 | Train accuracy: 99.22%.\n",
            "Mini batch: 135/870 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0422 | Train accuracy: 98.44%.\n",
            "Mini batch: 136/870 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.1025 | Train accuracy: 97.66%.\n",
            "Mini batch: 137/870 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0058 | Train accuracy: 100.00%.\n",
            "Mini batch: 138/870 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0097 | Train accuracy: 99.22%.\n",
            "Mini batch: 139/870 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0086 | Train accuracy: 99.22%.\n",
            "Mini batch: 140/870 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0259 | Train accuracy: 99.22%.\n",
            "Mini batch: 141/870 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0224 | Train accuracy: 99.22%.\n",
            "Mini batch: 142/870 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0339 | Train accuracy: 99.22%.\n",
            "Mini batch: 143/870 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0747 | Train accuracy: 96.88%.\n",
            "Mini batch: 144/870 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0043 | Train accuracy: 100.00%.\n",
            "Mini batch: 145/870 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0261 | Train accuracy: 99.03\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 40.37% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 1 with validation accuracy 47.21% and accuracy 0.0% under attack.\n",
            "Mini batch: 146/870 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0139 | Train accuracy: 99.22%.\n",
            "Mini batch: 147/870 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0590 | Train accuracy: 98.44%.\n",
            "Mini batch: 148/870 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0819 | Train accuracy: 98.44%.\n",
            "Mini batch: 149/870 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0389 | Train accuracy: 98.44%.\n",
            "Mini batch: 150/870 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0499 | Train accuracy: 98.44%.\n",
            "Mini batch: 151/870 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0248 | Train accuracy: 99.22%.\n",
            "Mini batch: 152/870 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0037 | Train accuracy: 100.00%.\n",
            "Mini batch: 153/870 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0322 | Train accuracy: 98.44%.\n",
            "Mini batch: 154/870 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.1266 | Train accuracy: 96.88%.\n",
            "Mini batch: 155/870 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0336 | Train accuracy: 98.44%.\n",
            "Mini batch: 156/870 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0298 | Train accuracy: 99.22%.\n",
            "Mini batch: 157/870 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0387 | Train accuracy: 98.44%.\n",
            "Mini batch: 158/870 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0155 | Train accuracy: 99.22%.\n",
            "Mini batch: 159/870 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0320 | Train accuracy: 98.44%.\n",
            "Mini batch: 160/870 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0286 | Train accuracy: 99.22%.\n",
            "Mini batch: 161/870 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0193 | Train accuracy: 99.22%.\n",
            "Mini batch: 162/870 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0135 | Train accuracy: 99.22%.\n",
            "Mini batch: 163/870 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0560 | Train accuracy: 98.44%.\n",
            "Mini batch: 164/870 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0707 | Train accuracy: 97.66%.\n",
            "Mini batch: 165/870 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0351 | Train accuracy: 98.44%.\n",
            "Mini batch: 166/870 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0351 | Train accuracy: 98.44%.\n",
            "Mini batch: 167/870 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0321 | Train accuracy: 99.22%.\n",
            "Mini batch: 168/870 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0281 | Train accuracy: 100.00%.\n",
            "Mini batch: 169/870 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0597 | Train accuracy: 98.44%.\n",
            "Mini batch: 170/870 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0037 | Train accuracy: 100.00%.\n",
            "Mini batch: 171/870 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0062 | Train accuracy: 100.00%.\n",
            "Mini batch: 172/870 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0062 | Train accuracy: 100.00%.\n",
            "Mini batch: 173/870 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0045 | Train accuracy: 100.00%.\n",
            "Mini batch: 174/870 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0338 | Train accuracy: 98.95\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 44.04% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 1 with validation accuracy 47.21% and accuracy 0.0% under attack.\n",
            "Mini batch: 175/870 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0081 | Train accuracy: 100.00%.\n",
            "Mini batch: 176/870 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0024 | Train accuracy: 100.00%.\n",
            "Mini batch: 177/870 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0061 | Train accuracy: 99.22%.\n",
            "Mini batch: 178/870 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0168 | Train accuracy: 99.22%.\n",
            "Mini batch: 179/870 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0153 | Train accuracy: 99.22%.\n",
            "Mini batch: 180/870 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0185 | Train accuracy: 99.22%.\n",
            "Mini batch: 181/870 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00%.\n",
            "Mini batch: 182/870 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0561 | Train accuracy: 99.22%.\n",
            "Mini batch: 183/870 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00%.\n",
            "Mini batch: 184/870 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0076 | Train accuracy: 100.00%.\n",
            "Mini batch: 185/870 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.1153 | Train accuracy: 96.88%.\n",
            "Mini batch: 186/870 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0259 | Train accuracy: 98.44%.\n",
            "Mini batch: 187/870 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00%.\n",
            "Mini batch: 188/870 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0024 | Train accuracy: 100.00%.\n",
            "Mini batch: 189/870 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0916 | Train accuracy: 96.88%.\n",
            "Mini batch: 190/870 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0109 | Train accuracy: 99.22%.\n",
            "Mini batch: 191/870 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0937 | Train accuracy: 96.09%.\n",
            "Mini batch: 192/870 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0599 | Train accuracy: 99.22%.\n",
            "Mini batch: 193/870 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0369 | Train accuracy: 97.66%.\n",
            "Mini batch: 194/870 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0922 | Train accuracy: 97.66%.\n",
            "Mini batch: 195/870 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0461 | Train accuracy: 99.22%.\n",
            "Mini batch: 196/870 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.1203 | Train accuracy: 96.09%.\n",
            "Mini batch: 197/870 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0575 | Train accuracy: 98.44%.\n",
            "Mini batch: 198/870 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0419 | Train accuracy: 98.44%.\n",
            "Mini batch: 199/870 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0136 | Train accuracy: 100.00%.\n",
            "Mini batch: 200/870 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0196 | Train accuracy: 99.22%.\n",
            "Mini batch: 201/870 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0340 | Train accuracy: 99.22%.\n",
            "Mini batch: 202/870 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0041 | Train accuracy: 100.00%.\n",
            "Mini batch: 203/870 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0345 | Train accuracy: 98.92\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 46.37% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 1 with validation accuracy 47.21% and accuracy 0.0% under attack.\n",
            "Mini batch: 204/870 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0656 | Train accuracy: 97.66%.\n",
            "Mini batch: 205/870 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0038 | Train accuracy: 100.00%.\n",
            "Mini batch: 206/870 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0016 | Train accuracy: 100.00%.\n",
            "Mini batch: 207/870 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0129 | Train accuracy: 99.22%.\n",
            "Mini batch: 208/870 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0347 | Train accuracy: 98.44%.\n",
            "Mini batch: 209/870 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0167 | Train accuracy: 99.22%.\n",
            "Mini batch: 210/870 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0117 | Train accuracy: 99.22%.\n",
            "Mini batch: 211/870 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0040 | Train accuracy: 100.00%.\n",
            "Mini batch: 212/870 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0151 | Train accuracy: 99.22%.\n",
            "Mini batch: 213/870 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0068 | Train accuracy: 100.00%.\n",
            "Mini batch: 214/870 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0059 | Train accuracy: 100.00%.\n",
            "Mini batch: 215/870 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0049 | Train accuracy: 100.00%.\n",
            "Mini batch: 216/870 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0052 | Train accuracy: 100.00%.\n",
            "Mini batch: 217/870 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0067 | Train accuracy: 100.00%.\n",
            "Mini batch: 218/870 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0018 | Train accuracy: 100.00%.\n",
            "Mini batch: 219/870 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0160 | Train accuracy: 99.22%.\n",
            "Mini batch: 220/870 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0044 | Train accuracy: 100.00%.\n",
            "Mini batch: 221/870 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0302 | Train accuracy: 98.44%.\n",
            "Mini batch: 222/870 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0213 | Train accuracy: 99.22%.\n",
            "Mini batch: 223/870 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0147 | Train accuracy: 99.22%.\n",
            "Mini batch: 224/870 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0019 | Train accuracy: 100.00%.\n",
            "Mini batch: 225/870 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0136 | Train accuracy: 100.00%.\n",
            "Mini batch: 226/870 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00%.\n",
            "Mini batch: 227/870 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0775 | Train accuracy: 99.22%.\n",
            "Mini batch: 228/870 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 229/870 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0031 | Train accuracy: 100.00%.\n",
            "Mini batch: 230/870 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0104 | Train accuracy: 100.00%.\n",
            "Mini batch: 231/870 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0040 | Train accuracy: 100.00%.\n",
            "Mini batch: 232/870 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0036 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0138 | Train accuracy: 99.60\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 47.83% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 8 with validation accuracy 47.83% and accuracy 0.0% under attack.\n",
            "Mini batch: 233/870 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0458 | Train accuracy: 97.66%.\n",
            "Mini batch: 234/870 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0073 | Train accuracy: 100.00%.\n",
            "Mini batch: 235/870 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0013 | Train accuracy: 100.00%.\n",
            "Mini batch: 236/870 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0147 | Train accuracy: 98.44%.\n",
            "Mini batch: 237/870 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0240 | Train accuracy: 98.44%.\n",
            "Mini batch: 238/870 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0202 | Train accuracy: 99.22%.\n",
            "Mini batch: 239/870 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00%.\n",
            "Mini batch: 240/870 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.1163 | Train accuracy: 97.66%.\n",
            "Mini batch: 241/870 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "Mini batch: 242/870 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0029 | Train accuracy: 100.00%.\n",
            "Mini batch: 243/870 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0014 | Train accuracy: 100.00%.\n",
            "Mini batch: 244/870 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0413 | Train accuracy: 99.22%.\n",
            "Mini batch: 245/870 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0057 | Train accuracy: 100.00%.\n",
            "Mini batch: 246/870 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0139 | Train accuracy: 100.00%.\n",
            "Mini batch: 247/870 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0135 | Train accuracy: 100.00%.\n",
            "Mini batch: 248/870 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0131 | Train accuracy: 100.00%.\n",
            "Mini batch: 249/870 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0036 | Train accuracy: 100.00%.\n",
            "Mini batch: 250/870 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0111 | Train accuracy: 99.22%.\n",
            "Mini batch: 251/870 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0034 | Train accuracy: 100.00%.\n",
            "Mini batch: 252/870 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0326 | Train accuracy: 98.44%.\n",
            "Mini batch: 253/870 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0078 | Train accuracy: 100.00%.\n",
            "Mini batch: 254/870 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0091 | Train accuracy: 100.00%.\n",
            "Mini batch: 255/870 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0243 | Train accuracy: 99.22%.\n",
            "Mini batch: 256/870 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0403 | Train accuracy: 97.66%.\n",
            "Mini batch: 257/870 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0150 | Train accuracy: 99.22%.\n",
            "Mini batch: 258/870 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0043 | Train accuracy: 100.00%.\n",
            "Mini batch: 259/870 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0065 | Train accuracy: 100.00%.\n",
            "Mini batch: 260/870 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0052 | Train accuracy: 100.00%.\n",
            "Mini batch: 261/870 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0181 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0174 | Train accuracy: 99.46\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 48.04% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 9 with validation accuracy 48.04% and accuracy 0.0% under attack.\n",
            "Mini batch: 262/870 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0164 | Train accuracy: 99.22%.\n",
            "Mini batch: 263/870 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0333 | Train accuracy: 99.22%.\n",
            "Mini batch: 264/870 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0333 | Train accuracy: 99.22%.\n",
            "Mini batch: 265/870 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0068 | Train accuracy: 100.00%.\n",
            "Mini batch: 266/870 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00%.\n",
            "Mini batch: 267/870 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0670 | Train accuracy: 99.22%.\n",
            "Mini batch: 268/870 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00%.\n",
            "Mini batch: 269/870 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0854 | Train accuracy: 98.44%.\n",
            "Mini batch: 270/870 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00%.\n",
            "Mini batch: 271/870 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0074 | Train accuracy: 99.22%.\n",
            "Mini batch: 272/870 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "Mini batch: 273/870 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0013 | Train accuracy: 100.00%.\n",
            "Mini batch: 274/870 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0017 | Train accuracy: 100.00%.\n",
            "Mini batch: 275/870 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0048 | Train accuracy: 100.00%.\n",
            "Mini batch: 276/870 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0018 | Train accuracy: 100.00%.\n",
            "Mini batch: 277/870 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0036 | Train accuracy: 100.00%.\n",
            "Mini batch: 278/870 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00%.\n",
            "Mini batch: 279/870 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0255 | Train accuracy: 98.44%.\n",
            "Mini batch: 280/870 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0024 | Train accuracy: 100.00%.\n",
            "Mini batch: 281/870 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0155 | Train accuracy: 99.22%.\n",
            "Mini batch: 282/870 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0024 | Train accuracy: 100.00%.\n",
            "Mini batch: 283/870 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0055 | Train accuracy: 100.00%.\n",
            "Mini batch: 284/870 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00%.\n",
            "Mini batch: 285/870 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0304 | Train accuracy: 98.44%.\n",
            "Mini batch: 286/870 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "Mini batch: 287/870 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0219 | Train accuracy: 99.22%.\n",
            "Mini batch: 288/870 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0029 | Train accuracy: 100.00%.\n",
            "Mini batch: 289/870 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0022 | Train accuracy: 100.00%.\n",
            "Mini batch: 290/870 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0130 | Train accuracy: 99.65\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 46.96% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 9 with validation accuracy 48.04% and accuracy 0.0% under attack.\n",
            "Mini batch: 291/870 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0098 | Train accuracy: 100.00%.\n",
            "Mini batch: 292/870 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0407 | Train accuracy: 99.22%.\n",
            "Mini batch: 293/870 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0141 | Train accuracy: 100.00%.\n",
            "Mini batch: 294/870 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0364 | Train accuracy: 97.66%.\n",
            "Mini batch: 295/870 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00%.\n",
            "Mini batch: 296/870 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0016 | Train accuracy: 100.00%.\n",
            "Mini batch: 297/870 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0017 | Train accuracy: 100.00%.\n",
            "Mini batch: 298/870 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0196 | Train accuracy: 99.22%.\n",
            "Mini batch: 299/870 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0104 | Train accuracy: 99.22%.\n",
            "Mini batch: 300/870 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0075 | Train accuracy: 99.22%.\n",
            "Mini batch: 301/870 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0042 | Train accuracy: 100.00%.\n",
            "Mini batch: 302/870 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0026 | Train accuracy: 100.00%.\n",
            "Mini batch: 303/870 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0025 | Train accuracy: 100.00%.\n",
            "Mini batch: 304/870 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0073 | Train accuracy: 99.22%.\n",
            "Mini batch: 305/870 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00%.\n",
            "Mini batch: 306/870 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "Mini batch: 307/870 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 308/870 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00%.\n",
            "Mini batch: 309/870 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0023 | Train accuracy: 100.00%.\n",
            "Mini batch: 310/870 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0024 | Train accuracy: 100.00%.\n",
            "Mini batch: 311/870 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0340 | Train accuracy: 99.22%.\n",
            "Mini batch: 312/870 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00%.\n",
            "Mini batch: 313/870 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "Mini batch: 314/870 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0481 | Train accuracy: 98.44%.\n",
            "Mini batch: 315/870 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0028 | Train accuracy: 100.00%.\n",
            "Mini batch: 316/870 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0026 | Train accuracy: 100.00%.\n",
            "Mini batch: 317/870 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00%.\n",
            "Mini batch: 318/870 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0048 | Train accuracy: 100.00%.\n",
            "Mini batch: 319/870 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0090 | Train accuracy: 99.70\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 46.04% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 9 with validation accuracy 48.04% and accuracy 0.0% under attack.\n",
            "Mini batch: 320/870 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0065 | Train accuracy: 99.22%.\n",
            "Mini batch: 321/870 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0022 | Train accuracy: 100.00%.\n",
            "Mini batch: 322/870 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "Mini batch: 323/870 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00%.\n",
            "Mini batch: 324/870 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "Mini batch: 325/870 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00%.\n",
            "Mini batch: 326/870 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0048 | Train accuracy: 100.00%.\n",
            "Mini batch: 327/870 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0018 | Train accuracy: 100.00%.\n",
            "Mini batch: 328/870 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0079 | Train accuracy: 99.22%.\n",
            "Mini batch: 329/870 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0026 | Train accuracy: 100.00%.\n",
            "Mini batch: 330/870 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 331/870 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0047 | Train accuracy: 100.00%.\n",
            "Mini batch: 332/870 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0471 | Train accuracy: 99.22%.\n",
            "Mini batch: 333/870 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0014 | Train accuracy: 100.00%.\n",
            "Mini batch: 334/870 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0025 | Train accuracy: 100.00%.\n",
            "Mini batch: 335/870 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0114 | Train accuracy: 100.00%.\n",
            "Mini batch: 336/870 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0044 | Train accuracy: 100.00%.\n",
            "Mini batch: 337/870 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0042 | Train accuracy: 100.00%.\n",
            "Mini batch: 338/870 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0047 | Train accuracy: 100.00%.\n",
            "Mini batch: 339/870 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0013 | Train accuracy: 100.00%.\n",
            "Mini batch: 340/870 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0049 | Train accuracy: 100.00%.\n",
            "Mini batch: 341/870 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00%.\n",
            "Mini batch: 342/870 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00%.\n",
            "Mini batch: 343/870 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00%.\n",
            "Mini batch: 344/870 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 345/870 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00%.\n",
            "Mini batch: 346/870 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00%.\n",
            "Mini batch: 347/870 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00%.\n",
            "Mini batch: 348/870 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0042 | Train accuracy: 99.92\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 44.54% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 9 with validation accuracy 48.04% and accuracy 0.0% under attack.\n",
            "Mini batch: 349/870 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00%.\n",
            "Mini batch: 350/870 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0079 | Train accuracy: 99.22%.\n",
            "Mini batch: 351/870 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00%.\n",
            "Mini batch: 352/870 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0173 | Train accuracy: 99.22%.\n",
            "Mini batch: 353/870 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00%.\n",
            "Mini batch: 354/870 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0125 | Train accuracy: 99.22%.\n",
            "Mini batch: 355/870 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 356/870 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 357/870 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0020 | Train accuracy: 100.00%.\n",
            "Mini batch: 358/870 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0013 | Train accuracy: 100.00%.\n",
            "Mini batch: 359/870 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "Mini batch: 360/870 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0125 | Train accuracy: 99.22%.\n",
            "Mini batch: 361/870 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00%.\n",
            "Mini batch: 362/870 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00%.\n",
            "Mini batch: 363/870 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00%.\n",
            "Mini batch: 364/870 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00%.\n",
            "Mini batch: 365/870 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0014 | Train accuracy: 100.00%.\n",
            "Mini batch: 366/870 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00%.\n",
            "Mini batch: 367/870 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00%.\n",
            "Mini batch: 368/870 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0046 | Train accuracy: 100.00%.\n",
            "Mini batch: 369/870 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0015 | Train accuracy: 100.00%.\n",
            "Mini batch: 370/870 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00%.\n",
            "Mini batch: 371/870 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00%.\n",
            "Mini batch: 372/870 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0085 | Train accuracy: 99.22%.\n",
            "Mini batch: 373/870 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 374/870 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00%.\n",
            "Mini batch: 375/870 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0013 | Train accuracy: 100.00%.\n",
            "Mini batch: 376/870 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 377/870 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0028 | Train accuracy: 99.87\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 48.04% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 13 with validation accuracy 48.04% and accuracy 0.0% under attack.\n",
            "Mini batch: 378/870 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00%.\n",
            "Mini batch: 379/870 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0184 | Train accuracy: 99.22%.\n",
            "Mini batch: 380/870 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00%.\n",
            "Mini batch: 381/870 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00%.\n",
            "Mini batch: 382/870 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "Mini batch: 383/870 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0133 | Train accuracy: 99.22%.\n",
            "Mini batch: 384/870 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0024 | Train accuracy: 100.00%.\n",
            "Mini batch: 385/870 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0042 | Train accuracy: 100.00%.\n",
            "Mini batch: 386/870 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00%.\n",
            "Mini batch: 387/870 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "Mini batch: 388/870 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 389/870 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00%.\n",
            "Mini batch: 390/870 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0013 | Train accuracy: 100.00%.\n",
            "Mini batch: 391/870 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "Mini batch: 392/870 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 393/870 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 394/870 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 395/870 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00%.\n",
            "Mini batch: 396/870 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "Mini batch: 397/870 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0040 | Train accuracy: 100.00%.\n",
            "Mini batch: 398/870 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00%.\n",
            "Mini batch: 399/870 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 400/870 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "Mini batch: 401/870 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00%.\n",
            "Mini batch: 402/870 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 403/870 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00%.\n",
            "Mini batch: 404/870 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0048 | Train accuracy: 100.00%.\n",
            "Mini batch: 405/870 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 406/870 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0020 | Train accuracy: 99.95\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 47.04% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 13 with validation accuracy 48.04% and accuracy 0.0% under attack.\n",
            "Mini batch: 407/870 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 408/870 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 409/870 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00%.\n",
            "Mini batch: 410/870 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 411/870 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0152 | Train accuracy: 99.22%.\n",
            "Mini batch: 412/870 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 413/870 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00%.\n",
            "Mini batch: 414/870 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 415/870 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 416/870 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00%.\n",
            "Mini batch: 417/870 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0251 | Train accuracy: 99.22%.\n",
            "Mini batch: 418/870 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0022 | Train accuracy: 100.00%.\n",
            "Mini batch: 419/870 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00%.\n",
            "Mini batch: 420/870 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0024 | Train accuracy: 100.00%.\n",
            "Mini batch: 421/870 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 422/870 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 423/870 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 424/870 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0021 | Train accuracy: 100.00%.\n",
            "Mini batch: 425/870 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0021 | Train accuracy: 100.00%.\n",
            "Mini batch: 426/870 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0376 | Train accuracy: 98.44%.\n",
            "Mini batch: 427/870 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 428/870 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0040 | Train accuracy: 100.00%.\n",
            "Mini batch: 429/870 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00%.\n",
            "Mini batch: 430/870 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0277 | Train accuracy: 99.22%.\n",
            "Mini batch: 431/870 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 432/870 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0030 | Train accuracy: 100.00%.\n",
            "Mini batch: 433/870 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0186 | Train accuracy: 99.22%.\n",
            "Mini batch: 434/870 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0355 | Train accuracy: 99.22%.\n",
            "Mini batch: 435/870 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0062 | Train accuracy: 99.81\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 46.83% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 13 with validation accuracy 48.04% and accuracy 0.0% under attack.\n",
            "Mini batch: 436/870 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0465 | Train accuracy: 99.22%.\n",
            "Mini batch: 437/870 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0019 | Train accuracy: 100.00%.\n",
            "Mini batch: 438/870 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 439/870 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0017 | Train accuracy: 100.00%.\n",
            "Mini batch: 440/870 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 441/870 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00%.\n",
            "Mini batch: 442/870 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00%.\n",
            "Mini batch: 443/870 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0914 | Train accuracy: 97.66%.\n",
            "Mini batch: 444/870 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00%.\n",
            "Mini batch: 445/870 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00%.\n",
            "Mini batch: 446/870 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0024 | Train accuracy: 100.00%.\n",
            "Mini batch: 447/870 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0041 | Train accuracy: 100.00%.\n",
            "Mini batch: 448/870 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0016 | Train accuracy: 100.00%.\n",
            "Mini batch: 449/870 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0039 | Train accuracy: 100.00%.\n",
            "Mini batch: 450/870 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0038 | Train accuracy: 100.00%.\n",
            "Mini batch: 451/870 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0085 | Train accuracy: 99.22%.\n",
            "Mini batch: 452/870 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00%.\n",
            "Mini batch: 453/870 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0083 | Train accuracy: 100.00%.\n",
            "Mini batch: 454/870 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0016 | Train accuracy: 100.00%.\n",
            "Mini batch: 455/870 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0147 | Train accuracy: 99.22%.\n",
            "Mini batch: 456/870 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "Mini batch: 457/870 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.1119 | Train accuracy: 99.22%.\n",
            "Mini batch: 458/870 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00%.\n",
            "Mini batch: 459/870 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0024 | Train accuracy: 100.00%.\n",
            "Mini batch: 460/870 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00%.\n",
            "Mini batch: 461/870 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00%.\n",
            "Mini batch: 462/870 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "Mini batch: 463/870 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0020 | Train accuracy: 100.00%.\n",
            "Mini batch: 464/870 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0109 | Train accuracy: 99.81\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 47.96% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 13 with validation accuracy 48.04% and accuracy 0.0% under attack.\n",
            "Mini batch: 465/870 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0031 | Train accuracy: 100.00%.\n",
            "Mini batch: 466/870 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0047 | Train accuracy: 100.00%.\n",
            "Mini batch: 467/870 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00%.\n",
            "Mini batch: 468/870 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0027 | Train accuracy: 100.00%.\n",
            "Mini batch: 469/870 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0014 | Train accuracy: 100.00%.\n",
            "Mini batch: 470/870 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00%.\n",
            "Mini batch: 471/870 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00%.\n",
            "Mini batch: 472/870 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00%.\n",
            "Mini batch: 473/870 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "Mini batch: 474/870 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "Mini batch: 475/870 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00%.\n",
            "Mini batch: 476/870 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 477/870 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0021 | Train accuracy: 100.00%.\n",
            "Mini batch: 478/870 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0072 | Train accuracy: 99.22%.\n",
            "Mini batch: 479/870 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0179 | Train accuracy: 99.22%.\n",
            "Mini batch: 480/870 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0063 | Train accuracy: 99.22%.\n",
            "Mini batch: 481/870 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 482/870 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 483/870 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "Mini batch: 484/870 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "Mini batch: 485/870 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0083 | Train accuracy: 99.22%.\n",
            "Mini batch: 486/870 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0030 | Train accuracy: 100.00%.\n",
            "Mini batch: 487/870 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0073 | Train accuracy: 100.00%.\n",
            "Mini batch: 488/870 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0165 | Train accuracy: 99.22%.\n",
            "Mini batch: 489/870 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00%.\n",
            "Mini batch: 490/870 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0016 | Train accuracy: 100.00%.\n",
            "Mini batch: 491/870 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00%.\n",
            "Mini batch: 492/870 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00%.\n",
            "Mini batch: 493/870 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0031 | Train accuracy: 99.87\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 47.91% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 13 with validation accuracy 48.04% and accuracy 0.0% under attack.\n",
            "Mini batch: 494/870 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00%.\n",
            "Mini batch: 495/870 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0099 | Train accuracy: 99.22%.\n",
            "Mini batch: 496/870 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0024 | Train accuracy: 100.00%.\n",
            "Mini batch: 497/870 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0041 | Train accuracy: 100.00%.\n",
            "Mini batch: 498/870 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 499/870 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00%.\n",
            "Mini batch: 500/870 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00%.\n",
            "Mini batch: 501/870 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0042 | Train accuracy: 100.00%.\n",
            "Mini batch: 502/870 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 503/870 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0014 | Train accuracy: 100.00%.\n",
            "Mini batch: 504/870 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 505/870 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 506/870 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 507/870 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 508/870 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0025 | Train accuracy: 100.00%.\n",
            "Mini batch: 509/870 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 510/870 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 511/870 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 512/870 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0021 | Train accuracy: 100.00%.\n",
            "Mini batch: 513/870 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "Mini batch: 514/870 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 515/870 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0933 | Train accuracy: 99.22%.\n",
            "Mini batch: 516/870 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 517/870 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0022 | Train accuracy: 100.00%.\n",
            "Mini batch: 518/870 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 519/870 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0718 | Train accuracy: 99.22%.\n",
            "Mini batch: 520/870 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0037 | Train accuracy: 100.00%.\n",
            "Mini batch: 521/870 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0031 | Train accuracy: 100.00%.\n",
            "Mini batch: 522/870 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0014 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0071 | Train accuracy: 99.92\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 47.54% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 13 with validation accuracy 48.04% and accuracy 0.0% under attack.\n",
            "Mini batch: 523/870 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0393 | Train accuracy: 98.44%.\n",
            "Mini batch: 524/870 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0073 | Train accuracy: 100.00%.\n",
            "Mini batch: 525/870 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00%.\n",
            "Mini batch: 526/870 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 527/870 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 528/870 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00%.\n",
            "Mini batch: 529/870 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "Mini batch: 530/870 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.2039 | Train accuracy: 96.88%.\n",
            "Mini batch: 531/870 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0066 | Train accuracy: 99.22%.\n",
            "Mini batch: 532/870 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00%.\n",
            "Mini batch: 533/870 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00%.\n",
            "Mini batch: 534/870 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0035 | Train accuracy: 100.00%.\n",
            "Mini batch: 535/870 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0038 | Train accuracy: 100.00%.\n",
            "Mini batch: 536/870 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0070 | Train accuracy: 100.00%.\n",
            "Mini batch: 537/870 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0088 | Train accuracy: 100.00%.\n",
            "Mini batch: 538/870 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0505 | Train accuracy: 98.44%.\n",
            "Mini batch: 539/870 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0074 | Train accuracy: 100.00%.\n",
            "Mini batch: 540/870 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0061 | Train accuracy: 100.00%.\n",
            "Mini batch: 541/870 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0422 | Train accuracy: 99.22%.\n",
            "Mini batch: 542/870 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00%.\n",
            "Mini batch: 543/870 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "Mini batch: 544/870 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00%.\n",
            "Mini batch: 545/870 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "Mini batch: 546/870 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0031 | Train accuracy: 100.00%.\n",
            "Mini batch: 547/870 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00%.\n",
            "Mini batch: 548/870 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0040 | Train accuracy: 100.00%.\n",
            "Mini batch: 549/870 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0085 | Train accuracy: 99.22%.\n",
            "Mini batch: 550/870 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0411 | Train accuracy: 98.44%.\n",
            "Mini batch: 551/870 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0155 | Train accuracy: 99.65\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 45.66% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 13 with validation accuracy 48.04% and accuracy 0.0% under attack.\n",
            "Mini batch: 552/870 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0337 | Train accuracy: 98.44%.\n",
            "Mini batch: 553/870 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0013 | Train accuracy: 100.00%.\n",
            "Mini batch: 554/870 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0043 | Train accuracy: 100.00%.\n",
            "Mini batch: 555/870 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0816 | Train accuracy: 98.44%.\n",
            "Mini batch: 556/870 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0065 | Train accuracy: 100.00%.\n",
            "Mini batch: 557/870 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0320 | Train accuracy: 99.22%.\n",
            "Mini batch: 558/870 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00%.\n",
            "Mini batch: 559/870 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 560/870 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 561/870 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0408 | Train accuracy: 98.44%.\n",
            "Mini batch: 562/870 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0146 | Train accuracy: 99.22%.\n",
            "Mini batch: 563/870 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0613 | Train accuracy: 98.44%.\n",
            "Mini batch: 564/870 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0035 | Train accuracy: 100.00%.\n",
            "Mini batch: 565/870 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "Mini batch: 566/870 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0591 | Train accuracy: 98.44%.\n",
            "Mini batch: 567/870 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0028 | Train accuracy: 100.00%.\n",
            "Mini batch: 568/870 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0104 | Train accuracy: 100.00%.\n",
            "Mini batch: 569/870 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0244 | Train accuracy: 99.22%.\n",
            "Mini batch: 570/870 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0079 | Train accuracy: 100.00%.\n",
            "Mini batch: 571/870 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0015 | Train accuracy: 100.00%.\n",
            "Mini batch: 572/870 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0042 | Train accuracy: 100.00%.\n",
            "Mini batch: 573/870 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0017 | Train accuracy: 100.00%.\n",
            "Mini batch: 574/870 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0014 | Train accuracy: 100.00%.\n",
            "Mini batch: 575/870 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0372 | Train accuracy: 99.22%.\n",
            "Mini batch: 576/870 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00%.\n",
            "Mini batch: 577/870 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0028 | Train accuracy: 100.00%.\n",
            "Mini batch: 578/870 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0111 | Train accuracy: 99.22%.\n",
            "Mini batch: 579/870 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00%.\n",
            "Mini batch: 580/870 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0154 | Train accuracy: 99.60\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 46.25% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 13 with validation accuracy 48.04% and accuracy 0.0% under attack.\n",
            "Mini batch: 581/870 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0064 | Train accuracy: 99.22%.\n",
            "Mini batch: 582/870 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00%.\n",
            "Mini batch: 583/870 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "Mini batch: 584/870 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0013 | Train accuracy: 100.00%.\n",
            "Mini batch: 585/870 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00%.\n",
            "Mini batch: 586/870 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00%.\n",
            "Mini batch: 587/870 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0263 | Train accuracy: 99.22%.\n",
            "Mini batch: 588/870 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0088 | Train accuracy: 99.22%.\n",
            "Mini batch: 589/870 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "Mini batch: 590/870 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0018 | Train accuracy: 100.00%.\n",
            "Mini batch: 591/870 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 592/870 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0049 | Train accuracy: 100.00%.\n",
            "Mini batch: 593/870 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 594/870 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00%.\n",
            "Mini batch: 595/870 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0346 | Train accuracy: 99.22%.\n",
            "Mini batch: 596/870 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0086 | Train accuracy: 99.22%.\n",
            "Mini batch: 597/870 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 598/870 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 599/870 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0163 | Train accuracy: 99.22%.\n",
            "Mini batch: 600/870 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "Mini batch: 601/870 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "Mini batch: 602/870 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0028 | Train accuracy: 100.00%.\n",
            "Mini batch: 603/870 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00%.\n",
            "Mini batch: 604/870 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00%.\n",
            "Mini batch: 605/870 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0131 | Train accuracy: 99.22%.\n",
            "Mini batch: 606/870 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0260 | Train accuracy: 99.22%.\n",
            "Mini batch: 607/870 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0649 | Train accuracy: 98.44%.\n",
            "Mini batch: 608/870 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0043 | Train accuracy: 100.00%.\n",
            "Mini batch: 609/870 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.7520 | Train accuracy: 92.31%.\n",
            "Training loss (epoch level): 0.0338 | Train accuracy: 99.47\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 40.58% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 13 with validation accuracy 48.04% and accuracy 0.0% under attack.\n",
            "Mini batch: 610/870 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0073 | Train accuracy: 100.00%.\n",
            "Mini batch: 611/870 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.1761 | Train accuracy: 95.31%.\n",
            "Mini batch: 612/870 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.5561 | Train accuracy: 95.31%.\n",
            "Mini batch: 613/870 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.1142 | Train accuracy: 96.09%.\n",
            "Mini batch: 614/870 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0112 | Train accuracy: 99.22%.\n",
            "Mini batch: 615/870 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0077 | Train accuracy: 100.00%.\n",
            "Mini batch: 616/870 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0626 | Train accuracy: 98.44%.\n",
            "Mini batch: 617/870 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0915 | Train accuracy: 96.88%.\n",
            "Mini batch: 618/870 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.1516 | Train accuracy: 95.31%.\n",
            "Mini batch: 619/870 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0328 | Train accuracy: 99.22%.\n",
            "Mini batch: 620/870 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0033 | Train accuracy: 100.00%.\n",
            "Mini batch: 621/870 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0325 | Train accuracy: 99.22%.\n",
            "Mini batch: 622/870 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0451 | Train accuracy: 97.66%.\n",
            "Mini batch: 623/870 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0620 | Train accuracy: 99.22%.\n",
            "Mini batch: 624/870 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0685 | Train accuracy: 99.22%.\n",
            "Mini batch: 625/870 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0072 | Train accuracy: 99.22%.\n",
            "Mini batch: 626/870 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0071 | Train accuracy: 99.22%.\n",
            "Mini batch: 627/870 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0366 | Train accuracy: 98.44%.\n",
            "Mini batch: 628/870 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.1276 | Train accuracy: 99.22%.\n",
            "Mini batch: 629/870 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0387 | Train accuracy: 98.44%.\n",
            "Mini batch: 630/870 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0086 | Train accuracy: 100.00%.\n",
            "Mini batch: 631/870 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0105 | Train accuracy: 99.22%.\n",
            "Mini batch: 632/870 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0025 | Train accuracy: 100.00%.\n",
            "Mini batch: 633/870 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0336 | Train accuracy: 99.22%.\n",
            "Mini batch: 634/870 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 635/870 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0272 | Train accuracy: 99.22%.\n",
            "Mini batch: 636/870 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0192 | Train accuracy: 99.22%.\n",
            "Mini batch: 637/870 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0015 | Train accuracy: 100.00%.\n",
            "Mini batch: 638/870 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0601 | Train accuracy: 98.71\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 47.25% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 13 with validation accuracy 48.04% and accuracy 0.0% under attack.\n",
            "Mini batch: 639/870 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0074 | Train accuracy: 100.00%.\n",
            "Mini batch: 640/870 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0039 | Train accuracy: 100.00%.\n",
            "Mini batch: 641/870 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0221 | Train accuracy: 98.44%.\n",
            "Mini batch: 642/870 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0016 | Train accuracy: 100.00%.\n",
            "Mini batch: 643/870 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0015 | Train accuracy: 100.00%.\n",
            "Mini batch: 644/870 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0189 | Train accuracy: 99.22%.\n",
            "Mini batch: 645/870 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0040 | Train accuracy: 100.00%.\n",
            "Mini batch: 646/870 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0204 | Train accuracy: 99.22%.\n",
            "Mini batch: 647/870 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0015 | Train accuracy: 100.00%.\n",
            "Mini batch: 648/870 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0055 | Train accuracy: 100.00%.\n",
            "Mini batch: 649/870 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0255 | Train accuracy: 99.22%.\n",
            "Mini batch: 650/870 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0774 | Train accuracy: 97.66%.\n",
            "Mini batch: 651/870 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 652/870 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0020 | Train accuracy: 100.00%.\n",
            "Mini batch: 653/870 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0032 | Train accuracy: 100.00%.\n",
            "Mini batch: 654/870 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 655/870 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00%.\n",
            "Mini batch: 656/870 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0425 | Train accuracy: 99.22%.\n",
            "Mini batch: 657/870 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.1891 | Train accuracy: 97.66%.\n",
            "Mini batch: 658/870 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.1070 | Train accuracy: 97.66%.\n",
            "Mini batch: 659/870 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00%.\n",
            "Mini batch: 660/870 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0123 | Train accuracy: 99.22%.\n",
            "Mini batch: 661/870 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0112 | Train accuracy: 100.00%.\n",
            "Mini batch: 662/870 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0648 | Train accuracy: 97.66%.\n",
            "Mini batch: 663/870 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0073 | Train accuracy: 99.22%.\n",
            "Mini batch: 664/870 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0021 | Train accuracy: 100.00%.\n",
            "Mini batch: 665/870 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0167 | Train accuracy: 99.22%.\n",
            "Mini batch: 666/870 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0036 | Train accuracy: 100.00%.\n",
            "Mini batch: 667/870 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0225 | Train accuracy: 99.43\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 47.41% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 13 with validation accuracy 48.04% and accuracy 0.0% under attack.\n",
            "Mini batch: 668/870 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0051 | Train accuracy: 100.00%.\n",
            "Mini batch: 669/870 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0024 | Train accuracy: 100.00%.\n",
            "Mini batch: 670/870 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00%.\n",
            "Mini batch: 671/870 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0252 | Train accuracy: 98.44%.\n",
            "Mini batch: 672/870 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0052 | Train accuracy: 100.00%.\n",
            "Mini batch: 673/870 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0175 | Train accuracy: 99.22%.\n",
            "Mini batch: 674/870 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00%.\n",
            "Mini batch: 675/870 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0337 | Train accuracy: 99.22%.\n",
            "Mini batch: 676/870 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00%.\n",
            "Mini batch: 677/870 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0054 | Train accuracy: 100.00%.\n",
            "Mini batch: 678/870 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00%.\n",
            "Mini batch: 679/870 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0026 | Train accuracy: 100.00%.\n",
            "Mini batch: 680/870 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0025 | Train accuracy: 100.00%.\n",
            "Mini batch: 681/870 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0015 | Train accuracy: 100.00%.\n",
            "Mini batch: 682/870 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0212 | Train accuracy: 99.22%.\n",
            "Mini batch: 683/870 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0081 | Train accuracy: 100.00%.\n",
            "Mini batch: 684/870 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0014 | Train accuracy: 100.00%.\n",
            "Mini batch: 685/870 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0155 | Train accuracy: 98.44%.\n",
            "Mini batch: 686/870 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0039 | Train accuracy: 100.00%.\n",
            "Mini batch: 687/870 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0169 | Train accuracy: 99.22%.\n",
            "Mini batch: 688/870 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0015 | Train accuracy: 100.00%.\n",
            "Mini batch: 689/870 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0107 | Train accuracy: 99.22%.\n",
            "Mini batch: 690/870 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00%.\n",
            "Mini batch: 691/870 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0318 | Train accuracy: 99.22%.\n",
            "Mini batch: 692/870 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 693/870 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0057 | Train accuracy: 100.00%.\n",
            "Mini batch: 694/870 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0021 | Train accuracy: 100.00%.\n",
            "Mini batch: 695/870 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0155 | Train accuracy: 99.22%.\n",
            "Mini batch: 696/870 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0083 | Train accuracy: 99.70\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 48.12% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 24 with validation accuracy 48.12% and accuracy 0.0% under attack.\n",
            "Mini batch: 697/870 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0024 | Train accuracy: 100.00%.\n",
            "Mini batch: 698/870 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0304 | Train accuracy: 99.22%.\n",
            "Mini batch: 699/870 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0311 | Train accuracy: 99.22%.\n",
            "Mini batch: 700/870 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0088 | Train accuracy: 99.22%.\n",
            "Mini batch: 701/870 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0054 | Train accuracy: 100.00%.\n",
            "Mini batch: 702/870 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 703/870 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00%.\n",
            "Mini batch: 704/870 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0052 | Train accuracy: 100.00%.\n",
            "Mini batch: 705/870 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0341 | Train accuracy: 98.44%.\n",
            "Mini batch: 706/870 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0015 | Train accuracy: 100.00%.\n",
            "Mini batch: 707/870 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00%.\n",
            "Mini batch: 708/870 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00%.\n",
            "Mini batch: 709/870 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0178 | Train accuracy: 99.22%.\n",
            "Mini batch: 710/870 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "Mini batch: 711/870 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00%.\n",
            "Mini batch: 712/870 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00%.\n",
            "Mini batch: 713/870 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00%.\n",
            "Mini batch: 714/870 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0064 | Train accuracy: 100.00%.\n",
            "Mini batch: 715/870 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0141 | Train accuracy: 99.22%.\n",
            "Mini batch: 716/870 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0493 | Train accuracy: 99.22%.\n",
            "Mini batch: 717/870 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00%.\n",
            "Mini batch: 718/870 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "Mini batch: 719/870 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00%.\n",
            "Mini batch: 720/870 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0186 | Train accuracy: 99.22%.\n",
            "Mini batch: 721/870 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "Mini batch: 722/870 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0015 | Train accuracy: 100.00%.\n",
            "Mini batch: 723/870 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0044 | Train accuracy: 100.00%.\n",
            "Mini batch: 724/870 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00%.\n",
            "Mini batch: 725/870 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0083 | Train accuracy: 99.76\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 47.58% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 24 with validation accuracy 48.12% and accuracy 0.0% under attack.\n",
            "Mini batch: 726/870 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00%.\n",
            "Mini batch: 727/870 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0057 | Train accuracy: 100.00%.\n",
            "Mini batch: 728/870 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00%.\n",
            "Mini batch: 729/870 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0018 | Train accuracy: 100.00%.\n",
            "Mini batch: 730/870 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00%.\n",
            "Mini batch: 731/870 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "Mini batch: 732/870 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "Mini batch: 733/870 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00%.\n",
            "Mini batch: 734/870 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "Mini batch: 735/870 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00%.\n",
            "Mini batch: 736/870 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0021 | Train accuracy: 100.00%.\n",
            "Mini batch: 737/870 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00%.\n",
            "Mini batch: 738/870 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00%.\n",
            "Mini batch: 739/870 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00%.\n",
            "Mini batch: 740/870 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 741/870 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00%.\n",
            "Mini batch: 742/870 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 743/870 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0054 | Train accuracy: 100.00%.\n",
            "Mini batch: 744/870 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00%.\n",
            "Mini batch: 745/870 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 746/870 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 747/870 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0028 | Train accuracy: 100.00%.\n",
            "Mini batch: 748/870 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "Mini batch: 749/870 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0016 | Train accuracy: 100.00%.\n",
            "Mini batch: 750/870 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 751/870 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00%.\n",
            "Mini batch: 752/870 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00%.\n",
            "Mini batch: 753/870 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "Mini batch: 754/870 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0011 | Train accuracy: 100.00\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 47.21% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 24 with validation accuracy 48.12% and accuracy 0.0% under attack.\n",
            "Mini batch: 755/870 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0111 | Train accuracy: 99.22%.\n",
            "Mini batch: 756/870 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00%.\n",
            "Mini batch: 757/870 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0015 | Train accuracy: 100.00%.\n",
            "Mini batch: 758/870 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0121 | Train accuracy: 99.22%.\n",
            "Mini batch: 759/870 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 760/870 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 761/870 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0040 | Train accuracy: 100.00%.\n",
            "Mini batch: 762/870 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 763/870 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "Mini batch: 764/870 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00%.\n",
            "Mini batch: 765/870 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 766/870 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0031 | Train accuracy: 100.00%.\n",
            "Mini batch: 767/870 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "Mini batch: 768/870 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00%.\n",
            "Mini batch: 769/870 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0030 | Train accuracy: 100.00%.\n",
            "Mini batch: 770/870 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 771/870 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 772/870 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 773/870 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0100 | Train accuracy: 99.22%.\n",
            "Mini batch: 774/870 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0043 | Train accuracy: 100.00%.\n",
            "Mini batch: 775/870 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0025 | Train accuracy: 100.00%.\n",
            "Mini batch: 776/870 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "Mini batch: 777/870 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 778/870 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 779/870 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 780/870 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 781/870 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00%.\n",
            "Mini batch: 782/870 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0040 | Train accuracy: 100.00%.\n",
            "Mini batch: 783/870 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0022 | Train accuracy: 99.92\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 48.37% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 27 with validation accuracy 48.37% and accuracy 0.0% under attack.\n",
            "Mini batch: 784/870 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 785/870 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 786/870 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 787/870 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 788/870 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00%.\n",
            "Mini batch: 789/870 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00%.\n",
            "Mini batch: 790/870 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "Mini batch: 791/870 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 792/870 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 793/870 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 794/870 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 795/870 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00%.\n",
            "Mini batch: 796/870 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 797/870 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 798/870 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "Mini batch: 799/870 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00%.\n",
            "Mini batch: 800/870 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 801/870 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00%.\n",
            "Mini batch: 802/870 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "Mini batch: 803/870 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00%.\n",
            "Mini batch: 804/870 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 805/870 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0063 | Train accuracy: 99.22%.\n",
            "Mini batch: 806/870 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 807/870 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 808/870 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 809/870 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 810/870 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 811/870 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 812/870 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0005 | Train accuracy: 99.97\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 48.54% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 28 with validation accuracy 48.54% and accuracy 0.0% under attack.\n",
            "Mini batch: 813/870 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 814/870 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 815/870 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 816/870 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 817/870 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "Mini batch: 818/870 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "Mini batch: 819/870 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0063 | Train accuracy: 99.22%.\n",
            "Mini batch: 820/870 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 821/870 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 822/870 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "Mini batch: 823/870 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00%.\n",
            "Mini batch: 824/870 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 825/870 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 826/870 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 827/870 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 828/870 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 829/870 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 830/870 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 831/870 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0018 | Train accuracy: 100.00%.\n",
            "Mini batch: 832/870 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 833/870 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 834/870 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 835/870 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 836/870 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0016 | Train accuracy: 100.00%.\n",
            "Mini batch: 837/870 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 838/870 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 839/870 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 840/870 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 841/870 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0004 | Train accuracy: 99.97\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 47.5% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 28 with validation accuracy 48.54% and accuracy 0.0% under attack.\n",
            "Mini batch: 842/870 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 843/870 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 844/870 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 845/870 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 846/870 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 847/870 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 848/870 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 849/870 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 850/870 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 851/870 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 852/870 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 853/870 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 854/870 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 855/870 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "Mini batch: 856/870 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 857/870 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 858/870 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 859/870 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 860/870 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 861/870 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 862/870 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 863/870 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "Mini batch: 864/870 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 865/870 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0083 | Train accuracy: 99.22%.\n",
            "Mini batch: 866/870 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Mini batch: 867/870 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0254 | Train accuracy: 99.22%.\n",
            "Mini batch: 868/870 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Mini batch: 869/870 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Mini batch: 870/870 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0013 | Train accuracy: 99.95\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "\tVal accuracy 48.0% with accuracy 0.0% under attack.\n",
            "\tModel select at epoch 28 with validation accuracy 48.54% and accuracy 0.0% under attack.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test: accuracy\n",
        "max_adv_training_model.load()\n",
        "max_adv_training_model.model.predict(test_Loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--3mtpw65v2c",
        "outputId": "35e59611-74f5-479a-b160-2a55bbd6a25a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy on the test dataset is 96.75000%\n",
            "The balanced accuracy on the test dataset is 96.73717%\n",
            "Other evaluation metrics we may need:\n",
            "False Negative Rate (FNR) is 1.98020%, False Positive Rate (FPR) is 4.54545%, F1 score is 96.82152%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_adv_training_model.adv_predict(test_Loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcH9mQEEC1Hb",
        "outputId": "c3f99eb8-2e33-4299-b244-c8123598da9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pgd linf: attack effectiveness 1.980%.\n",
            "\tadversarial accuracy  98.02% under attack.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# norm = ''l2''\n",
        "\n",
        "model = MalwareDetectionDNN(3216,2)\n",
        "model = model.double().to(device)\n",
        "attack = PGD(norm='l2', use_random=False,rounding_threshold=0.5,is_attacker=False,manipulation_x=manipulation_x, omega=omega,api_flag=api_flag,device=device)\n",
        "attack_param = {}\n",
        "max_adv_training_model = PGDAdvTraining(model, attack, attack_param)\n",
        "max_adv_training_model.fit(train_Loader,validation_Loader,adv_epochs=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "928092ed-8138-42ce-c61c-1115959d36ad",
        "id": "GzGJdauV5wD1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pgd l2: attack effectiveness 100.000%.\n",
            "Mini batch: 1/300 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.7264 | Train accuracy: 16.41%.\n",
            "pgd l2: attack effectiveness 54.688%.\n",
            "Mini batch: 2/300 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.6965 | Train accuracy: 53.12%.\n",
            "pgd l2: attack effectiveness 100.000%.\n",
            "Mini batch: 3/300 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.7009 | Train accuracy: 46.09%.\n",
            "pgd l2: attack effectiveness 48.529%.\n",
            "Mini batch: 4/300 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.6928 | Train accuracy: 42.97%.\n",
            "pgd l2: attack effectiveness 66.129%.\n",
            "Mini batch: 5/300 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.7273 | Train accuracy: 48.44%.\n",
            "pgd l2: attack effectiveness 54.545%.\n",
            "Mini batch: 6/300 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.7012 | Train accuracy: 45.31%.\n",
            "pgd l2: attack effectiveness 37.879%.\n",
            "Mini batch: 7/300 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.6211 | Train accuracy: 53.91%.\n",
            "pgd l2: attack effectiveness 29.508%.\n",
            "Mini batch: 8/300 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.6246 | Train accuracy: 58.59%.\n",
            "pgd l2: attack effectiveness 55.882%.\n",
            "Mini batch: 9/300 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.6330 | Train accuracy: 57.81%.\n",
            "pgd l2: attack effectiveness 47.619%.\n",
            "Mini batch: 10/300 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.5940 | Train accuracy: 61.70%.\n",
            "Training loss (epoch level): 0.6718 | Train accuracy: 48.44\n",
            "pgd l2: attack effectiveness 54.726%.\n",
            "\tVal accuracy 59.39% with accuracy 45.27% under attack.\n",
            "\tModel select at epoch 1 with validation accuracy 59.39% and accuracy 45.27% under attack.\n",
            "pgd l2: attack effectiveness 53.846%.\n",
            "Mini batch: 11/300 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.5543 | Train accuracy: 68.75%.\n",
            "pgd l2: attack effectiveness 54.688%.\n",
            "Mini batch: 12/300 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.5568 | Train accuracy: 71.88%.\n",
            "pgd l2: attack effectiveness 52.239%.\n",
            "Mini batch: 13/300 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.5868 | Train accuracy: 69.53%.\n",
            "pgd l2: attack effectiveness 50.000%.\n",
            "Mini batch: 14/300 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.5939 | Train accuracy: 70.31%.\n",
            "pgd l2: attack effectiveness 51.613%.\n",
            "Mini batch: 15/300 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.5979 | Train accuracy: 67.97%.\n",
            "pgd l2: attack effectiveness 41.818%.\n",
            "Mini batch: 16/300 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.6200 | Train accuracy: 68.75%.\n",
            "pgd l2: attack effectiveness 42.424%.\n",
            "Mini batch: 17/300 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.5213 | Train accuracy: 75.00%.\n",
            "pgd l2: attack effectiveness 36.066%.\n",
            "Mini batch: 18/300 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.4997 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 45.588%.\n",
            "Mini batch: 19/300 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.5404 | Train accuracy: 71.09%.\n",
            "pgd l2: attack effectiveness 42.857%.\n",
            "Mini batch: 20/300 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.5242 | Train accuracy: 74.47%.\n",
            "Training loss (epoch level): 0.5595 | Train accuracy: 71.59\n",
            "pgd l2: attack effectiveness 46.766%.\n",
            "\tVal accuracy 70.99% with accuracy 53.23% under attack.\n",
            "\tModel select at epoch 2 with validation accuracy 70.99% and accuracy 53.23% under attack.\n",
            "pgd l2: attack effectiveness 41.538%.\n",
            "Mini batch: 21/300 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.5235 | Train accuracy: 77.34%.\n",
            "pgd l2: attack effectiveness 39.062%.\n",
            "Mini batch: 22/300 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.4829 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 43.284%.\n",
            "Mini batch: 23/300 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.5073 | Train accuracy: 74.22%.\n",
            "pgd l2: attack effectiveness 44.118%.\n",
            "Mini batch: 24/300 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.4861 | Train accuracy: 75.78%.\n",
            "pgd l2: attack effectiveness 53.226%.\n",
            "Mini batch: 25/300 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.4654 | Train accuracy: 78.91%.\n",
            "pgd l2: attack effectiveness 41.818%.\n",
            "Mini batch: 26/300 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.5446 | Train accuracy: 75.00%.\n",
            "pgd l2: attack effectiveness 42.424%.\n",
            "Mini batch: 27/300 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.4740 | Train accuracy: 76.56%.\n",
            "pgd l2: attack effectiveness 36.066%.\n",
            "Mini batch: 28/300 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.4014 | Train accuracy: 83.59%.\n",
            "pgd l2: attack effectiveness 41.176%.\n",
            "Mini batch: 29/300 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.4975 | Train accuracy: 75.00%.\n",
            "pgd l2: attack effectiveness 38.095%.\n",
            "Mini batch: 30/300 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.4289 | Train accuracy: 80.85%.\n",
            "Training loss (epoch level): 0.4812 | Train accuracy: 77.54\n",
            "pgd l2: attack effectiveness 43.781%.\n",
            "\tVal accuracy 73.23% with accuracy 56.22% under attack.\n",
            "\tModel select at epoch 3 with validation accuracy 73.23% and accuracy 56.22% under attack.\n",
            "pgd l2: attack effectiveness 38.462%.\n",
            "Mini batch: 31/300 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.4769 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 34.375%.\n",
            "Mini batch: 32/300 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.3993 | Train accuracy: 80.47%.\n",
            "pgd l2: attack effectiveness 38.806%.\n",
            "Mini batch: 33/300 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.4636 | Train accuracy: 78.91%.\n",
            "pgd l2: attack effectiveness 41.176%.\n",
            "Mini batch: 34/300 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.4370 | Train accuracy: 76.56%.\n",
            "pgd l2: attack effectiveness 50.000%.\n",
            "Mini batch: 35/300 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.4920 | Train accuracy: 74.22%.\n",
            "pgd l2: attack effectiveness 41.818%.\n",
            "Mini batch: 36/300 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.5056 | Train accuracy: 78.91%.\n",
            "pgd l2: attack effectiveness 40.909%.\n",
            "Mini batch: 37/300 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.4666 | Train accuracy: 77.34%.\n",
            "pgd l2: attack effectiveness 40.984%.\n",
            "Mini batch: 38/300 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.4486 | Train accuracy: 80.47%.\n",
            "pgd l2: attack effectiveness 42.647%.\n",
            "Mini batch: 39/300 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.4940 | Train accuracy: 76.56%.\n",
            "pgd l2: attack effectiveness 47.619%.\n",
            "Mini batch: 40/300 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.4494 | Train accuracy: 78.72%.\n",
            "Training loss (epoch level): 0.4633 | Train accuracy: 78.03\n",
            "pgd l2: attack effectiveness 46.269%.\n",
            "\tVal accuracy 72.12% with accuracy 53.73% under attack.\n",
            "\tModel select at epoch 3 with validation accuracy 73.23% and accuracy 56.22% under attack.\n",
            "pgd l2: attack effectiveness 36.923%.\n",
            "Mini batch: 41/300 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.4273 | Train accuracy: 79.69%.\n",
            "pgd l2: attack effectiveness 35.938%.\n",
            "Mini batch: 42/300 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.4073 | Train accuracy: 81.25%.\n",
            "pgd l2: attack effectiveness 40.299%.\n",
            "Mini batch: 43/300 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.4583 | Train accuracy: 76.56%.\n",
            "pgd l2: attack effectiveness 42.647%.\n",
            "Mini batch: 44/300 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.4650 | Train accuracy: 75.00%.\n",
            "pgd l2: attack effectiveness 50.000%.\n",
            "Mini batch: 45/300 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.4545 | Train accuracy: 75.00%.\n",
            "pgd l2: attack effectiveness 40.000%.\n",
            "Mini batch: 46/300 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.5065 | Train accuracy: 79.69%.\n",
            "pgd l2: attack effectiveness 40.909%.\n",
            "Mini batch: 47/300 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.4840 | Train accuracy: 75.78%.\n",
            "pgd l2: attack effectiveness 39.344%.\n",
            "Mini batch: 48/300 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.4279 | Train accuracy: 81.25%.\n",
            "pgd l2: attack effectiveness 44.118%.\n",
            "Mini batch: 49/300 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.5123 | Train accuracy: 76.56%.\n",
            "pgd l2: attack effectiveness 47.619%.\n",
            "Mini batch: 50/300 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.4327 | Train accuracy: 80.85%.\n",
            "Training loss (epoch level): 0.4576 | Train accuracy: 78.16\n",
            "pgd l2: attack effectiveness 45.274%.\n",
            "\tVal accuracy 72.74% with accuracy 54.73% under attack.\n",
            "\tModel select at epoch 3 with validation accuracy 73.23% and accuracy 56.22% under attack.\n",
            "pgd l2: attack effectiveness 38.462%.\n",
            "Mini batch: 51/300 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.4109 | Train accuracy: 78.91%.\n",
            "pgd l2: attack effectiveness 35.938%.\n",
            "Mini batch: 52/300 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.4209 | Train accuracy: 81.25%.\n",
            "pgd l2: attack effectiveness 38.806%.\n",
            "Mini batch: 53/300 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.4204 | Train accuracy: 77.34%.\n",
            "pgd l2: attack effectiveness 42.647%.\n",
            "Mini batch: 54/300 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.4298 | Train accuracy: 75.78%.\n",
            "pgd l2: attack effectiveness 54.839%.\n",
            "Mini batch: 55/300 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.4426 | Train accuracy: 73.44%.\n",
            "pgd l2: attack effectiveness 47.273%.\n",
            "Mini batch: 56/300 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.4651 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 43.939%.\n",
            "Mini batch: 57/300 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.5158 | Train accuracy: 75.00%.\n",
            "pgd l2: attack effectiveness 37.705%.\n",
            "Mini batch: 58/300 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.4074 | Train accuracy: 81.25%.\n",
            "pgd l2: attack effectiveness 42.647%.\n",
            "Mini batch: 59/300 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.4542 | Train accuracy: 74.22%.\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "Mini batch: 60/300 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.3355 | Train accuracy: 89.36%.\n",
            "Training loss (epoch level): 0.4303 | Train accuracy: 78.47\n",
            "pgd l2: attack effectiveness 18.408%.\n",
            "\tVal accuracy 86.05% with accuracy 81.59% under attack.\n",
            "\tModel select at epoch 6 with validation accuracy 86.05% and accuracy 81.59% under attack.\n",
            "pgd l2: attack effectiveness 9.231%.\n",
            "Mini batch: 61/300 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.3578 | Train accuracy: 89.84%.\n",
            "pgd l2: attack effectiveness 12.500%.\n",
            "Mini batch: 62/300 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.3516 | Train accuracy: 87.50%.\n",
            "pgd l2: attack effectiveness 7.463%.\n",
            "Mini batch: 63/300 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.2988 | Train accuracy: 88.28%.\n",
            "pgd l2: attack effectiveness 36.765%.\n",
            "Mini batch: 64/300 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.4578 | Train accuracy: 76.56%.\n",
            "pgd l2: attack effectiveness 35.484%.\n",
            "Mini batch: 65/300 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.4317 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 41.818%.\n",
            "Mini batch: 66/300 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.5679 | Train accuracy: 73.44%.\n",
            "pgd l2: attack effectiveness 37.879%.\n",
            "Mini batch: 67/300 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.4224 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 36.066%.\n",
            "Mini batch: 68/300 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.4245 | Train accuracy: 80.47%.\n",
            "pgd l2: attack effectiveness 42.647%.\n",
            "Mini batch: 69/300 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.4736 | Train accuracy: 75.78%.\n",
            "pgd l2: attack effectiveness 38.095%.\n",
            "Mini batch: 70/300 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.3519 | Train accuracy: 80.85%.\n",
            "Training loss (epoch level): 0.4138 | Train accuracy: 80.90\n",
            "pgd l2: attack effectiveness 44.776%.\n",
            "\tVal accuracy 74.11% with accuracy 55.22% under attack.\n",
            "\tModel select at epoch 6 with validation accuracy 86.05% and accuracy 81.59% under attack.\n",
            "pgd l2: attack effectiveness 38.462%.\n",
            "Mini batch: 71/300 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.3806 | Train accuracy: 77.34%.\n",
            "pgd l2: attack effectiveness 32.812%.\n",
            "Mini batch: 72/300 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.3759 | Train accuracy: 83.59%.\n",
            "pgd l2: attack effectiveness 38.806%.\n",
            "Mini batch: 73/300 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.3845 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 39.706%.\n",
            "Mini batch: 74/300 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.3691 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 46.774%.\n",
            "Mini batch: 75/300 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.4030 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 38.182%.\n",
            "Mini batch: 76/300 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.4611 | Train accuracy: 80.47%.\n",
            "pgd l2: attack effectiveness 36.364%.\n",
            "Mini batch: 77/300 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.3839 | Train accuracy: 79.69%.\n",
            "pgd l2: attack effectiveness 34.426%.\n",
            "Mini batch: 78/300 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.3968 | Train accuracy: 82.03%.\n",
            "pgd l2: attack effectiveness 41.176%.\n",
            "Mini batch: 79/300 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.5220 | Train accuracy: 76.56%.\n",
            "pgd l2: attack effectiveness 42.857%.\n",
            "Mini batch: 80/300 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.3386 | Train accuracy: 80.85%.\n",
            "Training loss (epoch level): 0.4015 | Train accuracy: 79.49\n",
            "pgd l2: attack effectiveness 45.771%.\n",
            "\tVal accuracy 73.49% with accuracy 54.23% under attack.\n",
            "\tModel select at epoch 6 with validation accuracy 86.05% and accuracy 81.59% under attack.\n",
            "pgd l2: attack effectiveness 38.462%.\n",
            "Mini batch: 81/300 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.3552 | Train accuracy: 76.56%.\n",
            "pgd l2: attack effectiveness 32.812%.\n",
            "Mini batch: 82/300 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.3490 | Train accuracy: 83.59%.\n",
            "pgd l2: attack effectiveness 7.463%.\n",
            "Mini batch: 83/300 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.3588 | Train accuracy: 82.81%.\n",
            "pgd l2: attack effectiveness 10.294%.\n",
            "Mini batch: 84/300 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.3530 | Train accuracy: 89.06%.\n",
            "pgd l2: attack effectiveness 16.129%.\n",
            "Mini batch: 85/300 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.3924 | Train accuracy: 86.72%.\n",
            "pgd l2: attack effectiveness 18.182%.\n",
            "Mini batch: 86/300 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.4169 | Train accuracy: 81.25%.\n",
            "pgd l2: attack effectiveness 31.818%.\n",
            "Mini batch: 87/300 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.4469 | Train accuracy: 78.91%.\n",
            "pgd l2: attack effectiveness 37.705%.\n",
            "Mini batch: 88/300 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.4026 | Train accuracy: 76.56%.\n",
            "pgd l2: attack effectiveness 42.647%.\n",
            "Mini batch: 89/300 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.4723 | Train accuracy: 75.00%.\n",
            "pgd l2: attack effectiveness 38.095%.\n",
            "Mini batch: 90/300 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.3465 | Train accuracy: 85.11%.\n",
            "Training loss (epoch level): 0.3894 | Train accuracy: 81.56\n",
            "pgd l2: attack effectiveness 41.294%.\n",
            "\tVal accuracy 73.48% with accuracy 58.71% under attack.\n",
            "\tModel select at epoch 6 with validation accuracy 86.05% and accuracy 81.59% under attack.\n",
            "pgd l2: attack effectiveness 32.308%.\n",
            "Mini batch: 91/300 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.3750 | Train accuracy: 74.22%.\n",
            "pgd l2: attack effectiveness 29.688%.\n",
            "Mini batch: 92/300 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.3542 | Train accuracy: 80.47%.\n",
            "pgd l2: attack effectiveness 23.881%.\n",
            "Mini batch: 93/300 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.3532 | Train accuracy: 79.69%.\n",
            "pgd l2: attack effectiveness 10.294%.\n",
            "Mini batch: 94/300 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.3067 | Train accuracy: 89.06%.\n",
            "pgd l2: attack effectiveness 14.516%.\n",
            "Mini batch: 95/300 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.3137 | Train accuracy: 86.72%.\n",
            "pgd l2: attack effectiveness 16.364%.\n",
            "Mini batch: 96/300 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.3861 | Train accuracy: 82.81%.\n",
            "pgd l2: attack effectiveness 30.303%.\n",
            "Mini batch: 97/300 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.3849 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 34.426%.\n",
            "Mini batch: 98/300 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.3800 | Train accuracy: 81.25%.\n",
            "pgd l2: attack effectiveness 42.647%.\n",
            "Mini batch: 99/300 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.4648 | Train accuracy: 76.56%.\n",
            "pgd l2: attack effectiveness 42.857%.\n",
            "Mini batch: 100/300 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.3165 | Train accuracy: 80.85%.\n",
            "Training loss (epoch level): 0.3635 | Train accuracy: 80.98\n",
            "pgd l2: attack effectiveness 46.766%.\n",
            "\tVal accuracy 72.74% with accuracy 53.23% under attack.\n",
            "\tModel select at epoch 6 with validation accuracy 86.05% and accuracy 81.59% under attack.\n",
            "pgd l2: attack effectiveness 38.462%.\n",
            "Mini batch: 101/300 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.3388 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 23.438%.\n",
            "Mini batch: 102/300 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.2923 | Train accuracy: 89.84%.\n",
            "pgd l2: attack effectiveness 5.970%.\n",
            "Mini batch: 103/300 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.2612 | Train accuracy: 92.97%.\n",
            "pgd l2: attack effectiveness 5.882%.\n",
            "Mini batch: 104/300 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.2860 | Train accuracy: 93.75%.\n",
            "pgd l2: attack effectiveness 14.516%.\n",
            "Mini batch: 105/300 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.2830 | Train accuracy: 89.06%.\n",
            "pgd l2: attack effectiveness 10.909%.\n",
            "Mini batch: 106/300 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.3995 | Train accuracy: 80.47%.\n",
            "pgd l2: attack effectiveness 12.121%.\n",
            "Mini batch: 107/300 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.2823 | Train accuracy: 87.50%.\n",
            "pgd l2: attack effectiveness 29.508%.\n",
            "Mini batch: 108/300 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.3693 | Train accuracy: 81.25%.\n",
            "pgd l2: attack effectiveness 41.176%.\n",
            "Mini batch: 109/300 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.5746 | Train accuracy: 75.78%.\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "Mini batch: 110/300 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.3203 | Train accuracy: 85.11%.\n",
            "Training loss (epoch level): 0.3407 | Train accuracy: 85.39\n",
            "pgd l2: attack effectiveness 38.308%.\n",
            "\tVal accuracy 77.1% with accuracy 61.69% under attack.\n",
            "\tModel select at epoch 6 with validation accuracy 86.05% and accuracy 81.59% under attack.\n",
            "pgd l2: attack effectiveness 29.231%.\n",
            "Mini batch: 111/300 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.3208 | Train accuracy: 81.25%.\n",
            "pgd l2: attack effectiveness 32.812%.\n",
            "Mini batch: 112/300 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.3097 | Train accuracy: 82.03%.\n",
            "pgd l2: attack effectiveness 29.851%.\n",
            "Mini batch: 113/300 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.3422 | Train accuracy: 79.69%.\n",
            "pgd l2: attack effectiveness 27.941%.\n",
            "Mini batch: 114/300 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.3033 | Train accuracy: 86.72%.\n",
            "pgd l2: attack effectiveness 29.032%.\n",
            "Mini batch: 115/300 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.3208 | Train accuracy: 81.25%.\n",
            "pgd l2: attack effectiveness 10.909%.\n",
            "Mini batch: 116/300 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.3845 | Train accuracy: 79.69%.\n",
            "pgd l2: attack effectiveness 30.303%.\n",
            "Mini batch: 117/300 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.3710 | Train accuracy: 79.69%.\n",
            "pgd l2: attack effectiveness 26.230%.\n",
            "Mini batch: 118/300 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.3043 | Train accuracy: 82.81%.\n",
            "pgd l2: attack effectiveness 39.706%.\n",
            "Mini batch: 119/300 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.4709 | Train accuracy: 75.78%.\n",
            "pgd l2: attack effectiveness 38.095%.\n",
            "Mini batch: 120/300 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.3205 | Train accuracy: 80.85%.\n",
            "Training loss (epoch level): 0.3448 | Train accuracy: 80.98\n",
            "pgd l2: attack effectiveness 42.289%.\n",
            "\tVal accuracy 75.11% with accuracy 57.71% under attack.\n",
            "\tModel select at epoch 6 with validation accuracy 86.05% and accuracy 81.59% under attack.\n",
            "pgd l2: attack effectiveness 30.769%.\n",
            "Mini batch: 121/300 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.3099 | Train accuracy: 80.47%.\n",
            "pgd l2: attack effectiveness 23.438%.\n",
            "Mini batch: 122/300 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.3309 | Train accuracy: 86.72%.\n",
            "pgd l2: attack effectiveness 29.851%.\n",
            "Mini batch: 123/300 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.3280 | Train accuracy: 80.47%.\n",
            "pgd l2: attack effectiveness 26.471%.\n",
            "Mini batch: 124/300 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.2932 | Train accuracy: 82.81%.\n",
            "pgd l2: attack effectiveness 12.903%.\n",
            "Mini batch: 125/300 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.3362 | Train accuracy: 83.59%.\n",
            "pgd l2: attack effectiveness 7.273%.\n",
            "Mini batch: 126/300 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.3405 | Train accuracy: 82.81%.\n",
            "pgd l2: attack effectiveness 13.636%.\n",
            "Mini batch: 127/300 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.2706 | Train accuracy: 90.62%.\n",
            "pgd l2: attack effectiveness 21.311%.\n",
            "Mini batch: 128/300 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.2617 | Train accuracy: 85.16%.\n",
            "pgd l2: attack effectiveness 32.353%.\n",
            "Mini batch: 129/300 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.4720 | Train accuracy: 78.91%.\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "Mini batch: 130/300 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.2723 | Train accuracy: 82.98%.\n",
            "Training loss (epoch level): 0.3215 | Train accuracy: 83.45\n",
            "pgd l2: attack effectiveness 35.323%.\n",
            "\tVal accuracy 76.96% with accuracy 64.68% under attack.\n",
            "\tModel select at epoch 6 with validation accuracy 86.05% and accuracy 81.59% under attack.\n",
            "pgd l2: attack effectiveness 23.077%.\n",
            "Mini batch: 131/300 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.2844 | Train accuracy: 84.38%.\n",
            "pgd l2: attack effectiveness 18.750%.\n",
            "Mini batch: 132/300 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.3706 | Train accuracy: 82.81%.\n",
            "pgd l2: attack effectiveness 25.373%.\n",
            "Mini batch: 133/300 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.3793 | Train accuracy: 82.03%.\n",
            "pgd l2: attack effectiveness 33.824%.\n",
            "Mini batch: 134/300 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.3283 | Train accuracy: 83.59%.\n",
            "pgd l2: attack effectiveness 19.355%.\n",
            "Mini batch: 135/300 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.3842 | Train accuracy: 90.62%.\n",
            "pgd l2: attack effectiveness 18.182%.\n",
            "Mini batch: 136/300 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.3888 | Train accuracy: 86.72%.\n",
            "pgd l2: attack effectiveness 25.758%.\n",
            "Mini batch: 137/300 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.3647 | Train accuracy: 83.59%.\n",
            "pgd l2: attack effectiveness 26.230%.\n",
            "Mini batch: 138/300 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.2996 | Train accuracy: 88.28%.\n",
            "pgd l2: attack effectiveness 38.235%.\n",
            "Mini batch: 139/300 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.3851 | Train accuracy: 76.56%.\n",
            "pgd l2: attack effectiveness 38.095%.\n",
            "Mini batch: 140/300 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.3250 | Train accuracy: 82.98%.\n",
            "Training loss (epoch level): 0.3510 | Train accuracy: 84.16\n",
            "pgd l2: attack effectiveness 43.284%.\n",
            "\tVal accuracy 73.23% with accuracy 56.72% under attack.\n",
            "\tModel select at epoch 6 with validation accuracy 86.05% and accuracy 81.59% under attack.\n",
            "pgd l2: attack effectiveness 33.846%.\n",
            "Mini batch: 141/300 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.3293 | Train accuracy: 78.91%.\n",
            "pgd l2: attack effectiveness 35.938%.\n",
            "Mini batch: 142/300 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.4037 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 38.806%.\n",
            "Mini batch: 143/300 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.4292 | Train accuracy: 75.78%.\n",
            "pgd l2: attack effectiveness 42.647%.\n",
            "Mini batch: 144/300 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.4475 | Train accuracy: 73.44%.\n",
            "pgd l2: attack effectiveness 46.774%.\n",
            "Mini batch: 145/300 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.4066 | Train accuracy: 80.47%.\n",
            "pgd l2: attack effectiveness 14.545%.\n",
            "Mini batch: 146/300 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.4538 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 13.636%.\n",
            "Mini batch: 147/300 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.3593 | Train accuracy: 84.38%.\n",
            "pgd l2: attack effectiveness 22.951%.\n",
            "Mini batch: 148/300 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.2909 | Train accuracy: 82.81%.\n",
            "pgd l2: attack effectiveness 32.353%.\n",
            "Mini batch: 149/300 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.3623 | Train accuracy: 77.34%.\n",
            "pgd l2: attack effectiveness 38.095%.\n",
            "Mini batch: 150/300 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.3275 | Train accuracy: 78.72%.\n",
            "Training loss (epoch level): 0.3810 | Train accuracy: 78.81\n",
            "pgd l2: attack effectiveness 44.279%.\n",
            "\tVal accuracy 74.61% with accuracy 55.72% under attack.\n",
            "\tModel select at epoch 6 with validation accuracy 86.05% and accuracy 81.59% under attack.\n",
            "pgd l2: attack effectiveness 36.923%.\n",
            "Mini batch: 151/300 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.3530 | Train accuracy: 78.91%.\n",
            "pgd l2: attack effectiveness 34.375%.\n",
            "Mini batch: 152/300 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.3279 | Train accuracy: 82.81%.\n",
            "pgd l2: attack effectiveness 40.299%.\n",
            "Mini batch: 153/300 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.3449 | Train accuracy: 75.00%.\n",
            "pgd l2: attack effectiveness 36.765%.\n",
            "Mini batch: 154/300 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.3240 | Train accuracy: 78.91%.\n",
            "pgd l2: attack effectiveness 43.548%.\n",
            "Mini batch: 155/300 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.3787 | Train accuracy: 79.69%.\n",
            "pgd l2: attack effectiveness 34.545%.\n",
            "Mini batch: 156/300 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.3766 | Train accuracy: 79.69%.\n",
            "pgd l2: attack effectiveness 12.121%.\n",
            "Mini batch: 157/300 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.3153 | Train accuracy: 85.94%.\n",
            "pgd l2: attack effectiveness 19.672%.\n",
            "Mini batch: 158/300 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.2395 | Train accuracy: 88.28%.\n",
            "pgd l2: attack effectiveness 25.000%.\n",
            "Mini batch: 159/300 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.3577 | Train accuracy: 82.81%.\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "Mini batch: 160/300 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.2496 | Train accuracy: 85.11%.\n",
            "Training loss (epoch level): 0.3267 | Train accuracy: 81.71\n",
            "pgd l2: attack effectiveness 12.935%.\n",
            "\tVal accuracy 87.66% with accuracy 87.06% under attack.\n",
            "\tModel select at epoch 16 with validation accuracy 87.66% and accuracy 87.06% under attack.\n",
            "pgd l2: attack effectiveness 6.154%.\n",
            "Mini batch: 161/300 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.2582 | Train accuracy: 89.06%.\n",
            "pgd l2: attack effectiveness 18.750%.\n",
            "Mini batch: 162/300 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.3168 | Train accuracy: 85.16%.\n",
            "pgd l2: attack effectiveness 25.373%.\n",
            "Mini batch: 163/300 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.3749 | Train accuracy: 81.25%.\n",
            "pgd l2: attack effectiveness 29.412%.\n",
            "Mini batch: 164/300 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.3344 | Train accuracy: 84.38%.\n",
            "pgd l2: attack effectiveness 32.258%.\n",
            "Mini batch: 165/300 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.3040 | Train accuracy: 84.38%.\n",
            "pgd l2: attack effectiveness 30.909%.\n",
            "Mini batch: 166/300 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.4173 | Train accuracy: 79.69%.\n",
            "pgd l2: attack effectiveness 10.606%.\n",
            "Mini batch: 167/300 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.2267 | Train accuracy: 92.19%.\n",
            "pgd l2: attack effectiveness 18.033%.\n",
            "Mini batch: 168/300 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.2268 | Train accuracy: 85.94%.\n",
            "pgd l2: attack effectiveness 29.412%.\n",
            "Mini batch: 169/300 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.3431 | Train accuracy: 79.69%.\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "Mini batch: 170/300 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.2919 | Train accuracy: 87.23%.\n",
            "Training loss (epoch level): 0.3094 | Train accuracy: 84.90\n",
            "pgd l2: attack effectiveness 34.328%.\n",
            "\tVal accuracy 77.71% with accuracy 65.67% under attack.\n",
            "\tModel select at epoch 16 with validation accuracy 87.66% and accuracy 87.06% under attack.\n",
            "pgd l2: attack effectiveness 21.538%.\n",
            "Mini batch: 171/300 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.2836 | Train accuracy: 88.28%.\n",
            "pgd l2: attack effectiveness 23.438%.\n",
            "Mini batch: 172/300 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.3307 | Train accuracy: 86.72%.\n",
            "pgd l2: attack effectiveness 23.881%.\n",
            "Mini batch: 173/300 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.3441 | Train accuracy: 81.25%.\n",
            "pgd l2: attack effectiveness 33.824%.\n",
            "Mini batch: 174/300 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.3279 | Train accuracy: 79.69%.\n",
            "pgd l2: attack effectiveness 17.742%.\n",
            "Mini batch: 175/300 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.3362 | Train accuracy: 89.84%.\n",
            "pgd l2: attack effectiveness 16.364%.\n",
            "Mini batch: 176/300 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.3236 | Train accuracy: 85.16%.\n",
            "pgd l2: attack effectiveness 12.121%.\n",
            "Mini batch: 177/300 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.3058 | Train accuracy: 89.84%.\n",
            "pgd l2: attack effectiveness 19.672%.\n",
            "Mini batch: 178/300 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.2326 | Train accuracy: 87.50%.\n",
            "pgd l2: attack effectiveness 17.647%.\n",
            "Mini batch: 179/300 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.3233 | Train accuracy: 88.28%.\n",
            "pgd l2: attack effectiveness 14.286%.\n",
            "Mini batch: 180/300 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.1931 | Train accuracy: 91.49%.\n",
            "Training loss (epoch level): 0.3001 | Train accuracy: 86.81\n",
            "pgd l2: attack effectiveness 17.910%.\n",
            "\tVal accuracy 86.67% with accuracy 82.09% under attack.\n",
            "\tModel select at epoch 16 with validation accuracy 87.66% and accuracy 87.06% under attack.\n",
            "pgd l2: attack effectiveness 7.692%.\n",
            "Mini batch: 181/300 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.1889 | Train accuracy: 93.75%.\n",
            "pgd l2: attack effectiveness 12.500%.\n",
            "Mini batch: 182/300 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.2179 | Train accuracy: 91.41%.\n",
            "pgd l2: attack effectiveness 5.970%.\n",
            "Mini batch: 183/300 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.1665 | Train accuracy: 94.53%.\n",
            "pgd l2: attack effectiveness 7.353%.\n",
            "Mini batch: 184/300 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.2478 | Train accuracy: 88.28%.\n",
            "pgd l2: attack effectiveness 30.645%.\n",
            "Mini batch: 185/300 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.3182 | Train accuracy: 86.72%.\n",
            "pgd l2: attack effectiveness 10.909%.\n",
            "Mini batch: 186/300 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.3516 | Train accuracy: 85.16%.\n",
            "pgd l2: attack effectiveness 24.242%.\n",
            "Mini batch: 187/300 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.3488 | Train accuracy: 82.03%.\n",
            "pgd l2: attack effectiveness 9.836%.\n",
            "Mini batch: 188/300 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.2216 | Train accuracy: 89.84%.\n",
            "pgd l2: attack effectiveness 33.824%.\n",
            "Mini batch: 189/300 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.4592 | Train accuracy: 79.69%.\n",
            "pgd l2: attack effectiveness 28.571%.\n",
            "Mini batch: 190/300 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.2544 | Train accuracy: 85.11%.\n",
            "Training loss (epoch level): 0.2775 | Train accuracy: 87.65\n",
            "pgd l2: attack effectiveness 15.423%.\n",
            "\tVal accuracy 87.79% with accuracy 84.58% under attack.\n",
            "\tModel select at epoch 19 with validation accuracy 87.79% and accuracy 84.58% under attack.\n",
            "pgd l2: attack effectiveness 7.692%.\n",
            "Mini batch: 191/300 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.1959 | Train accuracy: 95.31%.\n",
            "pgd l2: attack effectiveness 9.375%.\n",
            "Mini batch: 192/300 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.2195 | Train accuracy: 94.53%.\n",
            "pgd l2: attack effectiveness 22.388%.\n",
            "Mini batch: 193/300 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.2812 | Train accuracy: 86.72%.\n",
            "pgd l2: attack effectiveness 5.882%.\n",
            "Mini batch: 194/300 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.2240 | Train accuracy: 94.53%.\n",
            "pgd l2: attack effectiveness 11.290%.\n",
            "Mini batch: 195/300 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.2304 | Train accuracy: 92.97%.\n",
            "pgd l2: attack effectiveness 16.364%.\n",
            "Mini batch: 196/300 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.3911 | Train accuracy: 81.25%.\n",
            "pgd l2: attack effectiveness 10.606%.\n",
            "Mini batch: 197/300 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.2575 | Train accuracy: 89.84%.\n",
            "pgd l2: attack effectiveness 19.672%.\n",
            "Mini batch: 198/300 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.3270 | Train accuracy: 84.38%.\n",
            "pgd l2: attack effectiveness 32.353%.\n",
            "Mini batch: 199/300 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.4016 | Train accuracy: 80.47%.\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "Mini batch: 200/300 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.2795 | Train accuracy: 87.23%.\n",
            "Training loss (epoch level): 0.2808 | Train accuracy: 88.72\n",
            "pgd l2: attack effectiveness 34.826%.\n",
            "\tVal accuracy 78.34% with accuracy 65.17% under attack.\n",
            "\tModel select at epoch 19 with validation accuracy 87.79% and accuracy 84.58% under attack.\n",
            "pgd l2: attack effectiveness 23.077%.\n",
            "Mini batch: 201/300 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.2410 | Train accuracy: 85.16%.\n",
            "pgd l2: attack effectiveness 32.812%.\n",
            "Mini batch: 202/300 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.3002 | Train accuracy: 81.25%.\n",
            "pgd l2: attack effectiveness 38.806%.\n",
            "Mini batch: 203/300 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.3258 | Train accuracy: 79.69%.\n",
            "pgd l2: attack effectiveness 33.824%.\n",
            "Mini batch: 204/300 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.3342 | Train accuracy: 82.03%.\n",
            "pgd l2: attack effectiveness 41.935%.\n",
            "Mini batch: 205/300 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.3388 | Train accuracy: 79.69%.\n",
            "pgd l2: attack effectiveness 30.909%.\n",
            "Mini batch: 206/300 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.3141 | Train accuracy: 85.94%.\n",
            "pgd l2: attack effectiveness 9.091%.\n",
            "Mini batch: 207/300 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.3019 | Train accuracy: 89.84%.\n",
            "pgd l2: attack effectiveness 18.033%.\n",
            "Mini batch: 208/300 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.2395 | Train accuracy: 91.41%.\n",
            "pgd l2: attack effectiveness 22.059%.\n",
            "Mini batch: 209/300 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.3420 | Train accuracy: 84.38%.\n",
            "pgd l2: attack effectiveness 38.095%.\n",
            "Mini batch: 210/300 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.2686 | Train accuracy: 82.98%.\n",
            "Training loss (epoch level): 0.3006 | Train accuracy: 84.24\n",
            "pgd l2: attack effectiveness 13.930%.\n",
            "\tVal accuracy 87.41% with accuracy 86.07% under attack.\n",
            "\tModel select at epoch 19 with validation accuracy 87.79% and accuracy 84.58% under attack.\n",
            "pgd l2: attack effectiveness 6.154%.\n",
            "Mini batch: 211/300 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.1973 | Train accuracy: 94.53%.\n",
            "pgd l2: attack effectiveness 20.312%.\n",
            "Mini batch: 212/300 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.3058 | Train accuracy: 87.50%.\n",
            "pgd l2: attack effectiveness 22.388%.\n",
            "Mini batch: 213/300 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.2792 | Train accuracy: 85.94%.\n",
            "pgd l2: attack effectiveness 27.941%.\n",
            "Mini batch: 214/300 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.3165 | Train accuracy: 83.59%.\n",
            "pgd l2: attack effectiveness 32.258%.\n",
            "Mini batch: 215/300 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.3761 | Train accuracy: 83.59%.\n",
            "pgd l2: attack effectiveness 32.727%.\n",
            "Mini batch: 216/300 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.3533 | Train accuracy: 83.59%.\n",
            "pgd l2: attack effectiveness 21.212%.\n",
            "Mini batch: 217/300 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.2993 | Train accuracy: 89.06%.\n",
            "pgd l2: attack effectiveness 19.672%.\n",
            "Mini batch: 218/300 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.2297 | Train accuracy: 89.06%.\n",
            "pgd l2: attack effectiveness 26.471%.\n",
            "Mini batch: 219/300 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.3005 | Train accuracy: 88.28%.\n",
            "pgd l2: attack effectiveness 23.810%.\n",
            "Mini batch: 220/300 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.1854 | Train accuracy: 91.49%.\n",
            "Training loss (epoch level): 0.2843 | Train accuracy: 87.66\n",
            "pgd l2: attack effectiveness 29.353%.\n",
            "\tVal accuracy 80.57% with accuracy 70.65% under attack.\n",
            "\tModel select at epoch 19 with validation accuracy 87.79% and accuracy 84.58% under attack.\n",
            "pgd l2: attack effectiveness 21.538%.\n",
            "Mini batch: 221/300 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.2506 | Train accuracy: 87.50%.\n",
            "pgd l2: attack effectiveness 7.812%.\n",
            "Mini batch: 222/300 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.2440 | Train accuracy: 92.19%.\n",
            "pgd l2: attack effectiveness 7.463%.\n",
            "Mini batch: 223/300 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.2523 | Train accuracy: 92.19%.\n",
            "pgd l2: attack effectiveness 8.824%.\n",
            "Mini batch: 224/300 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.2099 | Train accuracy: 93.75%.\n",
            "pgd l2: attack effectiveness 11.290%.\n",
            "Mini batch: 225/300 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.3161 | Train accuracy: 93.75%.\n",
            "pgd l2: attack effectiveness 10.909%.\n",
            "Mini batch: 226/300 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.2827 | Train accuracy: 88.28%.\n",
            "pgd l2: attack effectiveness 12.121%.\n",
            "Mini batch: 227/300 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.3142 | Train accuracy: 88.28%.\n",
            "pgd l2: attack effectiveness 6.557%.\n",
            "Mini batch: 228/300 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.2402 | Train accuracy: 90.62%.\n",
            "pgd l2: attack effectiveness 16.176%.\n",
            "Mini batch: 229/300 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.2786 | Train accuracy: 89.84%.\n",
            "pgd l2: attack effectiveness 14.286%.\n",
            "Mini batch: 230/300 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.2010 | Train accuracy: 91.49%.\n",
            "Training loss (epoch level): 0.2589 | Train accuracy: 90.79\n",
            "pgd l2: attack effectiveness 13.433%.\n",
            "\tVal accuracy 88.03% with accuracy 86.57% under attack.\n",
            "\tModel select at epoch 23 with validation accuracy 88.03% and accuracy 86.57% under attack.\n",
            "pgd l2: attack effectiveness 6.154%.\n",
            "Mini batch: 231/300 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.1970 | Train accuracy: 93.75%.\n",
            "pgd l2: attack effectiveness 15.625%.\n",
            "Mini batch: 232/300 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.2631 | Train accuracy: 89.84%.\n",
            "pgd l2: attack effectiveness 20.896%.\n",
            "Mini batch: 233/300 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.3006 | Train accuracy: 84.38%.\n",
            "pgd l2: attack effectiveness 10.294%.\n",
            "Mini batch: 234/300 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.2048 | Train accuracy: 93.75%.\n",
            "pgd l2: attack effectiveness 11.290%.\n",
            "Mini batch: 235/300 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.2205 | Train accuracy: 93.75%.\n",
            "pgd l2: attack effectiveness 30.909%.\n",
            "Mini batch: 236/300 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.3286 | Train accuracy: 84.38%.\n",
            "pgd l2: attack effectiveness 25.758%.\n",
            "Mini batch: 237/300 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.3388 | Train accuracy: 83.59%.\n",
            "pgd l2: attack effectiveness 16.393%.\n",
            "Mini batch: 238/300 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.2301 | Train accuracy: 86.72%.\n",
            "pgd l2: attack effectiveness 26.471%.\n",
            "Mini batch: 239/300 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.3101 | Train accuracy: 85.16%.\n",
            "pgd l2: attack effectiveness 9.524%.\n",
            "Mini batch: 240/300 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.2081 | Train accuracy: 93.62%.\n",
            "Training loss (epoch level): 0.2602 | Train accuracy: 88.89\n",
            "pgd l2: attack effectiveness 38.308%.\n",
            "\tVal accuracy 75.97% with accuracy 61.69% under attack.\n",
            "\tModel select at epoch 23 with validation accuracy 88.03% and accuracy 86.57% under attack.\n",
            "pgd l2: attack effectiveness 32.308%.\n",
            "Mini batch: 241/300 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.2872 | Train accuracy: 82.81%.\n",
            "pgd l2: attack effectiveness 28.125%.\n",
            "Mini batch: 242/300 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.2764 | Train accuracy: 83.59%.\n",
            "pgd l2: attack effectiveness 31.343%.\n",
            "Mini batch: 243/300 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.3053 | Train accuracy: 81.25%.\n",
            "pgd l2: attack effectiveness 39.706%.\n",
            "Mini batch: 244/300 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.3127 | Train accuracy: 82.03%.\n",
            "pgd l2: attack effectiveness 41.935%.\n",
            "Mini batch: 245/300 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.3601 | Train accuracy: 77.34%.\n",
            "pgd l2: attack effectiveness 20.000%.\n",
            "Mini batch: 246/300 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.3717 | Train accuracy: 85.94%.\n",
            "pgd l2: attack effectiveness 22.727%.\n",
            "Mini batch: 247/300 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.3274 | Train accuracy: 81.25%.\n",
            "pgd l2: attack effectiveness 19.672%.\n",
            "Mini batch: 248/300 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.3850 | Train accuracy: 85.94%.\n",
            "pgd l2: attack effectiveness 19.118%.\n",
            "Mini batch: 249/300 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.3092 | Train accuracy: 85.94%.\n",
            "pgd l2: attack effectiveness 28.571%.\n",
            "Mini batch: 250/300 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.2875 | Train accuracy: 87.23%.\n",
            "Training loss (epoch level): 0.3222 | Train accuracy: 83.33\n",
            "pgd l2: attack effectiveness 32.836%.\n",
            "\tVal accuracy 78.33% with accuracy 67.16% under attack.\n",
            "\tModel select at epoch 23 with validation accuracy 88.03% and accuracy 86.57% under attack.\n",
            "pgd l2: attack effectiveness 23.077%.\n",
            "Mini batch: 251/300 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.2911 | Train accuracy: 84.38%.\n",
            "pgd l2: attack effectiveness 7.812%.\n",
            "Mini batch: 252/300 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.2200 | Train accuracy: 95.31%.\n",
            "pgd l2: attack effectiveness 32.836%.\n",
            "Mini batch: 253/300 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.3610 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 39.706%.\n",
            "Mini batch: 254/300 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.3696 | Train accuracy: 77.34%.\n",
            "pgd l2: attack effectiveness 33.871%.\n",
            "Mini batch: 255/300 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.3752 | Train accuracy: 80.47%.\n",
            "pgd l2: attack effectiveness 16.364%.\n",
            "Mini batch: 256/300 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.3265 | Train accuracy: 88.28%.\n",
            "pgd l2: attack effectiveness 16.667%.\n",
            "Mini batch: 257/300 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.3014 | Train accuracy: 85.16%.\n",
            "pgd l2: attack effectiveness 18.033%.\n",
            "Mini batch: 258/300 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.3305 | Train accuracy: 85.94%.\n",
            "pgd l2: attack effectiveness 25.000%.\n",
            "Mini batch: 259/300 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.3376 | Train accuracy: 82.81%.\n",
            "pgd l2: attack effectiveness 23.810%.\n",
            "Mini batch: 260/300 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.2232 | Train accuracy: 87.23%.\n",
            "Training loss (epoch level): 0.3136 | Train accuracy: 84.50\n",
            "pgd l2: attack effectiveness 27.861%.\n",
            "\tVal accuracy 80.69% with accuracy 72.14% under attack.\n",
            "\tModel select at epoch 23 with validation accuracy 88.03% and accuracy 86.57% under attack.\n",
            "pgd l2: attack effectiveness 18.462%.\n",
            "Mini batch: 261/300 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.2694 | Train accuracy: 85.94%.\n",
            "pgd l2: attack effectiveness 17.188%.\n",
            "Mini batch: 262/300 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.2357 | Train accuracy: 88.28%.\n",
            "pgd l2: attack effectiveness 22.388%.\n",
            "Mini batch: 263/300 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.2823 | Train accuracy: 83.59%.\n",
            "pgd l2: attack effectiveness 35.294%.\n",
            "Mini batch: 264/300 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.2983 | Train accuracy: 80.47%.\n",
            "pgd l2: attack effectiveness 33.871%.\n",
            "Mini batch: 265/300 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.2905 | Train accuracy: 86.72%.\n",
            "pgd l2: attack effectiveness 23.636%.\n",
            "Mini batch: 266/300 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.2848 | Train accuracy: 85.16%.\n",
            "pgd l2: attack effectiveness 25.758%.\n",
            "Mini batch: 267/300 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.2638 | Train accuracy: 85.16%.\n",
            "pgd l2: attack effectiveness 24.590%.\n",
            "Mini batch: 268/300 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.2318 | Train accuracy: 88.28%.\n",
            "pgd l2: attack effectiveness 26.471%.\n",
            "Mini batch: 269/300 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.2367 | Train accuracy: 89.84%.\n",
            "pgd l2: attack effectiveness 28.571%.\n",
            "Mini batch: 270/300 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.1832 | Train accuracy: 89.36%.\n",
            "Training loss (epoch level): 0.2577 | Train accuracy: 86.28\n",
            "pgd l2: attack effectiveness 32.836%.\n",
            "\tVal accuracy 79.21% with accuracy 67.16% under attack.\n",
            "\tModel select at epoch 23 with validation accuracy 88.03% and accuracy 86.57% under attack.\n",
            "pgd l2: attack effectiveness 24.615%.\n",
            "Mini batch: 271/300 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.2369 | Train accuracy: 86.72%.\n",
            "pgd l2: attack effectiveness 20.312%.\n",
            "Mini batch: 272/300 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.3004 | Train accuracy: 89.06%.\n",
            "pgd l2: attack effectiveness 31.343%.\n",
            "Mini batch: 273/300 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.3424 | Train accuracy: 84.38%.\n",
            "pgd l2: attack effectiveness 25.000%.\n",
            "Mini batch: 274/300 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.2392 | Train accuracy: 85.16%.\n",
            "pgd l2: attack effectiveness 8.065%.\n",
            "Mini batch: 275/300 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.2411 | Train accuracy: 90.62%.\n",
            "pgd l2: attack effectiveness 7.273%.\n",
            "Mini batch: 276/300 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.3644 | Train accuracy: 82.81%.\n",
            "pgd l2: attack effectiveness 4.545%.\n",
            "Mini batch: 277/300 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.2170 | Train accuracy: 90.62%.\n",
            "pgd l2: attack effectiveness 6.557%.\n",
            "Mini batch: 278/300 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.1812 | Train accuracy: 90.62%.\n",
            "pgd l2: attack effectiveness 11.765%.\n",
            "Mini batch: 279/300 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.2220 | Train accuracy: 88.28%.\n",
            "pgd l2: attack effectiveness 9.524%.\n",
            "Mini batch: 280/300 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.1078 | Train accuracy: 93.62%.\n",
            "Training loss (epoch level): 0.2453 | Train accuracy: 88.19\n",
            "pgd l2: attack effectiveness 12.438%.\n",
            "\tVal accuracy 89.41% with accuracy 87.56% under attack.\n",
            "\tModel select at epoch 28 with validation accuracy 89.41% and accuracy 87.56% under attack.\n",
            "pgd l2: attack effectiveness 4.615%.\n",
            "Mini batch: 281/300 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.1048 | Train accuracy: 95.31%.\n",
            "pgd l2: attack effectiveness 12.500%.\n",
            "Mini batch: 282/300 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.2100 | Train accuracy: 93.75%.\n",
            "pgd l2: attack effectiveness 7.463%.\n",
            "Mini batch: 283/300 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.1816 | Train accuracy: 93.75%.\n",
            "pgd l2: attack effectiveness 7.353%.\n",
            "Mini batch: 284/300 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.1835 | Train accuracy: 96.09%.\n",
            "pgd l2: attack effectiveness 33.871%.\n",
            "Mini batch: 285/300 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.3391 | Train accuracy: 84.38%.\n",
            "pgd l2: attack effectiveness 9.091%.\n",
            "Mini batch: 286/300 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.2756 | Train accuracy: 94.53%.\n",
            "pgd l2: attack effectiveness 12.121%.\n",
            "Mini batch: 287/300 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.2684 | Train accuracy: 92.97%.\n",
            "pgd l2: attack effectiveness 13.115%.\n",
            "Mini batch: 288/300 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.1905 | Train accuracy: 91.41%.\n",
            "pgd l2: attack effectiveness 8.824%.\n",
            "Mini batch: 289/300 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.2253 | Train accuracy: 92.19%.\n",
            "pgd l2: attack effectiveness 9.524%.\n",
            "Mini batch: 290/300 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.1446 | Train accuracy: 91.49%.\n",
            "Training loss (epoch level): 0.2123 | Train accuracy: 92.59\n",
            "pgd l2: attack effectiveness 13.433%.\n",
            "\tVal accuracy 88.66% with accuracy 86.57% under attack.\n",
            "\tModel select at epoch 28 with validation accuracy 89.41% and accuracy 87.56% under attack.\n",
            "pgd l2: attack effectiveness 6.154%.\n",
            "Mini batch: 291/300 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.1713 | Train accuracy: 96.09%.\n",
            "pgd l2: attack effectiveness 14.062%.\n",
            "Mini batch: 292/300 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.2101 | Train accuracy: 92.97%.\n",
            "pgd l2: attack effectiveness 23.881%.\n",
            "Mini batch: 293/300 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.3086 | Train accuracy: 87.50%.\n",
            "pgd l2: attack effectiveness 27.941%.\n",
            "Mini batch: 294/300 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.3208 | Train accuracy: 84.38%.\n",
            "pgd l2: attack effectiveness 9.677%.\n",
            "Mini batch: 295/300 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.2043 | Train accuracy: 95.31%.\n",
            "pgd l2: attack effectiveness 10.909%.\n",
            "Mini batch: 296/300 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.2424 | Train accuracy: 92.19%.\n",
            "pgd l2: attack effectiveness 9.091%.\n",
            "Mini batch: 297/300 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.2048 | Train accuracy: 93.75%.\n",
            "pgd l2: attack effectiveness 14.754%.\n",
            "Mini batch: 298/300 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.1817 | Train accuracy: 91.41%.\n",
            "pgd l2: attack effectiveness 23.529%.\n",
            "Mini batch: 299/300 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.2494 | Train accuracy: 86.72%.\n",
            "pgd l2: attack effectiveness 23.810%.\n",
            "Mini batch: 300/300 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.1926 | Train accuracy: 89.36%.\n",
            "Training loss (epoch level): 0.2286 | Train accuracy: 90.97\n",
            "pgd l2: attack effectiveness 13.930%.\n",
            "\tVal accuracy 88.53% with accuracy 86.07% under attack.\n",
            "\tModel select at epoch 28 with validation accuracy 89.41% and accuracy 87.56% under attack.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test: accuracy\n",
        "max_adv_training_model.load()\n",
        "max_adv_training_model.model.predict(test_Loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_cupu1j6Wp7",
        "outputId": "7d10079c-b05c-4c5f-c384-79c8582738e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy on the test dataset is 96.66389%\n",
            "The balanced accuracy on the test dataset is 96.64761%\n",
            "Other evaluation metrics we may need:\n",
            "False Negative Rate (FNR) is 3.80623%, False Positive Rate (FPR) is 2.89855%, F1 score is 96.52778%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_adv_training_model.adv_predict(test_Loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVpzTPspCiwR",
        "outputId": "7d4cd16d-61da-46e9-ac56-f812a7885af3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pgd linf: attack effectiveness 3.806%.\n",
            "\tadversarial accuracy  96.19% under attack.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Norm : L1"
      ],
      "metadata": {
        "id": "hvyxydcghyGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PGDl1():\n",
        "    \"\"\"\n",
        "    Projected gradient descent (ascent) with gradients 'normalized' using l1 norm.\n",
        "    By comparing BCA, the api removal is leveraged\n",
        "\n",
        "    Parameters\n",
        "    ---------\n",
        "    @param is_attacker, Boolean, play the role of attacker (note: the defender conducts adversarial training)\n",
        "    @param oblivion, Boolean, whether know the adversary indicator or not\n",
        "    @param kappa, attack confidence\n",
        "    @param manipulation_x, manipulations\n",
        "    @param omega, the indices of interdependent apis corresponding to each api\n",
        "    @param device, 'cpu' or 'cuda'\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, is_attacker=True, oblivion=False, kappa=1., manipulation_x=None, omega=None, api_flag=None, device=None):\n",
        "        super(PGDl1, self).__init__()\n",
        "        self.is_attacker = is_attacker\n",
        "        self.lambda_ = 1.\n",
        "        self.omeag = omega\n",
        "        self.manipulation_x = manipulation_x\n",
        "        self.api_flag = api_flag\n",
        "        self.device = device\n",
        "\n",
        "    def _perturb(self, model, x,  label=None,\n",
        "                 steps=10,\n",
        "                 lambda_=1.):\n",
        "        \"\"\"\n",
        "        perturb node feature vectors\n",
        "\n",
        "        Parameters\n",
        "        -----------\n",
        "        @param model, a victim model\n",
        "        @param x: torch.FloatTensor, node feature vectors (each represents the occurrences of apis in a graph) with shape [batch_size, number_of_graphs, vocab_dim]\n",
        "        @param label: torch.LongTensor, ground truth labels\n",
        "        @param steps: Integer, maximum number of perturbations\n",
        "        @param lambda_, float, penalty factor\n",
        "        \"\"\"\n",
        "        adv_x = x\n",
        "        worst_x = x.detach().clone()\n",
        "        self.lambda_ = lambda_\n",
        "        self.padding_mask = torch.sum(adv_x, dim=-1, keepdim=True) > 1  # we set a graph contains two apis at least\n",
        "        model.eval()\n",
        "        for t in range(steps):\n",
        "            var_adv_x = torch.autograd.Variable(adv_x, requires_grad=True)\n",
        "            loss, done = self.get_loss(model, var_adv_x, label, self.lambda_)\n",
        "            worst_x[done] = adv_x[done]\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            grad = torch.autograd.grad(torch.mean(loss), var_adv_x)[0]\n",
        "            perturbation, direction = self.get_perturbation(grad, x, adv_x)\n",
        "            # stop perturbing the examples that are successful to evade the victim\n",
        "            perturbation[done] = 0.\n",
        "            adv_x = torch.clamp(adv_x + perturbation * direction, min=0., max=1.)\n",
        "        done = self.get_scores(model, adv_x, label)\n",
        "        worst_x[done] = adv_x[done]\n",
        "        return worst_x\n",
        "\n",
        "    def perturb(self, model, x, label=None,\n",
        "                steps=10,\n",
        "                min_lambda_=1e-5,\n",
        "                max_lambda_=1e5,\n",
        "                base=10.,\n",
        "                verbose=True):\n",
        "        \"\"\"\n",
        "        enhance attack\n",
        "        \"\"\"\n",
        "        model.eval()\n",
        "        if hasattr(model, 'is_detector_enabled'):\n",
        "            self.lambda_ = min_lambda_\n",
        "        else:\n",
        "            self.lambda_ = max_lambda_\n",
        "        adv_x = x.detach().clone().to(torch.double)\n",
        "        while self.lambda_ <= max_lambda_:\n",
        "            _, done = self.get_loss(model, adv_x, label, self.lambda_)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            pert_x = self._perturb(model, adv_x[~done], label[~done],\n",
        "                                   steps,\n",
        "                                   lambda_=self.lambda_\n",
        "                                   )\n",
        "            adv_x[~done] = pert_x\n",
        "            self.lambda_ *= base\n",
        "            #if not self.check_lambda(model):\n",
        "                #break\n",
        "        with torch.no_grad():\n",
        "            _, done = self.get_loss(model, adv_x, label, self.lambda_)\n",
        "            if verbose:\n",
        "                print(f\"pgd l1: attack effectiveness {done.sum().item() / x.size()[0]}.\")\n",
        "        return adv_x\n",
        "\n",
        "    def get_perturbation(self, gradients, features, adv_features):\n",
        "        # 1. mask paddings\n",
        "        gradients = gradients * self.padding_mask\n",
        "\n",
        "        # 2. look for allowable position, because only '1--> -' and '0 --> +' are permitted\n",
        "        #    2.1 api insertion\n",
        "        pos_insertion = (adv_features <= 0.5) * 1\n",
        "        grad4insertion = (gradients > 0) * pos_insertion * gradients\n",
        "        #    2.2 api removal\n",
        "        pos_removal = (adv_features > 0.5) * 1\n",
        "        grad4removal = (gradients <= 0) * (pos_removal & self.manipulation_x) * gradients\n",
        "        if self.is_attacker:\n",
        "            #     2.2.1 cope with the interdependent apis\n",
        "            checking_nonexist_api = (pos_removal ^ self.omega) & self.omega\n",
        "            grad4removal[:, self.api_flag] += torch.sum(gradients * checking_nonexist_api, dim=-1, keepdim=True)\n",
        "\n",
        "        gradients = grad4removal + grad4insertion\n",
        "\n",
        "        # 3. remove duplications\n",
        "        un_mod = torch.abs(features - adv_features) <= 1e-6\n",
        "        gradients = gradients * un_mod\n",
        "\n",
        "        # 4. look for important position\n",
        "        absolute_grad = torch.abs(gradients).reshape(features.shape[0], -1)\n",
        "        _, position = torch.max(absolute_grad, dim=-1)\n",
        "        perturbations = F.one_hot(position, num_classes=absolute_grad.shape[-1]).double()\n",
        "        perturbations = perturbations.reshape(features.shape)\n",
        "        directions = torch.sign(gradients) * (perturbations > 1e-6)\n",
        "\n",
        "        # 5. tailor the interdependent apis\n",
        "        if self.is_attacker:\n",
        "            perturbations += (torch.any(directions[:, self.api_flag] < 0, dim=-1, keepdim=True)) * checking_nonexist_api\n",
        "            directions += perturbations * self.omega\n",
        "        return perturbations, directions\n",
        "\n",
        "\n",
        "    def get_loss(self, model, adv_x, label, lambda_=None):\n",
        "        if hasattr(model, 'is_detector_enabled'):\n",
        "            logits_f, prob_g = model.forward(adv_x)\n",
        "        else:\n",
        "            logits_f = model.forward(adv_x)\n",
        "\n",
        "        ce = F.cross_entropy(logits_f, label, reduction='none')\n",
        "        y_pred = logits_f.argmax(1)\n",
        "        if hasattr(model, 'is_detector_enabled') and (not self.oblivion):\n",
        "            assert lambda_ is not None\n",
        "            tau = model.get_tau_sample_wise(y_pred)\n",
        "            if self.is_attacker:\n",
        "                loss_no_reduction = ce + lambda_ * (torch.clamp(tau - prob_g,\n",
        "                                                                max=self.kappa)\n",
        "                                                    )\n",
        "            else:\n",
        "                loss_no_reduction = ce + lambda_ * (tau - prob_g)\n",
        "            done = (y_pred != label) & (prob_g <= tau)\n",
        "        else:\n",
        "            loss_no_reduction = ce\n",
        "            done = y_pred != label\n",
        "        return loss_no_reduction, done\n",
        "\n",
        "    def get_scores(self, model, pertb_x, label, lmda=1.):\n",
        "        if hasattr(model, 'is_detector_enabled'):\n",
        "            logits_f, prob_g = model.forward(pertb_x)\n",
        "        else:\n",
        "            logits_f = model.forward(pertb_x)\n",
        "        y_pred = logits_f.argmax(1)\n",
        "        if hasattr(model, 'is_detector_enabled') and (not self.oblivion):\n",
        "            tau = model.get_tau_sample_wise(y_pred)\n",
        "            done = (y_pred != label) & (prob_g <= tau)\n",
        "        else:\n",
        "            done = y_pred != label\n",
        "        return done"
      ],
      "metadata": {
        "id": "q-FgY4O2hy2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def __init__(self, is_attacker=True, oblivion=False, kappa=1., manipulation_x=None, omega=None, device=None):\n",
        "        super(PGDl1, self).__init__(is_attacker, oblivion, kappa, manipulation_x, omega, device)"
      ],
      "metadata": {
        "id": "_9CCrkXhjtgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MalwareDetectionDNN(3216,2)\n",
        "model = model.double().to(device)\n",
        "attack = PGDl1(is_attacker=False,manipulation_x=manipulation_x, omega=omega,api_flag=api_flag,device=device)\n",
        "attack_param = {}\n",
        "max_adv_training_model = PGDAdvTraining(model, attack, attack_param)\n",
        "max_adv_training_model.fit(train_Loader,validation_Loader,adv_epochs=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuBfuwG2jkEA",
        "outputId": "0d2d44b3-241c-4d0c-883a-ce2df4551db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 1/300 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.6906 | Train accuracy: 51.56%.\n",
            "pgd l1: attack effectiveness 0.65625.\n",
            "Mini batch: 2/300 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.5953 | Train accuracy: 71.09%.\n",
            "pgd l1: attack effectiveness 0.4925373134328358.\n",
            "Mini batch: 3/300 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.4279 | Train accuracy: 75.00%.\n",
            "pgd l1: attack effectiveness 0.39705882352941174.\n",
            "Mini batch: 4/300 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.3318 | Train accuracy: 82.81%.\n",
            "pgd l1: attack effectiveness 0.14516129032258066.\n",
            "Mini batch: 5/300 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.3323 | Train accuracy: 84.38%.\n",
            "pgd l1: attack effectiveness 0.2.\n",
            "Mini batch: 6/300 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.4006 | Train accuracy: 81.25%.\n",
            "pgd l1: attack effectiveness 0.3181818181818182.\n",
            "Mini batch: 7/300 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.3173 | Train accuracy: 82.81%.\n",
            "pgd l1: attack effectiveness 0.11475409836065574.\n",
            "Mini batch: 8/300 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.2305 | Train accuracy: 89.06%.\n",
            "pgd l1: attack effectiveness 0.1323529411764706.\n",
            "Mini batch: 9/300 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.3457 | Train accuracy: 82.03%.\n",
            "pgd l1: attack effectiveness 0.23809523809523808.\n",
            "Mini batch: 10/300 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.3498 | Train accuracy: 80.85%.\n",
            "Training loss (epoch level): 0.4022 | Train accuracy: 78.09\n",
            "pgd l1: attack effectiveness 0.38308457711442784.\n",
            "\tVal accuracy 75.97% with accuracy 61.69% under attack.\n",
            "\tModel select at epoch 1 with validation accuracy 75.97% and accuracy 61.69% under attack.\n",
            "pgd l1: attack effectiveness 0.36923076923076925.\n",
            "Mini batch: 11/300 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.3096 | Train accuracy: 82.81%.\n",
            "pgd l1: attack effectiveness 0.109375.\n",
            "Mini batch: 12/300 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.2492 | Train accuracy: 86.72%.\n",
            "pgd l1: attack effectiveness 0.2835820895522388.\n",
            "Mini batch: 13/300 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.2365 | Train accuracy: 88.28%.\n",
            "pgd l1: attack effectiveness 0.45588235294117646.\n",
            "Mini batch: 14/300 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.2623 | Train accuracy: 81.25%.\n",
            "pgd l1: attack effectiveness 0.20967741935483872.\n",
            "Mini batch: 15/300 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.1707 | Train accuracy: 89.06%.\n",
            "pgd l1: attack effectiveness 0.2.\n",
            "Mini batch: 16/300 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.1906 | Train accuracy: 91.41%.\n",
            "pgd l1: attack effectiveness 0.16666666666666666.\n",
            "Mini batch: 17/300 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.1400 | Train accuracy: 92.19%.\n",
            "pgd l1: attack effectiveness 0.18032786885245902.\n",
            "Mini batch: 18/300 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.1643 | Train accuracy: 89.84%.\n",
            "pgd l1: attack effectiveness 0.22058823529411764.\n",
            "Mini batch: 19/300 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.2774 | Train accuracy: 88.28%.\n",
            "pgd l1: attack effectiveness 0.23809523809523808.\n",
            "Mini batch: 20/300 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.2669 | Train accuracy: 85.11%.\n",
            "Training loss (epoch level): 0.2268 | Train accuracy: 87.50\n",
            "pgd l1: attack effectiveness 0.13432835820895522.\n",
            "\tVal accuracy 89.16% with accuracy 86.57% under attack.\n",
            "\tModel select at epoch 2 with validation accuracy 89.16% and accuracy 86.57% under attack.\n",
            "pgd l1: attack effectiveness 0.1076923076923077.\n",
            "Mini batch: 21/300 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.2199 | Train accuracy: 89.84%.\n",
            "pgd l1: attack effectiveness 0.0625.\n",
            "Mini batch: 22/300 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.1822 | Train accuracy: 91.41%.\n",
            "pgd l1: attack effectiveness 0.05970149253731343.\n",
            "Mini batch: 23/300 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.2438 | Train accuracy: 85.94%.\n",
            "pgd l1: attack effectiveness 0.07352941176470588.\n",
            "Mini batch: 24/300 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.1134 | Train accuracy: 94.53%.\n",
            "pgd l1: attack effectiveness 0.24193548387096775.\n",
            "Mini batch: 25/300 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.1833 | Train accuracy: 86.72%.\n",
            "pgd l1: attack effectiveness 0.36363636363636365.\n",
            "Mini batch: 26/300 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.1956 | Train accuracy: 85.16%.\n",
            "pgd l1: attack effectiveness 0.3181818181818182.\n",
            "Mini batch: 27/300 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.1634 | Train accuracy: 88.28%.\n",
            "pgd l1: attack effectiveness 0.26229508196721313.\n",
            "Mini batch: 28/300 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.1687 | Train accuracy: 89.84%.\n",
            "pgd l1: attack effectiveness 0.16176470588235295.\n",
            "Mini batch: 29/300 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.2012 | Train accuracy: 91.41%.\n",
            "pgd l1: attack effectiveness 0.19047619047619047.\n",
            "Mini batch: 30/300 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.2015 | Train accuracy: 87.23%.\n",
            "Training loss (epoch level): 0.1873 | Train accuracy: 89.04\n",
            "pgd l1: attack effectiveness 0.11442786069651742.\n",
            "\tVal accuracy 90.4% with accuracy 88.56% under attack.\n",
            "\tModel select at epoch 3 with validation accuracy 90.4% and accuracy 88.56% under attack.\n",
            "pgd l1: attack effectiveness 0.09230769230769231.\n",
            "Mini batch: 31/300 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.1598 | Train accuracy: 92.19%.\n",
            "pgd l1: attack effectiveness 0.046875.\n",
            "Mini batch: 32/300 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.1069 | Train accuracy: 95.31%.\n",
            "pgd l1: attack effectiveness 0.05970149253731343.\n",
            "Mini batch: 33/300 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.1695 | Train accuracy: 89.84%.\n",
            "pgd l1: attack effectiveness 0.04411764705882353.\n",
            "Mini batch: 34/300 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.1595 | Train accuracy: 90.62%.\n",
            "pgd l1: attack effectiveness 0.11290322580645161.\n",
            "Mini batch: 35/300 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.1758 | Train accuracy: 88.28%.\n",
            "pgd l1: attack effectiveness 0.10909090909090909.\n",
            "Mini batch: 36/300 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.1796 | Train accuracy: 89.84%.\n",
            "pgd l1: attack effectiveness 0.09090909090909091.\n",
            "Mini batch: 37/300 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.1021 | Train accuracy: 92.19%.\n",
            "pgd l1: attack effectiveness 0.11475409836065574.\n",
            "Mini batch: 38/300 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.1131 | Train accuracy: 93.75%.\n",
            "pgd l1: attack effectiveness 0.4117647058823529.\n",
            "Mini batch: 39/300 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.2535 | Train accuracy: 82.81%.\n",
            "pgd l1: attack effectiveness 0.19047619047619047.\n",
            "Mini batch: 40/300 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.1601 | Train accuracy: 91.49%.\n",
            "Training loss (epoch level): 0.1580 | Train accuracy: 90.63\n",
            "pgd l1: attack effectiveness 0.24378109452736318.\n",
            "\tVal accuracy 85.19% with accuracy 75.62% under attack.\n",
            "\tModel select at epoch 3 with validation accuracy 90.4% and accuracy 88.56% under attack.\n",
            "pgd l1: attack effectiveness 0.16923076923076924.\n",
            "Mini batch: 41/300 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.1631 | Train accuracy: 90.62%.\n",
            "pgd l1: attack effectiveness 0.109375.\n",
            "Mini batch: 42/300 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0764 | Train accuracy: 95.31%.\n",
            "pgd l1: attack effectiveness 0.07462686567164178.\n",
            "Mini batch: 43/300 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0723 | Train accuracy: 95.31%.\n",
            "pgd l1: attack effectiveness 0.058823529411764705.\n",
            "Mini batch: 44/300 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0815 | Train accuracy: 94.53%.\n",
            "pgd l1: attack effectiveness 0.08064516129032258.\n",
            "Mini batch: 45/300 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.1163 | Train accuracy: 91.41%.\n",
            "pgd l1: attack effectiveness 0.05454545454545454.\n",
            "Mini batch: 46/300 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.1650 | Train accuracy: 91.41%.\n",
            "pgd l1: attack effectiveness 0.06060606060606061.\n",
            "Mini batch: 47/300 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.1174 | Train accuracy: 91.41%.\n",
            "pgd l1: attack effectiveness 0.06557377049180328.\n",
            "Mini batch: 48/300 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.1009 | Train accuracy: 96.09%.\n",
            "pgd l1: attack effectiveness 0.11764705882352941.\n",
            "Mini batch: 49/300 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.1363 | Train accuracy: 91.41%.\n",
            "pgd l1: attack effectiveness 0.09523809523809523.\n",
            "Mini batch: 50/300 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0833 | Train accuracy: 95.74%.\n",
            "Training loss (epoch level): 0.1112 | Train accuracy: 93.32\n",
            "pgd l1: attack effectiveness 0.23880597014925373.\n",
            "\tVal accuracy 85.43% with accuracy 76.12% under attack.\n",
            "\tModel select at epoch 3 with validation accuracy 90.4% and accuracy 88.56% under attack.\n",
            "pgd l1: attack effectiveness 0.16923076923076924.\n",
            "Mini batch: 51/300 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.1447 | Train accuracy: 90.62%.\n",
            "pgd l1: attack effectiveness 0.234375.\n",
            "Mini batch: 52/300 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.1127 | Train accuracy: 91.41%.\n",
            "pgd l1: attack effectiveness 0.08955223880597014.\n",
            "Mini batch: 53/300 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0480 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.058823529411764705.\n",
            "Mini batch: 54/300 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0464 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.11290322580645161.\n",
            "Mini batch: 55/300 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0812 | Train accuracy: 93.75%.\n",
            "pgd l1: attack effectiveness 0.07272727272727272.\n",
            "Mini batch: 56/300 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0822 | Train accuracy: 96.09%.\n",
            "pgd l1: attack effectiveness 0.06060606060606061.\n",
            "Mini batch: 57/300 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0687 | Train accuracy: 94.53%.\n",
            "pgd l1: attack effectiveness 0.04918032786885246.\n",
            "Mini batch: 58/300 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0686 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.07352941176470588.\n",
            "Mini batch: 59/300 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.1214 | Train accuracy: 93.75%.\n",
            "pgd l1: attack effectiveness 0.09523809523809523.\n",
            "Mini batch: 60/300 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0704 | Train accuracy: 97.87%.\n",
            "Training loss (epoch level): 0.0844 | Train accuracy: 94.94\n",
            "pgd l1: attack effectiveness 0.0945273631840796.\n",
            "\tVal accuracy 92.52% with accuracy 90.55% under attack.\n",
            "\tModel select at epoch 6 with validation accuracy 92.52% and accuracy 90.55% under attack.\n",
            "pgd l1: attack effectiveness 0.06153846153846154.\n",
            "Mini batch: 61/300 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0847 | Train accuracy: 95.31%.\n",
            "pgd l1: attack effectiveness 0.09375.\n",
            "Mini batch: 62/300 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0640 | Train accuracy: 96.09%.\n",
            "pgd l1: attack effectiveness 0.14925373134328357.\n",
            "Mini batch: 63/300 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0905 | Train accuracy: 91.41%.\n",
            "pgd l1: attack effectiveness 0.014705882352941176.\n",
            "Mini batch: 64/300 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0300 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.08064516129032258.\n",
            "Mini batch: 65/300 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0607 | Train accuracy: 95.31%.\n",
            "pgd l1: attack effectiveness 0.07272727272727272.\n",
            "Mini batch: 66/300 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0603 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.06060606060606061.\n",
            "Mini batch: 67/300 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0597 | Train accuracy: 96.09%.\n",
            "pgd l1: attack effectiveness 0.06557377049180328.\n",
            "Mini batch: 68/300 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0889 | Train accuracy: 95.31%.\n",
            "pgd l1: attack effectiveness 0.07352941176470588.\n",
            "Mini batch: 69/300 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0982 | Train accuracy: 93.75%.\n",
            "pgd l1: attack effectiveness 0.09523809523809523.\n",
            "Mini batch: 70/300 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0829 | Train accuracy: 93.62%.\n",
            "Training loss (epoch level): 0.0720 | Train accuracy: 95.22\n",
            "pgd l1: attack effectiveness 0.0845771144278607.\n",
            "\tVal accuracy 92.77% with accuracy 91.54% under attack.\n",
            "\tModel select at epoch 7 with validation accuracy 92.77% and accuracy 91.54% under attack.\n",
            "pgd l1: attack effectiveness 0.046153846153846156.\n",
            "Mini batch: 71/300 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0929 | Train accuracy: 94.53%.\n",
            "pgd l1: attack effectiveness 0.03125.\n",
            "Mini batch: 72/300 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0618 | Train accuracy: 96.09%.\n",
            "pgd l1: attack effectiveness 0.014925373134328358.\n",
            "Mini batch: 73/300 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0583 | Train accuracy: 96.09%.\n",
            "pgd l1: attack effectiveness 0.014705882352941176.\n",
            "Mini batch: 74/300 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0343 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.08064516129032258.\n",
            "Mini batch: 75/300 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0583 | Train accuracy: 95.31%.\n",
            "pgd l1: attack effectiveness 0.07272727272727272.\n",
            "Mini batch: 76/300 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0596 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.12121212121212122.\n",
            "Mini batch: 77/300 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0804 | Train accuracy: 93.75%.\n",
            "pgd l1: attack effectiveness 0.06557377049180328.\n",
            "Mini batch: 78/300 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0622 | Train accuracy: 95.31%.\n",
            "pgd l1: attack effectiveness 0.07352941176470588.\n",
            "Mini batch: 79/300 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0948 | Train accuracy: 96.09%.\n",
            "pgd l1: attack effectiveness 0.047619047619047616.\n",
            "Mini batch: 80/300 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0379 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0641 | Train accuracy: 96.25\n",
            "pgd l1: attack effectiveness 0.07960199004975124.\n",
            "\tVal accuracy 93.27% with accuracy 92.04% under attack.\n",
            "\tModel select at epoch 8 with validation accuracy 93.27% and accuracy 92.04% under attack.\n",
            "pgd l1: attack effectiveness 0.046153846153846156.\n",
            "Mini batch: 81/300 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0675 | Train accuracy: 94.53%.\n",
            "pgd l1: attack effectiveness 0.03125.\n",
            "Mini batch: 82/300 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0451 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.014925373134328358.\n",
            "Mini batch: 83/300 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0418 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 84/300 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0217 | Train accuracy: 99.22%.\n",
            "pgd l1: attack effectiveness 0.08064516129032258.\n",
            "Mini batch: 85/300 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0503 | Train accuracy: 95.31%.\n",
            "pgd l1: attack effectiveness 0.05454545454545454.\n",
            "Mini batch: 86/300 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0509 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.06060606060606061.\n",
            "Mini batch: 87/300 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0608 | Train accuracy: 95.31%.\n",
            "pgd l1: attack effectiveness 0.03278688524590164.\n",
            "Mini batch: 88/300 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0333 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.029411764705882353.\n",
            "Mini batch: 89/300 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0740 | Train accuracy: 96.09%.\n",
            "pgd l1: attack effectiveness 0.047619047619047616.\n",
            "Mini batch: 90/300 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0392 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0485 | Train accuracy: 97.11\n",
            "pgd l1: attack effectiveness 0.12437810945273632.\n",
            "\tVal accuracy 91.53% with accuracy 87.56% under attack.\n",
            "\tModel select at epoch 8 with validation accuracy 93.27% and accuracy 92.04% under attack.\n",
            "pgd l1: attack effectiveness 0.046153846153846156.\n",
            "Mini batch: 91/300 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0729 | Train accuracy: 94.53%.\n",
            "pgd l1: attack effectiveness 0.0625.\n",
            "Mini batch: 92/300 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0411 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.14925373134328357.\n",
            "Mini batch: 93/300 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0745 | Train accuracy: 93.75%.\n",
            "pgd l1: attack effectiveness 0.029411764705882353.\n",
            "Mini batch: 94/300 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0202 | Train accuracy: 100.00%.\n",
            "pgd l1: attack effectiveness 0.0967741935483871.\n",
            "Mini batch: 95/300 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0525 | Train accuracy: 96.09%.\n",
            "pgd l1: attack effectiveness 0.01818181818181818.\n",
            "Mini batch: 96/300 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0341 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.06060606060606061.\n",
            "Mini batch: 97/300 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0633 | Train accuracy: 96.09%.\n",
            "pgd l1: attack effectiveness 0.03278688524590164.\n",
            "Mini batch: 98/300 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0298 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.014705882352941176.\n",
            "Mini batch: 99/300 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0804 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.047619047619047616.\n",
            "Mini batch: 100/300 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0495 | Train accuracy: 95.74%.\n",
            "Training loss (epoch level): 0.0518 | Train accuracy: 96.68\n",
            "pgd l1: attack effectiveness 0.0845771144278607.\n",
            "\tVal accuracy 92.77% with accuracy 91.54% under attack.\n",
            "\tModel select at epoch 8 with validation accuracy 93.27% and accuracy 92.04% under attack.\n",
            "pgd l1: attack effectiveness 0.046153846153846156.\n",
            "Mini batch: 101/300 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0635 | Train accuracy: 96.09%.\n",
            "pgd l1: attack effectiveness 0.015625.\n",
            "Mini batch: 102/300 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0314 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.1044776119402985.\n",
            "Mini batch: 103/300 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0546 | Train accuracy: 96.09%.\n",
            "pgd l1: attack effectiveness 0.058823529411764705.\n",
            "Mini batch: 104/300 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0252 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.04838709677419355.\n",
            "Mini batch: 105/300 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0372 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.07272727272727272.\n",
            "Mini batch: 106/300 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0555 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.06060606060606061.\n",
            "Mini batch: 107/300 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0579 | Train accuracy: 94.53%.\n",
            "pgd l1: attack effectiveness 0.03278688524590164.\n",
            "Mini batch: 108/300 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0307 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.058823529411764705.\n",
            "Mini batch: 109/300 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0765 | Train accuracy: 95.31%.\n",
            "pgd l1: attack effectiveness 0.047619047619047616.\n",
            "Mini batch: 110/300 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0537 | Train accuracy: 95.74%.\n",
            "Training loss (epoch level): 0.0486 | Train accuracy: 96.76\n",
            "pgd l1: attack effectiveness 0.05970149253731343.\n",
            "\tVal accuracy 93.64% with accuracy 94.03% under attack.\n",
            "\tModel select at epoch 11 with validation accuracy 93.64% and accuracy 94.03% under attack.\n",
            "pgd l1: attack effectiveness 0.03076923076923077.\n",
            "Mini batch: 111/300 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0567 | Train accuracy: 96.09%.\n",
            "pgd l1: attack effectiveness 0.015625.\n",
            "Mini batch: 112/300 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0384 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 113/300 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0217 | Train accuracy: 99.22%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 114/300 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0114 | Train accuracy: 99.22%.\n",
            "pgd l1: attack effectiveness 0.16129032258064516.\n",
            "Mini batch: 115/300 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0811 | Train accuracy: 92.97%.\n",
            "pgd l1: attack effectiveness 0.03636363636363636.\n",
            "Mini batch: 116/300 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0363 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.12121212121212122.\n",
            "Mini batch: 117/300 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0741 | Train accuracy: 92.19%.\n",
            "pgd l1: attack effectiveness 0.03278688524590164.\n",
            "Mini batch: 118/300 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0269 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.08823529411764706.\n",
            "Mini batch: 119/300 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0973 | Train accuracy: 93.75%.\n",
            "pgd l1: attack effectiveness 0.047619047619047616.\n",
            "Mini batch: 120/300 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0383 | Train accuracy: 97.87%.\n",
            "Training loss (epoch level): 0.0482 | Train accuracy: 96.43\n",
            "pgd l1: attack effectiveness 0.04975124378109453.\n",
            "\tVal accuracy 93.89% with accuracy 95.02% under attack.\n",
            "\tModel select at epoch 12 with validation accuracy 93.89% and accuracy 95.02% under attack.\n",
            "pgd l1: attack effectiveness 0.03076923076923077.\n",
            "Mini batch: 121/300 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0780 | Train accuracy: 94.53%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 122/300 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0411 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 123/300 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0694 | Train accuracy: 95.31%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 124/300 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0213 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.03225806451612903.\n",
            "Mini batch: 125/300 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0261 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.09090909090909091.\n",
            "Mini batch: 126/300 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0408 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.13636363636363635.\n",
            "Mini batch: 127/300 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0771 | Train accuracy: 93.75%.\n",
            "pgd l1: attack effectiveness 0.26229508196721313.\n",
            "Mini batch: 128/300 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.1216 | Train accuracy: 92.19%.\n",
            "pgd l1: attack effectiveness 0.11764705882352941.\n",
            "Mini batch: 129/300 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0946 | Train accuracy: 91.41%.\n",
            "pgd l1: attack effectiveness 0.09523809523809523.\n",
            "Mini batch: 130/300 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0435 | Train accuracy: 97.87%.\n",
            "Training loss (epoch level): 0.0613 | Train accuracy: 95.65\n",
            "pgd l1: attack effectiveness 0.0845771144278607.\n",
            "\tVal accuracy 92.77% with accuracy 91.54% under attack.\n",
            "\tModel select at epoch 12 with validation accuracy 93.89% and accuracy 95.02% under attack.\n",
            "pgd l1: attack effectiveness 0.046153846153846156.\n",
            "Mini batch: 131/300 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0677 | Train accuracy: 96.09%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 132/300 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0356 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 133/300 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0706 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 134/300 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0414 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.016129032258064516.\n",
            "Mini batch: 135/300 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0415 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.01818181818181818.\n",
            "Mini batch: 136/300 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0550 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.030303030303030304.\n",
            "Mini batch: 137/300 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0461 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.09836065573770492.\n",
            "Mini batch: 138/300 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0491 | Train accuracy: 96.09%.\n",
            "pgd l1: attack effectiveness 0.16176470588235295.\n",
            "Mini batch: 139/300 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.1132 | Train accuracy: 91.41%.\n",
            "pgd l1: attack effectiveness 0.38095238095238093.\n",
            "Mini batch: 140/300 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.1550 | Train accuracy: 89.36%.\n",
            "Training loss (epoch level): 0.0675 | Train accuracy: 95.73\n",
            "pgd l1: attack effectiveness 0.0845771144278607.\n",
            "\tVal accuracy 93.65% with accuracy 91.54% under attack.\n",
            "\tModel select at epoch 12 with validation accuracy 93.89% and accuracy 95.02% under attack.\n",
            "pgd l1: attack effectiveness 0.06153846153846154.\n",
            "Mini batch: 141/300 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0557 | Train accuracy: 95.31%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 142/300 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0267 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 143/300 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0734 | Train accuracy: 95.31%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 144/300 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0833 | Train accuracy: 96.09%.\n",
            "pgd l1: attack effectiveness 0.016129032258064516.\n",
            "Mini batch: 145/300 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0742 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.01818181818181818.\n",
            "Mini batch: 146/300 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0870 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.030303030303030304.\n",
            "Mini batch: 147/300 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0450 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.19672131147540983.\n",
            "Mini batch: 148/300 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.1016 | Train accuracy: 90.62%.\n",
            "pgd l1: attack effectiveness 0.20588235294117646.\n",
            "Mini batch: 149/300 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.1071 | Train accuracy: 90.62%.\n",
            "pgd l1: attack effectiveness 0.19047619047619047.\n",
            "Mini batch: 150/300 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0889 | Train accuracy: 95.74%.\n",
            "Training loss (epoch level): 0.0743 | Train accuracy: 95.43\n",
            "pgd l1: attack effectiveness 0.13432835820895522.\n",
            "\tVal accuracy 90.66% with accuracy 86.57% under attack.\n",
            "\tModel select at epoch 12 with validation accuracy 93.89% and accuracy 95.02% under attack.\n",
            "pgd l1: attack effectiveness 0.07692307692307693.\n",
            "Mini batch: 151/300 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0556 | Train accuracy: 96.09%.\n",
            "pgd l1: attack effectiveness 0.0625.\n",
            "Mini batch: 152/300 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0437 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.014925373134328358.\n",
            "Mini batch: 153/300 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0266 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.014705882352941176.\n",
            "Mini batch: 154/300 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0217 | Train accuracy: 99.22%.\n",
            "pgd l1: attack effectiveness 0.04838709677419355.\n",
            "Mini batch: 155/300 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0672 | Train accuracy: 96.09%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 156/300 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0974 | Train accuracy: 94.53%.\n",
            "pgd l1: attack effectiveness 0.015151515151515152.\n",
            "Mini batch: 157/300 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0687 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.03278688524590164.\n",
            "Mini batch: 158/300 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0577 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.07352941176470588.\n",
            "Mini batch: 159/300 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0784 | Train accuracy: 95.31%.\n",
            "pgd l1: attack effectiveness 0.09523809523809523.\n",
            "Mini batch: 160/300 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0535 | Train accuracy: 95.74%.\n",
            "Training loss (epoch level): 0.0571 | Train accuracy: 96.61\n",
            "pgd l1: attack effectiveness 0.11940298507462686.\n",
            "\tVal accuracy 92.15% with accuracy 88.06% under attack.\n",
            "\tModel select at epoch 12 with validation accuracy 93.89% and accuracy 95.02% under attack.\n",
            "pgd l1: attack effectiveness 0.046153846153846156.\n",
            "Mini batch: 161/300 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0477 | Train accuracy: 95.31%.\n",
            "pgd l1: attack effectiveness 0.140625.\n",
            "Mini batch: 162/300 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0699 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.14925373134328357.\n",
            "Mini batch: 163/300 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0670 | Train accuracy: 95.31%.\n",
            "pgd l1: attack effectiveness 0.04411764705882353.\n",
            "Mini batch: 164/300 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0287 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.06451612903225806.\n",
            "Mini batch: 165/300 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0356 | Train accuracy: 96.09%.\n",
            "pgd l1: attack effectiveness 0.03636363636363636.\n",
            "Mini batch: 166/300 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0448 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.030303030303030304.\n",
            "Mini batch: 167/300 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0297 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.03278688524590164.\n",
            "Mini batch: 168/300 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0320 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.029411764705882353.\n",
            "Mini batch: 169/300 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0615 | Train accuracy: 96.09%.\n",
            "pgd l1: attack effectiveness 0.047619047619047616.\n",
            "Mini batch: 170/300 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0228 | Train accuracy: 97.87%.\n",
            "Training loss (epoch level): 0.0440 | Train accuracy: 96.66\n",
            "pgd l1: attack effectiveness 0.07960199004975124.\n",
            "\tVal accuracy 93.77% with accuracy 92.04% under attack.\n",
            "\tModel select at epoch 12 with validation accuracy 93.89% and accuracy 95.02% under attack.\n",
            "pgd l1: attack effectiveness 0.046153846153846156.\n",
            "Mini batch: 171/300 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0692 | Train accuracy: 94.53%.\n",
            "pgd l1: attack effectiveness 0.015625.\n",
            "Mini batch: 172/300 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0216 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.014925373134328358.\n",
            "Mini batch: 173/300 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0226 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 174/300 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0092 | Train accuracy: 99.22%.\n",
            "pgd l1: attack effectiveness 0.03225806451612903.\n",
            "Mini batch: 175/300 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0224 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.01818181818181818.\n",
            "Mini batch: 176/300 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0256 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.06060606060606061.\n",
            "Mini batch: 177/300 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0471 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.03278688524590164.\n",
            "Mini batch: 178/300 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0245 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.04411764705882353.\n",
            "Mini batch: 179/300 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0690 | Train accuracy: 95.31%.\n",
            "pgd l1: attack effectiveness 0.047619047619047616.\n",
            "Mini batch: 180/300 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0297 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0341 | Train accuracy: 97.66\n",
            "pgd l1: attack effectiveness 0.1691542288557214.\n",
            "\tVal accuracy 88.79% with accuracy 83.08% under attack.\n",
            "\tModel select at epoch 12 with validation accuracy 93.89% and accuracy 95.02% under attack.\n",
            "pgd l1: attack effectiveness 0.13846153846153847.\n",
            "Mini batch: 181/300 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0843 | Train accuracy: 94.53%.\n",
            "pgd l1: attack effectiveness 0.03125.\n",
            "Mini batch: 182/300 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0356 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 183/300 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0176 | Train accuracy: 99.22%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 184/300 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0111 | Train accuracy: 99.22%.\n",
            "pgd l1: attack effectiveness 0.03225806451612903.\n",
            "Mini batch: 185/300 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0253 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.01818181818181818.\n",
            "Mini batch: 186/300 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0402 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.015151515151515152.\n",
            "Mini batch: 187/300 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0396 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.01639344262295082.\n",
            "Mini batch: 188/300 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0310 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.17647058823529413.\n",
            "Mini batch: 189/300 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0985 | Train accuracy: 93.75%.\n",
            "pgd l1: attack effectiveness 0.23809523809523808.\n",
            "Mini batch: 190/300 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0862 | Train accuracy: 95.74%.\n",
            "Training loss (epoch level): 0.0469 | Train accuracy: 96.92\n",
            "pgd l1: attack effectiveness 0.15422885572139303.\n",
            "\tVal accuracy 90.29% with accuracy 84.58% under attack.\n",
            "\tModel select at epoch 12 with validation accuracy 93.89% and accuracy 95.02% under attack.\n",
            "pgd l1: attack effectiveness 0.046153846153846156.\n",
            "Mini batch: 191/300 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0455 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.046875.\n",
            "Mini batch: 192/300 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0359 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.13432835820895522.\n",
            "Mini batch: 193/300 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0498 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 194/300 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0016 | Train accuracy: 100.00%.\n",
            "pgd l1: attack effectiveness 0.06451612903225806.\n",
            "Mini batch: 195/300 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0375 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.05454545454545454.\n",
            "Mini batch: 196/300 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0254 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.030303030303030304.\n",
            "Mini batch: 197/300 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0306 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.03278688524590164.\n",
            "Mini batch: 198/300 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0257 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.014705882352941176.\n",
            "Mini batch: 199/300 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0510 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.047619047619047616.\n",
            "Mini batch: 200/300 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0358 | Train accuracy: 97.87%.\n",
            "Training loss (epoch level): 0.0339 | Train accuracy: 97.44\n",
            "pgd l1: attack effectiveness 0.04975124378109453.\n",
            "\tVal accuracy 94.39% with accuracy 95.02% under attack.\n",
            "\tModel select at epoch 20 with validation accuracy 94.39% and accuracy 95.02% under attack.\n",
            "pgd l1: attack effectiveness 0.03076923076923077.\n",
            "Mini batch: 201/300 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0487 | Train accuracy: 96.09%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 202/300 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0230 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 203/300 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0141 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 204/300 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0140 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.016129032258064516.\n",
            "Mini batch: 205/300 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0141 | Train accuracy: 99.22%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 206/300 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0212 | Train accuracy: 99.22%.\n",
            "pgd l1: attack effectiveness 0.015151515151515152.\n",
            "Mini batch: 207/300 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0354 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.01639344262295082.\n",
            "Mini batch: 208/300 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0182 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.058823529411764705.\n",
            "Mini batch: 209/300 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0602 | Train accuracy: 95.31%.\n",
            "pgd l1: attack effectiveness 0.09523809523809523.\n",
            "Mini batch: 210/300 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0400 | Train accuracy: 95.74%.\n",
            "Training loss (epoch level): 0.0289 | Train accuracy: 97.78\n",
            "pgd l1: attack effectiveness 0.18407960199004975.\n",
            "\tVal accuracy 88.92% with accuracy 81.59% under attack.\n",
            "\tModel select at epoch 20 with validation accuracy 94.39% and accuracy 95.02% under attack.\n",
            "pgd l1: attack effectiveness 0.13846153846153847.\n",
            "Mini batch: 211/300 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0831 | Train accuracy: 92.97%.\n",
            "pgd l1: attack effectiveness 0.15625.\n",
            "Mini batch: 212/300 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0794 | Train accuracy: 94.53%.\n",
            "pgd l1: attack effectiveness 0.014925373134328358.\n",
            "Mini batch: 213/300 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0113 | Train accuracy: 99.22%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 214/300 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0015 | Train accuracy: 100.00%.\n",
            "pgd l1: attack effectiveness 0.06451612903225806.\n",
            "Mini batch: 215/300 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0351 | Train accuracy: 96.09%.\n",
            "pgd l1: attack effectiveness 0.05454545454545454.\n",
            "Mini batch: 216/300 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0375 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.045454545454545456.\n",
            "Mini batch: 217/300 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0331 | Train accuracy: 96.09%.\n",
            "pgd l1: attack effectiveness 0.01639344262295082.\n",
            "Mini batch: 218/300 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0185 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.014705882352941176.\n",
            "Mini batch: 219/300 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0368 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.047619047619047616.\n",
            "Mini batch: 220/300 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0429 | Train accuracy: 97.87%.\n",
            "Training loss (epoch level): 0.0379 | Train accuracy: 96.90\n",
            "pgd l1: attack effectiveness 0.05472636815920398.\n",
            "\tVal accuracy 94.14% with accuracy 94.53% under attack.\n",
            "\tModel select at epoch 20 with validation accuracy 94.39% and accuracy 95.02% under attack.\n",
            "pgd l1: attack effectiveness 0.03076923076923077.\n",
            "Mini batch: 221/300 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0389 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 222/300 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0195 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 223/300 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0148 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 224/300 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0053 | Train accuracy: 100.00%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 225/300 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0179 | Train accuracy: 99.22%.\n",
            "pgd l1: attack effectiveness 0.01818181818181818.\n",
            "Mini batch: 226/300 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0365 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.015151515151515152.\n",
            "Mini batch: 227/300 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0295 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.01639344262295082.\n",
            "Mini batch: 228/300 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0231 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.029411764705882353.\n",
            "Mini batch: 229/300 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0500 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.047619047619047616.\n",
            "Mini batch: 230/300 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0242 | Train accuracy: 97.87%.\n",
            "Training loss (epoch level): 0.0260 | Train accuracy: 98.22\n",
            "pgd l1: attack effectiveness 0.11940298507462686.\n",
            "\tVal accuracy 92.28% with accuracy 88.06% under attack.\n",
            "\tModel select at epoch 20 with validation accuracy 94.39% and accuracy 95.02% under attack.\n",
            "pgd l1: attack effectiveness 0.03076923076923077.\n",
            "Mini batch: 231/300 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0311 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.03125.\n",
            "Mini batch: 232/300 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0324 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.04477611940298507.\n",
            "Mini batch: 233/300 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0176 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.04411764705882353.\n",
            "Mini batch: 234/300 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0210 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.11290322580645161.\n",
            "Mini batch: 235/300 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0639 | Train accuracy: 94.53%.\n",
            "pgd l1: attack effectiveness 0.05454545454545454.\n",
            "Mini batch: 236/300 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0306 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.06060606060606061.\n",
            "Mini batch: 237/300 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0527 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.03278688524590164.\n",
            "Mini batch: 238/300 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0245 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.014705882352941176.\n",
            "Mini batch: 239/300 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0360 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.047619047619047616.\n",
            "Mini batch: 240/300 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0389 | Train accuracy: 97.87%.\n",
            "Training loss (epoch level): 0.0349 | Train accuracy: 97.37\n",
            "pgd l1: attack effectiveness 0.029850746268656716.\n",
            "\tVal accuracy 94.76% with accuracy 97.01% under attack.\n",
            "\tModel select at epoch 24 with validation accuracy 94.76% and accuracy 97.01% under attack.\n",
            "pgd l1: attack effectiveness 0.015384615384615385.\n",
            "Mini batch: 241/300 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0491 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 242/300 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0194 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 243/300 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0177 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 244/300 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0080 | Train accuracy: 100.00%.\n",
            "pgd l1: attack effectiveness 0.016129032258064516.\n",
            "Mini batch: 245/300 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0216 | Train accuracy: 99.22%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 246/300 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0351 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.015151515151515152.\n",
            "Mini batch: 247/300 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0391 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.08196721311475409.\n",
            "Mini batch: 248/300 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0417 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.029411764705882353.\n",
            "Mini batch: 249/300 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0352 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.09523809523809523.\n",
            "Mini batch: 250/300 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0441 | Train accuracy: 97.87%.\n",
            "Training loss (epoch level): 0.0311 | Train accuracy: 98.22\n",
            "pgd l1: attack effectiveness 0.07462686567164178.\n",
            "\tVal accuracy 94.27% with accuracy 92.54% under attack.\n",
            "\tModel select at epoch 24 with validation accuracy 94.76% and accuracy 97.01% under attack.\n",
            "pgd l1: attack effectiveness 0.03076923076923077.\n",
            "Mini batch: 251/300 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0309 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 252/300 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0101 | Train accuracy: 99.22%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 253/300 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0025 | Train accuracy: 100.00%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 254/300 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "pgd l1: attack effectiveness 0.016129032258064516.\n",
            "Mini batch: 255/300 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0134 | Train accuracy: 100.00%.\n",
            "pgd l1: attack effectiveness 0.05454545454545454.\n",
            "Mini batch: 256/300 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0233 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.15151515151515152.\n",
            "Mini batch: 257/300 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0709 | Train accuracy: 94.53%.\n",
            "pgd l1: attack effectiveness 0.06557377049180328.\n",
            "Mini batch: 258/300 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0371 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.058823529411764705.\n",
            "Mini batch: 259/300 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0600 | Train accuracy: 95.31%.\n",
            "pgd l1: attack effectiveness 0.047619047619047616.\n",
            "Mini batch: 260/300 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0232 | Train accuracy: 97.87%.\n",
            "Training loss (epoch level): 0.0272 | Train accuracy: 97.91\n",
            "pgd l1: attack effectiveness 0.06965174129353234.\n",
            "\tVal accuracy 94.02% with accuracy 93.03% under attack.\n",
            "\tModel select at epoch 24 with validation accuracy 94.76% and accuracy 97.01% under attack.\n",
            "pgd l1: attack effectiveness 0.03076923076923077.\n",
            "Mini batch: 261/300 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0371 | Train accuracy: 96.09%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 262/300 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0180 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 263/300 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0227 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 264/300 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0168 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 265/300 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0236 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 266/300 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0280 | Train accuracy: 99.22%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 267/300 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0212 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.01639344262295082.\n",
            "Mini batch: 268/300 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0183 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.029411764705882353.\n",
            "Mini batch: 269/300 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0365 | Train accuracy: 96.09%.\n",
            "pgd l1: attack effectiveness 0.047619047619047616.\n",
            "Mini batch: 270/300 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0265 | Train accuracy: 97.87%.\n",
            "Training loss (epoch level): 0.0249 | Train accuracy: 97.91\n",
            "pgd l1: attack effectiveness 0.10945273631840796.\n",
            "\tVal accuracy 92.53% with accuracy 89.05% under attack.\n",
            "\tModel select at epoch 24 with validation accuracy 94.76% and accuracy 97.01% under attack.\n",
            "pgd l1: attack effectiveness 0.06153846153846154.\n",
            "Mini batch: 271/300 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0366 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 272/300 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0091 | Train accuracy: 99.22%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 273/300 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0041 | Train accuracy: 100.00%.\n",
            "pgd l1: attack effectiveness 0.014705882352941176.\n",
            "Mini batch: 274/300 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0142 | Train accuracy: 99.22%.\n",
            "pgd l1: attack effectiveness 0.04838709677419355.\n",
            "Mini batch: 275/300 | training time in 1 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0222 | Train accuracy: 99.22%.\n",
            "pgd l1: attack effectiveness 0.01818181818181818.\n",
            "Mini batch: 276/300 | training time in 1 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0130 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.06060606060606061.\n",
            "Mini batch: 277/300 | training time in 1 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0311 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.03278688524590164.\n",
            "Mini batch: 278/300 | training time in 1 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0234 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.08823529411764706.\n",
            "Mini batch: 279/300 | training time in 1 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0572 | Train accuracy: 94.53%.\n",
            "pgd l1: attack effectiveness 0.09523809523809523.\n",
            "Mini batch: 280/300 | training time in 1 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0303 | Train accuracy: 97.87%.\n",
            "Training loss (epoch level): 0.0241 | Train accuracy: 98.22\n",
            "pgd l1: attack effectiveness 0.0945273631840796.\n",
            "\tVal accuracy 92.65% with accuracy 90.55% under attack.\n",
            "\tModel select at epoch 24 with validation accuracy 94.76% and accuracy 97.01% under attack.\n",
            "pgd l1: attack effectiveness 0.015384615384615385.\n",
            "Mini batch: 281/300 | training time in 1 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0351 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 282/300 | training time in 1 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0146 | Train accuracy: 99.22%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 283/300 | training time in 1 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0125 | Train accuracy: 100.00%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 284/300 | training time in 1 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0097 | Train accuracy: 99.22%.\n",
            "pgd l1: attack effectiveness 0.016129032258064516.\n",
            "Mini batch: 285/300 | training time in 1 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0138 | Train accuracy: 99.22%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 286/300 | training time in 1 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0234 | Train accuracy: 99.22%.\n",
            "pgd l1: attack effectiveness 0.015151515151515152.\n",
            "Mini batch: 287/300 | training time in 1 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0565 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.18032786885245902.\n",
            "Mini batch: 288/300 | training time in 1 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0954 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.029411764705882353.\n",
            "Mini batch: 289/300 | training time in 1 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0370 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.047619047619047616.\n",
            "Mini batch: 290/300 | training time in 1 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0160 | Train accuracy: 97.87%.\n",
            "Training loss (epoch level): 0.0314 | Train accuracy: 98.62\n",
            "pgd l1: attack effectiveness 0.12437810945273632.\n",
            "\tVal accuracy 92.03% with accuracy 87.56% under attack.\n",
            "\tModel select at epoch 24 with validation accuracy 94.76% and accuracy 97.01% under attack.\n",
            "pgd l1: attack effectiveness 0.046153846153846156.\n",
            "Mini batch: 291/300 | training time in 1 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0449 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.03125.\n",
            "Mini batch: 292/300 | training time in 1 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0165 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.04477611940298507.\n",
            "Mini batch: 293/300 | training time in 1 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0172 | Train accuracy: 99.22%.\n",
            "pgd l1: attack effectiveness 0.029411764705882353.\n",
            "Mini batch: 294/300 | training time in 1 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0154 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.08064516129032258.\n",
            "Mini batch: 295/300 | training time in 1 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0536 | Train accuracy: 96.88%.\n",
            "pgd l1: attack effectiveness 0.05454545454545454.\n",
            "Mini batch: 296/300 | training time in 1 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0336 | Train accuracy: 98.44%.\n",
            "pgd l1: attack effectiveness 0.015151515151515152.\n",
            "Mini batch: 297/300 | training time in 1 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0235 | Train accuracy: 99.22%.\n",
            "pgd l1: attack effectiveness 0.01639344262295082.\n",
            "Mini batch: 298/300 | training time in 1 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0149 | Train accuracy: 99.22%.\n",
            "pgd l1: attack effectiveness 0.014705882352941176.\n",
            "Mini batch: 299/300 | training time in 1 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0273 | Train accuracy: 97.66%.\n",
            "pgd l1: attack effectiveness 0.0.\n",
            "Mini batch: 300/300 | training time in 1 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0296 | Train accuracy: 97.87%.\n",
            "Training loss (epoch level): 0.0276 | Train accuracy: 98.22\n",
            "pgd l1: attack effectiveness 0.029850746268656716.\n",
            "\tVal accuracy 94.63% with accuracy 97.01% under attack.\n",
            "\tModel select at epoch 24 with validation accuracy 94.76% and accuracy 97.01% under attack.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test: accuracy\n",
        "max_adv_training_model.load()\n",
        "max_adv_training_model.model.predict(test_Loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l85ZkQlmlQER",
        "outputId": "5e4c926c-ab40-4429-b96a-cfc3ba4e7e71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy on the test dataset is 93.00000%\n",
            "The balanced accuracy on the test dataset is 92.94929%\n",
            "Other evaluation metrics we may need:\n",
            "False Negative Rate (FNR) is 1.98020%, False Positive Rate (FPR) is 12.12121%, F1 score is 93.39623%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_adv_training_model.adv_predict(test_Loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyzdZ9yWlQYz",
        "outputId": "fe689719-3193-49b8-a8b5-eb7fb5c30baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pgd l1: attack effectiveness 0.039603960396039604.\n",
            "\tadversarial accuracy  96.04% under attack.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9W1PQ2JpkzC",
        "outputId": "6aebc881-2c5e-45fb-ee52-f77f39c86473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "malware_detection  sample_data\t    train_dataset.pt\n",
            "naive_data.zip\t   test_dataset.pt  validation_dataset.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/naive_data.zip"
      ],
      "metadata": {
        "id": "sZsmPn-7pXNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/naive_data/*  /content/malware_detection/datasets/naive_data"
      ],
      "metadata": {
        "id": "xA-l_DCsp0vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/malware_detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlVAaUd7qB0A",
        "outputId": "de981a51-d847-49e6-918b-78006082ed14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/malware_detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/malware_detection/datasets/drebin/benign_samples"
      ],
      "metadata": {
        "id": "VJ3RmuI_qV6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m examples.md_at_pgd_test  --cache --beta 1.0 --seed 0 --batch_size 128 --proc_number 10 --epochs 50 --max_vocab_size 10000 --dense_hidden_units \"200,200\" --weight_decay 0.0 --lr 0.001 --dropout 0.6 --steps_linf 50 --step_length_linf 0.02"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7oDmU10ooJd",
        "outputId": "675311b2-4986-4af4-caf9-22871acf8a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "2023-10-27 10:24:13,621 md_dnn.py[line:85] WARNING: Unknown hyper-parameters {'proc_number': 10, 'number_of_smali_files': 1000000, 'max_vocab_size': 10000, 'update': False, 'cuda': False, 'seed': 0, 'batch_size': 128, 'epochs': 50, 'lr': 0.001, 'weight_decay': 0.0, 'cache': True, 'mode': 'train', 'model_name': 'xxxxxxxx-xxxxxx', 'ratio': 0.95, 'beta': 1.0, 'steps_linf': 50, 'step_length_linf': 0.02}\n",
            "2023-10-27 10:24:13,645 md_dnn.py[line:62] INFO: ========================================dnn model architecture===============================\n",
            "2023-10-27 10:24:13,645 md_dnn.py[line:63] INFO: MalwareDetectionDNN(\n",
            "  (nn_model_layer_0): Linear(in_features=6693, out_features=200, bias=True)\n",
            "  (nn_model_layer_1): Linear(in_features=200, out_features=200, bias=True)\n",
            "  (nn_model_layer_2): Linear(in_features=200, out_features=2, bias=True)\n",
            ")\n",
            "2023-10-27 10:24:13,645 md_dnn.py[line:64] INFO: ===============================================end==========================================\n",
            "2023-10-27 10:24:13,701 md_at_pgd.py[line:45] INFO: Adversarial training incorporating the attack PGD\n",
            "2023-10-27 10:24:14,411 md_at_pgd.py[line:68] INFO: adversarial training is starting ...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "2023-10-27 10:24:14,574 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ccc2375726990d6e4f1f4dcf86e385d3c4412e84ef855cc83936393ca029d380.feat, zero vector used\n",
            "2023-10-27 10:24:14,575 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ad7fc7837541688f78cb925f571077b58257a14c9bf88253ff42166d88a378de.feat, zero vector used\n",
            "2023-10-27 10:24:14,577 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/aba92f7b2fefd88fe3215a68b2bdb80beb22136eed4260a3cdafc1fa5a43d663.feat, zero vector used\n",
            "2023-10-27 10:24:14,579 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/4508b2f9fb48b439955f08ceae184ea7231471bb29c4fe7d8b912789f3d441c6.feat, zero vector used\n",
            "2023-10-27 10:24:14,580 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/af4ccf9a53b002afe86c8a7bf703b0afdf1befa988b421c94364c12435313397.feat, zero vector used\n",
            "2023-10-27 10:24:14,581 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5c6f2c30e828a40a434eb1d4dd78ce1c17a136e3f362f6e1dd55ba20169caaae.feat, zero vector used\n",
            "2023-10-27 10:24:14,582 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/298dd2564cfae8576228f6b7da35f94ae00d62242c16beb8d061e2d106d93135.feat, zero vector used\n",
            "2023-10-27 10:24:14,582 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8d1e48144a733d5d64e8dc211853d524a991582dfcdf10da58a0de7be7a9cfcc.feat, zero vector used\n",
            "2023-10-27 10:24:14,583 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/0282fa1f63271e900a52a5482307028f47f4c1ce2023c0c8a1dadd68d916c299.feat, zero vector used\n",
            "2023-10-27 10:24:14,588 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5c08109d12d6f35c7edd1842d1e9273d726943f7e45c10c13c25c09f52a7a4cd.feat, zero vector used\n",
            "2023-10-27 10:24:14,589 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/98a046cc7ad795e640cc394c516dfe37411b38bb8fa2afed18fe4f19d506d813.feat, zero vector used\n",
            "2023-10-27 10:24:14,589 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f39b832ae1ee70e9ad993544a05c392e7fecd6789572f439c40a5f2ea4280ddf.feat, zero vector used\n",
            "2023-10-27 10:24:14,590 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6a24586a51837fec5755645f9b518ccfd5e183a74f8eba14aecd8011e0ee0e9c.feat, zero vector used\n",
            "2023-10-27 10:24:14,600 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/0e546be7c6e9c1a6110ef6c7b9d936c3098287c267c4ec80c92457b823fabc33.feat, zero vector used\n",
            "2023-10-27 10:24:14,612 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5fd4a8d3cf03ffe7e2661c829f553424fba9ef531ff7e6b6f0092b22bfe7945f.feat, zero vector used\n",
            "2023-10-27 10:24:14,613 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/48501843d00955d0bd810db740810a7a7d70941215538c00973ea19c47e8fb8d.feat, zero vector used\n",
            "2023-10-27 10:24:14,618 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d421f6704b146b5d301e5a53bc9179b17019a5dab215f7b2e1f1a35fc9ab792b.feat, zero vector used\n",
            "2023-10-27 10:24:14,629 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/243b1107c6f092ad78eb21915c5b400afde9d920e377af77c1e6d50a77a42a94.feat, zero vector used\n",
            "2023-10-27 10:24:14,647 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8b8b70379cda3d98025b2edd550913ee0c0a6081de310d444c179e2937437052.feat, zero vector used\n",
            "2023-10-27 10:24:14,648 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f6bec2d167f1ca611429e0c62c721d68f30adfba9baf6af323b229718f9650c4.feat, zero vector used\n",
            "2023-10-27 10:24:14,650 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/13af1e0e4e341c554a65e3fa0e1dfe36d139e04bc3690ab3cd53bab243a945d7.feat, zero vector used\n",
            "2023-10-27 10:24:14,650 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/cbcde5c2051741adfa50b7073ab2082fb6e45662df0b048d103cda3cc62d89fb.feat, zero vector used\n",
            "2023-10-27 10:24:14,652 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b0e12500a0f445c705827b54d96404796b91ed9ff3ad80150df40a592da314ca.feat, zero vector used\n",
            "2023-10-27 10:24:14,653 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b5de3ab0f862aa4ab92ce3a17c913d84dc6b6feaca66ea17e16b50ecf06ebba5.feat, zero vector used\n",
            "2023-10-27 10:24:14,653 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5346bd6802d1404739f299a19e62931c89632af172ad18503fa1e7d5a31d7f11.feat, zero vector used\n",
            "2023-10-27 10:24:14,654 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/0f41e5f54eb380a1e671f6595d3f2671e29f695fd05a7103020c3202045b3c99.feat, zero vector used\n",
            "2023-10-27 10:24:14,656 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1cd187c159c04bd9773eb18dcf59c1409f1ec27fade37428c9738ce2eb2be43b.feat, zero vector used\n",
            "2023-10-27 10:24:14,657 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/fe2ecbbc180cb2ec8ce40d5320c150a09a4d9de4933e700d086106133e25fea4.feat, zero vector used\n",
            "2023-10-27 10:24:14,658 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6c95120fbee2be2e59cb27851b1e94ed34f44f21c7cb362dd7feee77a2aeda68.feat, zero vector used\n",
            "2023-10-27 10:24:14,671 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/fd738fc13c48ab19561c067dc33ef739ddcec4adee37335996a58f4da0af7987.feat, zero vector used\n",
            "2023-10-27 10:24:14,672 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/50f747e6b91e96c946792ef5f3626cd09a32219f0439451c59428b7bded81b59.feat, zero vector used\n",
            "2023-10-27 10:24:14,674 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b7972790f3f50fa898133e3cef4c575d54ed2e31baf7fe4aa5f250758fea91f3.feat, zero vector used\n",
            "2023-10-27 10:24:14,687 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/aed6586f8742ced00da20210491bc5e365a164fabc3c2a8319c9038fb2076a4b.feat, zero vector used\n",
            "2023-10-27 10:24:14,688 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/16a4ec2156cda5a4bf2e3a63fbde4e5ee7f3ac9ae28e721d1044301e923feaad.feat, zero vector used\n",
            "2023-10-27 10:24:14,689 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ceb6bfd6727c1d15ff3957bb8cfb4aa4bdfd6caac9d6a93fd540021b0236509d.feat, zero vector used\n",
            "2023-10-27 10:24:14,690 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/09911cfc3c41cca04b69d0cec8d4cd2766b90c74dae4a756a92a913f90b3f784.feat, zero vector used\n",
            "2023-10-27 10:24:14,692 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/60c39f985ec69f160dc6f8db3a84eb7358bbce21f98246e8f1746402c158debf.feat, zero vector used\n",
            "2023-10-27 10:24:14,694 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5c7add30261da84f2d2c2bd6341dd761cd0489e7993e23b2a2c8ac3d67b70d5a.feat, zero vector used\n",
            "2023-10-27 10:24:14,695 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/455c2754c124dde74afe38acd325d9227b8ab0ff57b759eb158b08ee6a15c69c.feat, zero vector used\n",
            "2023-10-27 10:24:14,696 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d62433264e24dcb5608bfacb8c298125c2ee3e4797ecf42f79c981cf5a9a3d34.feat, zero vector used\n",
            "2023-10-27 10:24:14,702 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/259f679ddc8206c9e2e65df41cd08184c692cda5251d1cab18dc568f128d4b94.feat, zero vector used\n",
            "2023-10-27 10:24:14,703 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/589014632bd11bac05bcccc58540e0a0abcc5a23d1ad2604294e7396821a176e.feat, zero vector used\n",
            "2023-10-27 10:24:14,706 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1929cf0f88c20a187e57be8a6023a409257d038df7850a83275b0c2de6a734bd.feat, zero vector used\n",
            "2023-10-27 10:24:14,707 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/38c9d2724f5a82f94c70924d3a92a81cd67430a805521b19cb5fd9b78374c81b.feat, zero vector used\n",
            "2023-10-27 10:24:14,709 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/bcf416fce18e755edc6dd4a401492b0b8817e448a57d88f58847ef89183f3073.feat, zero vector used\n",
            "2023-10-27 10:24:14,711 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/78f42c9a161db18ba411563fc25d7ae095a80fcbb1054eec384cff0bf4f2d341.feat, zero vector used\n",
            "2023-10-27 10:24:14,712 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/808177a5b479db3257c0a55bdf0414786d4671d907bd861f5b8f4f00dc26ea0b.feat, zero vector used\n",
            "2023-10-27 10:24:14,716 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/cced3cb9001de597ca4d0562a1dbb40b97bc5f6f1af86f4c6ac950c2b63be64d.feat, zero vector used\n",
            "2023-10-27 10:24:14,716 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1359a9ec52da80c3930b1d63806e0a29e963de518324ba51575525117f1e612a.feat, zero vector used\n",
            "2023-10-27 10:24:14,716 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/20f24cee228d2d065e32dcb0d7ec53b28d79761d2d7b8d687972385d4cda81d7.feat, zero vector used\n",
            "2023-10-27 10:24:14,717 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/dbbd5b3c7b8f975c9c45b200ac64230631068a8744b32d622388ce3303b20ce3.feat, zero vector used\n",
            "2023-10-27 10:24:14,718 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b94154cdc49049128ae82c8f4e74ae0a2c22edf8f6c08461bb657fc6c377eba4.feat, zero vector used\n",
            "2023-10-27 10:24:14,719 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ead135f4b5fffccea12f0c1dd2a690ece1623151280d0d5d6ce621ad9fb5e09b.feat, zero vector used\n",
            "2023-10-27 10:24:14,723 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8ca25cc01494a333443ee61e67d8a9182481c7860a87c70465bb8b1cd66bd62e.feat, zero vector used\n",
            "2023-10-27 10:24:14,724 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/23a4495c327d31786e56639b284523b0b9d874565516e721cd361d23dff732f2.feat, zero vector used\n",
            "2023-10-27 10:24:14,727 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d2c1c7061f838cd92d60cf7893b2759ffa902ac7696375cba7e02d61abb675e0.feat, zero vector used\n",
            "2023-10-27 10:24:14,728 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/12a844240c8611041d6488fd79be9bb3fd645d1d1f24b3d0f26e4a0b3609ecf9.feat, zero vector used\n",
            "2023-10-27 10:24:14,728 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b2a95107f5abc9725dfe551653e3c624531195d385552e150f85b71c3380d092.feat, zero vector used\n",
            "2023-10-27 10:24:14,733 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b5223b05ad56871fda57482f34c7b32c52d7facfd6af89cc0bc090b2521f7e61.feat, zero vector used\n",
            "2023-10-27 10:24:14,735 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/3474555c2d7b85027a8e0f80d927d66e028fe45d4c4bf515850f9fdc7a6076c8.feat, zero vector used\n",
            "2023-10-27 10:24:14,736 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/c39c2e453117c6c2061573666340667f66afdf3da281ad3ff3a8839d19261204.feat, zero vector used\n",
            "2023-10-27 10:24:14,738 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6ed974cc9d0b111ed581bf8142a4b37dacb640e224f2c416f1b20bb6292364bd.feat, zero vector used\n",
            "2023-10-27 10:24:14,740 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/02dbe2fcf59a29cf64d28ba34aa66bd9f81009835bfc7b2987f44d9592438aa4.feat, zero vector used\n",
            "2023-10-27 10:24:14,741 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/9e9c4226cc482e28b0071de257e5a9c70484fa8ed0840b7afeb7b376eda073da.feat, zero vector used\n",
            "2023-10-27 10:24:14,744 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ed39e5e47c88086724032179c3f14e63788a3059a49607bade53d522d91b52e3.feat, zero vector used\n",
            "2023-10-27 10:24:14,745 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/473dcdbf9db0eae2c6c4056dd6e416933c026a17043b1c22c2f8ac202773f6d8.feat, zero vector used\n",
            "2023-10-27 10:24:14,752 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/9342eb215d51556844c22f3628c1a29150fd6eb49a67a6c32f8eabad3a0b7a42.feat, zero vector used\n",
            "2023-10-27 10:24:14,762 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e86d338a6fe1e910e80d4ff3b8f38c348244c5e67f4dded8c626591bbfdd5b59.feat, zero vector used\n",
            "2023-10-27 10:24:14,766 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/67b0ee9530d27afbfb08863b42e36acae902c6399f3be84a896b7e1a6337c168.feat, zero vector used\n",
            "2023-10-27 10:24:14,767 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d6b8a2706644903ef70c4f3a7f1e15573a9da3b2b1302f26bd0421a81d5c875d.feat, zero vector used\n",
            "2023-10-27 10:24:14,771 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/bf5a7fc54ab1ffdfd096629ef8c6a6f6200a407066e1bc1e70e4ede48fca5329.feat, zero vector used\n",
            "2023-10-27 10:24:14,771 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ed72ad632ed35f23a43803534592e4af773c34e9496272e156a733d8d9054d61.feat, zero vector used\n",
            "2023-10-27 10:24:14,773 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a888ee7d97cd5670117494a78740db45535e36d5b99a6016aca05b999a289093.feat, zero vector used\n",
            "2023-10-27 10:24:14,777 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/70e8a3cc4f69ea0a94c5b3be2cb48cd3ac0b0d4d8ef3e3104c0f80be74fb7426.feat, zero vector used\n",
            "2023-10-27 10:24:14,777 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/39de2b61a629729c72c27d86e64a452432dc6564de54f2be2c7dd8ebb0e86976.feat, zero vector used\n",
            "2023-10-27 10:24:14,781 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/24549cb7b49c35f6cb08d9af988ca7d62dee8c3c66aea719f5d5ce07c4565c18.feat, zero vector used\n",
            "2023-10-27 10:24:14,786 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2d045d788cd57c78ecc9370f9a7f2576bde8d43becc9786a2939fbcb7f05db47.feat, zero vector used\n",
            "2023-10-27 10:24:14,788 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/0ce7117d07049397cdce4bfda323e023d9106ddbe596cf958c71933b2a2beb38.feat, zero vector used\n",
            "2023-10-27 10:24:14,789 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/57ef773c8ddcdcf6332ca5c874829129db896ea1998670b2ae6be42ec0d2fad8.feat, zero vector used\n",
            "2023-10-27 10:24:14,792 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ec70b29b0cce321814c7a21cc7a57c5b03e112c91007543cfafb4439c938941b.feat, zero vector used\n",
            "2023-10-27 10:24:14,793 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/547753d5244cf95aafd9de1d0aeb12c321f86962d4ca69efbe4e0d8e7168bdd3.feat, zero vector used\n",
            "2023-10-27 10:24:14,793 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d58ea311095fe5457e35c89f9ab899f1ac7d22fc8dc8ce69867ff5f78b97d3b3.feat, zero vector used\n",
            "2023-10-27 10:24:14,795 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d79d71829807376487e650fefb6583b77b25cc140b54cfe779ba9363beb9d24c.feat, zero vector used\n",
            "2023-10-27 10:24:14,796 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d400ece5da723e32cfc380b2d8045fccfd382dd0f4d02724f35da21533345de7.feat, zero vector used\n",
            "2023-10-27 10:24:14,796 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/c74cb1ffe79f4065227413b5ce890baa27203b8aa7904c041a58e18f112d0c87.feat, zero vector used\n",
            "2023-10-27 10:24:14,797 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/876f0aeb87e225fd3851d960c5ddcf1f8774e923c9f386d756ca01449e4ad5af.feat, zero vector used\n",
            "2023-10-27 10:24:14,797 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/0a989c0a0c198d7e1cc830e8b4413ec796c62a339fb19ce8d9bfd13bd443e168.feat, zero vector used\n",
            "2023-10-27 10:24:14,800 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/403da3ffa9d2b9ced5aed5c877d44a8e31173d37ca3c8ce3238d32fca7358e9e.feat, zero vector used\n",
            "2023-10-27 10:24:14,802 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/9cb2b7c6da8db01a1dd0737ad5139350d149c1678adc8cd2ad81e123cfdad7c9.feat, zero vector used\n",
            "2023-10-27 10:24:14,805 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/0cf633bbfcb990647eb0a2f0054402f0d9b5b92b5b249da49d4fea0861c27135.feat, zero vector used\n",
            "2023-10-27 10:24:14,806 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f89da6343e5a60626e77df151df2f3d2ac0638cac77fb1de59104a6a0b512cf3.feat, zero vector used\n",
            "2023-10-27 10:24:14,819 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a2673130c44733139bc65dd19a1270146b43afee46180e811077ccf0b4279475.feat, zero vector used\n",
            "2023-10-27 10:24:14,819 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6f11f443a313ab9d66d991d209e3399daaf7d3a79851e769fd4a50cb699c391e.feat, zero vector used\n",
            "2023-10-27 10:24:14,825 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6c29f2a4d18dec7fed0852ecd1b6c3d756ee257de563c2f028106413828b12fb.feat, zero vector used\n",
            "2023-10-27 10:24:14,826 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e6a001eeeea25e15e5cae23a9aa2fab225c999e87ace481e26cdfec380496098.feat, zero vector used\n",
            "2023-10-27 10:24:14,828 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/16bdb0798be7427367b5c10ef829b43f7533470369d6bcd699eb6e29d86969ce.feat, zero vector used\n",
            "2023-10-27 10:24:14,828 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/70635c0e726ffb65b526e38a2ec422d654bbd79d3017b17548365df18df87dff.feat, zero vector used\n",
            "2023-10-27 10:24:14,841 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/89d7f3a5bd7a1f0341b17356004cbe235d985b73bf2b94ebe3b4b4b7c931c9d0.feat, zero vector used\n",
            "2023-10-27 10:24:14,842 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/bd5a89a7252394264d8bbc4c3e8cc689f489a6aecd5cd2e4e80f11c51e15d6ee.feat, zero vector used\n",
            "2023-10-27 10:24:14,842 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6735c622bd51983889b820872ebf281e49267d34c1a1a25ad9cccc1e57df40db.feat, zero vector used\n",
            "2023-10-27 10:24:14,864 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/49cb806f798107ec48e775f4c0f8ea7536b17b1ad64305d9f8d7a81d278c8af9.feat, zero vector used\n",
            "2023-10-27 10:24:14,865 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f2347f7020facd54dd3e35ace87eca6410ec7c6adc993b783e699a3c5490b17e.feat, zero vector used\n",
            "2023-10-27 10:24:14,868 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8cb3c6d6c0f4c90e3584d81e297fa24362c6c8eb1d54b6c1bda61585b172173d.feat, zero vector used\n",
            "2023-10-27 10:24:14,869 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/94755a123a3108218c800fa425bad359579043e1d3cce7cd2f0f7ea58264d04b.feat, zero vector used\n",
            "2023-10-27 10:24:14,872 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5ead312d1f17bf4369ba0dea2a941768ab79a92597367bbaa01f803c04e33a10.feat, zero vector used\n",
            "2023-10-27 10:24:14,872 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5d702a784359b42bd2246c027898318874a29a11b980ac890c2d03b650bf5b51.feat, zero vector used\n",
            "2023-10-27 10:24:14,877 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/7efc76a0b0911c868373f46087ba764afefb6f69dce19904393b0bbebd40d4f2.feat, zero vector used\n",
            "2023-10-27 10:24:14,879 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d7c56c4b5107eb0b51867ddbd1b9f5eb1d2634d80de5ee9c53bf7d268a77711d.feat, zero vector used\n",
            "2023-10-27 10:24:14,882 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b5a5f2037949fbd4d61d0c4235fabbd7b0a92e42b330228ef557eeca9253b747.feat, zero vector used\n",
            "2023-10-27 10:24:14,883 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ca3f2b7eed4aabf1390489b1efa45c26b6742f2203f3fe6e29535cb4d5c5ce06.feat, zero vector used\n",
            "2023-10-27 10:24:14,886 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6207b41482c143e529102d1ecec3eac1b14b2c11ae1c2ca7f258345e228ecec2.feat, zero vector used\n",
            "2023-10-27 10:24:14,894 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/9ba79ab7de6fda884df681eb98263922ce7d765ae061a2c71accedf3bb4edfc8.feat, zero vector used\n",
            "2023-10-27 10:24:14,920 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/537c99172dccb3b1eed2afe3a0be7545310479d959f6170168d1641d40435ca9.feat, zero vector used\n",
            "2023-10-27 10:24:14,921 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/829e1a6d14b8f212c404d0d9b3759dee158d14b60852445e20ceb424e6d16ed8.feat, zero vector used\n",
            "2023-10-27 10:24:14,922 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2d240a51fa183f194495e6fc59cdc0365453e37b2491604ba423afd2fed7e25c.feat, zero vector used\n",
            "2023-10-27 10:24:14,927 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d7efe13331b8e9f6ca7ac7223c01778d165b7cbc64309a83e8b53a2cf11c6f18.feat, zero vector used\n",
            "2023-10-27 10:24:14,927 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f9f5e4a8b7c8024739b0c36dd64447ce4d8fdc9e384bf0cb9ed5b0ec307caacd.feat, zero vector used\n",
            "2023-10-27 10:24:14,928 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a3026387741c12a0f7a0fbc472743b653f2d3ed8a49b7c12924eb192af5d2355.feat, zero vector used\n",
            "2023-10-27 10:24:14,928 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/76df57eb622af40a425d785f5dbc2c5f64d2ecd6578777d51ec2c22dfa46d175.feat, zero vector used\n",
            "2023-10-27 10:24:14,931 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/62ee3b74bfe7480b90ba7899b490c873c6968448b8d608c01661faa1342e9026.feat, zero vector used\n",
            "2023-10-27 10:24:14,931 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a068908bf78e27fcb8080eafcb2bb03aca6f76e44782e815eba32edeb8d5506f.feat, zero vector used\n",
            "2023-10-27 10:24:14,936 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/268403cab70e208919a84fdac0b033513ac82a4e175e4dd60079489f3c7d4da5.feat, zero vector used\n",
            "2023-10-27 10:24:14,937 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d86acc26805ada488dc835d75a213deff47a91dfb8cbf12431727d1d03e75551.feat, zero vector used\n",
            "2023-10-27 10:24:14,939 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d898a8e8d70c750ae39fb681b5e5bef025475bd1fc89c7c1b5a8bc17150a142e.feat, zero vector used\n",
            "2023-10-27 10:24:14,942 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a8fdab184c4caba236681d784be4f28bf1a2d0f55e72c8b57a85e8d33e333d48.feat, zero vector used\n",
            "2023-10-27 10:24:14,957 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/afcd76bda991d91dd019059f1727cf9f18a801c4d477b32733ad6150048f90a2.feat, zero vector used\n",
            "2023-10-27 10:24:14,959 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/93319444ba41c07b8eee54030d6779996ddc60dba4b8ec2ba3d84d7082649b74.feat, zero vector used\n",
            "2023-10-27 10:24:14,963 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/22a15d5695d28c7143066492cfc1c2e725e96b3d6a10dd214c9254d5e2361008.feat, zero vector used\n",
            "2023-10-27 10:24:14,963 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/0f7177a88f65b3c3e992f5b1cb2195602bb7ce86c3b6ee1283009b90feba72c1.feat, zero vector used\n",
            "2023-10-27 10:24:14,969 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/535590e1e3e367b30165378bd8f05874552bd74e36c74c4f1f4775d29b6e7f51.feat, zero vector used\n",
            "2023-10-27 10:24:14,972 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6e4cdcf3a193536d9b0dc53b460b3aef9e24f75389d6f4e087d39669f8aee20a.feat, zero vector used\n",
            "2023-10-27 10:24:14,973 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/3b25290f68f18d39626ef95a3d84d72cd7e8b805befccb29b6d7def1cd0357cc.feat, zero vector used\n",
            "2023-10-27 10:24:14,981 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/7eebac6a5a57c208e1b982366fdce4297c815491cf7696bc53f3945e11166ec9.feat, zero vector used\n",
            "2023-10-27 10:24:14,984 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b82ff1c36849300c13b7ccb21597fff28a65215aad9f7d23ffe1d034e7bcd8ec.feat, zero vector used\n",
            "2023-10-27 10:24:14,985 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d192fa6e8daedca73583043ae7f8eea33569f2c66adf241c1a5aaa545e13eab2.feat, zero vector used\n",
            "2023-10-27 10:24:14,986 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/bd82e6c3ce35a624e69353ebffa19c51de7dccf26a132d4afa404a18857e5d4a.feat, zero vector used\n",
            "2023-10-27 10:24:14,990 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/0d911db9fe7cd1c58a65c3847d5537d720748fc662611693fb80d389798c1738.feat, zero vector used\n",
            "2023-10-27 10:24:14,996 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/27cbf5a5af24d2be1f173db82071ba5117167f7f1b0b2cd998d0170d4e30f662.feat, zero vector used\n",
            "2023-10-27 10:24:14,997 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a07b76ece569526c3dd2a1d5c8618ed76ab82397132b53cec98a3ed6aa20e957.feat, zero vector used\n",
            "2023-10-27 10:24:14,997 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/3f8787f90cefefcc075aab36abef937bebf7932babfed851a102a4237c4b4660.feat, zero vector used\n",
            "2023-10-27 10:24:15,002 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b32d01c0afb60912a0bcade6790a41c14464d4a5f6edc26e5a36621a01180149.feat, zero vector used\n",
            "2023-10-27 10:24:15,007 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/0cb8fb25d042d2b9f9dcb34ecb27be2ef9870b34d8b83bc8c0a1a26f30598683.feat, zero vector used\n",
            "2023-10-27 10:24:15,008 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e8d8f7a53f5ec8515b94e03f003213fbc5f15376dff2448850da7c701833fd7f.feat, zero vector used\n",
            "2023-10-27 10:24:15,009 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/20046dde17daaaa628ee136cc1890568f4febe0b6fb1e13a8d7647d9f9751dfd.feat, zero vector used\n",
            "2023-10-27 10:24:15,010 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/76f985e9a3eb14510cb0bc0fa56904f7a3abcef969e7dda1486c761bdb12f14c.feat, zero vector used\n",
            "2023-10-27 10:24:15,011 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ad56941fe39254d8ffd95c530ea9cd25f9f1bc2cce0e354cb89282681f307e1d.feat, zero vector used\n",
            "2023-10-27 10:24:15,013 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/45c335d014a76754f9cf625e7be07a6820610f8dc4dd8660e8784b4064b46e43.feat, zero vector used\n",
            "2023-10-27 10:24:15,022 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b2ade9c8e7217d69467955ae343fe7e869f71c59c3eb4ac5a8987828a12c7ba9.feat, zero vector used\n",
            "2023-10-27 10:24:15,026 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/28f626ce13d1c11a848a9da2239a6a86cc234600295bbd42f7e0a1399085ddee.feat, zero vector used\n",
            "2023-10-27 10:24:15,043 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/026295d8639a0d73a836da7cd9131c7a21e9466a8313f469ee5e5b1714c008a4.feat, zero vector used\n",
            "2023-10-27 10:24:15,048 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/be467d6d56f1c11b819481072ac40438b307b31a4651eb79509b5e84ce240e15.feat, zero vector used\n",
            "2023-10-27 10:24:15,048 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/4a74ed4d45e725f32f5925ca8ae6d3c858ce87af53f3728861af1cc209152b54.feat, zero vector used\n",
            "2023-10-27 10:24:15,060 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/bb2276ef559959ca1b13a8b418cb41faff7bedc5d43036328da96ef85fe93277.feat, zero vector used\n",
            "2023-10-27 10:24:15,063 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ce93b6020794676cdcd399ec5c4c0778e9d99d09cc0759d5b3866e4f39c0bdf1.feat, zero vector used\n",
            "2023-10-27 10:24:15,064 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/410219b5bd6e6d91751c01536e90600b21fee1da9bd07d1a1b8b53b6d16b0ac5.feat, zero vector used\n",
            "2023-10-27 10:24:15,064 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b9091b479e5ca9df7d1774143fb8f860c4b1775b6fe6415e9e796b8267f35467.feat, zero vector used\n",
            "2023-10-27 10:24:15,067 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/4e702c95621e576088c0328bd2e4a33638d492acf015faba022c00c003aea788.feat, zero vector used\n",
            "2023-10-27 10:24:15,067 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6b5e4cd83dc25c797e9f5a1b38f0e7ceaf8fac9b328ea56f2157eca393a57be7.feat, zero vector used\n",
            "2023-10-27 10:24:15,068 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a16210005be6af426982b98f0bcc80b123fae37888f7c4e6a52c6cf942bc2255.feat, zero vector used\n",
            "2023-10-27 10:24:15,068 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/bb02b57872eab1bcf81b4544d26b5b2ac5918d8d8bcb90db9d72b79493d632ce.feat, zero vector used\n",
            "2023-10-27 10:24:15,070 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/7f4b9d4c9ecafe5e2759ec5801a6cd88d2612fd7ecbcb5a20588336bcee7d18a.feat, zero vector used\n",
            "2023-10-27 10:24:15,070 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/df1ee8fa58ec872ce141e03374d88437b2abbc1c4115046131dfa1abeab42415.feat, zero vector used\n",
            "2023-10-27 10:24:15,071 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6d80f700358be48e9187f1b4245a06994dca07dcc57d8f795baa31d37fce3215.feat, zero vector used\n",
            "2023-10-27 10:24:15,072 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/59c8ebb0908c9d630e3ff839f9e4081960c20f80a407be163677bc3ac4ff8341.feat, zero vector used\n",
            "2023-10-27 10:24:15,072 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/cf3fc8c289523a86ea46a564524c878e0a7a17d7013df49eb21c23f108045170.feat, zero vector used\n",
            "2023-10-27 10:24:15,073 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/bd19e7b31d567f13fb2bbe09073e17c45009f3cf09f604756d074fff21cecfed.feat, zero vector used\n",
            "2023-10-27 10:24:15,073 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/af1d2e8f61e2df2e2dcddf81e13691c9d1ed7ca663363c1485828b99850dd3e0.feat, zero vector used\n",
            "2023-10-27 10:24:15,073 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/bd13a56f6f574e450030f34809659a2d21d6863d1ab3b80e1eafd95ce7f8183c.feat, zero vector used\n",
            "2023-10-27 10:24:15,074 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f5db95d07275b3056cc87c95414134c751a9e0c16382057cfa259dec60d5805f.feat, zero vector used\n",
            "2023-10-27 10:24:15,075 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ddc3fadb653d336600ad91f85128a23abbd06cb892e4bc477fd5922e3a4361d5.feat, zero vector used\n",
            "2023-10-27 10:24:15,077 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/24e8e2336e46328f46ac22e4d3189a482e8c113b6f2bca6f5950269ad12e88c6.feat, zero vector used\n",
            "2023-10-27 10:24:15,077 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/384a369bee09d30f1b3d3b19e85a2900a1149165a4143c47a2a74afef72991fe.feat, zero vector used\n",
            "2023-10-27 10:24:15,080 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/72a8c196ebc9ab4496acbb7ea4da739224ce2b50d0c6f975553290894201bdd0.feat, zero vector used\n",
            "2023-10-27 10:24:15,081 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/53bbe36bd7102429e2d5b6a0ed9766882b635e30e908dec70dc3b867dbe33609.feat, zero vector used\n",
            "2023-10-27 10:24:15,081 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/667c883eb7f654c9e295377ecd8147f17f6ce9b014ad9ca6f583c31b417a3cba.feat, zero vector used\n",
            "2023-10-27 10:24:15,084 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/31ab52fcbc7a6a3ebbf4768694cd0a05a8cba57d0cf7a8b69b90a5f9d0b27b61.feat, zero vector used\n",
            "2023-10-27 10:24:15,084 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/95a48a2aa80ca96ac8af6c120709a1d5d60443bb9d848a528333412ac7b66f7e.feat, zero vector used\n",
            "2023-10-27 10:24:15,085 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/3cafb98828d6c54c401382930ed927fb79523bd99fdeceab9b8fb1b5e9cd4546.feat, zero vector used\n",
            "2023-10-27 10:24:15,086 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/7ac21aa4ad5e59aaa3161fe82be47db1df76064d7f6486f1e8de03e68dbcbdef.feat, zero vector used\n",
            "2023-10-27 10:24:15,089 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/81a064191e8c0ada606011994fc29286666c702f4259c68d05c49ce82a1ca2b1.feat, zero vector used\n",
            "2023-10-27 10:24:15,092 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6d49a6f0e1ec4386d8bc73a9c16eb58d31a35eeb70e1fbcb4337600d2faf160e.feat, zero vector used\n",
            "2023-10-27 10:24:15,092 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/9fc8d5ae665c0b27d24650fbbf145d20da9ef1619da274f8ade7be375df19d8b.feat, zero vector used\n",
            "2023-10-27 10:24:15,095 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/7f087df4b8d62a576d7618fa85c1c2f54e99314e202b0d00ff36ad4f4a85b1f1.feat, zero vector used\n",
            "2023-10-27 10:24:15,108 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/83c7d54afed5e5e44f4f8c1386fda806c6493c3d5eb7a52af26b6614e07b01de.feat, zero vector used\n",
            "2023-10-27 10:24:15,110 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5bf288d3ae84382aba51581979b14ea6064f5690271443f5211ec6361183e00a.feat, zero vector used\n",
            "2023-10-27 10:24:15,115 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2ffec65066ce81985285a0564335b4197fc2f45c05012deb7d8b9914afdb690e.feat, zero vector used\n",
            "2023-10-27 10:24:15,117 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/4e0853e5af0349be6cd6e2c6346354b226397fb0e2a56767aeeb28edf08a1da9.feat, zero vector used\n",
            "2023-10-27 10:24:15,117 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/61d65931f147b42816fe40ec27f769efc4faa30a76e092ab0624032c29efb495.feat, zero vector used\n",
            "2023-10-27 10:24:15,118 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/cc710518171beb52d9099c0509c5f4d2c62879ae861d3adcf33df4f62a37cc7f.feat, zero vector used\n",
            "2023-10-27 10:24:15,119 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ef19ea54f1b0056bb1440322dea959a00dcbd5362fea6dae748314b43baa9021.feat, zero vector used\n",
            "2023-10-27 10:24:15,122 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/c7b438efdb6adbb43a485c231848d7d95287b840cb53a3c53e01edb16ada312b.feat, zero vector used\n",
            "2023-10-27 10:24:15,122 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/69a589d29b83e8ae739b20cfcf1fc1cddd31909f970d1e587ffdaf32304728fb.feat, zero vector used\n",
            "2023-10-27 10:24:15,123 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6dab9503439f57c4e3de285cd75acf86a99b5dae7735df3d6681951d3856db8e.feat, zero vector used\n",
            "2023-10-27 10:24:15,123 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/633daeb8cecb8de53df672813b9b5ad993adc8f868737cb3b16c4735c8090b71.feat, zero vector used\n",
            "2023-10-27 10:24:15,124 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d1b4854033f752bb7e0b24e91a434afe96aaa5c7a823c944b3c78788f9bea3bb.feat, zero vector used\n",
            "2023-10-27 10:24:15,125 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f2f60d35cd90eaa60aa91a260a6b84f368dbaa6f56f57f1429ddb3abd7ae3ab6.feat, zero vector used\n",
            "2023-10-27 10:24:15,151 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/7c8cb1644d6636f3dbe91530efb5a50bba585f2ba7f629fbcbcbb83325f09212.feat, zero vector used\n",
            "2023-10-27 10:24:15,151 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/52fdf4c0ef1352045092733ea256e1e1b3626ebfac7471fddc6ea6b362c7a059.feat, zero vector used\n",
            "2023-10-27 10:24:15,152 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6814eac0104de934d64eb42099fe8a639202e95b2385a728fdc5f0a98b8521a1.feat, zero vector used\n",
            "2023-10-27 10:24:15,155 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/429ebfd9a966259a8bea6da1b553c6912ded30fc8edc006740133c4dacfd4235.feat, zero vector used\n",
            "2023-10-27 10:24:15,155 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/793b055ef2bf9f0e421f3ca893744863fbbb456177ce0851efca2b1ab338c2d1.feat, zero vector used\n",
            "2023-10-27 10:24:15,156 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/fe93ad668487c0e440b4f030ea312bf58a5cb3491fa731dc374b07fc32ed8cc5.feat, zero vector used\n",
            "2023-10-27 10:24:15,159 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/3b812f3da340a4738ab9af9cebc8cc6385b19bfe4cc334c141ca75a0f33c7a7a.feat, zero vector used\n",
            "2023-10-27 10:24:15,165 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e7d42d53790824c18b47d4d6c54c934ae5d40c1f0efae01c1946be58667728a2.feat, zero vector used\n",
            "2023-10-27 10:24:15,170 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d446a33604ce4caeb77dd9a6a89209db097748f5dd2b4fe299c17f227e4972b7.feat, zero vector used\n",
            "2023-10-27 10:24:15,172 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2d36577d33b1e82b2080876408c7038adc6e515dc2bc9c41084f63ae30a0611c.feat, zero vector used\n",
            "2023-10-27 10:24:15,173 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/4fb01a3a66ac473d14c4b1f26916e7e0d1ea57b47671d0d3f3d695c4e1e9ec17.feat, zero vector used\n",
            "2023-10-27 10:24:15,186 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/df18b07d73ab5191cf64fe1e29e0acf122402f05edf83afe47127d175f294698.feat, zero vector used\n",
            "2023-10-27 10:24:15,186 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/59a5a837ac5d4daf87f76ae8f0351ea0bdbcf96ebee53228c9d791c79623809a.feat, zero vector used\n",
            "2023-10-27 10:24:15,187 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/df213563b70507f0ac9bacd9679948096340ef475f5a0a2c6dda3fd24dace4cb.feat, zero vector used\n",
            "2023-10-27 10:24:15,187 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ca09a4175911876799b29798af439dd17f0e91366a1b3b46cf53ae35e49b7928.feat, zero vector used\n",
            "2023-10-27 10:24:15,188 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a2da02f2d842922fd11149aebcbe680d2125fa3cf3cb77f916b6ccc680f6be60.feat, zero vector used\n",
            "2023-10-27 10:24:15,188 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8e5e3e15017e4f3b9ad25cd0a2daecb54ec38fb2d67cc40b8d1b6d2ac6bb382e.feat, zero vector used\n",
            "2023-10-27 10:24:15,189 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/24aa39c2df252c1fd09baa3e69566e385b662870bbbd4fa15d31b530e22e2940.feat, zero vector used\n",
            "2023-10-27 10:24:15,189 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/4a094e51d72ec8f675013181e95fe0cdbdb0df89cd1bef6c422339ff62cd8f80.feat, zero vector used\n",
            "2023-10-27 10:24:15,208 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1ec877cb74a57c077bd94d7ff9cf971fab7c5b6e4ea30435d98f5adccc55a9bd.feat, zero vector used\n",
            "2023-10-27 10:24:15,216 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ad6a3af5c615baff54ffb821593890f2bf211eb5267e6bf078251faf34774727.feat, zero vector used\n",
            "2023-10-27 10:24:15,218 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5dfc2f1e44d66383b5777685e6dc13c2a17b94f124df7bbca601e38bc56dccb7.feat, zero vector used\n",
            "2023-10-27 10:24:15,220 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/78ea327a1a639074edc88242cf880350d487c060ffd9aee24532ceb80d4d3769.feat, zero vector used\n",
            "2023-10-27 10:24:15,221 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d4cf1c751a249042fffe27c2cc8c677f0f92ba0f81bfd9ed526b1cb4eb13b6bc.feat, zero vector used\n",
            "2023-10-27 10:24:15,222 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d54e3601577359402705e6be7ff6489332530ac8645fd357e11c49464cbc371d.feat, zero vector used\n",
            "2023-10-27 10:24:15,223 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/fd3b13592d97702d8841a0b0a1665561a2ece4215ea5d80fc166cefe1b7f49c3.feat, zero vector used\n",
            "2023-10-27 10:24:15,223 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d8f148667bc5583c5989b979a0c4e679fbb7a211d6db4784e5e77e9da10b3d13.feat, zero vector used\n",
            "2023-10-27 10:24:15,224 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6cc6f827ffac2955857509578d1a477bb67915dca955ca36bd2cd2e093b2ce2b.feat, zero vector used\n",
            "2023-10-27 10:24:15,225 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/daeaad359221a3479fa49b330c1472ceabcee13183dccdddd4d412fe54933604.feat, zero vector used\n",
            "2023-10-27 10:24:15,225 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d6ce57324c9119ce690c098edd7aa2dd1c7b3c702be46f063097925f0b01c796.feat, zero vector used\n",
            "2023-10-27 10:24:15,226 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2e896883ec348f4f52532b93b5f5e9a084da43a6abe1ad26c0c6523bb309169e.feat, zero vector used\n",
            "2023-10-27 10:24:15,230 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/4cdf1c42b9ae40e402ccc75d0885892ddbe5ac398ad1d629237ab241518e6858.feat, zero vector used\n",
            "2023-10-27 10:24:15,230 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/501611e4bd7deb7d8993fc0daeaec0765d5d8dfdf2bd6082ae38a9049c589916.feat, zero vector used\n",
            "2023-10-27 10:24:15,238 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ad4749067926cb81d70ba86645d1a5b58b2b08fda78d3866662d8fcfcb4a0340.feat, zero vector used\n",
            "2023-10-27 10:24:15,238 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ef197550a5f45259595e379126a2289ade5ffd0f781a0a00e02175fba9206f44.feat, zero vector used\n",
            "2023-10-27 10:24:15,240 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/17633b5ae3034c2d45b39fad16ed3559c4c2f914b29d2ac225931b3a772bfb90.feat, zero vector used\n",
            "2023-10-27 10:24:15,241 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2ce17c965dbbd2f12a7d139a9be3d995043f1173221e56b6976927e2ce6c98d5.feat, zero vector used\n",
            "2023-10-27 10:24:15,243 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6030824fa24f4e202de5660a7c3bda8b0d91a39d0b17c29084587e3693922072.feat, zero vector used\n",
            "2023-10-27 10:24:15,243 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/76c36622b52082ae1e7bc0b976114822624df1b3779d2d976cc50ef00acb21ad.feat, zero vector used\n",
            "2023-10-27 10:24:15,243 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/34368a96fbc9c90fd76857cfb3351d57393dba43f4451934315731b896e46a71.feat, zero vector used\n",
            "2023-10-27 10:24:15,244 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/eb96b41448c99890f56c5ff2755f5df082836daa9b0e607b3d76a23e0c91d86e.feat, zero vector used\n",
            "2023-10-27 10:24:15,244 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6a40e1a15df9f130730c596b0ef05a1da80ca1c28ec917dc25d11f1cc3b21cdb.feat, zero vector used\n",
            "2023-10-27 10:24:15,247 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f164c200d3b8ba2ac3643aeaad413339de8ddeb1635970951e10f8caaf041184.feat, zero vector used\n",
            "2023-10-27 10:24:15,247 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2873f9ca323be44ae03067f2d0d6fcc444f57104abad96fd8f0030ca5aeacca8.feat, zero vector used\n",
            "2023-10-27 10:24:15,248 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/81d88dc319c08a01700444d0af670366080b8de3093521064c0805edcfeb747c.feat, zero vector used\n",
            "2023-10-27 10:24:15,248 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/90d251f35cd8c5fc35968492ec90483d25a82986ee5d6d8093c02f01dedf2f36.feat, zero vector used\n",
            "2023-10-27 10:24:15,249 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/55b908f6446541c2cc047e9bba03a10ef21dcf4022010eca20200ee39a69ee7a.feat, zero vector used\n",
            "2023-10-27 10:24:15,249 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a432a84167e301220d6313dea0158c645b71fb92992342ca91051490c557a3c2.feat, zero vector used\n",
            "2023-10-27 10:24:15,250 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e2aaeff848edf0c1d9106dbbb6373c89bc376eb194bc5e24b3eb4ea4708a7cc6.feat, zero vector used\n",
            "2023-10-27 10:24:15,253 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/eed194eefed41685c60f6f218c787a4ec9b657a699a0280d850a49e06c2a0461.feat, zero vector used\n",
            "2023-10-27 10:24:15,253 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/11dd76383621cb80c7c001bb9dff02dfe55cdafa57f023fe17f0b9117c301dc4.feat, zero vector used\n",
            "2023-10-27 10:24:15,254 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/031533c9bf6741d8e46c0fc0f6b26b1951e954a0933831cfcec0ecc13a48a023.feat, zero vector used\n",
            "2023-10-27 10:24:15,254 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/9d13a0dd65ebe75ed3d13b6b32d5571b59485213b17fbf5f225cfc9d2e9e5fdf.feat, zero vector used\n",
            "2023-10-27 10:24:15,255 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8ef3b925bc14094e590b623d226b0fbf6b1aa218d80d7c4f6fdff8ed84a1f534.feat, zero vector used\n",
            "2023-10-27 10:24:15,256 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/de9e1c30405b840bbe872221c7a496be5638dabc0e1d6a0447dcec2352de2fed.feat, zero vector used\n",
            "2023-10-27 10:24:15,256 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/0b8e4b1bb4a0e6ec957b6811d1e4471f81f7f9bbaae8303d849558562ef400af.feat, zero vector used\n",
            "2023-10-27 10:24:15,256 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/538fd7f4b3b15893a0dbb579ab67ef1d3190abc477beb6f2d7b5f80d003ebde7.feat, zero vector used\n",
            "2023-10-27 10:24:15,257 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5ea3f252c7aa13dfa6d8f10f06d55188e7e56242af1dfea108d537efdf8c05f0.feat, zero vector used\n",
            "2023-10-27 10:24:15,259 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8d339196a77f44275a82af8f5497f367e0cd5117aaedcccac23c350930490a83.feat, zero vector used\n",
            "2023-10-27 10:24:15,260 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/31dda7afb8cb035ed381f2f07153484f8b9d1ca9b6bd60838833f9a182e752b6.feat, zero vector used\n",
            "2023-10-27 10:24:15,260 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/3c454e73daecf01ca2eccaf0c25b0879a36809e5f84951522ea6577ebc97cdc5.feat, zero vector used\n",
            "2023-10-27 10:24:15,263 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/c25457e4da4bbe0f6eb49962e56c4420799f1d46b9cb9e0cee6ec2b93f32da1a.feat, zero vector used\n",
            "2023-10-27 10:24:15,263 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e18ad173fc512623e4e6e73158c80ff1cef403a40f027d831afef1d44ca8ec8f.feat, zero vector used\n",
            "2023-10-27 10:24:15,270 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5a8221ca783e009fc9037d360b579f32075c8f9373b3d780bbdf53d339552c9e.feat, zero vector used\n",
            "2023-10-27 10:24:15,270 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/fc2864359aab7bb390e37c869e8a9cc4c825b3e99121b751b2f65b1f5d2b4f94.feat, zero vector used\n",
            "2023-10-27 10:24:15,271 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/68c199437708a154eb06797a067a3ea069699785cd21ed52cb00437c1415fd59.feat, zero vector used\n",
            "2023-10-27 10:24:15,273 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d949a4c809123e3c0332989b46563980fd59e2a89bf6f182239e5b65b72353f0.feat, zero vector used\n",
            "2023-10-27 10:24:15,275 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/3cdde4a432d5db80575be997e872984b407ce5d9f1c99c06319a81c661d9c106.feat, zero vector used\n",
            "2023-10-27 10:24:15,276 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/501a8ea8b16392261f4506a7bc1d848803da615285f34e1edc9abcd6d4cd9b05.feat, zero vector used\n",
            "2023-10-27 10:24:15,279 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/9085472232c5731569c079e85b2c3112e2c9bc81bcb96877ea2695c6e63ea589.feat, zero vector used\n",
            "2023-10-27 10:24:15,281 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6e159d58fcd747e1dfe5812d281ec2b29b9c4d568de69b8fb21e18fc47a68fb4.feat, zero vector used\n",
            "2023-10-27 10:24:15,284 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/4e0fa28c03e8aeaa05edeccecad40cbb6f4aa7bbfcda6a79cbdc019b9455c160.feat, zero vector used\n",
            "2023-10-27 10:24:15,288 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/cd329d4ea522e8ba8540cb883c9b46518cd871ff6b0b5d8d2559deb002293a89.feat, zero vector used\n",
            "2023-10-27 10:24:15,289 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f8d65379f1e6d72094e71d46714ff1febe4834b3f13acf5526a033f336156f96.feat, zero vector used\n",
            "2023-10-27 10:24:15,290 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b6a0286b9b6756e49b4d0605a7abf51c3a7973eb51d08b5b0644bc3bb1b3e25d.feat, zero vector used\n",
            "2023-10-27 10:24:15,290 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/45f2af78c2cb793f87ec6d9b2c61dc8bacbfb07cdfaef7ef8148e709d6387053.feat, zero vector used\n",
            "2023-10-27 10:24:15,291 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/0bdb834b2cd4bacbd1741823f862d8872d4cb68f5a2e64659a47f3dad58095b8.feat, zero vector used\n",
            "2023-10-27 10:24:15,293 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/68456ec03643d47be8654d4b1253328686f48b6501a39fac35f97dd8daefde3e.feat, zero vector used\n",
            "2023-10-27 10:24:15,293 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f8beb1a9565337574f115d5e04565e74a11dc4f3d868f6f580ba2204642c56a4.feat, zero vector used\n",
            "2023-10-27 10:24:15,298 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1b3ecbc6ad7f87904332b1e425df490b40bc23445ee39d0875ecb08a9c22481d.feat, zero vector used\n",
            "2023-10-27 10:24:15,298 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/cc8f1756f8871be214fe3d82ee4847014acbe591048f607dd74891e309af7952.feat, zero vector used\n",
            "2023-10-27 10:24:15,299 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/39633798ca24d291862a8bdb23555bb7519231d3d26c7a840da42ef004d8511b.feat, zero vector used\n",
            "2023-10-27 10:24:15,303 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/37ad5b08f362e149acaea11b24da1486b5914de74ca980dde68d53b2471d5117.feat, zero vector used\n",
            "2023-10-27 10:24:15,305 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2043a2a31ba1038a338f72a40a884d3895562205ecbcb3e1b12583a40a8dbd2d.feat, zero vector used\n",
            "2023-10-27 10:24:15,309 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2330ce529b588597b88087ed4d583e4f0d7c9ec1ab8fecba982973a3f088e45d.feat, zero vector used\n",
            "2023-10-27 10:24:15,309 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/112c30a288836676e9cfff94cc6ff92fd989e93677763172ea2b91232a3dd053.feat, zero vector used\n",
            "2023-10-27 10:24:15,309 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/59ee16c6f6110a095e22b7fb3956fd10ae7675cbd43f648d928a5b0509e849da.feat, zero vector used\n",
            "2023-10-27 10:24:15,313 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/14ea8faa441e956271d41a098712e6e2f2631bf22dcbd34fcc7a0515c81d3866.feat, zero vector used\n",
            "2023-10-27 10:24:15,313 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/0fc0a18b831f9dc67834c37bcb1e234433abd203fc338da447fa6b0a19e73026.feat, zero vector used\n",
            "2023-10-27 10:24:15,320 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f45d8d29e9c23dbe7d9f32387fb02612c806f8aa36b01fb52fae046eac37c8d9.feat, zero vector used\n",
            "2023-10-27 10:24:15,326 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/839a64987cb089ebb348b47e9b58935af92366731ce5649104ffce1a645aeac9.feat, zero vector used\n",
            "2023-10-27 10:24:15,327 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/c22398471ac8c4ce6acc0cf3fc39981a122383124f1804e198080d42eaffaa42.feat, zero vector used\n",
            "2023-10-27 10:24:15,342 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8d2ffe1f2632b9ff936ef8a88060ed61ff10000a98c62f381395869f5d03c66a.feat, zero vector used\n",
            "2023-10-27 10:24:15,343 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/7bc424303c12e0e5ffffe9a0f477266c9bbb2234abbafe4e4177d418f212891d.feat, zero vector used\n",
            "2023-10-27 10:24:15,345 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1e147e16db4423e3182a020f627d3381ea6e1cac48e1fc26956fc053c52f55ad.feat, zero vector used\n",
            "2023-10-27 10:24:15,346 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/83c0aa71962458a30b88fae8eeca9b7df52b8b62a67db0c2d01817ec823e0bfc.feat, zero vector used\n",
            "2023-10-27 10:24:15,349 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/c4af33bdf672b39fb0a31d527c6e729fb5017eee68f2cbd114fb765b8da4a751.feat, zero vector used\n",
            "2023-10-27 10:24:15,359 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f2a2edb914b237e55ce3e6a70975f0a0271c393bc6f5ce102b30619bd4ea5426.feat, zero vector used\n",
            "2023-10-27 10:24:15,362 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1c6655fe4a1c0559c72da2c0db11b14319e1509599e94b3878501727403e7a11.feat, zero vector used\n",
            "2023-10-27 10:24:15,363 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2b9ea4a49be6ac92683ceb22a9c1cd602a49072a2bd334914f53b87a9c0131cc.feat, zero vector used\n",
            "2023-10-27 10:24:15,368 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/c2d46ceee124e87a3ad1bddd9d89f2e4bd9a86f22f49ca745bdb5beb207b2d80.feat, zero vector used\n",
            "2023-10-27 10:24:15,371 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2d92fbfab7ff8d6c5fbdc79d965a0e40a269df238012a1d7b62fcb3d67bf4ffc.feat, zero vector used\n",
            "2023-10-27 10:24:15,372 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/fa409617db756fc5648e9c18e75c44ca9024f74674ff2a470646d5e2d3e3266e.feat, zero vector used\n",
            "2023-10-27 10:24:15,373 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8c6eddaa8e699a90db358aa43f13f7aa49b339eeb47b9ca8ae880020e02d2dc3.feat, zero vector used\n",
            "2023-10-27 10:24:15,374 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b874fde7cfb0b1e3d88f1c0f2f9589a685531a55021287bb3dd47c7f0979b981.feat, zero vector used\n",
            "2023-10-27 10:24:15,375 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5f0d003b2b68afe9709676b946cb485a92e9389b02affc8a7c2f948f9b00afcc.feat, zero vector used\n",
            "2023-10-27 10:24:15,379 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/4a21f2cdd3d4308d01884fab7bbd49936c6def4806b03e6ead51e466f1baf3bf.feat, zero vector used\n",
            "2023-10-27 10:24:15,380 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1b6c5d0fa2cf1f0dd6271dd2176b6977ef471d8260226442fd96b69f600c3476.feat, zero vector used\n",
            "2023-10-27 10:24:15,382 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/bded43593cc789da29822f39f55005275fbe892036fb6d7ad7b7e0d26164b8bc.feat, zero vector used\n",
            "2023-10-27 10:24:15,383 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d474b5e3d7793d721a4bd06535ca215e0f10e6179955b3e378ddc130eced24ed.feat, zero vector used\n",
            "2023-10-27 10:24:15,387 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/cfd87625b1bd949f1a963744f7205193bec746ebb4fd6a5ebbad4feabd2f56a5.feat, zero vector used\n",
            "2023-10-27 10:24:15,387 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/715fcc4c24ed0c9189713111059e3ec445dea4ab9a2f8ac43012c59434e8a0d4.feat, zero vector used\n",
            "2023-10-27 10:24:15,400 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/08dbfd8db1dfd8743a2fda1e2be8c1190b69fe105a6b5ce2b52526585e795579.feat, zero vector used\n",
            "2023-10-27 10:24:15,400 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/7060fc01d189deb646741093fe095a009e75704acb3b139cb7450cde974f59c2.feat, zero vector used\n",
            "2023-10-27 10:24:15,401 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/66ad9b92566664ad151d4ebd6ecc9915698eefee11918af27a3c274dd55c97aa.feat, zero vector used\n",
            "2023-10-27 10:24:15,406 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/04ef09892b19b66f51c201f2225e9fa038fd482ef7b4c207198260f7d2c51f50.feat, zero vector used\n",
            "2023-10-27 10:24:15,406 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/594f455cb742340b78fac3120a9838bc75dba771e4f50bf8292eecba17c8fe12.feat, zero vector used\n",
            "2023-10-27 10:24:15,407 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6cc8f96fd6d9290088a0accf4f415a9e16dcbadf08d30a027866e0615425998d.feat, zero vector used\n",
            "2023-10-27 10:24:15,408 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/4c068782cfb9a5ba8f0542a5764cd51455e4a9d4764089b263253ac8fdda9702.feat, zero vector used\n",
            "2023-10-27 10:24:15,408 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2d4b73ec4bcce8815e5f58d4650b8584429b9d61226c90c5b30b0fe16244d18a.feat, zero vector used\n",
            "2023-10-27 10:24:15,409 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/887c1ae5cc5d1b5ab023bdf8cbd8df454850cda2e881362e28b4eeb1fc1e1aec.feat, zero vector used\n",
            "2023-10-27 10:24:15,410 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/cd4978ef06b520e4899527a370ccc5cdee57598fc2c3f4cb4e1c7211510f86d2.feat, zero vector used\n",
            "2023-10-27 10:24:15,410 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5f40962820d8c2957e196baf82f348533fed0a64ae106628331f350b785efb91.feat, zero vector used\n",
            "2023-10-27 10:24:15,419 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/9fe3f39aa0d63d4309eedd2fc1ad0ac06583765ec263a561af7b6702b1811565.feat, zero vector used\n",
            "2023-10-27 10:24:15,419 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2c3b05f6f2ac665be02782c463d777c737b9be0351708817a3db9fb7e686d2e1.feat, zero vector used\n",
            "2023-10-27 10:24:15,422 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/64ef26404f39d4e65ef34aee7ba6aa70044071197f5b19e5c7b6040683607594.feat, zero vector used\n",
            "2023-10-27 10:24:15,424 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/181fc9b2857ee56f0507bfc0a2194985c4d6c342359d642b443979c1e57e2265.feat, zero vector used\n",
            "2023-10-27 10:24:15,425 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/7e6b055097a5c58551afab7889e2ecd568ede555038666b97b5bedf780ae3d80.feat, zero vector used\n",
            "2023-10-27 10:24:15,425 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b046a668e48a2e1df34df4c399fdf8dd006982080c554173f08dd8436554fdd2.feat, zero vector used\n",
            "2023-10-27 10:24:15,430 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/aae20819656747d80c8fe44a932989601f747e5ecc07cf88741d909f904db71d.feat, zero vector used\n",
            "2023-10-27 10:24:15,431 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/34a6966620da6bf993f367d304dabda5c0017915c11c93a2871f6b284987b7cf.feat, zero vector used\n",
            "2023-10-27 10:24:15,431 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b340e183b458c675987afbc1378f3fb38d8c4175e95beb0559ff33c30d60271b.feat, zero vector used\n",
            "2023-10-27 10:24:15,435 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/baf944c8789822257d68c87b18e379d73caaf38910d566fc86ad66c3fc2c9c2b.feat, zero vector used\n",
            "2023-10-27 10:24:15,435 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8e1b49b0d86b26f826177471eb3fbd09e763900491d51bdd8ee96b469288e5fa.feat, zero vector used\n",
            "2023-10-27 10:24:15,436 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2574c9350393f2ead3b4744d4b47edd36a1b5f74d11ee6799df2b03145ee99fd.feat, zero vector used\n",
            "2023-10-27 10:24:15,437 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d879e14c7a5d5f2e9c8d71ff72d81a3fa7d638c24db785678bc7c36f1061f714.feat, zero vector used\n",
            "2023-10-27 10:24:15,438 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ef3fb20730e4ea565092bd5163b20e1408e1b338a5acbf31cc7c1a8571785cc1.feat, zero vector used\n",
            "2023-10-27 10:24:15,440 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5c91a78773e7e562466d5f3d3ad52af89c9753d106589275b9e5821df48fc7be.feat, zero vector used\n",
            "2023-10-27 10:24:15,440 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/449e237e4b73358d7e9716209984bd0f991a7dbd5c03b85d1ff4eafd9f51becd.feat, zero vector used\n",
            "2023-10-27 10:24:15,441 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1ab9bf8f1eb4083f54daf69e8dd0a7b1328156e37ade7bd45a2f0ae3e4fb7924.feat, zero vector used\n",
            "2023-10-27 10:24:15,441 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8f4cf39049160460046f40767a63abcfeb13098d8a9942333cfd261ae1f73d80.feat, zero vector used\n",
            "2023-10-27 10:24:15,443 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/54ff2b5cf230f16093a1eb947868753e9afacf6bfe31d5e5ebe304ed3a01f821.feat, zero vector used\n",
            "2023-10-27 10:24:15,443 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2ad2746807d57950f8acc498cf1e07aa3147e5f626bc9ff06ea0ff1fab2896ba.feat, zero vector used\n",
            "2023-10-27 10:24:15,450 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/76a86c9bdafaf1723655eb9f6a846cedab2070cd474a071836568f209d198bc7.feat, zero vector used\n",
            "2023-10-27 10:24:15,453 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8aeec64f0bd9de4606b41ffe8ee90cfd569100b75a09e0d8a6e8c9fe6b21911e.feat, zero vector used\n",
            "2023-10-27 10:24:15,470 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/7fd427a2819182097c72653f157e2c59df60382aba86bcb427c52a082e1bcedc.feat, zero vector used\n",
            "2023-10-27 10:24:15,470 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f4191fc0b70bb93ee0534498a2d70d367246a4811b27fa16ad0285a668fb76c3.feat, zero vector used\n",
            "2023-10-27 10:24:15,471 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/7dfb331ec661333b040f330b5c0b94b2ba830eba76f51977489f0fcd4c067d81.feat, zero vector used\n",
            "2023-10-27 10:24:15,471 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2e03abec3182dfc3d7c9d57d22299eea5a92d1eca7446149ad7f6cd61c3b27bd.feat, zero vector used\n",
            "2023-10-27 10:24:15,478 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/c042898215d80fadc403c6e34ccfd48a72d9c499d26d01e935d3f72345205357.feat, zero vector used\n",
            "2023-10-27 10:24:15,478 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/cc9b83a77e4fda074367d62e183c900610778868a904d6b6e9eaf8b3d2a6cff9.feat, zero vector used\n",
            "2023-10-27 10:24:15,483 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b171126a35c0dd3d8ef04fd6b9ce8aef86129bc071611bc29d00273762903b6a.feat, zero vector used\n",
            "2023-10-27 10:24:15,500 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a8057f1e9da000a22bec6ba9097d12d1631fdc13b9c95105b3bae6df62b2bd7d.feat, zero vector used\n",
            "2023-10-27 10:24:15,501 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2f355eabd8682942282c16979e069224b7172f9f4e454f8a0d6337f3f181c5bd.feat, zero vector used\n",
            "2023-10-27 10:24:15,501 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/120cb73c0b9b05116a78b8a1c56602cd1ba8c3e623ce9aa0c28d629fe0823a5f.feat, zero vector used\n",
            "2023-10-27 10:24:15,514 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f59ac61891ef8c8036fe72530c3ef1d833e5f4e6b48f78c5bd9ca3e11e948f21.feat, zero vector used\n",
            "2023-10-27 10:24:15,514 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/0b85488788f7f83e879f41591d674b50d4daafb60094918391d98f143ba54ddc.feat, zero vector used\n",
            "2023-10-27 10:24:15,514 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/4cf77c0ad13c83b25cb95e8d72be8bbd324d95aaf56225802f17aeb7188873b8.feat, zero vector used\n",
            "2023-10-27 10:24:15,514 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/c2111ab781930192fc7a14b6b0bbf3a802cb45676317d318fec384030df02ba0.feat, zero vector used\n",
            "2023-10-27 10:24:15,518 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/9ca874397f4925f139562dd9585c735069315fef4e6ecdf7288dd93b43960cd8.feat, zero vector used\n",
            "2023-10-27 10:24:15,519 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/43b0089f85b6ff483af224200fc3ee430877b53da27185b21c842a16efac5328.feat, zero vector used\n",
            "2023-10-27 10:24:15,520 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/276b43f8fded4e6af89a3d7a1864ec255ec5baf9ee7ea629794ad77ba9a46303.feat, zero vector used\n",
            "2023-10-27 10:24:15,527 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b7c20f9b6a3eed5aa570c5cf0c56f72f08fc02a01e1ae1d70b5aa5c6adcbe5f3.feat, zero vector used\n",
            "2023-10-27 10:24:15,529 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e69dde5a1269f046388a8c56e567d21f73ac0dfbb6b9251c9e06864bb8653594.feat, zero vector used\n",
            "2023-10-27 10:24:15,532 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f8b4cd468b8926b832550b30bcdf41d6edc696bad9cfa4cea08d1ec10327688d.feat, zero vector used\n",
            "2023-10-27 10:24:15,535 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5a74f2239dd85b0b6f4986928d4181f6d65c2639711fc69ad9b5db3587681c22.feat, zero vector used\n",
            "2023-10-27 10:24:15,535 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/db4f8a4862eb9ac89a060c1c44cae7df3dab94fb4c7e111d39990a06d5bf693d.feat, zero vector used\n",
            "2023-10-27 10:24:15,541 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/dabb8b597c9319c5a8b1d9cb78ad99937df4adb681f847876bc7773416268ea5.feat, zero vector used\n",
            "2023-10-27 10:24:15,543 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5eeaea4032c101270297c33678c73107f3134ce4ce691c6ae4525dd8c6b01d75.feat, zero vector used\n",
            "2023-10-27 10:24:15,547 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/51b64050880704179d55ae6ba27bbe7f1da7f2519ad5a1eba0b77f168c5d9a77.feat, zero vector used\n",
            "2023-10-27 10:24:15,547 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/4d13bbca64e3e5745989ca84510322c07a6f88630bdf9b83b48eb64cf2d1d3eb.feat, zero vector used\n",
            "2023-10-27 10:24:15,547 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/28ef6370a28dd5bdcf2659346d68b7881ddcdb35e67cb273a0ce50f147085176.feat, zero vector used\n",
            "2023-10-27 10:24:15,548 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f5854f9ad480fa37ac061b59f4f432525d8900ba64e4e86ac034c200dcf0759a.feat, zero vector used\n",
            "2023-10-27 10:24:15,548 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2e4eef20cce03aefbee0bc8966404fc31164ed94cbc905c280089dcd0008a1a9.feat, zero vector used\n",
            "2023-10-27 10:24:15,562 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/becce63a8bf66beb9e43e86a57ac636e3a3142638709eb05fa78519466fbe5a7.feat, zero vector used\n",
            "2023-10-27 10:24:15,562 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/961fd5774e352a2322af8878df7c370200f020ea044c66ff1474fcfb02288b3a.feat, zero vector used\n",
            "2023-10-27 10:24:15,563 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/01c21ac2f9fd10a5b7fb70f4c5bd7cd236f687df51fb53d652517747cd945e9b.feat, zero vector used\n",
            "2023-10-27 10:24:15,565 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/37e2b8be7e55233850e9f8b05d9116d4e292dfb16bc2287847f4ae59e5f3027e.feat, zero vector used\n",
            "2023-10-27 10:24:15,565 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/44e4cd37e9a1166d6eedcfd8e885042d8abb542fc49bc925267bea797f6b998f.feat, zero vector used\n",
            "2023-10-27 10:24:15,566 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2c70f9494cb2a317bc2de0c3afefa90230097e17720916bb192c48eb03ab48e0.feat, zero vector used\n",
            "2023-10-27 10:24:15,568 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8113702f0efe25bea1cfd194f424d5048fbf45d5d79a983f50cb65b27b262994.feat, zero vector used\n",
            "2023-10-27 10:24:15,569 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b15785c2385d88905fad6695b4f36b38d112a91591f082c82c9523e749fb77b8.feat, zero vector used\n",
            "2023-10-27 10:24:15,572 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/33bdbf7ec87c8a5083ddbbf0b44201ed5350178b7455cdb18901f7fcf4372921.feat, zero vector used\n",
            "2023-10-27 10:24:15,572 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/671b9e94ae5d79134ae3affcb26ea3f8249dd32d31ed6ac8c3cc26056bcefaab.feat, zero vector used\n",
            "2023-10-27 10:24:15,573 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/c47ffb7be61e0fbe670030fd7893cd83b23e640a3b6d38026cd59d9126fc46e6.feat, zero vector used\n",
            "2023-10-27 10:24:15,573 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/687822d5b3b6a6a090b0a0aafd638d5d8a2b9fbc0d21b3886966d694a1177937.feat, zero vector used\n",
            "2023-10-27 10:24:15,574 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d0c285de4ccabc8bffdaca2058e82f250a08044ff3b70a1684115446dd57c6f8.feat, zero vector used\n",
            "2023-10-27 10:24:15,575 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/705cb638b7c8bdc60e4f0ba853127da5aec37355c99509b714e40c2dee136f1c.feat, zero vector used\n",
            "2023-10-27 10:24:15,576 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b31934f42d102d3dfa106ec167b654c124aa3c032d14703586647085db391703.feat, zero vector used\n",
            "2023-10-27 10:24:15,578 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/fa895aea5973034a0b2ddb56a2f300d2256c9e961650025d8364e95171382214.feat, zero vector used\n",
            "2023-10-27 10:24:15,580 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a6b103d92b9241e7790a3599bf0538b02d27e8b59c264c28d734b7c4716d9ea3.feat, zero vector used\n",
            "2023-10-27 10:24:15,580 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d414aea794dafdce1844e6b3ea5b3e5d6972a10c95f3145f2039031325cc9e72.feat, zero vector used\n",
            "2023-10-27 10:24:15,583 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/4bf912f4aac11bcdad2e3079e3e2ad12602a937cffc706ecac63bface1fdc7ed.feat, zero vector used\n",
            "2023-10-27 10:24:15,586 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/dbe431868be37baf84465dcf8d3f7e920d73d44e7185cea5695d7f22f20161d1.feat, zero vector used\n",
            "2023-10-27 10:24:15,587 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6dce7b4b479fc45fe63920ec84a46d3354e5539c09acf166180c0d4db32a7264.feat, zero vector used\n",
            "2023-10-27 10:24:15,589 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d51d9ff82a6568f6f5fef91dabfbebbf73a88938d463ab2159b644e03247427d.feat, zero vector used\n",
            "2023-10-27 10:24:15,593 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/476a72919abca14bbd72f82c121acc33a384a5ab3e91c8390a39eafd56c41292.feat, zero vector used\n",
            "2023-10-27 10:24:15,595 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/595405a209a38721128d7a3699228b9b4f91aacebb9fc0aaaced2f809c77bc39.feat, zero vector used\n",
            "2023-10-27 10:24:15,598 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2e4cf5b367965aaa0dc9fc9ed8ad715061b51bdf83bb40f9b11473a0058b09fe.feat, zero vector used\n",
            "2023-10-27 10:24:15,598 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/87654842f2ec809372ba320be8dc4b0d93297bafb4ca8a8b163ea9922e901e69.feat, zero vector used\n",
            "2023-10-27 10:24:15,600 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/64b4f887f5fcbbf2f4c49b894086e00f52345abaa3c85fd44790b017279ac5a9.feat, zero vector used\n",
            "2023-10-27 10:24:15,603 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ee36fffe11dcf856eceb9232c62d0e779502064d50bacb455fed893efc36771a.feat, zero vector used\n",
            "2023-10-27 10:24:15,603 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e8ebe41d246b34a3243dda54517a3944a71dfdc75bff3bafe7058cb32e865ed2.feat, zero vector used\n",
            "2023-10-27 10:24:15,604 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6ee6de12a75351ba5b91ae700cd673ebb4f467ab4e6d0d471774a7159be96486.feat, zero vector used\n",
            "2023-10-27 10:24:15,605 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/aa84c12e3d8b06cd4de079b22c2abb96dc09da67dff123d00ff45ec19e86fe89.feat, zero vector used\n",
            "2023-10-27 10:24:15,605 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e09274fd5e74e2c8ff178d001ff755267b13bac8330f0e1200f1359696ee2dc0.feat, zero vector used\n",
            "2023-10-27 10:24:15,608 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/328141e5875571c335759f3d543340d3e40a5504e6703ad7d62592322ba40bf2.feat, zero vector used\n",
            "2023-10-27 10:24:15,609 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/43e2585335d4de26a41a77153f938a94c4326ce3abfdc555c048cf529afb6fdc.feat, zero vector used\n",
            "2023-10-27 10:24:15,613 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/37a1463641780d7f993fbd440045534312de0016f696e36812ff88f03f7254cf.feat, zero vector used\n",
            "2023-10-27 10:24:15,626 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a41137bc27d68bed07476d5ef352efb243500167e17577a9beda526b58c67cde.feat, zero vector used\n",
            "2023-10-27 10:24:15,626 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/3ead8b4835dac5c5dd15654f3f6bf75902aa9fd66160dcc969b042624f57d8a6.feat, zero vector used\n",
            "2023-10-27 10:24:15,627 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/4d7762f42c1f5def06bce90599c1e106ebfe7e16ab197e6de7ad7414963257a6.feat, zero vector used\n",
            "2023-10-27 10:24:15,633 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/9f008be0ae3f8a599ecf84d791397091e3a7ec8e85ebf20f3ae6a74bb7eccfa2.feat, zero vector used\n",
            "2023-10-27 10:24:15,643 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/4803b1e488164beac5d275314234d549f7d2f33e9dce37878dba86325906ecea.feat, zero vector used\n",
            "2023-10-27 10:24:15,648 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/3a187ac9c52ff5a6b4945f5c0f26c1375045b5cd4da2307d725e8458840d9aa1.feat, zero vector used\n",
            "2023-10-27 10:24:15,648 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/23bc6a90da8071f767e4026b0e590e43463eb0d68311c6d5734ee7ab71eac51e.feat, zero vector used\n",
            "2023-10-27 10:24:15,649 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/73e1aa034dd802af011b8da163bdc33bedcc3ad4c38227453f8df1b6ad68f71c.feat, zero vector used\n",
            "2023-10-27 10:24:15,649 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/cae2bed2ad2e4c0c616de7832cafae221a142c0da805f3cbb0b4fa06d7e96162.feat, zero vector used\n",
            "2023-10-27 10:24:15,656 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1d17adeeeb1d25e3837571d1f33afcdb210cfa20ee1ef5081c3ad41323f7f00d.feat, zero vector used\n",
            "2023-10-27 10:24:15,656 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/db39eb47507f94902e2094673fd4146e249ca155f81ddd651074510a5c1912c7.feat, zero vector used\n",
            "2023-10-27 10:24:15,657 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f33d8f69124807fbe4b3f449b964177cde9d0708da08bb89c576471b35c69077.feat, zero vector used\n",
            "2023-10-27 10:24:15,658 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d051af049a1b76e4a3b71d4ceffae50ad3646b397713e0973fc911ce12e506f8.feat, zero vector used\n",
            "2023-10-27 10:24:15,659 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5593994d7bed3360fb919221d8d1750b4e7256f1fe9c76770479083e0ca05497.feat, zero vector used\n",
            "2023-10-27 10:24:15,660 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/06a3dc2f66101ab21cb8040c1c4771aa7ead816c0a65ca1d19a08f9373dd7f10.feat, zero vector used\n",
            "2023-10-27 10:24:15,662 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6e6273412bef423fea4bff9bf70cec649e42c682022316ab81bb469fdf764263.feat, zero vector used\n",
            "2023-10-27 10:24:15,665 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e30cb3a9b24ce0ac186576168fbe972e47ce905895d17f8e41a70185b6f4cc74.feat, zero vector used\n",
            "2023-10-27 10:24:15,666 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b3bfdd0706dc4236c3e6c1cd75fb546966e844b26410949a70cceb881de07d23.feat, zero vector used\n",
            "2023-10-27 10:24:15,669 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d3b462dc6d2fd57c9bd343d6e759fa0b0e40d897b4ecf784a5c95f2652879cea.feat, zero vector used\n",
            "2023-10-27 10:24:15,669 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/7b2ffdf292b98058abf44610d58690a95538138c035bf6f6bfe02141224d6a52.feat, zero vector used\n",
            "2023-10-27 10:24:15,670 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/9733e8ba9d99c971bedfb6d22b5d0221bcbdb2355800ef4e24c29275df6f1b75.feat, zero vector used\n",
            "2023-10-27 10:24:15,671 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a27150a3d72ce8e1bbd979a602393fe04a4051f74e5e0d21d98dab031dfbb3a9.feat, zero vector used\n",
            "2023-10-27 10:24:15,680 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5258e81c2746e7295928b543f121649422767ecaf5df0b70ad7981d698ccf92f.feat, zero vector used\n",
            "2023-10-27 10:24:15,697 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/c3bf09510c0bd5c9afc97cd1f28a593559d684cab96f25ac801beaa7bbbda915.feat, zero vector used\n",
            "2023-10-27 10:24:15,697 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a8c9cdb6a2027b8233c8a2b8fa700752b9642e5e4c25ff6ca605b6a345900d0d.feat, zero vector used\n",
            "2023-10-27 10:24:15,702 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/3e9cbcef2fd52720891c64987bff0c26c32cb8be490619711cb3f6ee05277323.feat, zero vector used\n",
            "2023-10-27 10:24:15,720 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/398e0e3d73ebf037ee87d8894c821295b4802e9817fabe979f64af8702805e6e.feat, zero vector used\n",
            "2023-10-27 10:24:15,720 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/0fd259a1a3884517f2cb275c8c94363e6d609d3df52f094efb2b961edd1771ae.feat, zero vector used\n",
            "2023-10-27 10:24:15,722 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8a7b0353a20bcdb0326e1c2ef4443440bd7f6b853fc538ffd775456ef9fb36de.feat, zero vector used\n",
            "2023-10-27 10:24:15,725 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5ed192becd2a3bf69f26f13dabb39750ceddf39ffe43db6b3dbb11268c777a02.feat, zero vector used\n",
            "2023-10-27 10:24:15,736 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/9333045601c1b4050039f04f787a2eb146a769e1c48d0afe6664fbc59a352e5f.feat, zero vector used\n",
            "2023-10-27 10:24:15,738 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2954fc07e87f2c5cb1587278371a42254d1c609e18dd3280397af3c85eb06327.feat, zero vector used\n",
            "2023-10-27 10:24:15,739 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e125475059a786b829db78f43f4d5ce03106563e8e74e0067fa104b7478ac872.feat, zero vector used\n",
            "2023-10-27 10:24:15,740 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e1c7cb78cbab2e394ef9384a7b183ce23a686bfd9265bab5e5b0f5d766f8b7bf.feat, zero vector used\n",
            "2023-10-27 10:24:15,743 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/3a5bae961394e14a99c43609610e176a73326724963fec085ce46c371b984b25.feat, zero vector used\n",
            "2023-10-27 10:24:15,746 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/66a0acdf4bd36d428bd09773b0334c6f62f14a93d4ff73ebef6dc17b6e880931.feat, zero vector used\n",
            "2023-10-27 10:24:15,746 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5ba278f00f9a9b10111fdfee53640c63e1f2cab7c73563db6836f8cc1ce9c7e1.feat, zero vector used\n",
            "2023-10-27 10:24:15,751 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d75c3ff7a4951acc9a6b8998fe3bcae1dd34659842b148e0fe10637ef841593d.feat, zero vector used\n",
            "2023-10-27 10:24:15,753 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/4bc2bf30466e401058378f38a300a645668ad6b601617b837e88f036afba58ed.feat, zero vector used\n",
            "2023-10-27 10:24:15,758 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/607a5ce87cad9039f41065770532c386ab2af8fe08ef55f6a73612f89843e20f.feat, zero vector used\n",
            "2023-10-27 10:24:15,760 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5d7e0d5f9655b0874c2f1f662a0891996e3076d211e6ac6f1c653552e12656d4.feat, zero vector used\n",
            "2023-10-27 10:24:15,768 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/86bbe3357fafa9ad618fa27d1f2a8fc505b26529c0b3273fd972c8a30e421583.feat, zero vector used\n",
            "2023-10-27 10:24:15,771 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/30bfd2fed2c0395a1368fe4ea142605a3fa73e2269d83fdd1cdbabefde414acb.feat, zero vector used\n",
            "2023-10-27 10:24:15,773 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/08c7b7aae519c3370fda03d7f8e32e63ac7ddcd9504a91e7566634dc4914300e.feat, zero vector used\n",
            "2023-10-27 10:24:15,780 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/c21262099faa7616982928b7f4fb0e3e0f9d9ee553f9b0161c65649f07e09f4f.feat, zero vector used\n",
            "2023-10-27 10:24:15,786 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/daf6173fcd29359e0e0a143efa60755c5ccc4fcaa59ab9c1b0a0b616bf52f86c.feat, zero vector used\n",
            "2023-10-27 10:24:15,787 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8376ef8ab6693fdc9f56d685c644f4966c8429cd0f95aee53d7bd89c2dac5bab.feat, zero vector used\n",
            "2023-10-27 10:24:15,788 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/dfd24975e206ab21126d1c2c906d97883aa1d3d5583abb9483fc4fa5ed04a6f2.feat, zero vector used\n",
            "2023-10-27 10:24:15,790 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/42c592a7fb1475a5a4376e09d80a069d14258d13bfac4b628ca83e2e2b21bc67.feat, zero vector used\n",
            "2023-10-27 10:24:15,793 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/577fe1e02dc5db8d42572d8dbe4bb292dc041a2c25a8040647220769815da170.feat, zero vector used\n",
            "2023-10-27 10:24:15,793 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/62184930bf819345d953635ea09d237e7cedb8384936d033c20cd7533e1fbebd.feat, zero vector used\n",
            "2023-10-27 10:24:15,798 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/990d2b5423ebe172ace9eccfff8dff98d07ae5795ab2bae9c2cb60696b1e1c67.feat, zero vector used\n",
            "2023-10-27 10:24:15,799 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/0134d60915e935a002fc8f9a3c6dda16504b5aa26a538ccaf26e9c6b9e7b59b6.feat, zero vector used\n",
            "2023-10-27 10:24:15,799 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/7fea83efe8cc7d91f8328def70c82064a5df94c233a262f10540262aae9e972f.feat, zero vector used\n",
            "2023-10-27 10:24:15,800 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d42791a78dbf4a2eb9da1beb882b37895233c59d7ac2b1294a62d5b34a1e6f6b.feat, zero vector used\n",
            "2023-10-27 10:24:15,807 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8b50a92ae82797b311c9ae574739268beb441c0a66ef33ad80945b00304356f8.feat, zero vector used\n",
            "2023-10-27 10:24:15,807 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/20d045a117840bc25ccbf6a9dbdce541a6488f3570306776264e2bda6bdea33d.feat, zero vector used\n",
            "2023-10-27 10:24:15,829 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b82135947c748380a6289263c4f126f4458db09f73b2399a8bbd3b887c5c9d3b.feat, zero vector used\n",
            "2023-10-27 10:24:15,830 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d692faf23617968a43094c299801cc5153c64e2c8a0888b530313f5e16e2d533.feat, zero vector used\n",
            "2023-10-27 10:24:15,831 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d1ef5474778aa6def947955d778c31506088efd1d3710760021a2d0677c2ce95.feat, zero vector used\n",
            "2023-10-27 10:24:15,830 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/3d3d3eab2c8fcadca1ee1d9166e9074fc4f4b8713d2a7e55c8bf2c2df6013e2e.feat, zero vector used\n",
            "2023-10-27 10:24:15,838 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/11204ec2b2d7e7cb06a3585402fc00b2f527d06843343116630b6ccf6c530801.feat, zero vector used\n",
            "2023-10-27 10:24:15,837 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/dffcd51a79693480606ce15deb70442823473e1da66e9145428fd78d4863ea37.feat, zero vector used\n",
            "2023-10-27 10:24:15,845 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1325cc88359b1cc74feec6bee919812705655193ca3892c6a5f4cb6b584ec160.feat, zero vector used\n",
            "2023-10-27 10:24:15,848 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d07d6af4933d94387fb6a0ef7f25a987e090a9c7089c297c874cfec3d4de822d.feat, zero vector used\n",
            "2023-10-27 10:24:15,867 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/76b0bb0a0bfe5a6c6ffb8b18124cbe7af18a6362c50ad2bf00983a9ee989f347.feat, zero vector used\n",
            "2023-10-27 10:24:15,867 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a9ac289b5d6c2ec8c6c2809d566a15b8b3f1de3f2b9e04acf909789e120d0a0d.feat, zero vector used\n",
            "2023-10-27 10:24:15,871 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2c11c6127b8df4c2650d9b141c738750542f787353b6a30320f2154cf9cd50d4.feat, zero vector used\n",
            "2023-10-27 10:24:15,871 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/da1c6fca1cb9709bcebb19e8b5b2c02857f3007278f09750f8ce8dd67811b2e1.feat, zero vector used\n",
            "2023-10-27 10:24:15,872 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2f968f9efb2421ce891e6d52fac633ad952e0336311732fadd76180fb9501726.feat, zero vector used\n",
            "2023-10-27 10:24:15,873 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/c625e1c47fd0e7639f5a14bcc76de2f8002c375b34dc0dd63e90abb9071c46e3.feat, zero vector used\n",
            "2023-10-27 10:24:15,874 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e6cda2e9b58bfbaa7ca178ad51131a1683c00b9313bb0642c52fa3ee5019b900.feat, zero vector used\n",
            "2023-10-27 10:24:15,878 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/be5b326afa991edbb13f3f489aabd16ba5450d9ff6b715ba2faca748324a30bb.feat, zero vector used\n",
            "2023-10-27 10:24:15,878 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5ea1c132dd862f1095329950573a760b218288f45faef989624a8ce9301c8c6e.feat, zero vector used\n",
            "2023-10-27 10:24:15,879 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/9d8bd467ad05c3c9a48e7eec0b13c285cd810bf651662f2d7bd4b63539676614.feat, zero vector used\n",
            "2023-10-27 10:24:15,882 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/0c6f326ac731d6342438a1f6efb5be820effdd534254ac6aad9d0f44234f03bf.feat, zero vector used\n",
            "2023-10-27 10:24:15,884 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/76f32f3feab330b5f38ece3ea23d5eabc496489359c48a49c0f23a01ecdcd738.feat, zero vector used\n",
            "2023-10-27 10:24:15,892 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/44f19f8256d23d02e4bf7eac9007826779f240d9ae05c36b94d5c3b160da0c7d.feat, zero vector used\n",
            "2023-10-27 10:24:15,893 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d4a9c05711085d0d87e1b8073cc87272cdef2cd6b2bb4ef42ab733bedd5e0b1c.feat, zero vector used\n",
            "2023-10-27 10:24:15,898 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b007243706d5c64355197e2d7ff74f29a8bf70d9df4890c2067d7e58aa4d4c6e.feat, zero vector used\n",
            "2023-10-27 10:24:15,898 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e1c9bca14e045d44c5edca54d2343b6f7acc0eb5bc62b1032dc9b9e0e8f717ef.feat, zero vector used\n",
            "2023-10-27 10:24:15,898 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/c762a656656093f531907faf003625f5c574690c2acee93925f5bb6a0f1e85f2.feat, zero vector used\n",
            "2023-10-27 10:24:15,899 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e42ab1d87e32d5ed36d09ae9ce43f82c5d5fa694e07d810f5e96f5762e517e42.feat, zero vector used\n",
            "2023-10-27 10:24:15,899 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/89578559478f58374af6aa57c98fcb2cf1d6a11d7f34fd6560bb77063944ec16.feat, zero vector used\n",
            "2023-10-27 10:24:15,905 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/61943555a8921f1390b4857deed083d81a9d6b46b65de4b5de7a7b5072a493a6.feat, zero vector used\n",
            "2023-10-27 10:24:15,905 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/62d947767f77505ceba73e8a3ce505a8339199a3c3aabb15171908d29c9b49b2.feat, zero vector used\n",
            "2023-10-27 10:24:15,910 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/515f96a38759ddff6d79bfc0e2b76ccdc3364463f147b1fcbb4ad02e5c20d82b.feat, zero vector used\n",
            "2023-10-27 10:24:15,913 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f53f6d1d957e651b1357da990d39b69b9ccfd974e29505f5f01c20271dfa7766.feat, zero vector used\n",
            "2023-10-27 10:24:15,913 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/9fb9d31779c18fa0ea8742359da4364c7e2e81256166fa5c13002d083c1297a7.feat, zero vector used\n",
            "2023-10-27 10:24:15,928 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5774220fc1d6f982185b38d8e2888d745b1f1ee69ee1da28ebb6c0a3eb1946d2.feat, zero vector used\n",
            "2023-10-27 10:24:15,934 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/06876812b6f7919e6a36e1fcd5e8cb1acc6bfdddc6327a43127997534cfcbb53.feat, zero vector used\n",
            "2023-10-27 10:24:15,949 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/9c94e135b341608577d913cf79e980d527de7611bb243e39756a7c10ada903c4.feat, zero vector used\n",
            "2023-10-27 10:24:15,956 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5c0de1c7452bc92c42000e4d248fe8d4679ab078d2c9cbe3db6b467ea5d3a2b4.feat, zero vector used\n",
            "2023-10-27 10:24:15,960 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/477605f375ad94efca9f58f22e14351fe9fb1033634900017c6853bea48fbf24.feat, zero vector used\n",
            "2023-10-27 10:24:15,961 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/3b45ff48172ccf21ad1cdea492b56f03c14b430e3c93c325a033ff764dec6d39.feat, zero vector used\n",
            "2023-10-27 10:24:15,968 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/7d2f02222554da691150768fea7e84c031ebeaf0f7408f8d943b3fa32d7f310b.feat, zero vector used\n",
            "2023-10-27 10:24:15,969 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/31cf5c315a798992c9a30fa119850c649034d8aa0d942b6b475efb9622fb1115.feat, zero vector used\n",
            "2023-10-27 10:24:15,970 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6550d66db911ebd597865600faf431abbd79284ce8f364b261b6a5107953d166.feat, zero vector used\n",
            "2023-10-27 10:24:15,971 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/0e96a53f6bb9a8cd0b5d73b556046ff527599dc61e36afa774f3d5c3657b4972.feat, zero vector used\n",
            "2023-10-27 10:24:15,971 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1a8626a33a723752e0bb3f5c7ea48a77f2a4c62cd0d3bf662a91ee05dd29dec7.feat, zero vector used\n",
            "2023-10-27 10:24:15,975 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/15d16b75abfbdd67bf6a22f64e10a1d51d3e5758b460032d5f6959ae5d569af6.feat, zero vector used\n",
            "2023-10-27 10:24:15,975 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d2f36dff075439705056702447312b76e1e759a07d84d93fc495dcfa70941fe9.feat, zero vector used\n",
            "2023-10-27 10:24:15,976 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/27853e8f7bd56e98929d162a6a704079ffcb2be7d603845ac24eb5f506870789.feat, zero vector used\n",
            "2023-10-27 10:24:15,977 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/bbd18b2d9fe3413dd9fb600ecf0232376ec4f60d722991e7c8fa378dd344a890.feat, zero vector used\n",
            "2023-10-27 10:24:15,982 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d7cbfc74ba6b8870f2bf39c925c718668da7aa75c1ede1ee1af72d7fa2b2eee5.feat, zero vector used\n",
            "2023-10-27 10:24:15,982 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5bcf84f9f089993e56c70137b124c31733990485dafcca7488503701e7898ce6.feat, zero vector used\n",
            "2023-10-27 10:24:15,983 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/42773e61bedca2f8cb2bb071a63cc2bb555ca2caff37543cc7442efe7a1389e9.feat, zero vector used\n",
            "2023-10-27 10:24:15,983 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e75390dabe94c9d420eeab6dbe9fabb4a36217b3bb6d6561a9cc6c2b4638fda3.feat, zero vector used\n",
            "2023-10-27 10:24:15,985 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/3e28ad9b214d474444188e8bfaa3dd4db47e351e9dd9d74c4a05cae4c5029b1e.feat, zero vector used\n",
            "2023-10-27 10:24:15,999 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ae9b7ce5af7431e8a35668264f0ecce8e1f2b389f0910cfcaaba385fdd4c4045.feat, zero vector used\n",
            "2023-10-27 10:24:16,003 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f8fb15d62cc7e2140a9fd9588ec6976dd662d974d4765faf8e9f5b7cccab1f1c.feat, zero vector used\n",
            "2023-10-27 10:24:16,003 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5cde1a6da47dbe2572ae1ff66a45a9e03131e802c14c5f5bd1cee87c71f23819.feat, zero vector used\n",
            "2023-10-27 10:24:16,004 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a83f49e34a6be3baac78ff1d4454fe43646702df70b818c13850b49f5321f3f1.feat, zero vector used\n",
            "2023-10-27 10:24:16,004 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/84900a2e225b44f68fe38fc34e93ba8cdb86451ebc52e019672928c4c8c10f55.feat, zero vector used\n",
            "2023-10-27 10:24:16,007 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d45aabeac934b091dfcf242bd11fb56c8420b16dbc53734b2b3959ea6b7bc191.feat, zero vector used\n",
            "2023-10-27 10:24:16,005 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/235c357b653ff10a4a7a0a64d680e856435e0052bd117cca8476e22ea15a8957.feat, zero vector used\n",
            "2023-10-27 10:24:16,013 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/62b9fcaa612ea89043cb5eb62055da10eea93ca8554017d7ddb5f4e0b7bf0185.feat, zero vector used\n",
            "2023-10-27 10:24:16,016 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/04cfc1a6cdd650666d841601f2d127d90be29cbef8a0edefd742b4218ebe31ff.feat, zero vector used\n",
            "2023-10-27 10:24:16,018 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/9357243d2eba3a4c12e76a4f2682cb8128aed41b87cf2414199631ffb510fa0a.feat, zero vector used\n",
            "2023-10-27 10:24:16,019 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/3d4b4fc47b1d71c20f1be656915e25f54abb7ff50f9fb6031afeff588d926b92.feat, zero vector used\n",
            "2023-10-27 10:24:16,028 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/aaa34050db9a0987079d0178a118fcbc66ab1880e371197217276c0187fa4348.feat, zero vector used\n",
            "2023-10-27 10:24:16,034 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a8806bfaefd1bf1f73165589f30ee5bfe7e600f105e24991d124dc2126be96ac.feat, zero vector used\n",
            "2023-10-27 10:24:16,036 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/bc9aa1ba12cdf0a8248903a605dbb032a513f5d8eed26f7ce16174de1dc41214.feat, zero vector used\n",
            "2023-10-27 10:24:16,038 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/3cc210171a246c97ff5613748afedbbc9dbed71cbc7dc299dfd0f8a39f5c92b7.feat, zero vector used\n",
            "2023-10-27 10:24:16,039 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/648342ff6f5f5a0775e28c979ef6889a06e1a9c1477561aad1c0789a401621b7.feat, zero vector used\n",
            "2023-10-27 10:24:16,043 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5b511bf509ba4f5b21127d0844a73d2b3cd2bb8aaf3102de47a77d01d9602564.feat, zero vector used\n",
            "2023-10-27 10:24:16,044 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/142cc3732ce7fd785d972cbc211ff4e560a4e7eeee57bafbbd3ad8039b8dc72c.feat, zero vector used\n",
            "2023-10-27 10:24:16,045 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/118c6e59a8630519f08bbefd1f8a4173889312de6740a2e3d768030a5e4313d0.feat, zero vector used\n",
            "2023-10-27 10:24:16,047 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/099d4c24240f4cb24e0d2765d017c7a71fbef65302a636d34e2b55c44987cfe1.feat, zero vector used\n",
            "2023-10-27 10:24:16,052 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6c0ccc4747dcd3b79e73d510c19e66861c11f33d56f3069bf19f8e43fd0de400.feat, zero vector used\n",
            "2023-10-27 10:24:16,053 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2c1fd60797ec83d921b7fe79e6a2bac0664b40cdb0bf174f7c65efa2242c0a42.feat, zero vector used\n",
            "2023-10-27 10:24:16,054 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d0198531726b40eac5f5e7df5abe56298a0a0279f9a524aa5e34bd75ecf3a49b.feat, zero vector used\n",
            "2023-10-27 10:24:16,054 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1077de39e900ebd0392e4682df1faa853ef7ba3f868d7399ee1813c9ac526c31.feat, zero vector used\n",
            "2023-10-27 10:24:16,056 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a0b8657f50b2771140920fb30d4b5218bbb5f743cf558e675e4051aa0394b4a1.feat, zero vector used\n",
            "2023-10-27 10:24:16,056 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/4b02c6a448659bc0abab9b303a2de1a667e5dfc65222bf5710e6523284aa7599.feat, zero vector used\n",
            "2023-10-27 10:24:16,057 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/87a1f5927e8c811a1bc2fc997d52e5c7c678e29f4dcb0aa335cbc40d3dd57694.feat, zero vector used\n",
            "2023-10-27 10:24:16,064 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/cbb4a9b228ec2fd5ac7d2c097fbf7344d07cb2f0aedcfd94537724bf5f639961.feat, zero vector used\n",
            "2023-10-27 10:24:16,064 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/dcfba4743d7ed76830db3801744bec62385b51b8314f8ddfb4302fc56ad64240.feat, zero vector used\n",
            "2023-10-27 10:24:16,065 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1752f00b63c2b7a52f32511338e0d2b0584955bd00bebfcd3827c08e13310602.feat, zero vector used\n",
            "2023-10-27 10:24:16,068 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/3aa223ed95d6d7727d1c0592a42ae02858500b89e836492e8e8383bc43a44c6f.feat, zero vector used\n",
            "2023-10-27 10:24:16,071 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/dbc4fb5070d2e6434307ceaffe2f79484cd7487ed2d1a36d74407a5ae5fdda0e.feat, zero vector used\n",
            "2023-10-27 10:24:16,087 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/06b49e4bf6be41825ff85fe927d05fbc658abc3f6ca6906ebfeef94733fb209f.feat, zero vector used\n",
            "2023-10-27 10:24:16,090 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/382cd9721d12b6f395ef7075f3232dffd9432102bca0cc805bfaaf496fc120a3.feat, zero vector used\n",
            "2023-10-27 10:24:16,092 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/16bb6afc2af1fd50064cc18043cbfe7f7999dcc9c1f56552cbc325c7b47fa2b0.feat, zero vector used\n",
            "2023-10-27 10:24:16,102 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/bb9f8fa244355293fe288175a7bf875dbfb16b33acc48608691cd5688fb6879b.feat, zero vector used\n",
            "2023-10-27 10:24:16,122 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/9aec08962530f2ca7365a894e3e1928972bb9199d1f83779ecbc692528ed0621.feat, zero vector used\n",
            "2023-10-27 10:24:16,123 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e8cb374d717f34dca47dfa4bbcdec80d570985560d02b07168b4c93f26a4cd41.feat, zero vector used\n",
            "2023-10-27 10:24:16,124 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/0e35fcb1b61f75ae03878e1f3fca742b66437d5866286e427faf15cb2daf0504.feat, zero vector used\n",
            "2023-10-27 10:24:16,129 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/18c4fe0195598296ceeba0c5c6df471a8b44b260a11689134e1872fc4b29bc7e.feat, zero vector used\n",
            "2023-10-27 10:24:16,130 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f7f5d71e16b0d9987093b33d338dc637a687bcccebdb731fb3e8094b568a7d1b.feat, zero vector used\n",
            "2023-10-27 10:24:16,140 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/464d44af98e5956f464227cf6b89fc2d72328b86d2d5c25e061c2705869c78da.feat, zero vector used\n",
            "2023-10-27 10:24:16,144 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/3138d0587b27a466240b9098356171c68110ea9c5945a56e47df221d33a9e51a.feat, zero vector used\n",
            "2023-10-27 10:24:16,149 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ea045f1926c591cf2c241cd8835b74df0ed9df036313ac26db926bdd6392a151.feat, zero vector used\n",
            "2023-10-27 10:24:16,149 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e3ef7a501ef481e64765e74aa42ee2a825d93d6ae5afabd32c06a4402c2f3f09.feat, zero vector used\n",
            "2023-10-27 10:24:16,152 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/7d885cc51e4e6e0735929e5555c9f31822eb759a922c56e2ff90c0455d14170a.feat, zero vector used\n",
            "2023-10-27 10:24:16,155 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/28d61fd8ea2064a5d33e12186b15a5b856235c9ed0bd42480d3596b7d28aaf6a.feat, zero vector used\n",
            "2023-10-27 10:24:16,156 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6a02a89e289be63993adea55401d6f9c5b7fac8571ade6b61c5507f6450f7804.feat, zero vector used\n",
            "2023-10-27 10:24:16,158 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d1d30000d0730a43da43e35d3f7c6de9413e4f65b1d9a9e0279611645326ab8a.feat, zero vector used\n",
            "2023-10-27 10:24:16,170 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8d30b02fc7aa5c0aed564d1ac2bf8e98d56c64a61f5664766bfe1378eefdc22f.feat, zero vector used\n",
            "2023-10-27 10:24:16,175 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/329f94dae4a9f23c3941281536965514f35399f2cd587eec67e1498d80fce6ae.feat, zero vector used\n",
            "2023-10-27 10:24:16,176 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/53b1cee4f1b0081111c140ab680a0eac7e116061ede359608011b0230772edba.feat, zero vector used\n",
            "2023-10-27 10:24:16,179 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/22ce5ffb026d114480b451a56554dd24abe9dac801f81b7e20a97a84d5295225.feat, zero vector used\n",
            "2023-10-27 10:24:16,182 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b65357889945c2cdc9cbe1719bf3910c4abc69fb980d9337968ea7f57d1373d0.feat, zero vector used\n",
            "2023-10-27 10:24:16,183 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/bcf5d047243604eb42bbef736c9a9a9a49c35859d42058f75a640c1b1b0500ed.feat, zero vector used\n",
            "2023-10-27 10:24:16,184 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/870d6b70edfce70e92504ee4b0fb03876eb8741ad4da537501ad99537d526366.feat, zero vector used\n",
            "2023-10-27 10:24:16,185 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8fea7b1b0c14e461c623d154b58e6fe66a64ad2e3c95b0b701c88d7f9d6bab09.feat, zero vector used\n",
            "2023-10-27 10:24:16,187 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/80a4bc4514399244c6ab06546b5c4191e3619981859c9e10bd2733417c8b1071.feat, zero vector used\n",
            "2023-10-27 10:24:16,187 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8bcee7397e9729a13fecfb50097e701e700a76db42895496994cacb5394a83b9.feat, zero vector used\n",
            "2023-10-27 10:24:16,189 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/537d843800038df2257783e745bfcc305a1d78bf0e5908db9225da8e39b145ee.feat, zero vector used\n",
            "2023-10-27 10:24:16,189 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f054527705b88df7f1ecb78f26782c968f1a52de66523de0852d545547807b0f.feat, zero vector used\n",
            "2023-10-27 10:24:16,190 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2423c5f0cd79c6f0405c33dcebfcee28b53f9036ac975bbc280c2692b53fa804.feat, zero vector used\n",
            "2023-10-27 10:24:16,190 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b18e313571d7d034500cd8e7f23fda69dc61bff889aba9ceb239ed5056475b32.feat, zero vector used\n",
            "2023-10-27 10:24:16,191 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/305d5d1574ec7b93477b47f3d24b4269f9a54a9ac38151caeee9b2c288a7e9ec.feat, zero vector used\n",
            "2023-10-27 10:24:16,192 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2ff24624eb6827ed2fd22debb2d11448ec9ec4878153dbccdbfeee715bfcaffa.feat, zero vector used\n",
            "2023-10-27 10:24:16,193 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b2e5b4de7811519fd810117e11bb521315e2805e28ed3fae2ee2385c4c93fc9d.feat, zero vector used\n",
            "2023-10-27 10:24:16,193 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/7d09380edcb948eecee1f98b91628563c853f6bf391dc469ecae6f38df6f8480.feat, zero vector used\n",
            "2023-10-27 10:24:16,194 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/205da93ebe50487359a565c818164ba25a324a63157988a5d7be99d00e374162.feat, zero vector used\n",
            "2023-10-27 10:24:16,194 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/47ceb7e106c76aab04f09fb52f22b5f6cccb4173f413b8b611b3d96ad2859b1d.feat, zero vector used\n",
            "2023-10-27 10:24:16,194 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f57079cc8c57484fc559d2996d3ad94ea7d3547bddb848bf546b092da66c8701.feat, zero vector used\n",
            "2023-10-27 10:24:16,197 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1dd083a8cdab7dcea75992306713258d2d2eb3d1d2af1413361efbae26908db9.feat, zero vector used\n",
            "2023-10-27 10:24:16,198 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/781633cca19c12f8285d7b80826f1c8ce1631efa4c0c872bd0c9ca8036e70e78.feat, zero vector used\n",
            "2023-10-27 10:24:16,201 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/4ea08b974da18695b6b40a63bafb8579a5877060a60f452360a5c7ba450b3e06.feat, zero vector used\n",
            "2023-10-27 10:24:16,204 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2b07d0c3aa9a028926b3f79e67322fafab87dcdf071144acb4d7cbc1509757cc.feat, zero vector used\n",
            "2023-10-27 10:24:16,204 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/7965eae7ebb4db31b6d0611825733e96fcc2a5ee19559543aa34f5f43e8ff8bf.feat, zero vector used\n",
            "2023-10-27 10:24:16,208 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/7696884308bb91ebeeebdb4512cddf89bd3ad501f0ad96e67fa991e5731d1610.feat, zero vector used\n",
            "2023-10-27 10:24:16,217 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1618d82ab877ef4c7e28e1abbb403bc8fdddaa0f8cf08e475fbbe2bd82118778.feat, zero vector used\n",
            "2023-10-27 10:24:16,218 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ada9cc10cfaa8e58e85f3fc26ce863d584d31e89f5cba014bf96cd17a6dbb627.feat, zero vector used\n",
            "2023-10-27 10:24:16,219 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/7ee19bd40eaacf6c691560e576783f55fc7886ed2e17ad131985c43bda7db643.feat, zero vector used\n",
            "2023-10-27 10:24:16,221 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/84ec2833a2f18cb2d7063e8b29749ea16ecd128c33402cfe71b4d1a96bc64c6e.feat, zero vector used\n",
            "2023-10-27 10:24:16,222 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1034fcbccebb072ae523830a0bf72ef5e6a0794d7f46f4c5b178dcfc8bcedca2.feat, zero vector used\n",
            "2023-10-27 10:24:16,222 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b1cdf3df8c0682af7d9ce78a50948f0f7282eaa0ad62ee8edc3896d99b768379.feat, zero vector used\n",
            "2023-10-27 10:24:16,224 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ced0221e042e78461ab912d398feca79eee45d78cfefcda39a26de457fb62a8f.feat, zero vector used\n",
            "2023-10-27 10:24:16,226 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6ec241e11d8b5b18f7ceb07a0d3d79e152dc0153b1e20a7c2f9379632a13606c.feat, zero vector used\n",
            "2023-10-27 10:24:16,236 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/09821d031f0f3d92e542aa893f49c213c96bacb7eaa228835f4b5928f51814e4.feat, zero vector used\n",
            "2023-10-27 10:24:16,237 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/303f64b1364b356bd6819bbd02a15316ed75655a477cd9d8e4c0259affa3b65d.feat, zero vector used\n",
            "2023-10-27 10:24:16,237 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a345df9d4292f99ef7d0770bdb40953f1eb9e49b7743cfb7b6efbab5450985ce.feat, zero vector used\n",
            "2023-10-27 10:24:16,239 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/c1c9305ff6fed3ba1cae2962e6b067fcdcc9297df2e7adc564dd4542b6e19b6a.feat, zero vector used\n",
            "2023-10-27 10:24:16,239 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/64a3fc9701c670fb4dffff696401f632c3c9294d34480946b8efb7b6696fbfb3.feat, zero vector used\n",
            "2023-10-27 10:24:16,239 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f788636a18c924d04ef08885d8742553bf2cea0e9e4bf53b2d6863d0ef1ba393.feat, zero vector used\n",
            "2023-10-27 10:24:16,241 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e0ac7b80fafb060da0486f2732cdfd8af093cd4769618597c15fa018cb2486b1.feat, zero vector used\n",
            "2023-10-27 10:24:16,242 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/63b2d4ab94cdfb8d797cad07d72ab7f76576ad1dce27f1b8502d3bcc2983fd41.feat, zero vector used\n",
            "2023-10-27 10:24:16,242 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1f8245b6b077621531bcd8ce332543f8bfb7adcc47c1cd87931c4ecddcfd111b.feat, zero vector used\n",
            "2023-10-27 10:24:16,243 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/581698cfcb18efd78938cd2bf29424c73f2c3bf082a826af95793c9fa6221a67.feat, zero vector used\n",
            "2023-10-27 10:24:16,247 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/c1ac12fef76a3a9d4583148b5d7229adc2436fb67237c48869686f293d512bf6.feat, zero vector used\n",
            "2023-10-27 10:24:16,247 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/12a579472ced4772647371e2e8f2b59783f4872b0fea65a83420e64e83bbb4d7.feat, zero vector used\n",
            "2023-10-27 10:24:16,250 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/c95f7a4993f9845de3339d78281d3f6dc9951ebe7cd203566aa30ea66f0f64c8.feat, zero vector used\n",
            "2023-10-27 10:24:16,252 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d18cfdc52b2fef105ac40d859d850ad21666e6b30f31bdb0f1efc96a12ec189a.feat, zero vector used\n",
            "2023-10-27 10:24:16,253 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/3ff13cf8a1e28e16134c84a95cee87b019b547cb0ae2579255a91e628ddf57a2.feat, zero vector used\n",
            "2023-10-27 10:24:16,253 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/49d3d2b8fffb10a65ebb94bbef458a5be7b45c72f1fa5601670616a01b932862.feat, zero vector used\n",
            "2023-10-27 10:24:16,254 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1be836a6b49fd0e398e453c78f93514378dfd08d164dfbd9d48ff9a786045ff4.feat, zero vector used\n",
            "2023-10-27 10:24:16,256 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/68586b21faa614787e5274bef73faa2cd2668bb70420a5841bbaaa765fb6b2f9.feat, zero vector used\n",
            "2023-10-27 10:24:16,259 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/66837c48b4e9431ac4b2fd1278beeedb749f6bed10da9401a9c4c9880e54272d.feat, zero vector used\n",
            "2023-10-27 10:24:16,261 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/3cac782e3184c3fc0f71310861b43c0d5c7eed2375810388143237955e716de5.feat, zero vector used\n",
            "2023-10-27 10:24:16,273 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/0bc8904771fc773934377bc84a83f2bf560a2a5d7607843b6c7da05534265644.feat, zero vector used\n",
            "2023-10-27 10:24:16,278 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/832b8278c8d58ea9ce97a57d5344fbc9bccbc21a4f70b82b52822015e3303288.feat, zero vector used\n",
            "2023-10-27 10:24:16,282 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/67d8e801658f69b90b9a50e3802c804c43a0e93ff5c47d29766f031f46b143d7.feat, zero vector used\n",
            "2023-10-27 10:24:16,285 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/792c9fa5399d2cd2de9bf7e08ed684af008cf1374b5731cc6f217835fb77be0d.feat, zero vector used\n",
            "2023-10-27 10:24:16,295 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b36286836ef368655b6a9e87e14743642a582639049727ede6d518a15f767dee.feat, zero vector used\n",
            "2023-10-27 10:24:16,310 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/bc0595fc840d6b3aff20f425e275c533ff1b5f641ddda5244ef389cdf2706d35.feat, zero vector used\n",
            "2023-10-27 10:24:16,311 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d6b47578236208c165dc1dcda18ebb47f3782201610d91f6819342838f97c4da.feat, zero vector used\n",
            "2023-10-27 10:24:16,313 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e0fbfe040309def46c7d52b99f432223c362c30c04018192f3800ceeda56f79e.feat, zero vector used\n",
            "2023-10-27 10:24:16,316 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/c21616d0b06383d36914fa194a81e00fd5c4f7f956216f99afade0841e51573b.feat, zero vector used\n",
            "2023-10-27 10:24:16,318 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/260f2e3bcdeff4ae9de4e770f8c92c6977bb58cda701dfc324af67607d92a191.feat, zero vector used\n",
            "2023-10-27 10:24:16,319 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/880a5de4bf8bb66797c0abb3e8c2e655c474c8ead73ab1e05e05dee8be69719b.feat, zero vector used\n",
            "2023-10-27 10:24:16,320 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/775e62d9ffe614a2a29e835b8e3d3651b51f8c3c5c38735061cf38cd404398fa.feat, zero vector used\n",
            "2023-10-27 10:24:16,320 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2a521a5f05160d45334527ede47401e1b80eb38e063c86ef011ca23d73e63eac.feat, zero vector used\n",
            "2023-10-27 10:24:16,321 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d4f915d9c299bf3bf8ebd5b17ffc3c8cafd7e459f698ce607f7d0fcd87fc1896.feat, zero vector used\n",
            "2023-10-27 10:24:16,321 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b2fc624efb4a72a5005f4e5b6b1b0acca7d0a8a9484861464184871b165d3c0e.feat, zero vector used\n",
            "2023-10-27 10:24:16,324 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/cd004b14de8eca186cc22097b354b57a40bd25798b309f88fd1b24cecdb2b4bc.feat, zero vector used\n",
            "2023-10-27 10:24:16,325 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/85504dfef3f55a2bfe264db5cfc066859381e39589cac151775a314fe6cc62d1.feat, zero vector used\n",
            "2023-10-27 10:24:16,331 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8d7147403babc40d1928eb533f332e340653209e60a87e30c6d822391c7926a4.feat, zero vector used\n",
            "2023-10-27 10:24:16,331 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/bab60e9303a78e8c934ec54339c5a3e5ca75b1864fa0b8a4d0faea2210d75ddf.feat, zero vector used\n",
            "2023-10-27 10:24:16,331 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/aed2f2e0fb6b4ac208c3f99485a1d10a7e2f9a4e7a74e3cb29301e34bd241a35.feat, zero vector used\n",
            "2023-10-27 10:24:16,332 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/001a32872755f51362824eaa5f7ab0778c642b3848a4d2ca25531619d04e6e37.feat, zero vector used\n",
            "2023-10-27 10:24:16,332 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ad0d17331fe1c7480ea7c3ced3a6343bfde34a80a1722a37e9e232c7b74c28f8.feat, zero vector used\n",
            "2023-10-27 10:24:16,332 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/88c3e429e1272e5ecb4aa0e4be0e401c7fa2a66db34a23924d9db3cd354585e6.feat, zero vector used\n",
            "2023-10-27 10:24:16,333 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/798c9585fa15a2f8f08162bac7ca01d1447ba5a2bb57b4134d9fd4f06d2067da.feat, zero vector used\n",
            "2023-10-27 10:24:16,340 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/21d4874ec2fedb81924b1aa043ff066074efece760d8162825722e3136ce84ef.feat, zero vector used\n",
            "2023-10-27 10:24:16,343 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/893e8b86dbdaf6b5b0693c4664d4e9354f33b642448002baa593a9eca444b30c.feat, zero vector used\n",
            "2023-10-27 10:24:16,344 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8b9e03aa8987f08284f7aba4b9d6671e8ea5dc3a10381f2be37e14d2e31bc07d.feat, zero vector used\n",
            "2023-10-27 10:24:16,344 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/689effe9fd11862ed6531c2a723b3dd877997f3f280e464ca5c86c3ba26acd72.feat, zero vector used\n",
            "2023-10-27 10:24:16,349 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8de74d1978a4b378c5ff37d392cd8c56a4f5da33d14c5e1436b98c30d24af960.feat, zero vector used\n",
            "2023-10-27 10:24:16,350 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8b7ae6742ba73e840c2f937776657ecb3a7828df80821f953601aa9a23a20161.feat, zero vector used\n",
            "2023-10-27 10:24:16,354 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/59fc39a86b4c24a00221da492da9f20ec63f9efd0432ef61ca938e96105529d4.feat, zero vector used\n",
            "2023-10-27 10:24:16,356 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1246221c0e1d13e64eb15a4686e4a71af6e209426c611957dde4dda4977dc4ae.feat, zero vector used\n",
            "2023-10-27 10:24:16,358 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1890d855c1b8c735d101dff02dc372821717b4aff2401a8be662d0029cc1b4e8.feat, zero vector used\n",
            "2023-10-27 10:24:16,360 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/711c0f615465b27e8ff389f258a708ce51518a31e1b206cea445d0e738c5347b.feat, zero vector used\n",
            "2023-10-27 10:24:16,360 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/95f1fe8ce2291fd8b0a1669ee89d674fc4aaf4b743b00ea9bc67498c24c11e3e.feat, zero vector used\n",
            "2023-10-27 10:24:16,362 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ace9a4326910fe956d8a6ef95ad3bff625bad721ee996aeea94c88a4386a549f.feat, zero vector used\n",
            "2023-10-27 10:24:16,365 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d963b267dd3bce2ecbcef57deb878d778eabd76090678a726745764298655ffe.feat, zero vector used\n",
            "2023-10-27 10:24:16,365 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/03e0a903cd323efafefb6d731e441f5057f5c0c16a9fc64b235bb46c8c36ba42.feat, zero vector used\n",
            "2023-10-27 10:24:16,366 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/fd7b26d5200e5492e6d61f7a1c4a2ecf07c944891dd8559c57d8fc140d40f812.feat, zero vector used\n",
            "2023-10-27 10:24:16,370 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5910019343bcc038f80fae994acb11ed787dfdd289b30713d730f3ab74dbbcd3.feat, zero vector used\n",
            "2023-10-27 10:24:16,371 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b72416924a9d368c33b909dc5b30cbcb15bc789b8d0cc1fc27f2647fff02a9e7.feat, zero vector used\n",
            "2023-10-27 10:24:16,374 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/9d67ddb1629623a16ae386ca598d090d6c71d94f89796734c0f1dddd7f103497.feat, zero vector used\n",
            "2023-10-27 10:24:16,378 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1b96046ca45f1e4c79f9a80b58d5c88a8cada80cf080d92c50e04b122532256d.feat, zero vector used\n",
            "2023-10-27 10:24:16,381 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e12df5c76f553cd13bb316cd3949f88b336e170f8f38aac91753ae59aa9149d9.feat, zero vector used\n",
            "2023-10-27 10:24:16,385 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8b41227e39f7f8b151dd55808e533f4f275f99ac05fd267287f32ccc6d9dfa62.feat, zero vector used\n",
            "2023-10-27 10:24:16,386 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/58ba7d45fa9b315e7acdecb48723a0f3582d73af09866d832ad224a7f2294cf0.feat, zero vector used\n",
            "2023-10-27 10:24:16,387 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f366b0b146281b22c15831faa576b9b928fc94d7c23dda01eff0a293d3d980e8.feat, zero vector used\n",
            "2023-10-27 10:24:16,391 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/4f1e80625a3d147985d949781339524afe735fbbf3f558c2d39159fc36a70d16.feat, zero vector used\n",
            "2023-10-27 10:24:16,394 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f1a55b014275b3f2b8e685abe9673319398e2d2fa661e37a1ff82ab179d29600.feat, zero vector used\n",
            "2023-10-27 10:24:16,395 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/cb9c8d6493a2dc63bddc0b2756411a99a06df0d829f07d696d5d717135bf0cff.feat, zero vector used\n",
            "2023-10-27 10:24:16,395 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/fca565acda441b11c391b7e9ebf5e3869efe6a7cb9f8efda1f1c2e87c1b58a1c.feat, zero vector used\n",
            "2023-10-27 10:24:16,396 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/850aa38bc954641595fe21d97ad1c6410e8951fc94f6604b1cee20d296fb9b3c.feat, zero vector used\n",
            "2023-10-27 10:24:16,399 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/21ab1e725d9895fab82b40c117c8bcfe859a38e0090d3a240cb585e4332ad364.feat, zero vector used\n",
            "2023-10-27 10:24:16,405 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a001a4300e299cf87f72205005a9020382f21713b786d3adf4daac903cb5224f.feat, zero vector used\n",
            "2023-10-27 10:24:16,409 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e2a5f4667258ccdbab52257d9535c007a6be2e1b38e4f243ff9f252760de9deb.feat, zero vector used\n",
            "2023-10-27 10:24:16,415 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/cf9ed685f9dd27f4828eaabe48e688e9e196486752849448e12fca26e5acf194.feat, zero vector used\n",
            "2023-10-27 10:24:16,415 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/697eca9132d0959030102b0bebb64779c3981d2537f9b0403c0f820a586ee0c6.feat, zero vector used\n",
            "2023-10-27 10:24:16,424 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/3df8f2d3a8731edfb2168364b08d409bf2077d95db3be79c682b2cd8397e4d69.feat, zero vector used\n",
            "2023-10-27 10:24:16,424 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/113bccfb8cc91f2315f68ab45efa9d274b1837b08f48dc574b58dcd665ea1940.feat, zero vector used\n",
            "2023-10-27 10:24:16,429 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/3afd29128e917906f41a288922e8c5aaac5da08322c66eb6580669484e85ab62.feat, zero vector used\n",
            "2023-10-27 10:24:16,442 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f942057b96ba673b3b18dc30ac25c2456e3946d13798c07ae53dfabf2532b2a5.feat, zero vector used\n",
            "2023-10-27 10:24:16,443 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/013772fe06ad9ac4b021923c59ea165923d945bae09cddbbce5e4406db6c8d36.feat, zero vector used\n",
            "2023-10-27 10:24:16,447 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b40f789f5189c4695de355e5d68c3b2fd26cd167c189ccb1798f17b660e50ca6.feat, zero vector used\n",
            "2023-10-27 10:24:16,450 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f397461457a10f5da0c4d7c3bd4f7eab8b89dd464e70b159de773cb1b388d0ef.feat, zero vector used\n",
            "2023-10-27 10:24:16,453 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/9593b27ed0d8d54478c5881aa2b812e184a4040d0e2275e2d1ec1cea9e95a3c3.feat, zero vector used\n",
            "2023-10-27 10:24:16,472 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/aa7e3625f019d67b323712698db68bc40e090169cb125f8b028e5007cd6cb4f1.feat, zero vector used\n",
            "2023-10-27 10:24:16,474 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/86a77fe76b341d703749e5dd57222ceb9d70134068518d15498a33d06f2cbf05.feat, zero vector used\n",
            "2023-10-27 10:24:16,475 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8cca78267755a43e31cfad111a18805ea22215c1d560a354c9cde713ca609852.feat, zero vector used\n",
            "2023-10-27 10:24:16,476 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/226e61c2773884adb036156496b6aaa727739db3184f00831d461c47046b791c.feat, zero vector used\n",
            "2023-10-27 10:24:16,481 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/df85ed6664df68c70f6b597a1b0047840b013eed8a9525aaf53731e575c460d4.feat, zero vector used\n",
            "2023-10-27 10:24:16,482 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/cc8f4049b3c89ba345f432485740351e02bc25814adfc16bd4c348ac72518575.feat, zero vector used\n",
            "2023-10-27 10:24:16,487 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d3b535f65c37ee8118c96e304a2c958216d9a87e63c6744619e7f290bfb9b20c.feat, zero vector used\n",
            "2023-10-27 10:24:16,489 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/cd5566a616e713178b24c41cc2ea17204f4d15c38ac1abb218271c1a3133f517.feat, zero vector used\n",
            "2023-10-27 10:24:16,505 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1c4c238e1ccb890a5b670886f558670e144710fe84fe2227fe47789ced081751.feat, zero vector used\n",
            "2023-10-27 10:24:16,506 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d650207e1d0d5ecf28f42e2eabd90bffa9f28d8be3f6e5d5049d8a58ed16f2fa.feat, zero vector used\n",
            "2023-10-27 10:24:16,507 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/aec10a4f3fd8617ba84ef8d9088bca7341c9a010fa6c2d08678dcb5b3933a515.feat, zero vector used\n",
            "2023-10-27 10:24:16,510 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/58cae13a9b4dcc4b0705e33ab58a699ee4eb3a235de725914135663c7a5cb783.feat, zero vector used\n",
            "2023-10-27 10:24:16,510 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/7e4130ac5e3eecd9d2d2462611d5aaece16bdac912fe6897b38a0ce3c2d20dab.feat, zero vector used\n",
            "2023-10-27 10:24:16,516 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/fc8082da3e45ede01fea72913996fb73c7ff1716365e42a6ac194bc9622ad261.feat, zero vector used\n",
            "2023-10-27 10:24:16,517 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/06e9b560679613aa19669cee5c301dac517befb463de767aea61dc0b0957d71b.feat, zero vector used\n",
            "2023-10-27 10:24:16,521 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f401a339760be0cd22e84d34dc6ac8cdbc774d368f355f6e3c7eee2ff99ff920.feat, zero vector used\n",
            "2023-10-27 10:24:16,523 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a95c12fb47ff4c410af100f88acd4d920d6af6e106ab7224584930b17254c47b.feat, zero vector used\n",
            "2023-10-27 10:24:16,523 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b3214da23cf9dd49ce171c58b786519da63c84e6ec07c8a8278442581d1a4b54.feat, zero vector used\n",
            "2023-10-27 10:24:16,535 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/654a9183086b1e6c1409f3c917cc8e29a85a141362240cc58fe48684e2384533.feat, zero vector used\n",
            "2023-10-27 10:24:16,536 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e9e6edf77a27091d3b38f594c05b869225189f41668c2c34e45d4aabbcf4b75e.feat, zero vector used\n",
            "2023-10-27 10:24:16,536 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2974b2827df49725db1b0fb5f14d5b9b051ab6910398c212bc49dd0084d54096.feat, zero vector used\n",
            "2023-10-27 10:24:16,539 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5f8987e4ba68af8e6ace1f5ce0e6a31c922982e17fcbb7ecdc20dbc976efbcd5.feat, zero vector used\n",
            "2023-10-27 10:24:16,550 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/c3f7db76a380eef7fddd6e5223d25f041392fc150e510ed4f223b7f55d7a72c9.feat, zero vector used\n",
            "2023-10-27 10:24:16,563 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e5c56f29c34965e83d9ec683a262fe5cb97de5c33972de1734c659ca1285b647.feat, zero vector used\n",
            "2023-10-27 10:24:16,567 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1cb6132179a0b35ebe5d7223271042487ad6fb2210f8fa0d6b03e8c1dcd75e0f.feat, zero vector used\n",
            "2023-10-27 10:24:16,569 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/4c9f732d75e2439aad35a77188c8ca771100dce71f4ae535992f9e6b33f9128b.feat, zero vector used\n",
            "2023-10-27 10:24:16,570 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/af413a20dfd8a4c003b225280e043ead1652565c46f7ba0b630053da3af82024.feat, zero vector used\n",
            "2023-10-27 10:24:16,572 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/10bf57b2fe0b8f9012457d1743c6f6fbb07a62badb70aa724e5ac1dbd2b1cb2b.feat, zero vector used\n",
            "2023-10-27 10:24:16,577 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b81c7211f9065bd49677db9227660412a6eca3ba3c98201c32d2bcc89e9e2d95.feat, zero vector used\n",
            "2023-10-27 10:24:16,578 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ffbaca1a2378cee44d2cee0d1ef0b8596ce7288c89b0a28678058d38b7716dae.feat, zero vector used\n",
            "2023-10-27 10:24:16,585 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a86ab9f30a7c9d5e93c198ba99e7b4cd2d973a4f6ee32203672bcce5747036f9.feat, zero vector used\n",
            "2023-10-27 10:24:16,589 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d9f290ff10f1dafd5f86b19ad3267fecfe06a136e6b0be726fd669e9b33f7cd5.feat, zero vector used\n",
            "2023-10-27 10:24:16,592 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8fde1740a889762bbed4737cccb7e47eeb2583173485b998b6f42155e8acfd87.feat, zero vector used\n",
            "2023-10-27 10:24:16,597 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/18e09f2b36cc52d57105ca63c27a8126f7453cb4711d262e9a6578325cfbb82d.feat, zero vector used\n",
            "2023-10-27 10:24:16,603 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/95a16a917832632aef164158f1cc6e8dbb7708cdf25a90653dd5093ffe093917.feat, zero vector used\n",
            "2023-10-27 10:24:16,605 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f5fa3a8a05598e706909f7f9ceb57484dac90974f499e7281a83ca740418f296.feat, zero vector used\n",
            "2023-10-27 10:24:16,605 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/c7761faa85765b139f10cda45fbf9aa47161f4f2dbb21ce7cc475ed02d66e728.feat, zero vector used\n",
            "2023-10-27 10:24:16,612 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8aec452bfc30614ab76c4d71a860cbb347bb38648185ce76e32a4ce1e67c416a.feat, zero vector used\n",
            "2023-10-27 10:24:16,617 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6059358de63a271267ce64ad36f705934eb2505a79867875f399e825ac6b7926.feat, zero vector used\n",
            "2023-10-27 10:24:16,620 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/bd1b9bb583230a766291331fa4e10650c4e02b4757398380a553b01cdd338284.feat, zero vector used\n",
            "2023-10-27 10:24:16,621 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6cb88ad12e922956c3a40aae7457d07ec110b8e57d2a15373e8c999fdf1b61b9.feat, zero vector used\n",
            "2023-10-27 10:24:16,623 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/61a17031328725cb766d53c46f30f81c68e935818eb1211001ee049e36e0158e.feat, zero vector used\n",
            "2023-10-27 10:24:16,623 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/77f602b96d36e07986ab476713efa0d00e3496741ad99cb97bd9eb1db2bebf77.feat, zero vector used\n",
            "2023-10-27 10:24:16,624 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ffa1d9861bda822c38b16e316eb0af5c1cf0683055e9c4eecc2696d8b500a172.feat, zero vector used\n",
            "2023-10-27 10:24:16,624 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8a7db918d89ee294b8d92f14e5cfb245fb1671697a664570ca2953f92ac666ea.feat, zero vector used\n",
            "2023-10-27 10:24:16,632 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/99275b5ec299d1c5337ad8891544c8a55db934903aa9e9258ea61e9af300b747.feat, zero vector used\n",
            "2023-10-27 10:24:16,643 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/4b63d269a1d240763932c35abc4c7d993b88c72659bf35dda7902bb13c5431ce.feat, zero vector used\n",
            "2023-10-27 10:24:16,647 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f28efbd9649292d4ef8d697449142d33aacd4bd522f457e4c1648085f46b556b.feat, zero vector used\n",
            "2023-10-27 10:24:16,649 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f5d672bc7998901f180cb6ab65fb13f1d50465750d17489f205f4d5830bcf8b4.feat, zero vector used\n",
            "2023-10-27 10:24:16,649 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/12c63f2b13325b2d204085e118b8d22016a1d997500c47e73a7332901b4c4a33.feat, zero vector used\n",
            "2023-10-27 10:24:16,650 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/76f9a158f7e4bc6dfa313b5e213ce739301709924e51fe1cad9a915627848a1e.feat, zero vector used\n",
            "2023-10-27 10:24:16,650 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/945328fb41e6b09c83d9b3e06f87fb796f47709a0321e8a409356cfd160fcc1e.feat, zero vector used\n",
            "2023-10-27 10:24:16,651 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/dbba933d83a5a47201bf0616faf6ec4b9de648ae47dcef153f784b91c01713e6.feat, zero vector used\n",
            "2023-10-27 10:24:16,651 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ac853eda424cc0d3882611da12fa4f7884fe5b08917c879eba92049e1e848759.feat, zero vector used\n",
            "2023-10-27 10:24:16,651 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/63637f66671329e3583bbd30dd0da7db1c329acf5c259bb4dd30b3a42fd9a00f.feat, zero vector used\n",
            "2023-10-27 10:24:16,653 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/fd0f5fb424580344c980cae240a02a37ebca5cb7b6eaf395d601cd88d0222ccd.feat, zero vector used\n",
            "2023-10-27 10:24:16,657 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/29962295ac08e7433123994ac54be64410953e578f08a34513f9d77bd93ddd60.feat, zero vector used\n",
            "2023-10-27 10:24:16,660 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/26d1da989de67e3f49789dcd2ce84d632d89f20850cc93bced7876f23b9e9271.feat, zero vector used\n",
            "2023-10-27 10:24:16,660 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/3107b3c4ed7ed39373da4c2791b7e52a195bb9d40a9722e052bf2e1d1de5f391.feat, zero vector used\n",
            "2023-10-27 10:24:16,661 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/da4cb1ad136afa0397c356b4f407a368c854341149bd41518a176911569d6bb7.feat, zero vector used\n",
            "2023-10-27 10:24:16,662 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/facea56cdd77a2d2492612fa31c0e1592ceb6c08dbd89cee8271bdf13baf855d.feat, zero vector used\n",
            "2023-10-27 10:24:16,665 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/55501e8920efce4e75150bbd77f345b5d083c3f099cfa452a9b865ccec115b43.feat, zero vector used\n",
            "2023-10-27 10:24:16,666 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/9ba2c292789f12405819fd1d423b07756a3f7e823332e3e00ae608e605f65cc0.feat, zero vector used\n",
            "2023-10-27 10:24:16,666 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/95bf4f5278c53a2b9b7919782720b39eef1cb8f1866bbc0418d7cf38fda34494.feat, zero vector used\n",
            "2023-10-27 10:24:16,666 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/32289663593bfbd7cfb78976041565ff9c88cd905740236bf6c027187449d1d5.feat, zero vector used\n",
            "2023-10-27 10:24:16,667 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a59769922f68f36c45bb5b63b60889d72ebc71e63d38bcc7435e33645216e868.feat, zero vector used\n",
            "2023-10-27 10:24:16,671 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ed6d97c08b42496c955733371eb34301d8649b96319dc5bf7d90bb214b8cff21.feat, zero vector used\n",
            "2023-10-27 10:24:16,672 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/258201ecd2300b008a334293b401664f45d1b9798db070d02623df0c1efd751d.feat, zero vector used\n",
            "2023-10-27 10:24:16,672 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/7d3d1343dc03b036f63a24aaf8c42f8475c93a7af0f545ca59efa94718b9350d.feat, zero vector used\n",
            "2023-10-27 10:24:16,672 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2490c47f4172032efc642bb5b158d1ce23395e4dc839b23786d5c88411d2f117.feat, zero vector used\n",
            "2023-10-27 10:24:16,673 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/57e50ee7b340a73b8835bbd7ee6992e22869563e419a37c897170bd47ae5c3bc.feat, zero vector used\n",
            "2023-10-27 10:24:16,674 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6aa85de1d04dacf5aebaa8ddeb68ef5b717baa929b7da9566e124f4520ec0f60.feat, zero vector used\n",
            "2023-10-27 10:24:16,674 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8fe699dce69222b306383a9557c38a83bab2d0d53c60803ccd12fa5fa18cb8f7.feat, zero vector used\n",
            "2023-10-27 10:24:16,674 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/13eb1ae50f42161c5208f499cee51ff6162f3345b102143a9cca4a7a63ce8155.feat, zero vector used\n",
            "2023-10-27 10:24:16,675 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8f8578e0cda7cb5dc516b522b62065b9969ccbe9142392ecbb4b1edbc0dc974f.feat, zero vector used\n",
            "2023-10-27 10:24:16,681 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b89d735df157b4a91fdfe5971aec0c294cb82ec233cb1d7f248960b0685df04d.feat, zero vector used\n",
            "2023-10-27 10:24:16,688 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/af7e0a24df6da4363dfcbbb104ab893c25f16c1f048227981b8981b76eb7c654.feat, zero vector used\n",
            "2023-10-27 10:24:16,714 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/c0cb4c850ae1c456e4b0aef5de14fd1751fa67ec413482131c7a9fc11749be2e.feat, zero vector used\n",
            "2023-10-27 10:24:16,714 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6d610ad63a154b9597499b7b13cfac12e93b754c12af137d35e4ceee4f1df60a.feat, zero vector used\n",
            "2023-10-27 10:24:16,729 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f9754ea86424a92a2f43d93d20ec60606016ceed8780211451254c6e31b7fa10.feat, zero vector used\n",
            "2023-10-27 10:24:16,733 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8532ec138eff9a3c8086a239ea2721a981eec112220d9fbb8bc900fdb8b6f236.feat, zero vector used\n",
            "2023-10-27 10:24:16,734 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ea6d0c3c1d408d70f9f5d87e50159b50760be2748edba90cc5b94f234c1cca37.feat, zero vector used\n",
            "2023-10-27 10:24:16,738 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/623a38da7ae61702dc0d64bb8dc1b1b1e857ae27db28a70f152940029da4f25b.feat, zero vector used\n",
            "2023-10-27 10:24:16,741 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/08f23074eb3462b82777238812eabf750d2f0c3958dc77e544232492f9eafb9e.feat, zero vector used\n",
            "2023-10-27 10:24:16,746 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/9961c48b8e85cead2c181ba12176e0c65c377b908307a45c4d17aa32a3dfa4c6.feat, zero vector used\n",
            "2023-10-27 10:24:16,752 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/9f01f35cfeec255e28dc1c044e15405470f1f72331f9c4e1ce4a00dd3d8bfd79.feat, zero vector used\n",
            "2023-10-27 10:24:16,755 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/66f6c1fe341dae8085964be863097a8d5411cfb1305fe712179dde6c315e1291.feat, zero vector used\n",
            "2023-10-27 10:24:16,758 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/95988a96b29147bf6cc28b330491a8110baa4741e7086c34c610ca0c14b3277a.feat, zero vector used\n",
            "2023-10-27 10:24:16,764 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/cc239934d7cf7c55a6aefb934a36d04a7f9b065d81559d3073b6a00c13bc80ab.feat, zero vector used\n",
            "2023-10-27 10:24:16,764 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d017c56d03c281454613d6844e2fc7f4b586a24b22930cf11f4c0adbf7d0518b.feat, zero vector used\n",
            "2023-10-27 10:24:16,769 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1f685ed689fcae838563f3f89005d7d16742e561c16536d8fbd12e9a0022ff70.feat, zero vector used\n",
            "2023-10-27 10:24:16,772 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e6b75bc68466995e0c27acf96205e756b465ba60e3ca2c226f5bfad8f736174a.feat, zero vector used\n",
            "2023-10-27 10:24:16,774 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/0b18e0c0ef7b5c92921a9201878bdf156d590007c5aba1150046da165bc0dc9d.feat, zero vector used\n",
            "2023-10-27 10:24:16,774 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/faa6b8689dc2135e28face2c688410d5a9c73a02a7dc36bbe9fc51156348d665.feat, zero vector used\n",
            "2023-10-27 10:24:16,778 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/c30a1c1068da2a7e501e79a07e140620ae880f84a1c0df298efa4e4a208471fa.feat, zero vector used\n",
            "2023-10-27 10:24:16,779 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/399f6129a886a45f401debde0b334bfe61d9a5558ee3ed5a07615852fa228b6f.feat, zero vector used\n",
            "2023-10-27 10:24:16,777 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8e9a223eb96a5f3c0db99d578073320ba54c093415a4b1efd4181aa5e7fee41d.feat, zero vector used\n",
            "2023-10-27 10:24:16,780 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ef8099c68dd0d8cb11e7869ce9187b322a70e51dabf44481806d48ec70537b76.feat, zero vector used\n",
            "2023-10-27 10:24:16,791 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/dd90e37aeed315b00e2d27fbe63c8e0746ce001038d397f0070bd9584bbda3b8.feat, zero vector used\n",
            "2023-10-27 10:24:16,792 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6571509277fb6fedcd1f91f63546fc9ddb42cdc399faf7529be4668e660bfc67.feat, zero vector used\n",
            "2023-10-27 10:24:16,792 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a2f4e8fa9acd0ec30a90c13d1d71ee1ffcbb06295bd513d39f6c288bf92417e4.feat, zero vector used\n",
            "2023-10-27 10:24:16,793 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f77d83e6a2dd9adc5f88279e969e63a6945a6b415cb4a6b777f8b4e318027367.feat, zero vector used\n",
            "2023-10-27 10:24:16,793 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5742183f01291f94e204d7733680f862a11adc564346573f2bb590909ad3515b.feat, zero vector used\n",
            "2023-10-27 10:24:16,795 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ef7854393b27947c956b0a86da2a6a577d993e98b85f79d25b4e052fe12ae561.feat, zero vector used\n",
            "2023-10-27 10:24:16,796 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/109511b2e82ddb590bca3086a05023199d602f6e838a8e856952655302ea8c65.feat, zero vector used\n",
            "2023-10-27 10:24:16,799 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5ad45a091060f3479d361effd78af4d1e22ee4a242591c4fa2676cc35d96d6e1.feat, zero vector used\n",
            "2023-10-27 10:24:16,799 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f1fd450fe483f632f1d07eff29f1bf318929edd0b7fcad8e13446c498e69aea3.feat, zero vector used\n",
            "2023-10-27 10:24:16,800 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/2a28ea8a4f60022ee2195be7c2ecda3bd4d889ab60468cb328e05758f1573e18.feat, zero vector used\n",
            "2023-10-27 10:24:16,803 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/4706ca41a52fdc4610e3ca9355a057e4261d961362b731ff21755e9f4b545df4.feat, zero vector used\n",
            "2023-10-27 10:24:16,804 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b4b47f619325f742793556232d3304b07d652aabdbd71a73ee02dd5e30672ee1.feat, zero vector used\n",
            "2023-10-27 10:24:16,805 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/fa2d8027c013541e9be0333a017317422634819eb6eb8082f854a2b47b4e9fc8.feat, zero vector used\n",
            "2023-10-27 10:24:16,806 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8ba6c5c4e623ab9ea25fe0bc9a29911549644b923d4dc2b59dc6cd028818e943.feat, zero vector used\n",
            "2023-10-27 10:24:16,808 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/46b463c30e23c9f1994cc0b8b7cab3c1db375855b26cd61fd439735dac689dfc.feat, zero vector used\n",
            "2023-10-27 10:24:16,817 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d3798efeabc83582ef4d077f4a736f2755ab404d4ef437bd36ef182912b88f1c.feat, zero vector used\n",
            "2023-10-27 10:24:16,823 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a024d05cb9710b0c8c174f575c06d8c8e3ff5ae87c5c6e24bb50edc22c26c659.feat, zero vector used\n",
            "2023-10-27 10:24:16,832 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/305d1b01f3a4766612c8849fded270fff79708ded8c94f563060402e8f2de95b.feat, zero vector used\n",
            "2023-10-27 10:24:16,833 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/0a28a1e611dca9c434c0fd4044c9ea59bf1fe9e6b4e53af1b076d9c18b3ef7ac.feat, zero vector used\n",
            "2023-10-27 10:24:16,833 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/45b284998d5978cc6c7dfea2be6ccd9191ceae8da22474c9fcd2924535374bd6.feat, zero vector used\n",
            "2023-10-27 10:24:16,834 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/04686c1a33d860238088b4107a3cca2f7086b39719c6f88f1107c03ed2ae7079.feat, zero vector used\n",
            "2023-10-27 10:24:16,837 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d9cd0b852711155cf30c73aac80a55d3796c7c23b2c6097b8bd091bd4d8113b6.feat, zero vector used\n",
            "2023-10-27 10:24:16,843 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/0284f1318a89a29a7e623336e02ad6993d1dd1bcf15b3a1b41d8c6f8df41dbb6.feat, zero vector used\n",
            "2023-10-27 10:24:16,845 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/47e460ba813cc450338ff7680ebf94d27d24f3627643eb09be78d427d430ad23.feat, zero vector used\n",
            "2023-10-27 10:24:16,847 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e3d96734d3fe1079fe1b370ab15ff32f4c865f4ff11813619701ce10cd41d5c6.feat, zero vector used\n",
            "2023-10-27 10:24:16,848 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/3dd5f53ecd33164cb49848db6c0fff3c89f34987fb94b11c0f3b3bb58f2c1d24.feat, zero vector used\n",
            "2023-10-27 10:24:16,848 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/74b08f704a207af16c47efd06e872ce18f5b85630a10b4ab2c2c745b2c9fa65e.feat, zero vector used\n",
            "2023-10-27 10:24:16,848 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8cd8c2cade8a19c39d2dabcac85dc1584c76fd69db05db3834a37cd66db5daef.feat, zero vector used\n",
            "2023-10-27 10:24:16,850 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/b0056ffcf6e9e9161a52d2d1337a83b286902fdfe0e58a4f3c9560de47e4d37d.feat, zero vector used\n",
            "2023-10-27 10:24:16,853 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/642ef6942001be39f2c8dca1bac5091f3b7f32690bd242bf930ac2a2d1f823c5.feat, zero vector used\n",
            "2023-10-27 10:24:16,855 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/0b15e999a1238af68fa44822c745bc4857322130132c1b29846ed964b626ce97.feat, zero vector used\n",
            "2023-10-27 10:24:16,858 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/136f811bbc385a235656ee9a570ad891c891f4c866d45a205f16c7cf0038bba3.feat, zero vector used\n",
            "2023-10-27 10:24:16,866 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/cd13cd717ec049b9387ad0ce3d93f9dab9b585d32db937f3a875bda001e26ac4.feat, zero vector used\n",
            "2023-10-27 10:24:16,870 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/5ce7b7a747d50454fe634426e6833abae3a36fc5c6acfcd1f857eed5d504b71e.feat, zero vector used\n",
            "2023-10-27 10:24:16,873 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/4aa728d24f1e46e17314e6bcbeb2eedf0d73531198361383ab11862c8bbb6121.feat, zero vector used\n",
            "2023-10-27 10:24:16,873 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f5101033e2f69623086373cf4687c487215ee9a9e100d54cd06a4b42af2c90be.feat, zero vector used\n",
            "2023-10-27 10:24:16,878 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/647f18ff863076c6ad4bd8634d07909866d758c638103231d15a105c8c8c7f7a.feat, zero vector used\n",
            "2023-10-27 10:24:16,880 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a446e01eaed3cb2a1e236482dda9c7b204d10102ef97eb99e3f39d9bf8036a09.feat, zero vector used\n",
            "2023-10-27 10:24:16,881 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8442a7a28729602e231a98c38906fad043df29381d7f4dff311342a207b9a22c.feat, zero vector used\n",
            "2023-10-27 10:24:16,881 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/cf06d7d4030d827fc8620cd93ff88ef04dadd82c59390e49429c1292fd1bbb93.feat, zero vector used\n",
            "2023-10-27 10:24:16,883 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/918c721988e892ec680eaf80e1422ce597d7f9b3da5d7ecbcbd578fb0ba16058.feat, zero vector used\n",
            "2023-10-27 10:24:16,886 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/11a1ddbf37de640d94275f10642773c3f9adc6f632bf40677419cb88068606a4.feat, zero vector used\n",
            "2023-10-27 10:24:16,890 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f0aed1c00fba1b6c842fbd3d7423c178d342b27b6e2051c4adfcbbf515648560.feat, zero vector used\n",
            "2023-10-27 10:24:16,898 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a2990853c057f53fdd37343d03aca3af44ad2566081ec783886d85dc96e1aa58.feat, zero vector used\n",
            "2023-10-27 10:24:16,913 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e6c913e9aa2a34f486079cca18d1f25e61d2eca67ebf79c939d1d9d7dca8da9d.feat, zero vector used\n",
            "2023-10-27 10:24:16,914 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/6d3cd0b1d6e74ffc6e017e53929c3d23e228d2f87f39056d506514a58938cfd2.feat, zero vector used\n",
            "2023-10-27 10:24:16,915 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/caf6cbe51799bdefa62d298cdbbe70e84b3ed777f4f1a824d9c9227e050b3437.feat, zero vector used\n",
            "2023-10-27 10:24:16,916 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/dba3ab03968f112f25335ed60916abbcb3836db9927bf24ca1bf7141d4bb6d33.feat, zero vector used\n",
            "2023-10-27 10:24:16,917 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/97ce93860651ba02bdee1daa434a3ce7336dd55e20bbfa6e39901dd058631163.feat, zero vector used\n",
            "2023-10-27 10:24:16,917 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/efc1a92fcf45d3144e305c01122aeebc73b27393e57960d7fb2fb48499d93ba4.feat, zero vector used\n",
            "2023-10-27 10:24:16,918 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8c7b97a0085dbf24b5607e60d9cc49614b9927ffdb803f807e15ec9b1a0dd7dc.feat, zero vector used\n",
            "2023-10-27 10:24:16,919 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/435f0d106f88b00cd01ad58b75c636b4804bcafca93873e0953fac10ce4ee62a.feat, zero vector used\n",
            "2023-10-27 10:24:16,919 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/83f96593cf81b58c577f667fe9416c43aa17dd35bc1fb4375b58979218a142af.feat, zero vector used\n",
            "2023-10-27 10:24:16,921 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/de122ff8b73dbd403dd66d2f8fae19e5ef2bb2fd1aad5f4422f4e1aad85c57b9.feat, zero vector used\n",
            "2023-10-27 10:24:16,921 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d54840c497567f526227a402fc3bf5d23d4933f6380cde2b5feb9f90f1dc4edd.feat, zero vector used\n",
            "2023-10-27 10:24:16,922 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8e2b5205d6bff8edd82a0acaafb385859e25b85b3e083b3d034171035e92e668.feat, zero vector used\n",
            "2023-10-27 10:24:16,922 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e448db5be9782f10b8dfb9a47632ee42d4ba9d13368800713a39df02c96ad1f6.feat, zero vector used\n",
            "2023-10-27 10:24:16,925 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/390459daa8c13ebdb1bb27f9561947445334034e754b538681c1fc511a56b763.feat, zero vector used\n",
            "2023-10-27 10:24:16,926 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1e060f134f8b1643fc3bfc85a7d33c38422ded6c1b293ae53712352bafada697.feat, zero vector used\n",
            "2023-10-27 10:24:16,927 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/ae20ae4198903cb82a0297d2ec0cef3bf5e0681d9345d8b58edc68c0cd3aa8db.feat, zero vector used\n",
            "2023-10-27 10:24:16,928 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/09704c2a8f8501326c1c84f281708432d13d6f648bfd2d74cf7917c6a40edeed.feat, zero vector used\n",
            "2023-10-27 10:24:16,934 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e6706c1198279c8df42a61fadb1f7be7caad1da2c53308179367efcd61d06c09.feat, zero vector used\n",
            "2023-10-27 10:24:16,934 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/4ea2e636a4d27dfddde0586dc1d555cf1af13575d787d30283fffbd8654aa30d.feat, zero vector used\n",
            "2023-10-27 10:24:16,935 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/954957169ae52a7a3e8e48c09f134cc0ff3ff3f283385135d8d3c7ca13fc0ed3.feat, zero vector used\n",
            "2023-10-27 10:24:16,936 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a9db22dd8963a3baf49f14c31a2ab91dfe026238a71fefdf2001daedca6d147b.feat, zero vector used\n",
            "2023-10-27 10:24:16,936 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/3e2cb3560b1c2bfb7099f95a7b3107b563662e6dcecd48e64cf1cef9f6e9308b.feat, zero vector used\n",
            "2023-10-27 10:24:16,937 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/bddb159fabd058a6844e0cbe619bda51c0e0067f07d301a5d0e9d7b09017366f.feat, zero vector used\n",
            "2023-10-27 10:24:16,936 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/bf8e67d1e7a5b1a9a27dcd0b9b49a14aa6f6e429fcfab51e080ff9e9d15403dd.feat, zero vector used\n",
            "2023-10-27 10:24:16,938 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d6e73e60f22d561c1598d836ba923e9f6b30b5facd01c8966cba6e453ad1d17a.feat, zero vector used\n",
            "2023-10-27 10:24:16,941 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1bc1d0169aebffee872406278d1ffd7c62267d672c53b51feeb1739c9e779db0.feat, zero vector used\n",
            "2023-10-27 10:24:16,941 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/1123151c6c52f5232e4efc021d58b9402e8a6bddc5fbf58036899d98ed38fc77.feat, zero vector used\n",
            "2023-10-27 10:24:16,941 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/8227fad29a4b7e7a26e0044821d78a9bd7bacaeafdfff4ac774e82be11ebfe67.feat, zero vector used\n",
            "2023-10-27 10:24:16,942 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/376161336d8f3fb5a70b493d29ce3a148b8d31c096bc59deefc196301a2408c7.feat, zero vector used\n",
            "2023-10-27 10:24:16,950 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/c10caab4edefae48eba0b4b858ed3be6d5b2046d1fb3f41c50b42a16cece7abe.feat, zero vector used\n",
            "2023-10-27 10:24:16,953 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/3d88da21660b344d48af1c71202cb1d252f332de1cebb44a8e3a768b6f534c0e.feat, zero vector used\n",
            "2023-10-27 10:24:16,954 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/15d22963e661f1e77a5aaed7d3de42b8b67f94d84e3cd2ddeeb99dad2dec7148.feat, zero vector used\n",
            "2023-10-27 10:24:16,963 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/99599c4e089b38f19938728e0ded9c251b0d5588eb935df7d1e90010c5981fb2.feat, zero vector used\n",
            "2023-10-27 10:24:16,963 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/151c45f0af81d27d1438f9c0f8db64a769c47413d8e2b0e71d3dbc596703b720.feat, zero vector used\n",
            "2023-10-27 10:24:16,966 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/a0c28387b30de36179da2e2220541406865b92fba1d53a88079ccf9ef47ac59b.feat, zero vector used\n",
            "2023-10-27 10:24:16,966 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/292a87235ced592d13ea36891800608a890709399d40fbf92c89c84d1da3e578.feat, zero vector used\n",
            "2023-10-27 10:24:16,967 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/36ae0a1c4f0e660e962e3429816b972925ef59bb8c29845be866957d6c3a7e21.feat, zero vector used\n",
            "2023-10-27 10:24:16,967 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e5afe46b41ffb12bd26697243afa2228547b1b1628380aca8739a5628b255a5c.feat, zero vector used\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/malware_detection/examples/md_at_pgd_test.py\", line 76, in <module>\n",
            "    _main()\n",
            "  File \"/content/malware_detection/examples/md_at_pgd_test.py\", line 58, in _main\n",
            "    max_adv_training_model.fit(train_dataset_producer,\n",
            "  File \"/content/malware_detection/core/defense/md_at_pgd.py\", line 74, in fit\n",
            "    for idx_batch, (x_batch, y_batch) in enumerate(train_data_producer):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1345, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1371, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_utils.py\", line 694, in reraise\n",
            "    raise exception\n",
            "TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n",
            "    return self.collate_fn(data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n",
            "    return collate(batch, collate_fn_map=default_collate_fn_map)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\", line 142, in collate\n",
            "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\", line 142, in <listcomp>\n",
            "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\", line 137, in collate\n",
            "    if not all(len(elem) == elem_size for elem in it):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\", line 137, in <genexpr>\n",
            "    if not all(len(elem) == elem_size for elem in it):\n",
            "TypeError: object of type 'numpy.int32' has no len()\n",
            "\n",
            "2023-10-27 10:24:16,984 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/c034e99824830538ed591ddff53d9e9ff99d0a69776e9bd86d3abd9d9172967e.feat, zero vector used\n",
            "2023-10-27 10:24:16,984 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/58c031ecf89bdd9b1cd50582ed8c07f7cce060bc675db182675c3b18c32d53b4.feat, zero vector used\n",
            "2023-10-27 10:24:16,987 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/f6df21135b7f2f037af62d66b5d91620b4ac8f61be04e500eb62aac45d87f521.feat, zero vector used\n",
            "2023-10-27 10:24:16,996 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/e9a62d7ee2cc568646d6135cba665aad2e1989edd2459c5f4a4f3bfc083c31c7.feat, zero vector used\n",
            "2023-10-27 10:24:16,996 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/21b19243032b4ec841752f0a26509971dc2e3145d3d243d8149e626e98960d6a.feat, zero vector used\n",
            "2023-10-27 10:24:17,001 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/dd2890eb3c0877a9dbe60710269c65df5a8a61847b290550e9826ee44d158dd8.feat, zero vector used\n",
            "2023-10-27 10:24:17,002 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/bcc568386e5ac20e82c5489d6d14758b5661cc0b161f6cd76db66306ed96b525.feat, zero vector used\n",
            "2023-10-27 10:24:17,046 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d0d828aebac75eeed2a1b8cf91c6ae36683107e3c41a184aed5df174b7edfc2e.feat, zero vector used\n",
            "2023-10-27 10:24:17,057 feature_extraction.py[line:224] WARNING: Cannot find the feature path: /content/malware_detection/datasets/naive_data/d9cf17d8763a016b375031815f288253f517f1084903c42ddb73974aa8109ba7.feat, zero vector used\n"
          ]
        }
      ]
    }
  ]
}