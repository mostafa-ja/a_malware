{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIpz4Lh9zn425uvbEGj75t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/a_malware/blob/main/PGD2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install androguard\n",
        "import androguard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdWcbQsbDh0u",
        "outputId": "1715134f-d066-43b0-ae9a-6cfad4b6ab7b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting androguard\n",
            "  Downloading androguard-3.3.5-py3-none-any.whl (922 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.4/922.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asn1crypto>=0.24.0 (from androguard)\n",
            "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from androguard) (8.1.7)\n",
            "Collecting colorama (from androguard)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from androguard) (0.18.3)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from androguard) (7.34.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from androguard) (4.9.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from androguard) (3.7.1)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.10/dist-packages (from androguard) (3.2)\n",
            "Requirement already satisfied: pydot>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from androguard) (1.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from androguard) (2.16.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->androguard)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (3.0.39)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (4.8.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot>=1.4.1->androguard) (3.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (2.8.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->androguard) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->androguard) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->androguard) (0.2.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->androguard) (1.16.0)\n",
            "Installing collected packages: asn1crypto, jedi, colorama, androguard\n",
            "Successfully installed androguard-3.3.5 asn1crypto-1.5.1 colorama-0.4.6 jedi-0.19.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eRx10YoAiFg",
        "outputId": "812f6481-7192-4591-abd5-a23e41f8721c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "Cloning into 'malware_detection'...\n",
            "remote: Enumerating objects: 16013, done.\u001b[K\n",
            "remote: Counting objects: 100% (2165/2165), done.\u001b[K\n",
            "remote: Compressing objects: 100% (154/154), done.\u001b[K\n",
            "remote: Total 16013 (delta 2008), reused 2151 (delta 1998), pack-reused 13848\u001b[K\n",
            "Receiving objects: 100% (16013/16013), 207.57 MiB | 20.24 MiB/s, done.\n",
            "Resolving deltas: 100% (12938/12938), done.\n",
            "Updating files: 100% (144/144), done.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import os.path as path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "!git clone https://github.com/mostafa-ja/malware_detection.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "\n",
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, samples):\n",
        "        self.samples = [(torch.tensor(data, dtype=torch.float32), label) for data, label in samples]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.samples[index]"
      ],
      "metadata": {
        "id": "a4E-Kgs2AoJG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MalwareDetectionDNN(nn.Module):\n",
        "    def __init__(self, input_size, n_classes, device='cpu', name='DNN', dense_hidden_units=[200, 200], dropout=0.6, smooth=False):\n",
        "        \"\"\"\n",
        "        Construct malware detector\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        @param input_size: Integer, the dimentionality number of input vector\n",
        "        @param n_classes: Integer, the number of classes, n=2\n",
        "        @param device: String, 'cpu' or 'cuda'\n",
        "        @param name: String, model name\n",
        "        \"\"\"\n",
        "        super(MalwareDetectionDNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.n_classes = n_classes\n",
        "        self.name = name\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.smooth = smooth\n",
        "        self.dense_hidden_units = dense_hidden_units\n",
        "\n",
        "        self.dense_layers = []\n",
        "        if len(self.dense_hidden_units) >= 1:\n",
        "            self.dense_layers.append(nn.Linear(self.input_size, self.dense_hidden_units[0]))\n",
        "        else:\n",
        "            raise ValueError(\"Expect at least one hidden layer.\")\n",
        "        for i in range(len(self.dense_hidden_units[0:-1])):\n",
        "            self.dense_layers.append(nn.Linear(self.dense_hidden_units[i],  # start from idx=1\n",
        "                                               self.dense_hidden_units[i + 1]))\n",
        "        self.dense_layers.append(nn.Linear(self.dense_hidden_units[-1], self.n_classes))\n",
        "\n",
        "        # registration\n",
        "        for idx_i, dense_layer in enumerate(self.dense_layers):\n",
        "            self.add_module('nn_model_layer_{}'.format(idx_i), dense_layer)\n",
        "\n",
        "        if self.smooth:\n",
        "            self.activation_func = F.selu  # partial(F.elu, alpha=self.alpha_)\n",
        "        else:\n",
        "            self.activation_func = F.relu\n",
        "\n",
        "        self.model_save_path = path.join('/content/malware_detection/save/drebin/md_dnn'+ '_' + self.name,'model.pth')\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Go through the neural network\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        @param x: 2D tensor, feature representation\n",
        "        \"\"\"\n",
        "        for dense_layer in self.dense_layers[:-1]:\n",
        "            x = self.activation_func(dense_layer(x))\n",
        "\n",
        "        latent_representation = F.dropout(x, self.dropout, training=self.training)\n",
        "        logits = self.dense_layers[-1](latent_representation)\n",
        "        return logits\n",
        "\n",
        "    def customize_loss(self, logits, gt_labels, representation = None, mini_batch_idx=None):\n",
        "        return F.cross_entropy(logits, gt_labels)\n",
        "\n",
        "    def inference_batch_wise(self, x):\n",
        "        \"\"\"\n",
        "        support malware samples solely\n",
        "        \"\"\"\n",
        "        assert isinstance(x, torch.Tensor)\n",
        "        logit = self.forward(x)\n",
        "        return torch.softmax(logit, dim=-1).detach().cpu().numpy(), np.ones((logit.size()[0],))"
      ],
      "metadata": {
        "id": "IBNqn_OEAuV-"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples,labels = next(iter(test_Loader))\n",
        "x,label = samples[0:1],labels[0:1]"
      ],
      "metadata": {
        "id": "w6WruXy3DXQC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/malware_detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRRx7oWaDnGY",
        "outputId": "ffbf070a-276b-4d02-b1ed-46a872268f3f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/malware_detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Projected gradient descent (ascent)."
      ],
      "metadata": {
        "id": "-45R7q66ygAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from core.droidfeature import InverseDroidFeature\n",
        "\n",
        "inverse_feature = InverseDroidFeature()\n",
        "\n",
        "# manipulation_x : removable features\n",
        "manipulation_x = inverse_feature.get_manipulation()\n",
        "manipulation_x = torch.LongTensor(manipulation_x).to(device)\n",
        "\n",
        "# index of vocab which are interdependent\n",
        "omega = inverse_feature.get_interdependent_apis()\n",
        "omega = torch.sum(F.one_hot(torch.tensor(omega), num_classes=len(inverse_feature.vocab)),dim=0).to(device)\n",
        "\n",
        "# a list of vocab length : if the type of feature is api , index of that feature will be true\n",
        "api_flag = inverse_feature.get_api_flag()"
      ],
      "metadata": {
        "id": "sY7SRwnGYixM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_x0(x, rounding_threshold=0.5, is_sample=False):\n",
        "    \"\"\"\n",
        "    Helper function to randomly initialize the the inner maximizer algos\n",
        "    randomize such that the functionality is preserved.\n",
        "    :param x: training sample\n",
        "    :param is_sample: flag to sample randomly from feasible area or return just x\n",
        "    :return: randomly sampled feasible version of x\n",
        "    \"\"\"\n",
        "    if is_sample:\n",
        "        rand_x = round_x(torch.rand(x.size()), alpha=rounding_threshold)\n",
        "        if x.is_cuda:\n",
        "            rand_x = rand_x.cuda()\n",
        "        return (rand_x.byte() | x.byte()).double()\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "\n",
        "def round_x(x, alpha=0.5):\n",
        "    \"\"\"\n",
        "    rounds x by thresholding it according to alpha which can be a scalar or vector\n",
        "    :param x:\n",
        "    :param alpha: threshold parameter\n",
        "    :return: a double tensor of 0s and 1s.\n",
        "    \"\"\"\n",
        "    return (x >= alpha).double()"
      ],
      "metadata": {
        "id": "Ye0d01eYuWZv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PGD():\n",
        "    \"\"\"\n",
        "    Projected gradient descent (ascent).\n",
        "\n",
        "    Parameters\n",
        "    ---------\n",
        "    @param norm, 'l2' or 'linf'\n",
        "    @param use_random, Boolean,  whether use random start point\n",
        "    @param rounding_threshold, float, a threshold for rounding real scalars\n",
        "    @param is_attacker, Boolean, play the role of attacker (note: the defender conducts adversarial training)\n",
        "    @param oblivion, Boolean, whether know the adversary indicator or not\n",
        "    @param kappa, attack confidence\n",
        "    @param manipulation_x, manipulations\n",
        "    @param omega, the indices of interdependent apis corresponding to each api\n",
        "    @param device, 'cpu' or 'cuda'\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, norm, use_random=False, rounding_threshold=0.5,\n",
        "                 is_attacker=True, manipulation_x=None, omega=None,api_flag=None, device=None):\n",
        "        super(PGD, self).__init__()\n",
        "        assert norm == 'l1' or norm == 'l2' or norm == 'linf', \"Expect 'l1', 'l2' or 'linf'.\"\n",
        "        self.norm = norm\n",
        "        self.use_random = use_random\n",
        "        self.round_threshold = rounding_threshold\n",
        "        self.is_attacker = is_attacker\n",
        "        self.lambda_ = 1.\n",
        "        self.omeag = omega\n",
        "        self.manipulation_x = manipulation_x\n",
        "        self.api_flag = api_flag\n",
        "        self.device = device\n",
        "    def _perturb(self, model, x, label=None,\n",
        "                 steps=10,\n",
        "                 step_length=1.,\n",
        "                 lambda_=1.,\n",
        "                 ):\n",
        "        \"\"\"\n",
        "        perturb node feature vectors\n",
        "\n",
        "        Parameters\n",
        "        -----------\n",
        "        @param model, a victim model\n",
        "        @param x: torch.FloatTensor, node feature vectors (each represents the occurrences of apis in a graph) with shape [batch_size, vocab_dim]\n",
        "        @param label: torch.LongTensor, ground truth labels\n",
        "        @param steps: Integer, maximum number of iterations\n",
        "        @param step_length: float, the step length in each iteration\n",
        "        @param lambda_, float, penalty factor\n",
        "        \"\"\"\n",
        "        adv_x = x\n",
        "        self.lambda_ = lambda_\n",
        "        model.eval()\n",
        "        loss_natural = 0.\n",
        "        for t in range(steps):\n",
        "            if t == 0 and self.use_random:\n",
        "                adv_x = get_x0(adv_x, rounding_threshold=self.round_threshold, is_sample=True)\n",
        "            var_adv_x = torch.autograd.Variable(adv_x, requires_grad=True)\n",
        "            loss, done = self.get_loss(model, var_adv_x, label, self.lambda_)\n",
        "            if t == 0:\n",
        "                loss_natural = loss\n",
        "            grad = torch.autograd.grad(torch.mean(loss), var_adv_x)[0].detach().data\n",
        "            perturbation = self.get_perturbation(grad, x, adv_x)\n",
        "            adv_x = torch.clamp(adv_x + perturbation * step_length, min=0., max=1.)\n",
        "        # round\n",
        "        if self.norm == 'linf' and (not hasattr(model, 'is_detector_enabled')):\n",
        "            round_threshold = torch.rand(x.size()).to(self.device)\n",
        "        else:\n",
        "            round_threshold = self.round_threshold\n",
        "        adv_x = round_x(adv_x, round_threshold)\n",
        "        loss_adv, _1 = self.get_loss(model, adv_x, label, self.lambda_)\n",
        "        replace_flag = (loss_adv < loss_natural).unsqueeze(1).expand_as(adv_x)\n",
        "        adv_x[replace_flag] = x[replace_flag]\n",
        "        return adv_x\n",
        "\n",
        "    def perturb(self, model, x, label=None,\n",
        "                steps=10,\n",
        "                step_length=1.,\n",
        "                min_lambda_=1e-5,\n",
        "                max_lambda_=1e5,\n",
        "                base=10.,\n",
        "                verbose=False):\n",
        "        \"\"\"\n",
        "        enhance attack\n",
        "        \"\"\"\n",
        "        model.eval()\n",
        "        if hasattr(model, 'is_detector_enabled'):\n",
        "            self.lambda_ = min_lambda_\n",
        "        else:\n",
        "            self.lambda_ = max_lambda_\n",
        "\n",
        "        adv_x = x.detach().clone().to(torch.double)\n",
        "        while self.lambda_ <= max_lambda_:\n",
        "            with torch.no_grad():\n",
        "                _, done = self.get_loss(model, adv_x, label, self.lambda_)\n",
        "            if torch.all(done):\n",
        "                break\n",
        "            pert_x = self._perturb(model, adv_x[~done], label[~done],\n",
        "                                   steps,\n",
        "                                   step_length,\n",
        "                                   lambda_=self.lambda_\n",
        "                                   )\n",
        "            adv_x[~done] = pert_x\n",
        "            self.lambda_ *= base\n",
        "        with torch.no_grad():\n",
        "            _, done = self.get_loss(model, adv_x, label, self.lambda_)\n",
        "            print(f\"pgd {self.norm}: attack effectiveness {done.sum().item() / done.size()[0] * 100:.3f}%.\")\n",
        "        return adv_x\n",
        "\n",
        "    def get_perturbation(self, gradients, features, adv_features):\n",
        "        # look for allowable position, because only '1--> -' and '0 --> +' are permitted\n",
        "        # api insertion\n",
        "        pos_insertion = (adv_features <= 0.5) * 1 * (adv_features >= 0.)\n",
        "        grad4insertion = (gradients >= 0) * pos_insertion * gradients\n",
        "        # grad4insertion = (gradients > 0) * gradients\n",
        "        # api removal\n",
        "        pos_removal = (adv_features > 0.5) * 1\n",
        "        grad4removal = (gradients < 0) * (pos_removal & self.manipulation_x) * gradients\n",
        "        if self.is_attacker:\n",
        "            # cope with the interdependent apis\n",
        "            checking_nonexist_api = (pos_removal ^ self.omega) & self.omega\n",
        "            grad4removal[:, self.api_flag] += torch.sum(gradients * checking_nonexist_api, dim=-1, keepdim=True)\n",
        "        gradients = grad4removal + grad4insertion\n",
        "\n",
        "        # norm\n",
        "        if self.norm == 'linf':\n",
        "            perturbation = torch.sign(gradients)\n",
        "        elif self.norm == 'l2':\n",
        "            l2norm = torch.linalg.norm(gradients, dim=-1, keepdim=True)\n",
        "            perturbation = torch.minimum(\n",
        "                torch.tensor(1., dtype=features.dtype, device=features.device),\n",
        "                gradients / l2norm\n",
        "            )\n",
        "            perturbation = torch.where(torch.isnan(perturbation), 0., perturbation)\n",
        "            perturbation = torch.where(torch.isinf(perturbation), 1., perturbation)\n",
        "        else:\n",
        "            raise ValueError(\"Expect 'l2' or 'linf' norm.\")\n",
        "\n",
        "        # add the extra perturbation owing to the interdependent apis\n",
        "        if self.norm == 'linf' and self.is_attacker:\n",
        "            perturbation += torch.any(perturbation[:, self.api_flag] < 0, dim=-1,\n",
        "                                      keepdim=True) * checking_nonexist_api\n",
        "        if self.norm == 'l2' and self.is_attacker:\n",
        "            min_val = torch.amin(perturbation, dim=-1, keepdim=True).clamp_(max=0.)\n",
        "            perturbation += (torch.any(perturbation[:, self.api_flag] < 0, dim=-1,\n",
        "                                       keepdim=True) * torch.abs(min_val) * checking_nonexist_api)\n",
        "        return perturbation\n",
        "\n",
        "    def get_loss(self, model, adv_x, label, lambda_=None):\n",
        "        if hasattr(model, 'is_detector_enabled'):\n",
        "            logits_f, prob_g = model.forward(adv_x)\n",
        "        else:\n",
        "            logits_f = model.forward(adv_x)\n",
        "\n",
        "        ce = F.cross_entropy(logits_f, label, reduction='none')\n",
        "        y_pred = logits_f.argmax(1)\n",
        "        if hasattr(model, 'is_detector_enabled') and (not self.oblivion):\n",
        "            assert lambda_ is not None\n",
        "            tau = model.get_tau_sample_wise(y_pred)\n",
        "            if self.is_attacker:\n",
        "                loss_no_reduction = ce + lambda_ * (torch.clamp(tau - prob_g,\n",
        "                                                                max=self.kappa)\n",
        "                                                    )\n",
        "            else:\n",
        "                loss_no_reduction = ce + lambda_ * (tau - prob_g)\n",
        "            done = (y_pred != label) & (prob_g <= tau)\n",
        "        else:\n",
        "            loss_no_reduction = ce\n",
        "            done = y_pred != label\n",
        "        return loss_no_reduction, done"
      ],
      "metadata": {
        "id": "Wd8Q6mNduaya"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PGDAdvTraining(object):\n",
        "    \"\"\"adversarial training incorporating pgd attack\n",
        "\n",
        "    Parameters\n",
        "    -------\n",
        "    @param model, Object,  a model to be protected, e.g., MalwareDetector\n",
        "    @attack_model: Object, adversary's model for generating adversarial malware on the feature space\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, attack=None, attack_param=None):\n",
        "        self.model = model\n",
        "        self.attack = attack\n",
        "        self.attack_param = attack_param\n",
        "\n",
        "        self.name = self.model.name\n",
        "        self.model_save_path =  path.join('/content/malware_detection/save/md_at_pgd' + '_' + 'train','model.pth')\n",
        "\n",
        "    def fit(self, train_data_producer, validation_data_producer=None, adv_epochs=45,beta=0.001,lr=0.005,weight_decay=0, verbose=True):\n",
        "        \"\"\"\n",
        "        Applying adversarial train to enhance the malware detector.\n",
        "\n",
        "        Parameters\n",
        "        -------\n",
        "        @param train_data_producer: Object, an dataloader object for producing a batch of training data\n",
        "        @param validation_data_producer: Object, an dataloader object for producing validation dataset\n",
        "        @param epochs: Integer, epochs for adversarial training\n",
        "        @param adv_epochs: Integer, epochs for adversarial training\n",
        "        @param beta: Float, penalty factor for adversarial loss\n",
        "        @param lr: Float, learning rate of Adam optimizer\n",
        "        @param weight_decay: Float, penalty factor, default value 5e-4\n",
        "        @param verbose: Boolean, whether to show verbose info\n",
        "        \"\"\"\n",
        "        optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "        total_time = 0.\n",
        "        nbatches = len(train_data_producer)\n",
        "        best_acc_val = 0.\n",
        "        acc_val_adv_be = 0.\n",
        "        best_epoch = 0\n",
        "        for i in range(adv_epochs):\n",
        "            losses, accuracies = [], []\n",
        "            for idx_batch, (x_batch, y_batch) in enumerate(train_data_producer):\n",
        "                x_batch, y_batch = x_batch.double().to(device), y_batch.long().to(device)\n",
        "                batch_size = x_batch.shape[0]\n",
        "                # make data\n",
        "                mal_x_batch, ben_x_batch, mal_y_batch, ben_y_batch = x_batch[y_batch == 1], x_batch[y_batch == 0], y_batch[y_batch == 1], y_batch[y_batch == 0]\n",
        "                start_time = time.time()\n",
        "                self.model.eval()\n",
        "                pertb_mal_x = self.attack.perturb(self.model, mal_x_batch, mal_y_batch,**self.attack_param)\n",
        "                total_time += time.time() - start_time\n",
        "                x_batch = torch.cat([ben_x_batch, pertb_mal_x], dim=0)\n",
        "                y_batch = torch.cat([ben_y_batch, mal_y_batch])\n",
        "                start_time = time.time()\n",
        "                self.model.train()\n",
        "                optimizer.zero_grad()\n",
        "                logits = self.model.forward(x_batch)\n",
        "                loss_train = self.model.customize_loss(logits,y_batch)\n",
        "\n",
        "                loss_train.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                total_time += time.time() - start_time\n",
        "                mins, secs = int(total_time / 60), int(total_time % 60)\n",
        "                acc_train = (logits.argmax(1) == y_batch).sum().item()\n",
        "                acc_train /= x_batch.size()[0]\n",
        "                accuracies.append(acc_train)\n",
        "                losses.append(loss_train.item())\n",
        "                if verbose:\n",
        "                    print(f'Mini batch: {i * nbatches + idx_batch + 1}/{adv_epochs * nbatches} | training time in {mins:.0f} minutes, {secs} seconds.')\n",
        "                    print(f'Training loss (batch level): {losses[-1]:.4f} | Train accuracy: {acc_train * 100:.2f}%.')\n",
        "            if verbose:\n",
        "                print(f'Training loss (epoch level): {np.mean(losses):.4f} | Train accuracy: {np.mean(accuracies) * 100:.2f}')\n",
        "\n",
        "            # select model\n",
        "            self.model.eval()\n",
        "            # long-time to train (save the model temporally in case of interruption)\n",
        "            self.save_to_disk(i + 1, optimizer, self.model_save_path + '.tmp')\n",
        "\n",
        "            res_val = []\n",
        "            avg_acc_val = []\n",
        "            for x_val, y_val in validation_data_producer:\n",
        "                x_val, y_val = x_val.double().to(device), y_val.long().to(device)\n",
        "                logits = self.model.forward(x_val)\n",
        "                acc_val = (logits.argmax(1) == y_val).sum().item()\n",
        "                acc_val /= x_val.size()[0]\n",
        "                avg_acc_val.append(acc_val)\n",
        "\n",
        "                mal_x_batch, mal_y_batch = x_batch[y_batch == 1], y_batch[y_batch == 1]\n",
        "                pertb_mal_x = self.attack.perturb(self.model, mal_x_batch, mal_y_batch,**self.attack_param)\n",
        "                y_cent_batch, x_density_batch = self.model.inference_batch_wise(pertb_mal_x)\n",
        "                y_pred = np.argmax(y_cent_batch, axis=-1)\n",
        "                res_val.append(y_pred == 1.)\n",
        "            assert len(res_val) > 0\n",
        "            res_val = np.concatenate(res_val)\n",
        "            acc_val_adv = np.sum(res_val).astype(float) / res_val.shape[0]\n",
        "            acc_val = (np.mean(avg_acc_val) + acc_val_adv) / 2.\n",
        "            # Owing to we look for a new threshold after each epoch, this hinders the convergence of training.\n",
        "            # We save the model's parameters at last several epochs as a well-trained model may be obtained.\n",
        "            if acc_val >= best_acc_val:\n",
        "                best_acc_val = acc_val\n",
        "                acc_val_adv_be = acc_val_adv\n",
        "                best_epoch = i + 1\n",
        "                self.save_to_disk(best_epoch, optimizer, self.model_save_path)\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"\\tVal accuracy {acc_val * 100:.4}% with accuracy {acc_val_adv * 100:.4}% under attack.\")\n",
        "                print(f\"\\tModel select at epoch {best_epoch} with validation accuracy {best_acc_val * 100:.4}% and accuracy {acc_val_adv_be * 100:.4}% under attack.\")\n",
        "                if hasattr(self.model, 'tau'):\n",
        "                    print(f'The threshold is {self.model.tau}.')\n",
        "\n",
        "    def load(self):\n",
        "        assert path.exists(self.model_save_path), 'train model first'\n",
        "        ckpt = torch.load(self.model_save_path)\n",
        "        self.model.load_state_dict(ckpt['model'])\n",
        "\n",
        "    def save_to_disk(self, epoch, optimizer, save_path=None):\n",
        "        if not path.exists(save_path):\n",
        "            os.makedirs(path.dirname(save_path), exist_ok = True)\n",
        "        torch.save({'model': self.model.state_dict(),\n",
        "                    'epoch': epoch,\n",
        "                    'optimizer_state_dict': optimizer.state_dict()\n",
        "                    },\n",
        "                   save_path)"
      ],
      "metadata": {
        "id": "4eqeD6NWvqhF"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying adversarial train to enhance the malware detector."
      ],
      "metadata": {
        "id": "He1Ak73MyYtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torch.load('/content/malware_detection/datasets/train_dataset.pt')\n",
        "train_Loader = data.DataLoader(train_dataset, batch_size=128, shuffle=False)\n",
        "validation_dataset = torch.load('/content/malware_detection/datasets/validation_dataset.pt')\n",
        "validation_Loader = data.DataLoader(validation_dataset, batch_size=10000, shuffle=False)\n",
        "test_dataset = torch.load('/content/malware_detection/datasets/test_dataset.pt')\n",
        "test_Loader = data.DataLoader(test_dataset, batch_size=10000, shuffle=False)"
      ],
      "metadata": {
        "id": "MRAX7j_qywXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# norm = 'linf'\n",
        "\n",
        "model = MalwareDetectionDNN(3216,2)\n",
        "model = model.double().to(device)\n",
        "attack = PGD(norm='linf', use_random=False,rounding_threshold=0.5,is_attacker=False,manipulation_x=manipulation_x, omega=omega,api_flag=api_flag,device=device)\n",
        "attack_param = {}\n",
        "max_adv_training_model = PGDAdvTraining(model, attack, attack_param)\n",
        "max_adv_training_model.fit(train_Loader,validation_Loader,adv_epochs=40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41DiMLnjfGBG",
        "outputId": "201adac9-3f9d-45cb-ea64-4b912821ae45"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pgd linf: attack effectiveness 100.000%.\n",
            "Mini batch: 1/400 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.7011 | Train accuracy: 49.22%.\n",
            "pgd linf: attack effectiveness 100.000%.\n",
            "Mini batch: 2/400 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 1.1448 | Train accuracy: 53.12%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 3/400 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.6682 | Train accuracy: 55.47%.\n",
            "pgd linf: attack effectiveness 2.941%.\n",
            "Mini batch: 4/400 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.5871 | Train accuracy: 67.19%.\n",
            "pgd linf: attack effectiveness 11.290%.\n",
            "Mini batch: 5/400 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.5259 | Train accuracy: 88.28%.\n",
            "pgd linf: attack effectiveness 14.545%.\n",
            "Mini batch: 6/400 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.4865 | Train accuracy: 82.03%.\n",
            "pgd linf: attack effectiveness 21.212%.\n",
            "Mini batch: 7/400 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.4671 | Train accuracy: 78.91%.\n",
            "pgd linf: attack effectiveness 29.508%.\n",
            "Mini batch: 8/400 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.5666 | Train accuracy: 72.66%.\n",
            "pgd linf: attack effectiveness 36.765%.\n",
            "Mini batch: 9/400 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.5477 | Train accuracy: 73.44%.\n",
            "pgd linf: attack effectiveness 38.095%.\n",
            "Mini batch: 10/400 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.5992 | Train accuracy: 68.09%.\n",
            "Training loss (epoch level): 0.6294 | Train accuracy: 68.84\n",
            "pgd linf: attack effectiveness 38.095%.\n",
            "\tVal accuracy 74.95% with accuracy 61.9% under attack.\n",
            "\tModel select at epoch 1 with validation accuracy 74.95% and accuracy 61.9% under attack.\n",
            "pgd linf: attack effectiveness 38.462%.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-ecfac4671c7e>:94: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  acc_val_adv = np.sum(res_val).astype(np.float) / res_val.shape[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mini batch: 11/400 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.7427 | Train accuracy: 69.53%.\n",
            "pgd linf: attack effectiveness 42.188%.\n",
            "Mini batch: 12/400 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.6756 | Train accuracy: 75.00%.\n",
            "pgd linf: attack effectiveness 43.284%.\n",
            "Mini batch: 13/400 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.5098 | Train accuracy: 72.66%.\n",
            "pgd linf: attack effectiveness 44.118%.\n",
            "Mini batch: 14/400 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.4368 | Train accuracy: 76.56%.\n",
            "pgd linf: attack effectiveness 48.387%.\n",
            "Mini batch: 15/400 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.5733 | Train accuracy: 68.75%.\n",
            "pgd linf: attack effectiveness 40.000%.\n",
            "Mini batch: 16/400 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.5700 | Train accuracy: 71.09%.\n",
            "pgd linf: attack effectiveness 33.333%.\n",
            "Mini batch: 17/400 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.4604 | Train accuracy: 76.56%.\n",
            "pgd linf: attack effectiveness 29.508%.\n",
            "Mini batch: 18/400 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.4451 | Train accuracy: 79.69%.\n",
            "pgd linf: attack effectiveness 33.824%.\n",
            "Mini batch: 19/400 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.3978 | Train accuracy: 82.03%.\n",
            "pgd linf: attack effectiveness 38.095%.\n",
            "Mini batch: 20/400 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.4025 | Train accuracy: 80.85%.\n",
            "Training loss (epoch level): 0.5214 | Train accuracy: 75.27\n",
            "pgd linf: attack effectiveness 33.333%.\n",
            "\tVal accuracy 78.71% with accuracy 66.67% under attack.\n",
            "\tModel select at epoch 2 with validation accuracy 78.71% and accuracy 66.67% under attack.\n",
            "pgd linf: attack effectiveness 29.231%.\n",
            "Mini batch: 21/400 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.4056 | Train accuracy: 80.47%.\n",
            "pgd linf: attack effectiveness 31.250%.\n",
            "Mini batch: 22/400 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.4135 | Train accuracy: 81.25%.\n",
            "pgd linf: attack effectiveness 38.806%.\n",
            "Mini batch: 23/400 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.4369 | Train accuracy: 75.00%.\n",
            "pgd linf: attack effectiveness 7.353%.\n",
            "Mini batch: 24/400 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.3211 | Train accuracy: 85.94%.\n",
            "pgd linf: attack effectiveness 9.677%.\n",
            "Mini batch: 25/400 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.3900 | Train accuracy: 82.03%.\n",
            "pgd linf: attack effectiveness 14.545%.\n",
            "Mini batch: 26/400 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.3360 | Train accuracy: 89.06%.\n",
            "pgd linf: attack effectiveness 15.152%.\n",
            "Mini batch: 27/400 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.2918 | Train accuracy: 87.50%.\n",
            "pgd linf: attack effectiveness 14.754%.\n",
            "Mini batch: 28/400 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.2675 | Train accuracy: 88.28%.\n",
            "pgd linf: attack effectiveness 17.647%.\n",
            "Mini batch: 29/400 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.3643 | Train accuracy: 85.94%.\n",
            "pgd linf: attack effectiveness 23.810%.\n",
            "Mini batch: 30/400 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.2618 | Train accuracy: 89.36%.\n",
            "Training loss (epoch level): 0.3489 | Train accuracy: 84.48\n",
            "pgd linf: attack effectiveness 23.810%.\n",
            "\tVal accuracy 84.47% with accuracy 76.19% under attack.\n",
            "\tModel select at epoch 3 with validation accuracy 84.47% and accuracy 76.19% under attack.\n",
            "pgd linf: attack effectiveness 9.231%.\n",
            "Mini batch: 31/400 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.2542 | Train accuracy: 90.62%.\n",
            "pgd linf: attack effectiveness 7.812%.\n",
            "Mini batch: 32/400 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.2607 | Train accuracy: 92.19%.\n",
            "pgd linf: attack effectiveness 4.478%.\n",
            "Mini batch: 33/400 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.1887 | Train accuracy: 93.75%.\n",
            "pgd linf: attack effectiveness 4.412%.\n",
            "Mini batch: 34/400 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.1344 | Train accuracy: 95.31%.\n",
            "pgd linf: attack effectiveness 8.065%.\n",
            "Mini batch: 35/400 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.1465 | Train accuracy: 96.09%.\n",
            "pgd linf: attack effectiveness 12.727%.\n",
            "Mini batch: 36/400 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.1567 | Train accuracy: 92.97%.\n",
            "pgd linf: attack effectiveness 7.576%.\n",
            "Mini batch: 37/400 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.1814 | Train accuracy: 93.75%.\n",
            "pgd linf: attack effectiveness 13.115%.\n",
            "Mini batch: 38/400 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.1928 | Train accuracy: 91.41%.\n",
            "pgd linf: attack effectiveness 11.765%.\n",
            "Mini batch: 39/400 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.2156 | Train accuracy: 90.62%.\n",
            "pgd linf: attack effectiveness 19.048%.\n",
            "Mini batch: 40/400 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.3244 | Train accuracy: 91.49%.\n",
            "Training loss (epoch level): 0.2056 | Train accuracy: 92.82\n",
            "pgd linf: attack effectiveness 14.286%.\n",
            "\tVal accuracy 88.98% with accuracy 85.71% under attack.\n",
            "\tModel select at epoch 4 with validation accuracy 88.98% and accuracy 85.71% under attack.\n",
            "pgd linf: attack effectiveness 6.154%.\n",
            "Mini batch: 41/400 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.1762 | Train accuracy: 92.97%.\n",
            "pgd linf: attack effectiveness 3.125%.\n",
            "Mini batch: 42/400 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.1096 | Train accuracy: 96.09%.\n",
            "pgd linf: attack effectiveness 1.493%.\n",
            "Mini batch: 43/400 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.1057 | Train accuracy: 96.09%.\n",
            "pgd linf: attack effectiveness 1.471%.\n",
            "Mini batch: 44/400 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0818 | Train accuracy: 98.44%.\n",
            "pgd linf: attack effectiveness 4.839%.\n",
            "Mini batch: 45/400 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0877 | Train accuracy: 98.44%.\n",
            "pgd linf: attack effectiveness 5.455%.\n",
            "Mini batch: 46/400 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.1054 | Train accuracy: 96.88%.\n",
            "pgd linf: attack effectiveness 4.545%.\n",
            "Mini batch: 47/400 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0753 | Train accuracy: 97.66%.\n",
            "pgd linf: attack effectiveness 8.197%.\n",
            "Mini batch: 48/400 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.1006 | Train accuracy: 96.88%.\n",
            "pgd linf: attack effectiveness 8.824%.\n",
            "Mini batch: 49/400 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.1891 | Train accuracy: 94.53%.\n",
            "pgd linf: attack effectiveness 14.286%.\n",
            "Mini batch: 50/400 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.2276 | Train accuracy: 91.49%.\n",
            "Training loss (epoch level): 0.1259 | Train accuracy: 95.95\n",
            "pgd linf: attack effectiveness 14.286%.\n",
            "\tVal accuracy 89.86% with accuracy 85.71% under attack.\n",
            "\tModel select at epoch 5 with validation accuracy 89.86% and accuracy 85.71% under attack.\n",
            "pgd linf: attack effectiveness 4.615%.\n",
            "Mini batch: 51/400 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.1028 | Train accuracy: 96.88%.\n",
            "pgd linf: attack effectiveness 1.562%.\n",
            "Mini batch: 52/400 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0644 | Train accuracy: 97.66%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 53/400 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0863 | Train accuracy: 97.66%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 54/400 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0541 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 3.226%.\n",
            "Mini batch: 55/400 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0580 | Train accuracy: 98.44%.\n",
            "pgd linf: attack effectiveness 3.636%.\n",
            "Mini batch: 56/400 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0670 | Train accuracy: 98.44%.\n",
            "pgd linf: attack effectiveness 3.030%.\n",
            "Mini batch: 57/400 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0443 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 4.918%.\n",
            "Mini batch: 58/400 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0814 | Train accuracy: 97.66%.\n",
            "pgd linf: attack effectiveness 7.353%.\n",
            "Mini batch: 59/400 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.1221 | Train accuracy: 96.09%.\n",
            "pgd linf: attack effectiveness 9.524%.\n",
            "Mini batch: 60/400 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.1759 | Train accuracy: 95.74%.\n",
            "Training loss (epoch level): 0.0856 | Train accuracy: 97.70\n",
            "pgd linf: attack effectiveness 9.524%.\n",
            "\tVal accuracy 93.11% with accuracy 90.48% under attack.\n",
            "\tModel select at epoch 6 with validation accuracy 93.11% and accuracy 90.48% under attack.\n",
            "pgd linf: attack effectiveness 4.615%.\n",
            "Mini batch: 61/400 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0928 | Train accuracy: 96.88%.\n",
            "pgd linf: attack effectiveness 1.562%.\n",
            "Mini batch: 62/400 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0238 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 63/400 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0365 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 64/400 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0415 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 1.613%.\n",
            "Mini batch: 65/400 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0582 | Train accuracy: 98.44%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 66/400 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.1143 | Train accuracy: 98.44%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 67/400 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0434 | Train accuracy: 98.44%.\n",
            "pgd linf: attack effectiveness 1.639%.\n",
            "Mini batch: 68/400 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0450 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 4.412%.\n",
            "Mini batch: 69/400 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0622 | Train accuracy: 96.88%.\n",
            "pgd linf: attack effectiveness 9.524%.\n",
            "Mini batch: 70/400 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.1207 | Train accuracy: 95.74%.\n",
            "Training loss (epoch level): 0.0638 | Train accuracy: 98.17\n",
            "pgd linf: attack effectiveness 9.524%.\n",
            "\tVal accuracy 92.74% with accuracy 90.48% under attack.\n",
            "\tModel select at epoch 6 with validation accuracy 93.11% and accuracy 90.48% under attack.\n",
            "pgd linf: attack effectiveness 4.615%.\n",
            "Mini batch: 71/400 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0808 | Train accuracy: 97.66%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 72/400 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0199 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 73/400 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0150 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 74/400 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0221 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 1.613%.\n",
            "Mini batch: 75/400 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0424 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 76/400 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0614 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 77/400 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0397 | Train accuracy: 98.44%.\n",
            "pgd linf: attack effectiveness 1.639%.\n",
            "Mini batch: 78/400 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0344 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 79/400 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0513 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 4.762%.\n",
            "Mini batch: 80/400 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0528 | Train accuracy: 97.87%.\n",
            "Training loss (epoch level): 0.0420 | Train accuracy: 99.01\n",
            "pgd linf: attack effectiveness 4.762%.\n",
            "\tVal accuracy 95.37% with accuracy 95.24% under attack.\n",
            "\tModel select at epoch 8 with validation accuracy 95.37% and accuracy 95.24% under attack.\n",
            "pgd linf: attack effectiveness 3.077%.\n",
            "Mini batch: 81/400 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0459 | Train accuracy: 98.44%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 82/400 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0047 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 83/400 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0065 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 84/400 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0039 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 4.839%.\n",
            "Mini batch: 85/400 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0613 | Train accuracy: 97.66%.\n",
            "pgd linf: attack effectiveness 1.818%.\n",
            "Mini batch: 86/400 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0506 | Train accuracy: 98.44%.\n",
            "pgd linf: attack effectiveness 1.515%.\n",
            "Mini batch: 87/400 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0135 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 1.639%.\n",
            "Mini batch: 88/400 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0170 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 89/400 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0594 | Train accuracy: 98.44%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 90/400 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0089 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0272 | Train accuracy: 99.14\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.0% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 9 with validation accuracy 98.0% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 1.538%.\n",
            "Mini batch: 91/400 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0364 | Train accuracy: 98.44%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 92/400 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0082 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 93/400 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0082 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 94/400 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0025 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 3.226%.\n",
            "Mini batch: 95/400 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0521 | Train accuracy: 97.66%.\n",
            "pgd linf: attack effectiveness 1.818%.\n",
            "Mini batch: 96/400 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.0325 | Train accuracy: 98.44%.\n",
            "pgd linf: attack effectiveness 1.515%.\n",
            "Mini batch: 97/400 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0237 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 1.639%.\n",
            "Mini batch: 98/400 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0118 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 99/400 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0317 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 100/400 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0137 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0221 | Train accuracy: 99.22\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.0% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 10 with validation accuracy 98.0% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 1.538%.\n",
            "Mini batch: 101/400 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0284 | Train accuracy: 98.44%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 102/400 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0159 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 103/400 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0149 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 104/400 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0020 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 1.613%.\n",
            "Mini batch: 105/400 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0234 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 106/400 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0221 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 107/400 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.0047 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 1.639%.\n",
            "Mini batch: 108/400 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0308 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 2.941%.\n",
            "Mini batch: 109/400 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0253 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 4.762%.\n",
            "Mini batch: 110/400 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0157 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0183 | Train accuracy: 99.38\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.0% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 11 with validation accuracy 98.0% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 111/400 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0089 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 112/400 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0143 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 113/400 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.0094 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 114/400 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0063 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 1.613%.\n",
            "Mini batch: 115/400 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0273 | Train accuracy: 98.44%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 116/400 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.0281 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 117/400 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0103 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 118/400 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0078 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 119/400 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0067 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 120/400 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.0069 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0126 | Train accuracy: 99.61\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.0% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 12 with validation accuracy 98.0% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 1.538%.\n",
            "Mini batch: 121/400 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0519 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 122/400 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0039 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 123/400 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0023 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 124/400 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0923 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 1.613%.\n",
            "Mini batch: 125/400 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.0201 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 126/400 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0266 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 127/400 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0093 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 128/400 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0133 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 129/400 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0218 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 130/400 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0021 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0244 | Train accuracy: 99.53\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.12% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 13 with validation accuracy 98.12% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 1.538%.\n",
            "Mini batch: 131/400 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.0224 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 132/400 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0075 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 133/400 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0017 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 134/400 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0018 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 3.226%.\n",
            "Mini batch: 135/400 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0225 | Train accuracy: 98.44%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 136/400 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.0066 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 1.515%.\n",
            "Mini batch: 137/400 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0300 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 138/400 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0109 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 139/400 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0116 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 140/400 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0047 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0120 | Train accuracy: 99.45\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.12% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 14 with validation accuracy 98.12% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 141/400 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0313 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 142/400 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.0037 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 143/400 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0024 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 144/400 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 145/400 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0042 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 146/400 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0217 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 147/400 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.0038 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 148/400 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0045 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 149/400 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0050 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 4.762%.\n",
            "Mini batch: 150/400 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0168 | Train accuracy: 97.87%.\n",
            "Training loss (epoch level): 0.0095 | Train accuracy: 99.63\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.12% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 15 with validation accuracy 98.12% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 1.538%.\n",
            "Mini batch: 151/400 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0354 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 152/400 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0032 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 153/400 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.0024 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 154/400 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0040 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 155/400 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0051 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 156/400 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0172 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 157/400 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0092 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 158/400 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.0034 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 159/400 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0161 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 160/400 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0016 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0097 | Train accuracy: 99.84\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 97.88% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 15 with validation accuracy 98.12% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 1.538%.\n",
            "Mini batch: 161/400 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0114 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 162/400 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0088 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 163/400 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0015 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 164/400 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 165/400 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0041 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 166/400 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0019 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 167/400 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 168/400 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0018 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 169/400 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0036 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 170/400 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.0024 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0038 | Train accuracy: 99.92\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.0% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 15 with validation accuracy 98.12% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 171/400 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0028 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 172/400 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 173/400 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 174/400 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.0015 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 175/400 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0025 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 176/400 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0063 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 177/400 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0017 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 178/400 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.0018 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 179/400 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 180/400 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0012 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0019 | Train accuracy: 100.00\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.12% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 18 with validation accuracy 98.12% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 181/400 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0016 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 182/400 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 183/400 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 184/400 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 185/400 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 186/400 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 1.515%.\n",
            "Mini batch: 187/400 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0080 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 188/400 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 189/400 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 190/400 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0013 | Train accuracy: 99.92\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.12% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 19 with validation accuracy 98.12% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 191/400 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0014 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 192/400 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0035 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 193/400 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 194/400 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 195/400 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0020 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 196/400 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0020 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 197/400 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0050 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 198/400 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 199/400 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 200/400 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0015 | Train accuracy: 100.00\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.5% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 20 with validation accuracy 98.5% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 1.538%.\n",
            "Mini batch: 201/400 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0064 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 202/400 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 203/400 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 204/400 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 205/400 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 206/400 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 207/400 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0021 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 208/400 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 209/400 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 210/400 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0012 | Train accuracy: 100.00\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.38% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 20 with validation accuracy 98.5% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 211/400 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0381 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 212/400 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0013 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 213/400 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 214/400 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 215/400 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0016 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 216/400 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 217/400 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 1.639%.\n",
            "Mini batch: 218/400 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0024 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 219/400 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0019 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 220/400 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0195 | Train accuracy: 97.87%.\n",
            "Training loss (epoch level): 0.0066 | Train accuracy: 99.71\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.38% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 20 with validation accuracy 98.5% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 1.538%.\n",
            "Mini batch: 221/400 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.0416 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 222/400 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 223/400 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 224/400 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 225/400 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0015 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 226/400 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0132 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 227/400 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.0085 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 228/400 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0019 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 229/400 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0097 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 230/400 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0027 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0081 | Train accuracy: 99.77\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.12% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 20 with validation accuracy 98.5% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 231/400 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0056 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 232/400 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 233/400 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 234/400 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 235/400 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0027 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 1.818%.\n",
            "Mini batch: 236/400 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0291 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 237/400 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 1.639%.\n",
            "Mini batch: 238/400 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0099 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 239/400 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 240/400 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0051 | Train accuracy: 99.84\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.0% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 20 with validation accuracy 98.5% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 241/400 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.0096 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 242/400 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0094 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 243/400 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 244/400 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0014 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 245/400 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 246/400 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 247/400 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 248/400 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 249/400 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 250/400 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0025 | Train accuracy: 99.84\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.0% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 20 with validation accuracy 98.5% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 1.538%.\n",
            "Mini batch: 251/400 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.0077 | Train accuracy: 99.22%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 252/400 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0026 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 253/400 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 254/400 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 255/400 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 256/400 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 257/400 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 258/400 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 259/400 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 260/400 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0014 | Train accuracy: 99.92\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.25% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 20 with validation accuracy 98.5% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 261/400 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0016 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 262/400 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 263/400 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 264/400 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 265/400 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 266/400 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 267/400 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 268/400 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 269/400 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 270/400 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0005 | Train accuracy: 100.00\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.38% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 20 with validation accuracy 98.5% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 271/400 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 272/400 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 273/400 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 274/400 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 275/400 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 276/400 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 277/400 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 278/400 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 279/400 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 280/400 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0002 | Train accuracy: 100.00\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.25% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 20 with validation accuracy 98.5% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 281/400 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0011 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 282/400 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 283/400 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 284/400 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 285/400 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 286/400 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 287/400 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 288/400 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 289/400 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 290/400 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0003 | Train accuracy: 100.00\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.25% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 20 with validation accuracy 98.5% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 291/400 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 292/400 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 293/400 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 294/400 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 295/400 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 296/400 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 297/400 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 298/400 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 299/400 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 300/400 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0002 | Train accuracy: 100.00\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.25% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 20 with validation accuracy 98.5% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 301/400 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 302/400 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 303/400 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 304/400 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 305/400 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 306/400 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 307/400 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 308/400 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 309/400 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 310/400 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0024 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0003 | Train accuracy: 100.00\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.25% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 20 with validation accuracy 98.5% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 311/400 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 312/400 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 313/400 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 314/400 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 315/400 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 316/400 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 317/400 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 318/400 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 319/400 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 320/400 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 97.88% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 20 with validation accuracy 98.5% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 321/400 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 322/400 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 323/400 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 324/400 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 325/400 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 326/400 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 327/400 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 328/400 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 329/400 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 330/400 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 97.88% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 20 with validation accuracy 98.5% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 331/400 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 332/400 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 333/400 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 334/400 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 335/400 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 336/400 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 337/400 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 338/400 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 339/400 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 340/400 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 97.88% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 20 with validation accuracy 98.5% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 341/400 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 342/400 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 343/400 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 344/400 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 345/400 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 346/400 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 347/400 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 348/400 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 349/400 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 350/400 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0002 | Train accuracy: 100.00\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.25% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 20 with validation accuracy 98.5% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 351/400 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 352/400 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 353/400 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 354/400 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 355/400 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 356/400 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 357/400 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 358/400 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 359/400 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 360/400 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.25% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 20 with validation accuracy 98.5% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 361/400 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 362/400 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 363/400 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 364/400 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 365/400 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 366/400 | training time in 1 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 367/400 | training time in 1 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 368/400 | training time in 1 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 369/400 | training time in 1 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 370/400 | training time in 1 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.25% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 20 with validation accuracy 98.5% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 371/400 | training time in 1 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 372/400 | training time in 1 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 373/400 | training time in 1 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 374/400 | training time in 1 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 375/400 | training time in 1 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 376/400 | training time in 1 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 377/400 | training time in 1 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 378/400 | training time in 1 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 379/400 | training time in 1 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 380/400 | training time in 1 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.25% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 20 with validation accuracy 98.5% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 381/400 | training time in 1 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 382/400 | training time in 1 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 383/400 | training time in 1 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 384/400 | training time in 1 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 385/400 | training time in 1 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 386/400 | training time in 1 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 387/400 | training time in 1 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 388/400 | training time in 1 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 389/400 | training time in 1 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 390/400 | training time in 1 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.25% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 20 with validation accuracy 98.5% and accuracy 100.0% under attack.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 391/400 | training time in 1 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 392/400 | training time in 1 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 393/400 | training time in 1 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 394/400 | training time in 1 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 395/400 | training time in 1 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 396/400 | training time in 1 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 397/400 | training time in 1 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 398/400 | training time in 1 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 399/400 | training time in 1 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00%.\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "Mini batch: 400/400 | training time in 1 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "pgd linf: attack effectiveness 0.000%.\n",
            "\tVal accuracy 98.38% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 20 with validation accuracy 98.5% and accuracy 100.0% under attack.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "--3mtpw65v2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# norm = ''l2''\n",
        "\n",
        "model = MalwareDetectionDNN(3216,2)\n",
        "model = model.double().to(device)\n",
        "attack = PGD(norm='l2', use_random=False,rounding_threshold=0.5,is_attacker=False,manipulation_x=manipulation_x, omega=omega,api_flag=api_flag,device=device)\n",
        "attack_param = {}\n",
        "max_adv_training_model = PGDAdvTraining(model, attack, attack_param)\n",
        "max_adv_training_model.fit(train_Loader,validation_Loader,adv_epochs=40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3584fcaa-8beb-4c3e-dbc4-548f9d02eace",
        "id": "GzGJdauV5wD1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pgd l2: attack effectiveness 100.000%.\n",
            "Mini batch: 1/400 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.6916 | Train accuracy: 48.44%.\n",
            "pgd l2: attack effectiveness 100.000%.\n",
            "Mini batch: 2/400 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.7246 | Train accuracy: 51.56%.\n",
            "pgd l2: attack effectiveness 65.672%.\n",
            "Mini batch: 3/400 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.8291 | Train accuracy: 37.50%.\n",
            "pgd l2: attack effectiveness 42.647%.\n",
            "Mini batch: 4/400 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.6980 | Train accuracy: 42.19%.\n",
            "pgd l2: attack effectiveness 58.065%.\n",
            "Mini batch: 5/400 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.6901 | Train accuracy: 45.31%.\n",
            "pgd l2: attack effectiveness 69.091%.\n",
            "Mini batch: 6/400 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.7015 | Train accuracy: 57.81%.\n",
            "pgd l2: attack effectiveness 50.000%.\n",
            "Mini batch: 7/400 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.5857 | Train accuracy: 71.88%.\n",
            "pgd l2: attack effectiveness 44.262%.\n",
            "Mini batch: 8/400 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.6055 | Train accuracy: 64.84%.\n",
            "pgd l2: attack effectiveness 58.824%.\n",
            "Mini batch: 9/400 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.6081 | Train accuracy: 63.28%.\n",
            "pgd l2: attack effectiveness 47.619%.\n",
            "Mini batch: 10/400 | training time in 0 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.5516 | Train accuracy: 68.09%.\n",
            "Training loss (epoch level): 0.6686 | Train accuracy: 55.09\n",
            "pgd l2: attack effectiveness 61.905%.\n",
            "\tVal accuracy 57.67% with accuracy 38.1% under attack.\n",
            "\tModel select at epoch 1 with validation accuracy 57.67% and accuracy 38.1% under attack.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-ecfac4671c7e>:94: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  acc_val_adv = np.sum(res_val).astype(np.float) / res_val.shape[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pgd l2: attack effectiveness 46.154%.\n",
            "Mini batch: 11/400 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.5620 | Train accuracy: 69.53%.\n",
            "pgd l2: attack effectiveness 51.562%.\n",
            "Mini batch: 12/400 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.6170 | Train accuracy: 69.53%.\n",
            "pgd l2: attack effectiveness 47.761%.\n",
            "Mini batch: 13/400 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.6416 | Train accuracy: 68.75%.\n",
            "pgd l2: attack effectiveness 50.000%.\n",
            "Mini batch: 14/400 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.5695 | Train accuracy: 67.97%.\n",
            "pgd l2: attack effectiveness 54.839%.\n",
            "Mini batch: 15/400 | training time in 0 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.6364 | Train accuracy: 63.28%.\n",
            "pgd l2: attack effectiveness 47.273%.\n",
            "Mini batch: 16/400 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.6234 | Train accuracy: 66.41%.\n",
            "pgd l2: attack effectiveness 46.970%.\n",
            "Mini batch: 17/400 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.5400 | Train accuracy: 71.88%.\n",
            "pgd l2: attack effectiveness 39.344%.\n",
            "Mini batch: 18/400 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.5240 | Train accuracy: 75.00%.\n",
            "pgd l2: attack effectiveness 45.588%.\n",
            "Mini batch: 19/400 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.5335 | Train accuracy: 71.88%.\n",
            "pgd l2: attack effectiveness 42.857%.\n",
            "Mini batch: 20/400 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.5203 | Train accuracy: 80.85%.\n",
            "Training loss (epoch level): 0.5768 | Train accuracy: 70.51\n",
            "pgd l2: attack effectiveness 61.905%.\n",
            "\tVal accuracy 62.55% with accuracy 38.1% under attack.\n",
            "\tModel select at epoch 2 with validation accuracy 62.55% and accuracy 38.1% under attack.\n",
            "pgd l2: attack effectiveness 40.000%.\n",
            "Mini batch: 21/400 | training time in 0 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.5085 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 40.625%.\n",
            "Mini batch: 22/400 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.4935 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 41.791%.\n",
            "Mini batch: 23/400 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.5284 | Train accuracy: 75.00%.\n",
            "pgd l2: attack effectiveness 44.118%.\n",
            "Mini batch: 24/400 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.4500 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 51.613%.\n",
            "Mini batch: 25/400 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.5804 | Train accuracy: 72.66%.\n",
            "pgd l2: attack effectiveness 41.818%.\n",
            "Mini batch: 26/400 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.5803 | Train accuracy: 73.44%.\n",
            "pgd l2: attack effectiveness 36.364%.\n",
            "Mini batch: 27/400 | training time in 0 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.4883 | Train accuracy: 76.56%.\n",
            "pgd l2: attack effectiveness 31.148%.\n",
            "Mini batch: 28/400 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.4518 | Train accuracy: 78.91%.\n",
            "pgd l2: attack effectiveness 41.176%.\n",
            "Mini batch: 29/400 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.5070 | Train accuracy: 71.09%.\n",
            "pgd l2: attack effectiveness 42.857%.\n",
            "Mini batch: 30/400 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.4866 | Train accuracy: 76.60%.\n",
            "Training loss (epoch level): 0.5075 | Train accuracy: 75.86\n",
            "pgd l2: attack effectiveness 61.905%.\n",
            "\tVal accuracy 63.3% with accuracy 38.1% under attack.\n",
            "\tModel select at epoch 3 with validation accuracy 63.3% and accuracy 38.1% under attack.\n",
            "pgd l2: attack effectiveness 40.000%.\n",
            "Mini batch: 31/400 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.5200 | Train accuracy: 76.56%.\n",
            "pgd l2: attack effectiveness 40.625%.\n",
            "Mini batch: 32/400 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.5183 | Train accuracy: 75.78%.\n",
            "pgd l2: attack effectiveness 44.776%.\n",
            "Mini batch: 33/400 | training time in 0 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.5198 | Train accuracy: 77.34%.\n",
            "pgd l2: attack effectiveness 42.647%.\n",
            "Mini batch: 34/400 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.4881 | Train accuracy: 75.00%.\n",
            "pgd l2: attack effectiveness 50.000%.\n",
            "Mini batch: 35/400 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.4967 | Train accuracy: 75.00%.\n",
            "pgd l2: attack effectiveness 40.000%.\n",
            "Mini batch: 36/400 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.5665 | Train accuracy: 78.91%.\n",
            "pgd l2: attack effectiveness 34.848%.\n",
            "Mini batch: 37/400 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.4824 | Train accuracy: 79.69%.\n",
            "pgd l2: attack effectiveness 34.426%.\n",
            "Mini batch: 38/400 | training time in 0 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.4195 | Train accuracy: 83.59%.\n",
            "pgd l2: attack effectiveness 42.647%.\n",
            "Mini batch: 39/400 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.4988 | Train accuracy: 75.78%.\n",
            "pgd l2: attack effectiveness 42.857%.\n",
            "Mini batch: 40/400 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.4566 | Train accuracy: 82.98%.\n",
            "Training loss (epoch level): 0.4967 | Train accuracy: 78.06\n",
            "pgd l2: attack effectiveness 52.381%.\n",
            "\tVal accuracy 68.31% with accuracy 47.62% under attack.\n",
            "\tModel select at epoch 4 with validation accuracy 68.31% and accuracy 47.62% under attack.\n",
            "pgd l2: attack effectiveness 40.000%.\n",
            "Mini batch: 41/400 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.4817 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 37.500%.\n",
            "Mini batch: 42/400 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.4261 | Train accuracy: 79.69%.\n",
            "pgd l2: attack effectiveness 38.806%.\n",
            "Mini batch: 43/400 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.4518 | Train accuracy: 78.91%.\n",
            "pgd l2: attack effectiveness 41.176%.\n",
            "Mini batch: 44/400 | training time in 0 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.4413 | Train accuracy: 77.34%.\n",
            "pgd l2: attack effectiveness 50.000%.\n",
            "Mini batch: 45/400 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.4799 | Train accuracy: 75.00%.\n",
            "pgd l2: attack effectiveness 41.818%.\n",
            "Mini batch: 46/400 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.5118 | Train accuracy: 80.47%.\n",
            "pgd l2: attack effectiveness 34.848%.\n",
            "Mini batch: 47/400 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.4253 | Train accuracy: 81.25%.\n",
            "pgd l2: attack effectiveness 31.148%.\n",
            "Mini batch: 48/400 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.3825 | Train accuracy: 84.38%.\n",
            "pgd l2: attack effectiveness 41.176%.\n",
            "Mini batch: 49/400 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.4527 | Train accuracy: 76.56%.\n",
            "pgd l2: attack effectiveness 38.095%.\n",
            "Mini batch: 50/400 | training time in 0 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.3657 | Train accuracy: 82.98%.\n",
            "Training loss (epoch level): 0.4419 | Train accuracy: 79.47\n",
            "pgd l2: attack effectiveness 42.857%.\n",
            "\tVal accuracy 74.7% with accuracy 57.14% under attack.\n",
            "\tModel select at epoch 5 with validation accuracy 74.7% and accuracy 57.14% under attack.\n",
            "pgd l2: attack effectiveness 36.923%.\n",
            "Mini batch: 51/400 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.4081 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 35.938%.\n",
            "Mini batch: 52/400 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.4014 | Train accuracy: 80.47%.\n",
            "pgd l2: attack effectiveness 38.806%.\n",
            "Mini batch: 53/400 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.4110 | Train accuracy: 76.56%.\n",
            "pgd l2: attack effectiveness 45.588%.\n",
            "Mini batch: 54/400 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.4118 | Train accuracy: 75.00%.\n",
            "pgd l2: attack effectiveness 51.613%.\n",
            "Mini batch: 55/400 | training time in 0 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.4671 | Train accuracy: 73.44%.\n",
            "pgd l2: attack effectiveness 41.818%.\n",
            "Mini batch: 56/400 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.5277 | Train accuracy: 73.44%.\n",
            "pgd l2: attack effectiveness 37.879%.\n",
            "Mini batch: 57/400 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.4469 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 32.787%.\n",
            "Mini batch: 58/400 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.3900 | Train accuracy: 81.25%.\n",
            "pgd l2: attack effectiveness 41.176%.\n",
            "Mini batch: 59/400 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.4535 | Train accuracy: 76.56%.\n",
            "pgd l2: attack effectiveness 38.095%.\n",
            "Mini batch: 60/400 | training time in 0 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.3390 | Train accuracy: 82.98%.\n",
            "Training loss (epoch level): 0.4257 | Train accuracy: 77.59\n",
            "pgd l2: attack effectiveness 42.857%.\n",
            "\tVal accuracy 74.57% with accuracy 57.14% under attack.\n",
            "\tModel select at epoch 5 with validation accuracy 74.7% and accuracy 57.14% under attack.\n",
            "pgd l2: attack effectiveness 36.923%.\n",
            "Mini batch: 61/400 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.3895 | Train accuracy: 78.91%.\n",
            "pgd l2: attack effectiveness 34.375%.\n",
            "Mini batch: 62/400 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.3848 | Train accuracy: 80.47%.\n",
            "pgd l2: attack effectiveness 38.806%.\n",
            "Mini batch: 63/400 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.4108 | Train accuracy: 75.78%.\n",
            "pgd l2: attack effectiveness 41.176%.\n",
            "Mini batch: 64/400 | training time in 0 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.3971 | Train accuracy: 77.34%.\n",
            "pgd l2: attack effectiveness 53.226%.\n",
            "Mini batch: 65/400 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.4401 | Train accuracy: 74.22%.\n",
            "pgd l2: attack effectiveness 43.636%.\n",
            "Mini batch: 66/400 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.4590 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 34.848%.\n",
            "Mini batch: 67/400 | training time in 0 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.4152 | Train accuracy: 81.25%.\n",
            "pgd l2: attack effectiveness 36.066%.\n",
            "Mini batch: 68/400 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.3536 | Train accuracy: 82.03%.\n",
            "pgd l2: attack effectiveness 41.176%.\n",
            "Mini batch: 69/400 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.4402 | Train accuracy: 77.34%.\n",
            "pgd l2: attack effectiveness 38.095%.\n",
            "Mini batch: 70/400 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.3032 | Train accuracy: 82.98%.\n",
            "Training loss (epoch level): 0.3993 | Train accuracy: 78.84\n",
            "pgd l2: attack effectiveness 42.857%.\n",
            "\tVal accuracy 74.57% with accuracy 57.14% under attack.\n",
            "\tModel select at epoch 5 with validation accuracy 74.7% and accuracy 57.14% under attack.\n",
            "pgd l2: attack effectiveness 36.923%.\n",
            "Mini batch: 71/400 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.3588 | Train accuracy: 78.91%.\n",
            "pgd l2: attack effectiveness 34.375%.\n",
            "Mini batch: 72/400 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.3904 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 40.299%.\n",
            "Mini batch: 73/400 | training time in 0 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.3872 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 36.765%.\n",
            "Mini batch: 74/400 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.3978 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 35.484%.\n",
            "Mini batch: 75/400 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.4221 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 32.727%.\n",
            "Mini batch: 76/400 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.4488 | Train accuracy: 75.78%.\n",
            "pgd l2: attack effectiveness 31.818%.\n",
            "Mini batch: 77/400 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.3825 | Train accuracy: 81.25%.\n",
            "pgd l2: attack effectiveness 32.787%.\n",
            "Mini batch: 78/400 | training time in 0 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.3398 | Train accuracy: 82.81%.\n",
            "pgd l2: attack effectiveness 42.647%.\n",
            "Mini batch: 79/400 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.4531 | Train accuracy: 75.00%.\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "Mini batch: 80/400 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.3007 | Train accuracy: 87.23%.\n",
            "Training loss (epoch level): 0.3881 | Train accuracy: 79.35\n",
            "pgd l2: attack effectiveness 57.143%.\n",
            "\tVal accuracy 67.8% with accuracy 42.86% under attack.\n",
            "\tModel select at epoch 5 with validation accuracy 74.7% and accuracy 57.14% under attack.\n",
            "pgd l2: attack effectiveness 23.077%.\n",
            "Mini batch: 81/400 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.3465 | Train accuracy: 82.03%.\n",
            "pgd l2: attack effectiveness 23.438%.\n",
            "Mini batch: 82/400 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.3727 | Train accuracy: 85.94%.\n",
            "pgd l2: attack effectiveness 14.925%.\n",
            "Mini batch: 83/400 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.4102 | Train accuracy: 82.81%.\n",
            "pgd l2: attack effectiveness 36.765%.\n",
            "Mini batch: 84/400 | training time in 0 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.3885 | Train accuracy: 82.03%.\n",
            "pgd l2: attack effectiveness 19.355%.\n",
            "Mini batch: 85/400 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.4263 | Train accuracy: 77.34%.\n",
            "pgd l2: attack effectiveness 36.364%.\n",
            "Mini batch: 86/400 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.4872 | Train accuracy: 68.75%.\n",
            "pgd l2: attack effectiveness 40.909%.\n",
            "Mini batch: 87/400 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.4834 | Train accuracy: 74.22%.\n",
            "pgd l2: attack effectiveness 39.344%.\n",
            "Mini batch: 88/400 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.4049 | Train accuracy: 75.00%.\n",
            "pgd l2: attack effectiveness 41.176%.\n",
            "Mini batch: 89/400 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.5031 | Train accuracy: 75.00%.\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "Mini batch: 90/400 | training time in 0 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.3361 | Train accuracy: 80.85%.\n",
            "Training loss (epoch level): 0.4159 | Train accuracy: 78.40\n",
            "pgd l2: attack effectiveness 38.095%.\n",
            "\tVal accuracy 76.58% with accuracy 61.9% under attack.\n",
            "\tModel select at epoch 9 with validation accuracy 76.58% and accuracy 61.9% under attack.\n",
            "pgd l2: attack effectiveness 35.385%.\n",
            "Mini batch: 91/400 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.3795 | Train accuracy: 75.00%.\n",
            "pgd l2: attack effectiveness 34.375%.\n",
            "Mini batch: 92/400 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.3755 | Train accuracy: 80.47%.\n",
            "pgd l2: attack effectiveness 34.328%.\n",
            "Mini batch: 93/400 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.3735 | Train accuracy: 75.78%.\n",
            "pgd l2: attack effectiveness 38.235%.\n",
            "Mini batch: 94/400 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.3589 | Train accuracy: 81.25%.\n",
            "pgd l2: attack effectiveness 46.774%.\n",
            "Mini batch: 95/400 | training time in 0 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.4046 | Train accuracy: 72.66%.\n",
            "pgd l2: attack effectiveness 32.727%.\n",
            "Mini batch: 96/400 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.4372 | Train accuracy: 79.69%.\n",
            "pgd l2: attack effectiveness 34.848%.\n",
            "Mini batch: 97/400 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.3478 | Train accuracy: 83.59%.\n",
            "pgd l2: attack effectiveness 32.787%.\n",
            "Mini batch: 98/400 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.3675 | Train accuracy: 79.69%.\n",
            "pgd l2: attack effectiveness 41.176%.\n",
            "Mini batch: 99/400 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.4732 | Train accuracy: 74.22%.\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "Mini batch: 100/400 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.2793 | Train accuracy: 85.11%.\n",
            "Training loss (epoch level): 0.3797 | Train accuracy: 78.75\n",
            "pgd l2: attack effectiveness 38.095%.\n",
            "\tVal accuracy 76.83% with accuracy 61.9% under attack.\n",
            "\tModel select at epoch 10 with validation accuracy 76.83% and accuracy 61.9% under attack.\n",
            "pgd l2: attack effectiveness 35.385%.\n",
            "Mini batch: 101/400 | training time in 0 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.3279 | Train accuracy: 82.03%.\n",
            "pgd l2: attack effectiveness 32.812%.\n",
            "Mini batch: 102/400 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.3734 | Train accuracy: 78.91%.\n",
            "pgd l2: attack effectiveness 32.836%.\n",
            "Mini batch: 103/400 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.3794 | Train accuracy: 77.34%.\n",
            "pgd l2: attack effectiveness 36.765%.\n",
            "Mini batch: 104/400 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.3940 | Train accuracy: 76.56%.\n",
            "pgd l2: attack effectiveness 17.742%.\n",
            "Mini batch: 105/400 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.3810 | Train accuracy: 85.16%.\n",
            "pgd l2: attack effectiveness 12.727%.\n",
            "Mini batch: 106/400 | training time in 0 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.3971 | Train accuracy: 79.69%.\n",
            "pgd l2: attack effectiveness 27.273%.\n",
            "Mini batch: 107/400 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.3781 | Train accuracy: 80.47%.\n",
            "pgd l2: attack effectiveness 14.754%.\n",
            "Mini batch: 108/400 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.3232 | Train accuracy: 85.94%.\n",
            "pgd l2: attack effectiveness 32.353%.\n",
            "Mini batch: 109/400 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.4137 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 28.571%.\n",
            "Mini batch: 110/400 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.3200 | Train accuracy: 85.11%.\n",
            "Training loss (epoch level): 0.3688 | Train accuracy: 80.93\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "\tVal accuracy 77.33% with accuracy 66.67% under attack.\n",
            "\tModel select at epoch 11 with validation accuracy 77.33% and accuracy 66.67% under attack.\n",
            "pgd l2: attack effectiveness 24.615%.\n",
            "Mini batch: 111/400 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.3817 | Train accuracy: 81.25%.\n",
            "pgd l2: attack effectiveness 34.375%.\n",
            "Mini batch: 112/400 | training time in 0 minutes, 20 seconds.\n",
            "Training loss (batch level): 0.4769 | Train accuracy: 77.34%.\n",
            "pgd l2: attack effectiveness 43.284%.\n",
            "Mini batch: 113/400 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.4725 | Train accuracy: 73.44%.\n",
            "pgd l2: attack effectiveness 42.647%.\n",
            "Mini batch: 114/400 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.4773 | Train accuracy: 73.44%.\n",
            "pgd l2: attack effectiveness 50.000%.\n",
            "Mini batch: 115/400 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.4020 | Train accuracy: 75.00%.\n",
            "pgd l2: attack effectiveness 41.818%.\n",
            "Mini batch: 116/400 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.4029 | Train accuracy: 84.38%.\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "Mini batch: 117/400 | training time in 0 minutes, 21 seconds.\n",
            "Training loss (batch level): 0.3715 | Train accuracy: 80.47%.\n",
            "pgd l2: attack effectiveness 36.066%.\n",
            "Mini batch: 118/400 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.3612 | Train accuracy: 80.47%.\n",
            "pgd l2: attack effectiveness 39.706%.\n",
            "Mini batch: 119/400 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.4221 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 38.095%.\n",
            "Mini batch: 120/400 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.3215 | Train accuracy: 82.98%.\n",
            "Training loss (epoch level): 0.4090 | Train accuracy: 78.69\n",
            "pgd l2: attack effectiveness 47.619%.\n",
            "\tVal accuracy 72.44% with accuracy 52.38% under attack.\n",
            "\tModel select at epoch 11 with validation accuracy 77.33% and accuracy 66.67% under attack.\n",
            "pgd l2: attack effectiveness 40.000%.\n",
            "Mini batch: 121/400 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.3883 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 37.500%.\n",
            "Mini batch: 122/400 | training time in 0 minutes, 22 seconds.\n",
            "Training loss (batch level): 0.4124 | Train accuracy: 78.91%.\n",
            "pgd l2: attack effectiveness 44.776%.\n",
            "Mini batch: 123/400 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.4611 | Train accuracy: 73.44%.\n",
            "pgd l2: attack effectiveness 42.647%.\n",
            "Mini batch: 124/400 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.4695 | Train accuracy: 72.66%.\n",
            "pgd l2: attack effectiveness 38.710%.\n",
            "Mini batch: 125/400 | training time in 0 minutes, 23 seconds.\n",
            "Training loss (batch level): 0.4276 | Train accuracy: 75.00%.\n",
            "pgd l2: attack effectiveness 40.000%.\n",
            "Mini batch: 126/400 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.4475 | Train accuracy: 75.78%.\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "Mini batch: 127/400 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.3574 | Train accuracy: 81.25%.\n",
            "pgd l2: attack effectiveness 21.311%.\n",
            "Mini batch: 128/400 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.3017 | Train accuracy: 85.94%.\n",
            "pgd l2: attack effectiveness 38.235%.\n",
            "Mini batch: 129/400 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.4080 | Train accuracy: 74.22%.\n",
            "pgd l2: attack effectiveness 38.095%.\n",
            "Mini batch: 130/400 | training time in 0 minutes, 24 seconds.\n",
            "Training loss (batch level): 0.2738 | Train accuracy: 87.23%.\n",
            "Training loss (epoch level): 0.3947 | Train accuracy: 78.25\n",
            "pgd l2: attack effectiveness 52.381%.\n",
            "\tVal accuracy 70.56% with accuracy 47.62% under attack.\n",
            "\tModel select at epoch 11 with validation accuracy 77.33% and accuracy 66.67% under attack.\n",
            "pgd l2: attack effectiveness 26.154%.\n",
            "Mini batch: 131/400 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.2953 | Train accuracy: 85.16%.\n",
            "pgd l2: attack effectiveness 37.500%.\n",
            "Mini batch: 132/400 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.3639 | Train accuracy: 80.47%.\n",
            "pgd l2: attack effectiveness 25.373%.\n",
            "Mini batch: 133/400 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.3467 | Train accuracy: 82.03%.\n",
            "pgd l2: attack effectiveness 10.294%.\n",
            "Mini batch: 134/400 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.2658 | Train accuracy: 92.97%.\n",
            "pgd l2: attack effectiveness 9.677%.\n",
            "Mini batch: 135/400 | training time in 0 minutes, 25 seconds.\n",
            "Training loss (batch level): 0.2894 | Train accuracy: 88.28%.\n",
            "pgd l2: attack effectiveness 9.091%.\n",
            "Mini batch: 136/400 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.4203 | Train accuracy: 78.91%.\n",
            "pgd l2: attack effectiveness 13.636%.\n",
            "Mini batch: 137/400 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.3096 | Train accuracy: 83.59%.\n",
            "pgd l2: attack effectiveness 14.754%.\n",
            "Mini batch: 138/400 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.2576 | Train accuracy: 85.94%.\n",
            "pgd l2: attack effectiveness 33.824%.\n",
            "Mini batch: 139/400 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.3995 | Train accuracy: 79.69%.\n",
            "pgd l2: attack effectiveness 42.857%.\n",
            "Mini batch: 140/400 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.3418 | Train accuracy: 78.72%.\n",
            "Training loss (epoch level): 0.3290 | Train accuracy: 83.58\n",
            "pgd l2: attack effectiveness 47.619%.\n",
            "\tVal accuracy 72.69% with accuracy 52.38% under attack.\n",
            "\tModel select at epoch 11 with validation accuracy 77.33% and accuracy 66.67% under attack.\n",
            "pgd l2: attack effectiveness 21.538%.\n",
            "Mini batch: 141/400 | training time in 0 minutes, 26 seconds.\n",
            "Training loss (batch level): 0.3336 | Train accuracy: 84.38%.\n",
            "pgd l2: attack effectiveness 29.688%.\n",
            "Mini batch: 142/400 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.3130 | Train accuracy: 85.16%.\n",
            "pgd l2: attack effectiveness 26.866%.\n",
            "Mini batch: 143/400 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.3357 | Train accuracy: 82.03%.\n",
            "pgd l2: attack effectiveness 27.941%.\n",
            "Mini batch: 144/400 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.2874 | Train accuracy: 84.38%.\n",
            "pgd l2: attack effectiveness 9.677%.\n",
            "Mini batch: 145/400 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.3233 | Train accuracy: 86.72%.\n",
            "pgd l2: attack effectiveness 7.273%.\n",
            "Mini batch: 146/400 | training time in 0 minutes, 27 seconds.\n",
            "Training loss (batch level): 0.3664 | Train accuracy: 79.69%.\n",
            "pgd l2: attack effectiveness 13.636%.\n",
            "Mini batch: 147/400 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.3416 | Train accuracy: 85.94%.\n",
            "pgd l2: attack effectiveness 13.115%.\n",
            "Mini batch: 148/400 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.2718 | Train accuracy: 87.50%.\n",
            "pgd l2: attack effectiveness 19.118%.\n",
            "Mini batch: 149/400 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.3212 | Train accuracy: 89.84%.\n",
            "pgd l2: attack effectiveness 14.286%.\n",
            "Mini batch: 150/400 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.2708 | Train accuracy: 91.49%.\n",
            "Training loss (epoch level): 0.3165 | Train accuracy: 85.71\n",
            "pgd l2: attack effectiveness 19.048%.\n",
            "\tVal accuracy 86.6% with accuracy 80.95% under attack.\n",
            "\tModel select at epoch 15 with validation accuracy 86.6% and accuracy 80.95% under attack.\n",
            "pgd l2: attack effectiveness 10.769%.\n",
            "Mini batch: 151/400 | training time in 0 minutes, 28 seconds.\n",
            "Training loss (batch level): 0.2557 | Train accuracy: 92.19%.\n",
            "pgd l2: attack effectiveness 9.375%.\n",
            "Mini batch: 152/400 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.2192 | Train accuracy: 92.97%.\n",
            "pgd l2: attack effectiveness 5.970%.\n",
            "Mini batch: 153/400 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.1971 | Train accuracy: 93.75%.\n",
            "pgd l2: attack effectiveness 10.294%.\n",
            "Mini batch: 154/400 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.2160 | Train accuracy: 92.97%.\n",
            "pgd l2: attack effectiveness 35.484%.\n",
            "Mini batch: 155/400 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.4256 | Train accuracy: 79.69%.\n",
            "pgd l2: attack effectiveness 34.545%.\n",
            "Mini batch: 156/400 | training time in 0 minutes, 29 seconds.\n",
            "Training loss (batch level): 0.4415 | Train accuracy: 77.34%.\n",
            "pgd l2: attack effectiveness 30.303%.\n",
            "Mini batch: 157/400 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.3327 | Train accuracy: 82.03%.\n",
            "pgd l2: attack effectiveness 21.311%.\n",
            "Mini batch: 158/400 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.2387 | Train accuracy: 88.28%.\n",
            "pgd l2: attack effectiveness 30.882%.\n",
            "Mini batch: 159/400 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.3523 | Train accuracy: 83.59%.\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "Mini batch: 160/400 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.2550 | Train accuracy: 85.11%.\n",
            "Training loss (epoch level): 0.2934 | Train accuracy: 86.79\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "\tVal accuracy 79.96% with accuracy 66.67% under attack.\n",
            "\tModel select at epoch 15 with validation accuracy 86.6% and accuracy 80.95% under attack.\n",
            "pgd l2: attack effectiveness 16.923%.\n",
            "Mini batch: 161/400 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.2682 | Train accuracy: 89.84%.\n",
            "pgd l2: attack effectiveness 7.812%.\n",
            "Mini batch: 162/400 | training time in 0 minutes, 30 seconds.\n",
            "Training loss (batch level): 0.2295 | Train accuracy: 93.75%.\n",
            "pgd l2: attack effectiveness 5.970%.\n",
            "Mini batch: 163/400 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.2175 | Train accuracy: 93.75%.\n",
            "pgd l2: attack effectiveness 27.941%.\n",
            "Mini batch: 164/400 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.2939 | Train accuracy: 84.38%.\n",
            "pgd l2: attack effectiveness 9.677%.\n",
            "Mini batch: 165/400 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.3132 | Train accuracy: 89.84%.\n",
            "pgd l2: attack effectiveness 7.273%.\n",
            "Mini batch: 166/400 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.3187 | Train accuracy: 89.06%.\n",
            "pgd l2: attack effectiveness 24.242%.\n",
            "Mini batch: 167/400 | training time in 0 minutes, 31 seconds.\n",
            "Training loss (batch level): 0.3465 | Train accuracy: 84.38%.\n",
            "pgd l2: attack effectiveness 27.869%.\n",
            "Mini batch: 168/400 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.2783 | Train accuracy: 85.16%.\n",
            "pgd l2: attack effectiveness 30.882%.\n",
            "Mini batch: 169/400 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.3710 | Train accuracy: 82.81%.\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "Mini batch: 170/400 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.2797 | Train accuracy: 85.11%.\n",
            "Training loss (epoch level): 0.2917 | Train accuracy: 87.81\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "\tVal accuracy 79.71% with accuracy 66.67% under attack.\n",
            "\tModel select at epoch 15 with validation accuracy 86.6% and accuracy 80.95% under attack.\n",
            "pgd l2: attack effectiveness 23.077%.\n",
            "Mini batch: 171/400 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.2600 | Train accuracy: 88.28%.\n",
            "pgd l2: attack effectiveness 26.562%.\n",
            "Mini batch: 172/400 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.2849 | Train accuracy: 83.59%.\n",
            "pgd l2: attack effectiveness 17.910%.\n",
            "Mini batch: 173/400 | training time in 0 minutes, 32 seconds.\n",
            "Training loss (batch level): 0.2909 | Train accuracy: 86.72%.\n",
            "pgd l2: attack effectiveness 8.824%.\n",
            "Mini batch: 174/400 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.1804 | Train accuracy: 95.31%.\n",
            "pgd l2: attack effectiveness 24.194%.\n",
            "Mini batch: 175/400 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.2617 | Train accuracy: 88.28%.\n",
            "pgd l2: attack effectiveness 20.000%.\n",
            "Mini batch: 176/400 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.3272 | Train accuracy: 89.06%.\n",
            "pgd l2: attack effectiveness 13.636%.\n",
            "Mini batch: 177/400 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.3087 | Train accuracy: 92.97%.\n",
            "pgd l2: attack effectiveness 18.033%.\n",
            "Mini batch: 178/400 | training time in 0 minutes, 33 seconds.\n",
            "Training loss (batch level): 0.2898 | Train accuracy: 89.06%.\n",
            "pgd l2: attack effectiveness 19.118%.\n",
            "Mini batch: 179/400 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.3184 | Train accuracy: 89.06%.\n",
            "pgd l2: attack effectiveness 14.286%.\n",
            "Mini batch: 180/400 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.1881 | Train accuracy: 91.49%.\n",
            "Training loss (epoch level): 0.2710 | Train accuracy: 89.38\n",
            "pgd l2: attack effectiveness 23.810%.\n",
            "\tVal accuracy 83.72% with accuracy 76.19% under attack.\n",
            "\tModel select at epoch 15 with validation accuracy 86.6% and accuracy 80.95% under attack.\n",
            "pgd l2: attack effectiveness 7.692%.\n",
            "Mini batch: 181/400 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.2169 | Train accuracy: 92.97%.\n",
            "pgd l2: attack effectiveness 20.312%.\n",
            "Mini batch: 182/400 | training time in 0 minutes, 34 seconds.\n",
            "Training loss (batch level): 0.2836 | Train accuracy: 86.72%.\n",
            "pgd l2: attack effectiveness 37.313%.\n",
            "Mini batch: 183/400 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.4132 | Train accuracy: 78.91%.\n",
            "pgd l2: attack effectiveness 42.647%.\n",
            "Mini batch: 184/400 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.4764 | Train accuracy: 78.12%.\n",
            "pgd l2: attack effectiveness 51.613%.\n",
            "Mini batch: 185/400 | training time in 0 minutes, 35 seconds.\n",
            "Training loss (batch level): 0.4760 | Train accuracy: 74.22%.\n",
            "pgd l2: attack effectiveness 12.727%.\n",
            "Mini batch: 186/400 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.3017 | Train accuracy: 90.62%.\n",
            "pgd l2: attack effectiveness 13.636%.\n",
            "Mini batch: 187/400 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.3016 | Train accuracy: 90.62%.\n",
            "pgd l2: attack effectiveness 6.557%.\n",
            "Mini batch: 188/400 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.2273 | Train accuracy: 94.53%.\n",
            "pgd l2: attack effectiveness 14.706%.\n",
            "Mini batch: 189/400 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.2827 | Train accuracy: 91.41%.\n",
            "pgd l2: attack effectiveness 14.286%.\n",
            "Mini batch: 190/400 | training time in 0 minutes, 36 seconds.\n",
            "Training loss (batch level): 0.2609 | Train accuracy: 95.74%.\n",
            "Training loss (epoch level): 0.3240 | Train accuracy: 87.39\n",
            "pgd l2: attack effectiveness 14.286%.\n",
            "\tVal accuracy 88.36% with accuracy 85.71% under attack.\n",
            "\tModel select at epoch 19 with validation accuracy 88.36% and accuracy 85.71% under attack.\n",
            "pgd l2: attack effectiveness 4.615%.\n",
            "Mini batch: 191/400 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.2215 | Train accuracy: 95.31%.\n",
            "pgd l2: attack effectiveness 14.062%.\n",
            "Mini batch: 192/400 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.2824 | Train accuracy: 88.28%.\n",
            "pgd l2: attack effectiveness 4.478%.\n",
            "Mini batch: 193/400 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.2022 | Train accuracy: 93.75%.\n",
            "pgd l2: attack effectiveness 8.824%.\n",
            "Mini batch: 194/400 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.1912 | Train accuracy: 95.31%.\n",
            "pgd l2: attack effectiveness 50.000%.\n",
            "Mini batch: 195/400 | training time in 0 minutes, 37 seconds.\n",
            "Training loss (batch level): 0.4480 | Train accuracy: 80.47%.\n",
            "pgd l2: attack effectiveness 34.545%.\n",
            "Mini batch: 196/400 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.4105 | Train accuracy: 81.25%.\n",
            "pgd l2: attack effectiveness 28.788%.\n",
            "Mini batch: 197/400 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.3493 | Train accuracy: 85.16%.\n",
            "pgd l2: attack effectiveness 14.754%.\n",
            "Mini batch: 198/400 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.2741 | Train accuracy: 91.41%.\n",
            "pgd l2: attack effectiveness 22.059%.\n",
            "Mini batch: 199/400 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.3030 | Train accuracy: 87.50%.\n",
            "pgd l2: attack effectiveness 14.286%.\n",
            "Mini batch: 200/400 | training time in 0 minutes, 38 seconds.\n",
            "Training loss (batch level): 0.1990 | Train accuracy: 93.62%.\n",
            "Training loss (epoch level): 0.2881 | Train accuracy: 89.21\n",
            "pgd l2: attack effectiveness 14.286%.\n",
            "\tVal accuracy 87.86% with accuracy 85.71% under attack.\n",
            "\tModel select at epoch 19 with validation accuracy 88.36% and accuracy 85.71% under attack.\n",
            "pgd l2: attack effectiveness 7.692%.\n",
            "Mini batch: 201/400 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.2327 | Train accuracy: 93.75%.\n",
            "pgd l2: attack effectiveness 15.625%.\n",
            "Mini batch: 202/400 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.3238 | Train accuracy: 86.72%.\n",
            "pgd l2: attack effectiveness 28.358%.\n",
            "Mini batch: 203/400 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.3522 | Train accuracy: 79.69%.\n",
            "pgd l2: attack effectiveness 36.765%.\n",
            "Mini batch: 204/400 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.3682 | Train accuracy: 78.91%.\n",
            "pgd l2: attack effectiveness 45.161%.\n",
            "Mini batch: 205/400 | training time in 0 minutes, 39 seconds.\n",
            "Training loss (batch level): 0.4315 | Train accuracy: 77.34%.\n",
            "pgd l2: attack effectiveness 36.364%.\n",
            "Mini batch: 206/400 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.3494 | Train accuracy: 82.03%.\n",
            "pgd l2: attack effectiveness 19.697%.\n",
            "Mini batch: 207/400 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.2991 | Train accuracy: 89.06%.\n",
            "pgd l2: attack effectiveness 13.115%.\n",
            "Mini batch: 208/400 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.2016 | Train accuracy: 92.97%.\n",
            "pgd l2: attack effectiveness 17.647%.\n",
            "Mini batch: 209/400 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.2503 | Train accuracy: 88.28%.\n",
            "pgd l2: attack effectiveness 14.286%.\n",
            "Mini batch: 210/400 | training time in 0 minutes, 40 seconds.\n",
            "Training loss (batch level): 0.2086 | Train accuracy: 91.49%.\n",
            "Training loss (epoch level): 0.3017 | Train accuracy: 86.02\n",
            "pgd l2: attack effectiveness 9.524%.\n",
            "\tVal accuracy 90.24% with accuracy 90.48% under attack.\n",
            "\tModel select at epoch 21 with validation accuracy 90.24% and accuracy 90.48% under attack.\n",
            "pgd l2: attack effectiveness 6.154%.\n",
            "Mini batch: 211/400 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.1792 | Train accuracy: 94.53%.\n",
            "pgd l2: attack effectiveness 18.750%.\n",
            "Mini batch: 212/400 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.2877 | Train accuracy: 83.59%.\n",
            "pgd l2: attack effectiveness 5.970%.\n",
            "Mini batch: 213/400 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.4021 | Train accuracy: 90.62%.\n",
            "pgd l2: attack effectiveness 19.118%.\n",
            "Mini batch: 214/400 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.2339 | Train accuracy: 89.06%.\n",
            "pgd l2: attack effectiveness 17.742%.\n",
            "Mini batch: 215/400 | training time in 0 minutes, 41 seconds.\n",
            "Training loss (batch level): 0.3170 | Train accuracy: 87.50%.\n",
            "pgd l2: attack effectiveness 43.636%.\n",
            "Mini batch: 216/400 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.5188 | Train accuracy: 76.56%.\n",
            "pgd l2: attack effectiveness 40.909%.\n",
            "Mini batch: 217/400 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.4159 | Train accuracy: 77.34%.\n",
            "pgd l2: attack effectiveness 29.508%.\n",
            "Mini batch: 218/400 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.2540 | Train accuracy: 85.16%.\n",
            "pgd l2: attack effectiveness 38.235%.\n",
            "Mini batch: 219/400 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.3519 | Train accuracy: 78.91%.\n",
            "pgd l2: attack effectiveness 28.571%.\n",
            "Mini batch: 220/400 | training time in 0 minutes, 42 seconds.\n",
            "Training loss (batch level): 0.2340 | Train accuracy: 87.23%.\n",
            "Training loss (epoch level): 0.3194 | Train accuracy: 85.05\n",
            "pgd l2: attack effectiveness 28.571%.\n",
            "\tVal accuracy 81.71% with accuracy 71.43% under attack.\n",
            "\tModel select at epoch 21 with validation accuracy 90.24% and accuracy 90.48% under attack.\n",
            "pgd l2: attack effectiveness 18.462%.\n",
            "Mini batch: 221/400 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.2294 | Train accuracy: 89.06%.\n",
            "pgd l2: attack effectiveness 12.500%.\n",
            "Mini batch: 222/400 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.2583 | Train accuracy: 91.41%.\n",
            "pgd l2: attack effectiveness 5.970%.\n",
            "Mini batch: 223/400 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.2422 | Train accuracy: 92.19%.\n",
            "pgd l2: attack effectiveness 38.235%.\n",
            "Mini batch: 224/400 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.3609 | Train accuracy: 80.47%.\n",
            "pgd l2: attack effectiveness 17.742%.\n",
            "Mini batch: 225/400 | training time in 0 minutes, 43 seconds.\n",
            "Training loss (batch level): 0.3428 | Train accuracy: 87.50%.\n",
            "pgd l2: attack effectiveness 38.182%.\n",
            "Mini batch: 226/400 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.4432 | Train accuracy: 82.03%.\n",
            "pgd l2: attack effectiveness 21.212%.\n",
            "Mini batch: 227/400 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.3536 | Train accuracy: 88.28%.\n",
            "pgd l2: attack effectiveness 13.115%.\n",
            "Mini batch: 228/400 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.2408 | Train accuracy: 93.75%.\n",
            "pgd l2: attack effectiveness 32.353%.\n",
            "Mini batch: 229/400 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.4046 | Train accuracy: 82.03%.\n",
            "pgd l2: attack effectiveness 28.571%.\n",
            "Mini batch: 230/400 | training time in 0 minutes, 44 seconds.\n",
            "Training loss (batch level): 0.2440 | Train accuracy: 87.23%.\n",
            "Training loss (epoch level): 0.3120 | Train accuracy: 87.40\n",
            "pgd l2: attack effectiveness 28.571%.\n",
            "\tVal accuracy 81.21% with accuracy 71.43% under attack.\n",
            "\tModel select at epoch 21 with validation accuracy 90.24% and accuracy 90.48% under attack.\n",
            "pgd l2: attack effectiveness 7.692%.\n",
            "Mini batch: 231/400 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.1901 | Train accuracy: 93.75%.\n",
            "pgd l2: attack effectiveness 7.812%.\n",
            "Mini batch: 232/400 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.2036 | Train accuracy: 96.09%.\n",
            "pgd l2: attack effectiveness 7.463%.\n",
            "Mini batch: 233/400 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.2274 | Train accuracy: 92.97%.\n",
            "pgd l2: attack effectiveness 17.647%.\n",
            "Mini batch: 234/400 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.2201 | Train accuracy: 89.84%.\n",
            "pgd l2: attack effectiveness 30.645%.\n",
            "Mini batch: 235/400 | training time in 0 minutes, 45 seconds.\n",
            "Training loss (batch level): 0.3273 | Train accuracy: 85.16%.\n",
            "pgd l2: attack effectiveness 10.909%.\n",
            "Mini batch: 236/400 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.3309 | Train accuracy: 89.06%.\n",
            "pgd l2: attack effectiveness 15.152%.\n",
            "Mini batch: 237/400 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.2818 | Train accuracy: 89.84%.\n",
            "pgd l2: attack effectiveness 19.672%.\n",
            "Mini batch: 238/400 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.2345 | Train accuracy: 90.62%.\n",
            "pgd l2: attack effectiveness 25.000%.\n",
            "Mini batch: 239/400 | training time in 0 minutes, 46 seconds.\n",
            "Training loss (batch level): 0.3337 | Train accuracy: 86.72%.\n",
            "pgd l2: attack effectiveness 19.048%.\n",
            "Mini batch: 240/400 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.1684 | Train accuracy: 91.49%.\n",
            "Training loss (epoch level): 0.2518 | Train accuracy: 90.56\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "\tVal accuracy 80.33% with accuracy 66.67% under attack.\n",
            "\tModel select at epoch 21 with validation accuracy 90.24% and accuracy 90.48% under attack.\n",
            "pgd l2: attack effectiveness 35.385%.\n",
            "Mini batch: 241/400 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.2679 | Train accuracy: 81.25%.\n",
            "pgd l2: attack effectiveness 21.875%.\n",
            "Mini batch: 242/400 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.2656 | Train accuracy: 89.06%.\n",
            "pgd l2: attack effectiveness 29.851%.\n",
            "Mini batch: 243/400 | training time in 0 minutes, 47 seconds.\n",
            "Training loss (batch level): 0.2782 | Train accuracy: 83.59%.\n",
            "pgd l2: attack effectiveness 10.294%.\n",
            "Mini batch: 244/400 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.2285 | Train accuracy: 93.75%.\n",
            "pgd l2: attack effectiveness 12.903%.\n",
            "Mini batch: 245/400 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.3392 | Train accuracy: 85.94%.\n",
            "pgd l2: attack effectiveness 10.909%.\n",
            "Mini batch: 246/400 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.3474 | Train accuracy: 84.38%.\n",
            "pgd l2: attack effectiveness 10.606%.\n",
            "Mini batch: 247/400 | training time in 0 minutes, 48 seconds.\n",
            "Training loss (batch level): 0.2528 | Train accuracy: 91.41%.\n",
            "pgd l2: attack effectiveness 21.311%.\n",
            "Mini batch: 248/400 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.2262 | Train accuracy: 92.97%.\n",
            "pgd l2: attack effectiveness 32.353%.\n",
            "Mini batch: 249/400 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.3255 | Train accuracy: 85.94%.\n",
            "pgd l2: attack effectiveness 33.333%.\n",
            "Mini batch: 250/400 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.2053 | Train accuracy: 89.36%.\n",
            "Training loss (epoch level): 0.2737 | Train accuracy: 87.76\n",
            "pgd l2: attack effectiveness 23.810%.\n",
            "\tVal accuracy 84.35% with accuracy 76.19% under attack.\n",
            "\tModel select at epoch 21 with validation accuracy 90.24% and accuracy 90.48% under attack.\n",
            "pgd l2: attack effectiveness 6.154%.\n",
            "Mini batch: 251/400 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.2135 | Train accuracy: 93.75%.\n",
            "pgd l2: attack effectiveness 32.812%.\n",
            "Mini batch: 252/400 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.2900 | Train accuracy: 85.94%.\n",
            "pgd l2: attack effectiveness 28.358%.\n",
            "Mini batch: 253/400 | training time in 0 minutes, 49 seconds.\n",
            "Training loss (batch level): 0.3345 | Train accuracy: 80.47%.\n",
            "pgd l2: attack effectiveness 4.412%.\n",
            "Mini batch: 254/400 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.2032 | Train accuracy: 93.75%.\n",
            "pgd l2: attack effectiveness 9.677%.\n",
            "Mini batch: 255/400 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.2988 | Train accuracy: 92.19%.\n",
            "pgd l2: attack effectiveness 10.909%.\n",
            "Mini batch: 256/400 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.4006 | Train accuracy: 84.38%.\n",
            "pgd l2: attack effectiveness 12.121%.\n",
            "Mini batch: 257/400 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.3201 | Train accuracy: 90.62%.\n",
            "pgd l2: attack effectiveness 16.393%.\n",
            "Mini batch: 258/400 | training time in 0 minutes, 50 seconds.\n",
            "Training loss (batch level): 0.2990 | Train accuracy: 88.28%.\n",
            "pgd l2: attack effectiveness 25.000%.\n",
            "Mini batch: 259/400 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.3315 | Train accuracy: 85.94%.\n",
            "pgd l2: attack effectiveness 28.571%.\n",
            "Mini batch: 260/400 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.2771 | Train accuracy: 85.11%.\n",
            "Training loss (epoch level): 0.2968 | Train accuracy: 88.04\n",
            "pgd l2: attack effectiveness 28.571%.\n",
            "\tVal accuracy 81.71% with accuracy 71.43% under attack.\n",
            "\tModel select at epoch 21 with validation accuracy 90.24% and accuracy 90.48% under attack.\n",
            "pgd l2: attack effectiveness 10.769%.\n",
            "Mini batch: 261/400 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.2277 | Train accuracy: 90.62%.\n",
            "pgd l2: attack effectiveness 31.250%.\n",
            "Mini batch: 262/400 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.4369 | Train accuracy: 82.03%.\n",
            "pgd l2: attack effectiveness 20.896%.\n",
            "Mini batch: 263/400 | training time in 0 minutes, 51 seconds.\n",
            "Training loss (batch level): 0.2787 | Train accuracy: 89.06%.\n",
            "pgd l2: attack effectiveness 13.235%.\n",
            "Mini batch: 264/400 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.2176 | Train accuracy: 91.41%.\n",
            "pgd l2: attack effectiveness 20.968%.\n",
            "Mini batch: 265/400 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.3006 | Train accuracy: 83.59%.\n",
            "pgd l2: attack effectiveness 7.273%.\n",
            "Mini batch: 266/400 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.2494 | Train accuracy: 92.19%.\n",
            "pgd l2: attack effectiveness 19.697%.\n",
            "Mini batch: 267/400 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.3211 | Train accuracy: 84.38%.\n",
            "pgd l2: attack effectiveness 14.754%.\n",
            "Mini batch: 268/400 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.2155 | Train accuracy: 92.19%.\n",
            "pgd l2: attack effectiveness 17.647%.\n",
            "Mini batch: 269/400 | training time in 0 minutes, 52 seconds.\n",
            "Training loss (batch level): 0.2983 | Train accuracy: 87.50%.\n",
            "pgd l2: attack effectiveness 9.524%.\n",
            "Mini batch: 270/400 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.1511 | Train accuracy: 95.74%.\n",
            "Training loss (epoch level): 0.2697 | Train accuracy: 88.87\n",
            "pgd l2: attack effectiveness 9.524%.\n",
            "\tVal accuracy 91.49% with accuracy 90.48% under attack.\n",
            "\tModel select at epoch 27 with validation accuracy 91.49% and accuracy 90.48% under attack.\n",
            "pgd l2: attack effectiveness 4.615%.\n",
            "Mini batch: 271/400 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.1750 | Train accuracy: 95.31%.\n",
            "pgd l2: attack effectiveness 9.375%.\n",
            "Mini batch: 272/400 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.2201 | Train accuracy: 92.19%.\n",
            "pgd l2: attack effectiveness 20.896%.\n",
            "Mini batch: 273/400 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.2686 | Train accuracy: 85.94%.\n",
            "pgd l2: attack effectiveness 26.471%.\n",
            "Mini batch: 274/400 | training time in 0 minutes, 53 seconds.\n",
            "Training loss (batch level): 0.3326 | Train accuracy: 84.38%.\n",
            "pgd l2: attack effectiveness 30.645%.\n",
            "Mini batch: 275/400 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.3417 | Train accuracy: 78.91%.\n",
            "pgd l2: attack effectiveness 27.273%.\n",
            "Mini batch: 276/400 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.3528 | Train accuracy: 85.94%.\n",
            "pgd l2: attack effectiveness 7.576%.\n",
            "Mini batch: 277/400 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.2336 | Train accuracy: 92.97%.\n",
            "pgd l2: attack effectiveness 6.557%.\n",
            "Mini batch: 278/400 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.1785 | Train accuracy: 94.53%.\n",
            "pgd l2: attack effectiveness 20.588%.\n",
            "Mini batch: 279/400 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.2483 | Train accuracy: 90.62%.\n",
            "pgd l2: attack effectiveness 19.048%.\n",
            "Mini batch: 280/400 | training time in 0 minutes, 54 seconds.\n",
            "Training loss (batch level): 0.1959 | Train accuracy: 95.74%.\n",
            "Training loss (epoch level): 0.2547 | Train accuracy: 89.65\n",
            "pgd l2: attack effectiveness 23.810%.\n",
            "\tVal accuracy 84.47% with accuracy 76.19% under attack.\n",
            "\tModel select at epoch 27 with validation accuracy 91.49% and accuracy 90.48% under attack.\n",
            "pgd l2: attack effectiveness 29.231%.\n",
            "Mini batch: 281/400 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.3339 | Train accuracy: 84.38%.\n",
            "pgd l2: attack effectiveness 15.625%.\n",
            "Mini batch: 282/400 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.2379 | Train accuracy: 91.41%.\n",
            "pgd l2: attack effectiveness 25.373%.\n",
            "Mini batch: 283/400 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.2625 | Train accuracy: 85.94%.\n",
            "pgd l2: attack effectiveness 23.529%.\n",
            "Mini batch: 284/400 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.2523 | Train accuracy: 84.38%.\n",
            "pgd l2: attack effectiveness 12.903%.\n",
            "Mini batch: 285/400 | training time in 0 minutes, 55 seconds.\n",
            "Training loss (batch level): 0.3162 | Train accuracy: 85.16%.\n",
            "pgd l2: attack effectiveness 9.091%.\n",
            "Mini batch: 286/400 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.3020 | Train accuracy: 89.84%.\n",
            "pgd l2: attack effectiveness 10.606%.\n",
            "Mini batch: 287/400 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.2964 | Train accuracy: 90.62%.\n",
            "pgd l2: attack effectiveness 9.836%.\n",
            "Mini batch: 288/400 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.2086 | Train accuracy: 92.97%.\n",
            "pgd l2: attack effectiveness 26.471%.\n",
            "Mini batch: 289/400 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.2979 | Train accuracy: 87.50%.\n",
            "pgd l2: attack effectiveness 28.571%.\n",
            "Mini batch: 290/400 | training time in 0 minutes, 56 seconds.\n",
            "Training loss (batch level): 0.1742 | Train accuracy: 89.36%.\n",
            "Training loss (epoch level): 0.2682 | Train accuracy: 88.15\n",
            "pgd l2: attack effectiveness 4.762%.\n",
            "\tVal accuracy 93.37% with accuracy 95.24% under attack.\n",
            "\tModel select at epoch 29 with validation accuracy 93.37% and accuracy 95.24% under attack.\n",
            "pgd l2: attack effectiveness 13.846%.\n",
            "Mini batch: 291/400 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.1956 | Train accuracy: 92.19%.\n",
            "pgd l2: attack effectiveness 17.188%.\n",
            "Mini batch: 292/400 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.2358 | Train accuracy: 88.28%.\n",
            "pgd l2: attack effectiveness 19.403%.\n",
            "Mini batch: 293/400 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.2592 | Train accuracy: 85.94%.\n",
            "pgd l2: attack effectiveness 30.882%.\n",
            "Mini batch: 294/400 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.3466 | Train accuracy: 83.59%.\n",
            "pgd l2: attack effectiveness 11.290%.\n",
            "Mini batch: 295/400 | training time in 0 minutes, 57 seconds.\n",
            "Training loss (batch level): 0.3233 | Train accuracy: 89.84%.\n",
            "pgd l2: attack effectiveness 10.909%.\n",
            "Mini batch: 296/400 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.2600 | Train accuracy: 92.19%.\n",
            "pgd l2: attack effectiveness 10.606%.\n",
            "Mini batch: 297/400 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.2382 | Train accuracy: 92.19%.\n",
            "pgd l2: attack effectiveness 13.115%.\n",
            "Mini batch: 298/400 | training time in 0 minutes, 58 seconds.\n",
            "Training loss (batch level): 0.2024 | Train accuracy: 92.19%.\n",
            "pgd l2: attack effectiveness 22.059%.\n",
            "Mini batch: 299/400 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.2691 | Train accuracy: 89.84%.\n",
            "pgd l2: attack effectiveness 4.762%.\n",
            "Mini batch: 300/400 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.1751 | Train accuracy: 95.74%.\n",
            "Training loss (epoch level): 0.2505 | Train accuracy: 90.20\n",
            "pgd l2: attack effectiveness 28.571%.\n",
            "\tVal accuracy 81.46% with accuracy 71.43% under attack.\n",
            "\tModel select at epoch 29 with validation accuracy 93.37% and accuracy 95.24% under attack.\n",
            "pgd l2: attack effectiveness 6.154%.\n",
            "Mini batch: 301/400 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.1973 | Train accuracy: 96.09%.\n",
            "pgd l2: attack effectiveness 6.250%.\n",
            "Mini batch: 302/400 | training time in 0 minutes, 59 seconds.\n",
            "Training loss (batch level): 0.1642 | Train accuracy: 95.31%.\n",
            "pgd l2: attack effectiveness 5.970%.\n",
            "Mini batch: 303/400 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.1499 | Train accuracy: 95.31%.\n",
            "pgd l2: attack effectiveness 13.235%.\n",
            "Mini batch: 304/400 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.1697 | Train accuracy: 92.19%.\n",
            "pgd l2: attack effectiveness 12.903%.\n",
            "Mini batch: 305/400 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.2822 | Train accuracy: 90.62%.\n",
            "pgd l2: attack effectiveness 16.364%.\n",
            "Mini batch: 306/400 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.3378 | Train accuracy: 89.06%.\n",
            "pgd l2: attack effectiveness 12.121%.\n",
            "Mini batch: 307/400 | training time in 1 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.2363 | Train accuracy: 91.41%.\n",
            "pgd l2: attack effectiveness 9.836%.\n",
            "Mini batch: 308/400 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.1930 | Train accuracy: 95.31%.\n",
            "pgd l2: attack effectiveness 13.235%.\n",
            "Mini batch: 309/400 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.2416 | Train accuracy: 92.19%.\n",
            "pgd l2: attack effectiveness 4.762%.\n",
            "Mini batch: 310/400 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.1897 | Train accuracy: 91.49%.\n",
            "Training loss (epoch level): 0.2162 | Train accuracy: 92.90\n",
            "pgd l2: attack effectiveness 9.524%.\n",
            "\tVal accuracy 91.11% with accuracy 90.48% under attack.\n",
            "\tModel select at epoch 29 with validation accuracy 93.37% and accuracy 95.24% under attack.\n",
            "pgd l2: attack effectiveness 6.154%.\n",
            "Mini batch: 311/400 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.1452 | Train accuracy: 96.09%.\n",
            "pgd l2: attack effectiveness 9.375%.\n",
            "Mini batch: 312/400 | training time in 1 minutes, 1 seconds.\n",
            "Training loss (batch level): 0.1827 | Train accuracy: 95.31%.\n",
            "pgd l2: attack effectiveness 22.388%.\n",
            "Mini batch: 313/400 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.2753 | Train accuracy: 88.28%.\n",
            "pgd l2: attack effectiveness 11.765%.\n",
            "Mini batch: 314/400 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.1944 | Train accuracy: 94.53%.\n",
            "pgd l2: attack effectiveness 12.903%.\n",
            "Mini batch: 315/400 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.2584 | Train accuracy: 92.97%.\n",
            "pgd l2: attack effectiveness 9.091%.\n",
            "Mini batch: 316/400 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.2398 | Train accuracy: 93.75%.\n",
            "pgd l2: attack effectiveness 9.091%.\n",
            "Mini batch: 317/400 | training time in 1 minutes, 2 seconds.\n",
            "Training loss (batch level): 0.2375 | Train accuracy: 94.53%.\n",
            "pgd l2: attack effectiveness 9.836%.\n",
            "Mini batch: 318/400 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.1881 | Train accuracy: 94.53%.\n",
            "pgd l2: attack effectiveness 11.765%.\n",
            "Mini batch: 319/400 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.2369 | Train accuracy: 94.53%.\n",
            "pgd l2: attack effectiveness 4.762%.\n",
            "Mini batch: 320/400 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.1472 | Train accuracy: 93.62%.\n",
            "Training loss (epoch level): 0.2106 | Train accuracy: 93.81\n",
            "pgd l2: attack effectiveness 4.762%.\n",
            "\tVal accuracy 93.12% with accuracy 95.24% under attack.\n",
            "\tModel select at epoch 29 with validation accuracy 93.37% and accuracy 95.24% under attack.\n",
            "pgd l2: attack effectiveness 4.615%.\n",
            "Mini batch: 321/400 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.1517 | Train accuracy: 96.88%.\n",
            "pgd l2: attack effectiveness 7.812%.\n",
            "Mini batch: 322/400 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.1742 | Train accuracy: 93.75%.\n",
            "pgd l2: attack effectiveness 4.478%.\n",
            "Mini batch: 323/400 | training time in 1 minutes, 3 seconds.\n",
            "Training loss (batch level): 0.1272 | Train accuracy: 96.09%.\n",
            "pgd l2: attack effectiveness 2.941%.\n",
            "Mini batch: 324/400 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.1187 | Train accuracy: 96.88%.\n",
            "pgd l2: attack effectiveness 30.645%.\n",
            "Mini batch: 325/400 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.3260 | Train accuracy: 84.38%.\n",
            "pgd l2: attack effectiveness 10.909%.\n",
            "Mini batch: 326/400 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.2086 | Train accuracy: 93.75%.\n",
            "pgd l2: attack effectiveness 7.576%.\n",
            "Mini batch: 327/400 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.1394 | Train accuracy: 94.53%.\n",
            "pgd l2: attack effectiveness 19.672%.\n",
            "Mini batch: 328/400 | training time in 1 minutes, 4 seconds.\n",
            "Training loss (batch level): 0.2076 | Train accuracy: 90.62%.\n",
            "pgd l2: attack effectiveness 16.176%.\n",
            "Mini batch: 329/400 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.2295 | Train accuracy: 91.41%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "Mini batch: 330/400 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.1091 | Train accuracy: 95.74%.\n",
            "Training loss (epoch level): 0.1792 | Train accuracy: 93.40\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "\tVal accuracy 95.88% with accuracy 100.0% under attack.\n",
            "\tModel select at epoch 33 with validation accuracy 95.88% and accuracy 100.0% under attack.\n",
            "pgd l2: attack effectiveness 3.077%.\n",
            "Mini batch: 331/400 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.1089 | Train accuracy: 98.44%.\n",
            "pgd l2: attack effectiveness 3.125%.\n",
            "Mini batch: 332/400 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.1140 | Train accuracy: 96.88%.\n",
            "pgd l2: attack effectiveness 4.478%.\n",
            "Mini batch: 333/400 | training time in 1 minutes, 5 seconds.\n",
            "Training loss (batch level): 0.1150 | Train accuracy: 96.09%.\n",
            "pgd l2: attack effectiveness 7.353%.\n",
            "Mini batch: 334/400 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.1276 | Train accuracy: 96.09%.\n",
            "pgd l2: attack effectiveness 8.065%.\n",
            "Mini batch: 335/400 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.1862 | Train accuracy: 96.09%.\n",
            "pgd l2: attack effectiveness 5.455%.\n",
            "Mini batch: 336/400 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.1262 | Train accuracy: 97.66%.\n",
            "pgd l2: attack effectiveness 10.606%.\n",
            "Mini batch: 337/400 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.2205 | Train accuracy: 94.53%.\n",
            "pgd l2: attack effectiveness 9.836%.\n",
            "Mini batch: 338/400 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.1981 | Train accuracy: 94.53%.\n",
            "pgd l2: attack effectiveness 17.647%.\n",
            "Mini batch: 339/400 | training time in 1 minutes, 6 seconds.\n",
            "Training loss (batch level): 0.2946 | Train accuracy: 90.62%.\n",
            "pgd l2: attack effectiveness 9.524%.\n",
            "Mini batch: 340/400 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.1342 | Train accuracy: 95.74%.\n",
            "Training loss (epoch level): 0.1625 | Train accuracy: 95.67\n",
            "pgd l2: attack effectiveness 9.524%.\n",
            "\tVal accuracy 91.86% with accuracy 90.48% under attack.\n",
            "\tModel select at epoch 33 with validation accuracy 95.88% and accuracy 100.0% under attack.\n",
            "pgd l2: attack effectiveness 6.154%.\n",
            "Mini batch: 341/400 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.1257 | Train accuracy: 96.88%.\n",
            "pgd l2: attack effectiveness 7.812%.\n",
            "Mini batch: 342/400 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.1754 | Train accuracy: 95.31%.\n",
            "pgd l2: attack effectiveness 2.985%.\n",
            "Mini batch: 343/400 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.1075 | Train accuracy: 97.66%.\n",
            "pgd l2: attack effectiveness 2.941%.\n",
            "Mini batch: 344/400 | training time in 1 minutes, 7 seconds.\n",
            "Training loss (batch level): 0.0977 | Train accuracy: 97.66%.\n",
            "pgd l2: attack effectiveness 6.452%.\n",
            "Mini batch: 345/400 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.1988 | Train accuracy: 94.53%.\n",
            "pgd l2: attack effectiveness 12.727%.\n",
            "Mini batch: 346/400 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.2254 | Train accuracy: 92.97%.\n",
            "pgd l2: attack effectiveness 9.091%.\n",
            "Mini batch: 347/400 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.1775 | Train accuracy: 95.31%.\n",
            "pgd l2: attack effectiveness 9.836%.\n",
            "Mini batch: 348/400 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.1750 | Train accuracy: 94.53%.\n",
            "pgd l2: attack effectiveness 16.176%.\n",
            "Mini batch: 349/400 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.3248 | Train accuracy: 91.41%.\n",
            "pgd l2: attack effectiveness 4.762%.\n",
            "Mini batch: 350/400 | training time in 1 minutes, 8 seconds.\n",
            "Training loss (batch level): 0.0891 | Train accuracy: 95.74%.\n",
            "Training loss (epoch level): 0.1697 | Train accuracy: 95.20\n",
            "pgd l2: attack effectiveness 14.286%.\n",
            "\tVal accuracy 89.73% with accuracy 85.71% under attack.\n",
            "\tModel select at epoch 33 with validation accuracy 95.88% and accuracy 100.0% under attack.\n",
            "pgd l2: attack effectiveness 15.385%.\n",
            "Mini batch: 351/400 | training time in 1 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.1384 | Train accuracy: 94.53%.\n",
            "pgd l2: attack effectiveness 10.938%.\n",
            "Mini batch: 352/400 | training time in 1 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.1872 | Train accuracy: 94.53%.\n",
            "pgd l2: attack effectiveness 34.328%.\n",
            "Mini batch: 353/400 | training time in 1 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.3200 | Train accuracy: 85.16%.\n",
            "pgd l2: attack effectiveness 8.824%.\n",
            "Mini batch: 354/400 | training time in 1 minutes, 9 seconds.\n",
            "Training loss (batch level): 0.1302 | Train accuracy: 95.31%.\n",
            "pgd l2: attack effectiveness 32.258%.\n",
            "Mini batch: 355/400 | training time in 1 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.3659 | Train accuracy: 80.47%.\n",
            "pgd l2: attack effectiveness 7.273%.\n",
            "Mini batch: 356/400 | training time in 1 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.2212 | Train accuracy: 94.53%.\n",
            "pgd l2: attack effectiveness 10.606%.\n",
            "Mini batch: 357/400 | training time in 1 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.2209 | Train accuracy: 94.53%.\n",
            "pgd l2: attack effectiveness 4.918%.\n",
            "Mini batch: 358/400 | training time in 1 minutes, 10 seconds.\n",
            "Training loss (batch level): 0.1361 | Train accuracy: 97.66%.\n",
            "pgd l2: attack effectiveness 10.294%.\n",
            "Mini batch: 359/400 | training time in 1 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.2306 | Train accuracy: 92.97%.\n",
            "pgd l2: attack effectiveness 9.524%.\n",
            "Mini batch: 360/400 | training time in 1 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.1649 | Train accuracy: 93.62%.\n",
            "Training loss (epoch level): 0.2115 | Train accuracy: 92.33\n",
            "pgd l2: attack effectiveness 9.524%.\n",
            "\tVal accuracy 90.99% with accuracy 90.48% under attack.\n",
            "\tModel select at epoch 33 with validation accuracy 95.88% and accuracy 100.0% under attack.\n",
            "pgd l2: attack effectiveness 15.385%.\n",
            "Mini batch: 361/400 | training time in 1 minutes, 11 seconds.\n",
            "Training loss (batch level): 0.1587 | Train accuracy: 91.41%.\n",
            "pgd l2: attack effectiveness 6.250%.\n",
            "Mini batch: 362/400 | training time in 1 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.1790 | Train accuracy: 95.31%.\n",
            "pgd l2: attack effectiveness 2.985%.\n",
            "Mini batch: 363/400 | training time in 1 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.0906 | Train accuracy: 97.66%.\n",
            "pgd l2: attack effectiveness 7.353%.\n",
            "Mini batch: 364/400 | training time in 1 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.1153 | Train accuracy: 96.09%.\n",
            "pgd l2: attack effectiveness 9.677%.\n",
            "Mini batch: 365/400 | training time in 1 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.1891 | Train accuracy: 93.75%.\n",
            "pgd l2: attack effectiveness 7.273%.\n",
            "Mini batch: 366/400 | training time in 1 minutes, 12 seconds.\n",
            "Training loss (batch level): 0.1578 | Train accuracy: 95.31%.\n",
            "pgd l2: attack effectiveness 12.121%.\n",
            "Mini batch: 367/400 | training time in 1 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.2334 | Train accuracy: 93.75%.\n",
            "pgd l2: attack effectiveness 13.115%.\n",
            "Mini batch: 368/400 | training time in 1 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.1665 | Train accuracy: 92.97%.\n",
            "pgd l2: attack effectiveness 13.235%.\n",
            "Mini batch: 369/400 | training time in 1 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.2829 | Train accuracy: 91.41%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "Mini batch: 370/400 | training time in 1 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.1084 | Train accuracy: 97.87%.\n",
            "Training loss (epoch level): 0.1682 | Train accuracy: 94.55\n",
            "pgd l2: attack effectiveness 4.762%.\n",
            "\tVal accuracy 93.37% with accuracy 95.24% under attack.\n",
            "\tModel select at epoch 33 with validation accuracy 95.88% and accuracy 100.0% under attack.\n",
            "pgd l2: attack effectiveness 4.615%.\n",
            "Mini batch: 371/400 | training time in 1 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.1039 | Train accuracy: 97.66%.\n",
            "pgd l2: attack effectiveness 4.688%.\n",
            "Mini batch: 372/400 | training time in 1 minutes, 13 seconds.\n",
            "Training loss (batch level): 0.1756 | Train accuracy: 93.75%.\n",
            "pgd l2: attack effectiveness 4.478%.\n",
            "Mini batch: 373/400 | training time in 1 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0996 | Train accuracy: 97.66%.\n",
            "pgd l2: attack effectiveness 4.412%.\n",
            "Mini batch: 374/400 | training time in 1 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.0886 | Train accuracy: 97.66%.\n",
            "pgd l2: attack effectiveness 11.290%.\n",
            "Mini batch: 375/400 | training time in 1 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.2341 | Train accuracy: 94.53%.\n",
            "pgd l2: attack effectiveness 29.091%.\n",
            "Mini batch: 376/400 | training time in 1 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.4597 | Train accuracy: 87.50%.\n",
            "pgd l2: attack effectiveness 9.091%.\n",
            "Mini batch: 377/400 | training time in 1 minutes, 14 seconds.\n",
            "Training loss (batch level): 0.1906 | Train accuracy: 94.53%.\n",
            "pgd l2: attack effectiveness 6.557%.\n",
            "Mini batch: 378/400 | training time in 1 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.1304 | Train accuracy: 96.88%.\n",
            "pgd l2: attack effectiveness 22.059%.\n",
            "Mini batch: 379/400 | training time in 1 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.2567 | Train accuracy: 88.28%.\n",
            "pgd l2: attack effectiveness 0.000%.\n",
            "Mini batch: 380/400 | training time in 1 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.0711 | Train accuracy: 100.00%.\n",
            "Training loss (epoch level): 0.1810 | Train accuracy: 94.84\n",
            "pgd l2: attack effectiveness 4.762%.\n",
            "\tVal accuracy 93.24% with accuracy 95.24% under attack.\n",
            "\tModel select at epoch 33 with validation accuracy 95.88% and accuracy 100.0% under attack.\n",
            "pgd l2: attack effectiveness 13.846%.\n",
            "Mini batch: 381/400 | training time in 1 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.1657 | Train accuracy: 92.19%.\n",
            "pgd l2: attack effectiveness 1.562%.\n",
            "Mini batch: 382/400 | training time in 1 minutes, 15 seconds.\n",
            "Training loss (batch level): 0.1190 | Train accuracy: 97.66%.\n",
            "pgd l2: attack effectiveness 2.985%.\n",
            "Mini batch: 383/400 | training time in 1 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.1176 | Train accuracy: 98.44%.\n",
            "pgd l2: attack effectiveness 1.471%.\n",
            "Mini batch: 384/400 | training time in 1 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.1083 | Train accuracy: 99.22%.\n",
            "pgd l2: attack effectiveness 19.355%.\n",
            "Mini batch: 385/400 | training time in 1 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.2556 | Train accuracy: 89.84%.\n",
            "pgd l2: attack effectiveness 7.273%.\n",
            "Mini batch: 386/400 | training time in 1 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.1846 | Train accuracy: 94.53%.\n",
            "pgd l2: attack effectiveness 6.061%.\n",
            "Mini batch: 387/400 | training time in 1 minutes, 16 seconds.\n",
            "Training loss (batch level): 0.1792 | Train accuracy: 96.09%.\n",
            "pgd l2: attack effectiveness 4.918%.\n",
            "Mini batch: 388/400 | training time in 1 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.1247 | Train accuracy: 97.66%.\n",
            "pgd l2: attack effectiveness 10.294%.\n",
            "Mini batch: 389/400 | training time in 1 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.2497 | Train accuracy: 94.53%.\n",
            "pgd l2: attack effectiveness 4.762%.\n",
            "Mini batch: 390/400 | training time in 1 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.0758 | Train accuracy: 97.87%.\n",
            "Training loss (epoch level): 0.1580 | Train accuracy: 95.80\n",
            "pgd l2: attack effectiveness 19.048%.\n",
            "\tVal accuracy 87.48% with accuracy 80.95% under attack.\n",
            "\tModel select at epoch 33 with validation accuracy 95.88% and accuracy 100.0% under attack.\n",
            "pgd l2: attack effectiveness 30.769%.\n",
            "Mini batch: 391/400 | training time in 1 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.2912 | Train accuracy: 84.38%.\n",
            "pgd l2: attack effectiveness 7.812%.\n",
            "Mini batch: 392/400 | training time in 1 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.2421 | Train accuracy: 94.53%.\n",
            "pgd l2: attack effectiveness 4.478%.\n",
            "Mini batch: 393/400 | training time in 1 minutes, 17 seconds.\n",
            "Training loss (batch level): 0.1364 | Train accuracy: 97.66%.\n",
            "pgd l2: attack effectiveness 1.471%.\n",
            "Mini batch: 394/400 | training time in 1 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.1197 | Train accuracy: 99.22%.\n",
            "pgd l2: attack effectiveness 6.452%.\n",
            "Mini batch: 395/400 | training time in 1 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.1823 | Train accuracy: 95.31%.\n",
            "pgd l2: attack effectiveness 7.273%.\n",
            "Mini batch: 396/400 | training time in 1 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.2609 | Train accuracy: 93.75%.\n",
            "pgd l2: attack effectiveness 6.061%.\n",
            "Mini batch: 397/400 | training time in 1 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.2147 | Train accuracy: 94.53%.\n",
            "pgd l2: attack effectiveness 4.918%.\n",
            "Mini batch: 398/400 | training time in 1 minutes, 18 seconds.\n",
            "Training loss (batch level): 0.1562 | Train accuracy: 96.09%.\n",
            "pgd l2: attack effectiveness 14.706%.\n",
            "Mini batch: 399/400 | training time in 1 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.2995 | Train accuracy: 92.97%.\n",
            "pgd l2: attack effectiveness 14.286%.\n",
            "Mini batch: 400/400 | training time in 1 minutes, 19 seconds.\n",
            "Training loss (batch level): 0.1800 | Train accuracy: 93.62%.\n",
            "Training loss (epoch level): 0.2083 | Train accuracy: 94.21\n",
            "pgd l2: attack effectiveness 9.524%.\n",
            "\tVal accuracy 91.61% with accuracy 90.48% under attack.\n",
            "\tModel select at epoch 33 with validation accuracy 95.88% and accuracy 100.0% under attack.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z_cupu1j6Wp7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}