{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1H1KnRs-6oLBOnUpT_3BQ1AoHPcf_q43r",
      "authorship_tag": "ABX9TyPMKxApbYVcb+mIH8A7QKFS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/a_malware/blob/main/MalwareDetectionDNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os.path as path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIN9uSWILNkN",
        "outputId": "6e2b8fcf-8ab9-42ab-ccdb-9e931862ef1f"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mostafa-ja/malware_detection.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvQzurUxzh7x",
        "outputId": "71327803-87a4-4672-860d-b793151ba85d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'malware_detection'...\n",
            "remote: Enumerating objects: 14653, done.\u001b[K\n",
            "remote: Counting objects: 100% (805/805), done.\u001b[K\n",
            "remote: Compressing objects: 100% (129/129), done.\u001b[K\n",
            "remote: Total 14653 (delta 716), reused 752 (delta 668), pack-reused 13848\u001b[K\n",
            "Receiving objects: 100% (14653/14653), 146.47 MiB | 32.14 MiB/s, done.\n",
            "Resolving deltas: 100% (11646/11646), done.\n",
            "Updating files: 100% (836/836), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "E9woBsXkq7HP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "\n",
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, samples):\n",
        "        self.samples = [(torch.tensor(data, dtype=torch.float32), label) for data, label in samples]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.samples[index]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torch.load('/content/malware_detection/datasets/train_dataset.pt')\n",
        "train_Loader = data.DataLoader(train_dataset, batch_size=128, shuffle=False)\n",
        "validation_dataset = torch.load('/content/malware_detection/datasets/validation_dataset.pt')\n",
        "validation_Loader = data.DataLoader(validation_dataset, batch_size=10000, shuffle=False)\n",
        "test_dataset = torch.load('/content/malware_detection/datasets/test_dataset.pt')\n",
        "test_Loader = data.DataLoader(test_dataset, batch_size=10000, shuffle=False)"
      ],
      "metadata": {
        "id": "B39GkhWXrGy3"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('train_dataset size : ', len(train_dataset))\n",
        "print('validation_dataset size : ', len(validation_dataset))\n",
        "print('test_dataset size : ', len(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqMvr0XR0WmF",
        "outputId": "f1ef9219-d828-4493-f390-90015a786290"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_dataset size :  420\n",
            "validation_dataset size :  140\n",
            "test_dataset size :  140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample,label = next(iter(train_dataset))\n",
        "print(sample.shape)\n",
        "print(label)\n",
        "print(sample)\n",
        "print(sum(sample))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1PexG7s9htv",
        "outputId": "203a5e65-7b12-465d-90d1-ae5d99c132e0"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1368])\n",
            "1\n",
            "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
            "tensor(63.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample,label = next(iter(validation_Loader))\n",
        "print(sample.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMOe0msmYcJl",
        "outputId": "91f79fa2-7903-40b3-87ae-14241e288d69"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([140, 1368])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "class MalwareDetectionDNN(nn.Module):\n",
        "    def __init__(self, input_size, n_classes, device='cpu', name='DNN', dense_hidden_units=[200, 200], dropout=0.6, smooth=False):\n",
        "        \"\"\"\n",
        "        Construct malware detector\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        @param input_size: Integer, the dimentionality number of input vector\n",
        "        @param n_classes: Integer, the number of classes, n=2\n",
        "        @param device: String, 'cpu' or 'cuda'\n",
        "        @param name: String, model name\n",
        "        \"\"\"\n",
        "        super(MalwareDetectionDNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.n_classes = n_classes\n",
        "        self.name = name\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.smooth = smooth\n",
        "        self.dense_hidden_units = dense_hidden_units\n",
        "\n",
        "        self.dense_layers = []\n",
        "        if len(self.dense_hidden_units) >= 1:\n",
        "            self.dense_layers.append(nn.Linear(self.input_size, self.dense_hidden_units[0]))\n",
        "        else:\n",
        "            raise ValueError(\"Expect at least one hidden layer.\")\n",
        "        for i in range(len(self.dense_hidden_units[0:-1])):\n",
        "            self.dense_layers.append(nn.Linear(self.dense_hidden_units[i],  # start from idx=1\n",
        "                                               self.dense_hidden_units[i + 1]))\n",
        "        self.dense_layers.append(nn.Linear(self.dense_hidden_units[-1], self.n_classes))\n",
        "\n",
        "        # registration\n",
        "        for idx_i, dense_layer in enumerate(self.dense_layers):\n",
        "            self.add_module('nn_model_layer_{}'.format(idx_i), dense_layer)\n",
        "\n",
        "        if self.smooth:\n",
        "            self.activation_func = F.selu  # partial(F.elu, alpha=self.alpha_)\n",
        "        else:\n",
        "            self.activation_func = F.relu\n",
        "\n",
        "        self.model_save_path = path.join('/content/malware_detection/save/drebin/md_dnn'+ '_' + self.name,'model.pth')\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Go through the neural network\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        @param x: 2D tensor, feature representation\n",
        "        \"\"\"\n",
        "        for dense_layer in self.dense_layers[:-1]:\n",
        "            x = self.activation_func(dense_layer(x))\n",
        "\n",
        "        latent_representation = F.dropout(x, self.dropout, training=self.training)\n",
        "        logits = self.dense_layers[-1](latent_representation)\n",
        "        return logits\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v0j39fpP-vlt"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MalwareDetectionDNN(1368,2)\n",
        "model = model.to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVPO6jQi_DPE",
        "outputId": "637cf179-64a5-41b3-b0a9-60f68ffe46c2"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MalwareDetectionDNN(\n",
              "  (nn_model_layer_0): Linear(in_features=1368, out_features=200, bias=True)\n",
              "  (nn_model_layer_1): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (nn_model_layer_2): Linear(in_features=200, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(model, input_size=(1368,))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_-ZtrKX-6rW",
        "outputId": "ebd65bda-0628-4133-aa46-639188bb29d9"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 200]         273,800\n",
            "            Linear-2                  [-1, 200]          40,200\n",
            "            Linear-3                    [-1, 2]             402\n",
            "================================================================\n",
            "Total params: 314,402\n",
            "Trainable params: 314,402\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 1.20\n",
            "Estimated Total Size (MB): 1.21\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr =0.005\n",
        "weight_decay = 0.\n",
        "epochs = 50\n",
        "dropout=0.6\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "best_avg_acc = 0.\n",
        "best_epoch = 0\n",
        "total_time = 0.\n",
        "nbatches = len(train_Loader)\n",
        "for i in range(epochs):\n",
        "    model.train()\n",
        "    losses, accuracies = [], []\n",
        "    for idx_batch, (x_train, y_train) in enumerate(train_Loader):\n",
        "        x_train = x_train.to(device)\n",
        "        y_train = y_train.long().to(device)\n",
        "        start_time = time.time()\n",
        "        optimizer.zero_grad()\n",
        "        logits = model.forward(x_train)\n",
        "        loss_train = loss_fn(logits, y_train)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        total_time = total_time + time.time() - start_time\n",
        "        acc_train = (logits.argmax(1) == y_train).sum().item()\n",
        "        acc_train /= x_train.size()[0]\n",
        "        mins, secs = int(total_time / 60), int(total_time % 60)\n",
        "        losses.append(loss_train.item())\n",
        "        accuracies.append(acc_train)\n",
        "\n",
        "        if True:\n",
        "            print(f'Mini batch: {i * nbatches + idx_batch + 1}/{epochs * nbatches} | training time in {mins:.0f} minutes, {secs} seconds.')\n",
        "            print(f'Training loss (batch level): {losses[-1]:.4f} | Train accuracy: {acc_train * 100:.2f}')\n",
        "\n",
        "    model.eval()\n",
        "    avg_acc_val = []\n",
        "    with torch.no_grad():\n",
        "        for x_val, y_val in validation_Loader:\n",
        "            x_val = x_val.to(device)\n",
        "            y_val = y_val.long().to(device)\n",
        "            logits = model.forward(x_val)\n",
        "            acc_val = (logits.argmax(1) == y_val).sum().item()\n",
        "            acc_val /= x_val.size()[0]\n",
        "            avg_acc_val.append(acc_val)\n",
        "        avg_acc_val = np.mean(avg_acc_val)\n",
        "\n",
        "    if avg_acc_val >= best_avg_acc:\n",
        "        best_avg_acc = avg_acc_val\n",
        "        best_epoch = i\n",
        "        torch.save(model.state_dict(), 'model.pth')\n",
        "\n",
        "    if True:\n",
        "        print(f'Training loss (epoch level): {np.mean(losses):.4f} | Train accuracy: {np.mean(accuracies) * 100:.2f}')\n",
        "        print(f'Validation accuracy: {avg_acc_val * 100:.2f} | The best validation accuracy: {best_avg_acc * 100:.2f} at epoch: {best_epoch}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaHrKhisKSMJ",
        "outputId": "920db536-0d74-42e8-c822-85d2719340de"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mini batch: 1/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.6915 | Train accuracy: 56.25\n",
            "Mini batch: 2/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.6138 | Train accuracy: 70.31\n",
            "Mini batch: 3/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.4502 | Train accuracy: 91.41\n",
            "Mini batch: 4/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.3038 | Train accuracy: 91.67\n",
            "Training loss (epoch level): 0.5148 | Train accuracy: 77.41\n",
            "Validation accuracy: 91.43 | The best validation accuracy: 91.43 at epoch: 0\n",
            "Mini batch: 5/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.3305 | Train accuracy: 89.84\n",
            "Mini batch: 6/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.3246 | Train accuracy: 83.59\n",
            "Mini batch: 7/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.1608 | Train accuracy: 91.41\n",
            "Mini batch: 8/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0416 | Train accuracy: 97.22\n",
            "Training loss (epoch level): 0.2144 | Train accuracy: 90.52\n",
            "Validation accuracy: 92.14 | The best validation accuracy: 92.14 at epoch: 1\n",
            "Mini batch: 9/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.2691 | Train accuracy: 92.19\n",
            "Mini batch: 10/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.2720 | Train accuracy: 91.41\n",
            "Mini batch: 11/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0760 | Train accuracy: 96.09\n",
            "Mini batch: 12/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0635 | Train accuracy: 97.22\n",
            "Training loss (epoch level): 0.1701 | Train accuracy: 94.23\n",
            "Validation accuracy: 89.29 | The best validation accuracy: 92.14 at epoch: 1\n",
            "Mini batch: 13/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.1529 | Train accuracy: 92.19\n",
            "Mini batch: 14/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.1218 | Train accuracy: 92.97\n",
            "Mini batch: 15/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0532 | Train accuracy: 97.66\n",
            "Mini batch: 16/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0102 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0845 | Train accuracy: 95.70\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 94.29 at epoch: 3\n",
            "Mini batch: 17/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.1521 | Train accuracy: 95.31\n",
            "Mini batch: 18/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.1060 | Train accuracy: 96.88\n",
            "Mini batch: 19/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0468 | Train accuracy: 97.66\n",
            "Mini batch: 20/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0067 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0779 | Train accuracy: 97.46\n",
            "Validation accuracy: 92.14 | The best validation accuracy: 94.29 at epoch: 3\n",
            "Mini batch: 21/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0381 | Train accuracy: 99.22\n",
            "Mini batch: 22/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0988 | Train accuracy: 95.31\n",
            "Mini batch: 23/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0942 | Train accuracy: 98.44\n",
            "Mini batch: 24/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0131 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0610 | Train accuracy: 98.24\n",
            "Validation accuracy: 93.57 | The best validation accuracy: 94.29 at epoch: 3\n",
            "Mini batch: 25/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0292 | Train accuracy: 98.44\n",
            "Mini batch: 26/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0570 | Train accuracy: 98.44\n",
            "Mini batch: 27/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0267 | Train accuracy: 99.22\n",
            "Mini batch: 28/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0084 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0303 | Train accuracy: 99.02\n",
            "Validation accuracy: 93.57 | The best validation accuracy: 94.29 at epoch: 3\n",
            "Mini batch: 29/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0387 | Train accuracy: 98.44\n",
            "Mini batch: 30/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0444 | Train accuracy: 98.44\n",
            "Mini batch: 31/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0224 | Train accuracy: 99.22\n",
            "Mini batch: 32/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0128 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0296 | Train accuracy: 99.02\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 7\n",
            "Mini batch: 33/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0103 | Train accuracy: 100.00\n",
            "Mini batch: 34/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0272 | Train accuracy: 99.22\n",
            "Mini batch: 35/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0227 | Train accuracy: 99.22\n",
            "Mini batch: 36/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0188 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0198 | Train accuracy: 99.61\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 7\n",
            "Mini batch: 37/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0059 | Train accuracy: 100.00\n",
            "Mini batch: 38/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0179 | Train accuracy: 99.22\n",
            "Mini batch: 39/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0118 | Train accuracy: 99.22\n",
            "Mini batch: 40/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0050 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0101 | Train accuracy: 99.61\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 9\n",
            "Mini batch: 41/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0058 | Train accuracy: 100.00\n",
            "Mini batch: 42/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0235 | Train accuracy: 98.44\n",
            "Mini batch: 43/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0072 | Train accuracy: 99.22\n",
            "Mini batch: 44/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0034 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0099 | Train accuracy: 99.41\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 10\n",
            "Mini batch: 45/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0025 | Train accuracy: 100.00\n",
            "Mini batch: 46/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0102 | Train accuracy: 99.22\n",
            "Mini batch: 47/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0094 | Train accuracy: 99.22\n",
            "Mini batch: 48/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0066 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0072 | Train accuracy: 99.61\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 11\n",
            "Mini batch: 49/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0014 | Train accuracy: 100.00\n",
            "Mini batch: 50/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0075 | Train accuracy: 100.00\n",
            "Mini batch: 51/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0095 | Train accuracy: 99.22\n",
            "Mini batch: 52/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0047 | Train accuracy: 99.80\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 11\n",
            "Mini batch: 53/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0013 | Train accuracy: 100.00\n",
            "Mini batch: 54/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0021 | Train accuracy: 100.00\n",
            "Mini batch: 55/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0096 | Train accuracy: 99.22\n",
            "Mini batch: 56/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0025 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0039 | Train accuracy: 99.80\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 13\n",
            "Mini batch: 57/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0021 | Train accuracy: 100.00\n",
            "Mini batch: 58/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0036 | Train accuracy: 100.00\n",
            "Mini batch: 59/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0016 | Train accuracy: 100.00\n",
            "Mini batch: 60/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0031 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0026 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 14\n",
            "Mini batch: 61/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0021 | Train accuracy: 100.00\n",
            "Mini batch: 62/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0020 | Train accuracy: 100.00\n",
            "Mini batch: 63/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0048 | Train accuracy: 100.00\n",
            "Mini batch: 64/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0022 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 15\n",
            "Mini batch: 65/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 66/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0015 | Train accuracy: 100.00\n",
            "Mini batch: 67/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0075 | Train accuracy: 99.22\n",
            "Mini batch: 68/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0024 | Train accuracy: 99.80\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 16\n",
            "Mini batch: 69/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0014 | Train accuracy: 100.00\n",
            "Mini batch: 70/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00\n",
            "Mini batch: 71/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 72/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0083 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0027 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 17\n",
            "Mini batch: 73/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0013 | Train accuracy: 100.00\n",
            "Mini batch: 74/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00\n",
            "Mini batch: 75/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0014 | Train accuracy: 100.00\n",
            "Mini batch: 76/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0009 | Train accuracy: 100.00\n",
            "Validation accuracy: 93.57 | The best validation accuracy: 95.00 at epoch: 17\n",
            "Mini batch: 77/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 78/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00\n",
            "Mini batch: 79/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0023 | Train accuracy: 100.00\n",
            "Mini batch: 80/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0008 | Train accuracy: 100.00\n",
            "Validation accuracy: 93.57 | The best validation accuracy: 95.00 at epoch: 17\n",
            "Mini batch: 81/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 82/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 83/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0055 | Train accuracy: 99.22\n",
            "Mini batch: 84/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0016 | Train accuracy: 99.80\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 17\n",
            "Mini batch: 85/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 86/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0013 | Train accuracy: 100.00\n",
            "Mini batch: 87/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 88/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0044 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0015 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 21\n",
            "Mini batch: 89/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00\n",
            "Mini batch: 90/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00\n",
            "Mini batch: 91/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 92/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0004 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 21\n",
            "Mini batch: 93/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 94/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 95/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00\n",
            "Mini batch: 96/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0003 | Train accuracy: 100.00\n",
            "Validation accuracy: 93.57 | The best validation accuracy: 95.00 at epoch: 21\n",
            "Mini batch: 97/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 98/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 99/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00\n",
            "Mini batch: 100/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0003 | Train accuracy: 100.00\n",
            "Validation accuracy: 93.57 | The best validation accuracy: 95.00 at epoch: 21\n",
            "Mini batch: 101/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 102/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 103/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 104/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0002 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 21\n",
            "Mini batch: 105/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 106/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 107/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 108/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0003 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 26\n",
            "Mini batch: 109/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 110/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 111/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 112/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0002 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 27\n",
            "Mini batch: 113/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 114/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 115/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 116/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 28\n",
            "Mini batch: 117/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 118/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 119/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 120/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 29\n",
            "Mini batch: 121/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 122/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 123/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 124/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0002 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 30\n",
            "Mini batch: 125/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 126/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 127/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 128/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 31\n",
            "Mini batch: 129/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 130/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 131/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 132/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 32\n",
            "Mini batch: 133/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 134/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 135/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 136/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0000 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 33\n",
            "Mini batch: 137/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 138/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 139/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 140/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 34\n",
            "Mini batch: 141/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 142/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 143/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 144/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 34\n",
            "Mini batch: 145/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 146/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 147/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 148/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 34\n",
            "Mini batch: 149/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 150/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 151/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 152/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0000 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 34\n",
            "Mini batch: 153/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 154/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 155/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 156/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 34\n",
            "Mini batch: 157/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 158/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 159/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 160/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 34\n",
            "Mini batch: 161/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 162/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 163/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 164/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0000 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 34\n",
            "Mini batch: 165/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 166/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 167/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 168/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 34\n",
            "Mini batch: 169/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 170/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 171/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 172/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0000 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 34\n",
            "Mini batch: 173/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 174/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 175/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 176/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0000 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 34\n",
            "Mini batch: 177/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 178/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 179/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 180/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 34\n",
            "Mini batch: 181/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 182/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 183/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 184/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0002 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 34\n",
            "Mini batch: 185/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 186/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 187/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 188/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0000 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 46\n",
            "Mini batch: 189/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 190/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 191/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 192/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0000 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 47\n",
            "Mini batch: 193/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 194/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 195/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 196/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0000 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 48\n",
            "Mini batch: 197/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 198/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 199/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 200/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sample,test_label = next(iter(test_Loader))\n",
        "test_sample,test_label = test_sample.to(device),test_label.to(device)\n",
        "\n",
        "model.load_state_dict(torch.load('/content/model.pth'))\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for x, y in test_Loader:\n",
        "        x = x.to(device)\n",
        "        logits = model.forward(x)\n",
        "        confidences = F.softmax(logits, dim=-1)\n",
        "\n",
        "\n",
        "y_pred = confidences.argmax(1).cpu().numpy()\n",
        "y_true = y.cpu().numpy()"
      ],
      "metadata": {
        "id": "bexBTwHcmn6L"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, balanced_accuracy_score\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "b_accuracy = balanced_accuracy_score(y_true, y_pred)\n",
        "print(\"The accuracy on the test dataset is {:.5f}%\".format(accuracy * 100))\n",
        "print(\"The balanced accuracy on the test dataset is {:.5f}%\".format(b_accuracy * 100))\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "fpr = fp / float(tn + fp)\n",
        "fnr = fn / float(tp + fn)\n",
        "f1 = f1_score(y_true, y_pred, average='binary')\n",
        "\n",
        "print(\"Other evaluation metrics we may need:\")\n",
        "print(\"False Negative Rate (FNR) is {:.5f}%, False Positive Rate (FPR) is {:.5f}%, F1 score is {:.5f}%\".format(fnr * 100, fpr * 100, f1 * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6GGkhFQdCXJ",
        "outputId": "09c9d5d4-5fb5-40df-9f47-0d3aa716920d"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy on the test dataset is 97.14286%\n",
            "The balanced accuracy on the test dataset is 97.05160%\n",
            "Other evaluation metrics we may need:\n",
            "False Negative Rate (FNR) is 4.54545%, False Positive Rate (FPR) is 1.35135%, F1 score is 96.92308%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test our result with the original code"
      ],
      "metadata": {
        "id": "9xQNS2S1wrwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/malware_detection/dataset/drebin"
      ],
      "metadata": {
        "id": "xAnxiXMwErrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/malware_detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QNb0HVfg6LF",
        "outputId": "fb500981-0704-43f1-9a31-d2cba0881685"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/malware_detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install androguard\n",
        "!pip install captum\n",
        "\n",
        "import androguard\n",
        "import captum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPz_B5yIhTw2",
        "outputId": "b6a2fd7c-0498-4fbe-e700-f0aac910f407"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting androguard\n",
            "  Downloading androguard-3.3.5-py3-none-any.whl (922 kB)\n",
            "\u001b[?25l     \u001b[90m\u001b[0m \u001b[32m0.0/922.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m368.6/922.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m\u001b[0m \u001b[32m922.4/922.4 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asn1crypto>=0.24.0 (from androguard)\n",
            "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[?25l     \u001b[90m\u001b[0m \u001b[32m0.0/105.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from androguard) (8.1.7)\n",
            "Collecting colorama (from androguard)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from androguard) (0.18.3)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from androguard) (7.34.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from androguard) (4.9.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from androguard) (3.7.1)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.10/dist-packages (from androguard) (3.1)\n",
            "Requirement already satisfied: pydot>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from androguard) (1.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from androguard) (2.16.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->androguard)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (3.0.39)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (4.8.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot>=1.4.1->androguard) (3.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (2.8.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->androguard) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->androguard) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->androguard) (0.2.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->androguard) (1.16.0)\n",
            "Installing collected packages: asn1crypto, jedi, colorama, androguard\n",
            "Successfully installed androguard-3.3.5 asn1crypto-1.5.1 colorama-0.4.6 jedi-0.19.1\n",
            "Collecting captum\n",
            "  Downloading captum-0.6.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from captum) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from captum) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from captum) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->captum) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->captum) (1.3.0)\n",
            "Installing collected packages: captum\n",
            "Successfully installed captum-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "folder_path = '/content/malware_detection/datasets/naive_data'\n",
        "file_count = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
        "print(f\"Number of files in naive_data : {file_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mE50minvT2x",
        "outputId": "b3e51f37-6302-4c1e-eecc-446760368bee"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files in naive_data : 700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df_benign = pd.read_csv('/content/malware_detection/datasets/benign_sha256.csv')\n",
        "\n",
        "# Extract the first column as a list\n",
        "benign_sha256 = df_benign.iloc[:, 0].tolist()[:350]"
      ],
      "metadata": {
        "id": "Uakws5slviu_"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEQMfH3n3BEA",
        "outputId": "62c8f945-541f-46f8-e1f1-cf2952929a69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded: ef204edf1176051cc9e17a874409118d41cf4c028ba84c316a9a4b0dee72b278\n",
            "Downloaded: 4e2fad79800a24f4d45d2f63335d8c09883d8f93a0b2ee54af394be99aa1fe0b\n",
            "Downloaded: b227e1b32c35fa7ca8dd9facc5404a980d2a3d788de2d86815c7636ab492cd7c\n",
            "Downloaded: f0fdc5d10c01bd3b3294e766d29d4cfecf4a3a725284bc7b670ae042bc560eba\n",
            "Downloaded: f7ab4420fad838ac67ebd681bd35fadf1d42bf76049a8479c59072df455b0d97\n",
            "Downloaded: 5ce062d42fa166af0638186e8509cfd18025ebbfca3b0fdbc59283d0e2a63af0\n",
            "Downloaded: 5f39a782c8230cb446e604f4c35ea4f5e95430aff8d65ae464d55c8a1e1b8fe1\n",
            "Downloaded: 7a3c63d0a9e9a0cc94b7ae880f515c621b9aa496fe8dcec27a60804afad89d0e\n",
            "Downloaded: e32a47354a6b84db80bd4da24b78285b305e9b0957cd6f739818a50ac843b42a\n",
            "Downloaded: 7e82b4c3fe6039a5c166ecbb96bf1dcc59d9902bfae901105eaa067f3c397200\n",
            "Downloaded: 2bfe6ac5d52efa498947a795fce9bd40942640d3caa70c7f1473fdfde2f0b3f9\n",
            "Downloaded: d3adeeb5df196e74ab9f2c578fad61636d5a6fabaccdb1ef31dbf3ad4f4dfc67\n",
            "Downloaded: 689992492bf0914fc74f03314052e925df2425988f5cddcf54f0a1e0ca8692cf\n",
            "Downloaded: bd44570884469185b0dc9c12e04366c37a4df94b45d1235e04e7dac95abccaad\n",
            "Downloaded: 09ba3148d5acc85cc37745d23447a5399d4a8af10511c766939b6fb31dff679d\n",
            "Downloaded: 0ca6d7957e5599361c9e0da293c3276516eb2bed13b3877a27504e92459721bd\n",
            "Downloaded: ff7b0aa25c01aa28a0839d9102d9042df876cb407439fdd4a5b873112a316a82\n",
            "Downloaded: 6e9b28c4339522c26a2dcaeff8525389e456bff148d028c7c95bfa2013d948df\n",
            "Downloaded: f4678982012e5d97adf0b1053d31f5137d5f8796d7291eb348297cb5e948dbb8\n",
            "Downloaded: 2760f1fc8f75091c5a7457b71e56411249d2a62cd2e25e36c7d08d83bd70fcb5\n",
            "Downloaded: fda1903e90e55ba9eda930d8ad33b3289defb8def94565bc7f3e2b9a76f7ba7b\n",
            "Downloaded: 877b8ceecf6926a1223997d475731b44f5f0f2f21cce240085ea1c15944597fc\n",
            "Downloaded: fe0a91973562d4cf63187924ee02907b47fa74dec0957fa099d61165cee1a06e\n",
            "Downloaded: ea5c97e07c804bd8957b86c016ec545850bbee4e3b516bcde59c907cad3d4b2b\n",
            "Downloaded: 0f302b9a6b5141b664c27da3236d166cc0d8dd00a23614ab445ca717e9e1d5fb\n",
            "Downloaded: a02576037cce8ae21354ff37297500b4f6214b1c7344b6440b13d51f2b4cfea3\n",
            "Downloaded: b247a2efd4a9237aa5c9b87b6030018e48401a854003b76f5dd13b7449fadb06\n",
            "Downloaded: c509ac8e68bba5771ec881fd77b578034844663324c0617e87a7cbfdeace6115\n",
            "Downloaded: 4d902e63bb1ebaee9fd091744b095e86db5fab810e3cfb29b33ba8fe6e50bce8\n",
            "Downloaded: ed5dab9e189c7e0c273cfbf0088ac8124617d3a61e4df20464bdde6b33e9fd51\n",
            "Downloaded: d414e4c7de2186f037a469d9398c216be7290b9c2c06c38f1b418aaca237bbd2\n",
            "Downloaded: 35f634617c281c6113318aa03542fc06ec13427440fde4573b7773a37218f22a\n",
            "Downloaded: a5f2fb86a91ba354d0f17bdcd4fbfb15242a2e799f9944765eedbe6a9675e14e\n",
            "Downloaded: 082e529d71e6a847835a954080934f6357e0696996728816a0e079b8bce8eafd\n",
            "Downloaded: da574a347d05c63dc4d6fc001bd3e59f76d51a17c29e60356683856ec473fef7\n",
            "Downloaded: 8c2f578d4a7fffa1655ac7ce58da34dbb5753467d915e9245882b02475f64a49\n",
            "Downloaded: 58f99d57ca8f5ba026ae0f529ad8dcdeb37a1458568b2b9f7f167c33cb88fa1e\n",
            "Downloaded: f41c7dbc627ee1e8b5b04f87421205e7487e509fd1c98232409c3f196d6ceeb1\n",
            "Downloaded: 7087b552e2bfe998ee177374da4ef4bd6f7c3494bc18265ca4e9f7597b8b5554\n",
            "Downloaded: 84e0f36d282bcbe81fca397cbc88f84a4043b70b45aa721d4ef9e584b760e878\n",
            "Downloaded: d9fed5e9d3803fc3cbca3d0b17210004292afb9f2695facaa2826b9782b0d0e7\n",
            "Downloaded: 5be4cb370b5c130ae66d289547197acc8ec2f34cf9ff002529630964dbad8215\n",
            "Downloaded: 362c649f26fa0026763a5a0fc5fbe3a79c1bbb960c891870c908091a80be9dde\n",
            "Downloaded: fc0a686b89ab03b43b4d58e0828c41fdb4acf11ec98c46effeff7fa009aa520e\n",
            "Downloaded: 75a7e03ad0b7c9d1f07315104f2736b9fa84f36eb7e8a4a398906f2451ac958f\n",
            "Downloaded: ecef54b8f8a6fd6805c1e1e226d6861d8274ae7c6851747b6f00648d2bdf4de0\n",
            "Downloaded: 9b7e74ac9e8cf937b00aefd0147ce48b97a49ef68d7208dba7a3b83cc58c301a\n",
            "Downloaded: 5935a43a3b73cd3d301b02d24cf937b167b11f80f5b9260448fe3559872048d6\n",
            "Downloaded: c2944ab5fbfc2add5db84fb8bb569c680efe718f1168ab5c4b272bf35dee0178\n",
            "Downloaded: 79ce8e4f27bea1dda37f96765dc0d7ea1eeef780ec55f6e467b12b011f66d753\n",
            "Downloaded: 3e33d60578419f191252778cb6dc1bec287c63d261b3e761ec8a801b0f461e3c\n",
            "Downloaded: f1ca4fed7a4146e5db842ead0f2af650a1ac6bd40eee8f13c6217605b76733e6\n",
            "Downloaded: 9620d0e141c5c2b440a289d3e7dbfc9d0f7e91c0d19d0b6973802fe3a8f44b86\n",
            "Downloaded: 29d7e78d17319f693f3629eeee131047c3dc693a62947526ab3ae31edba988a3\n",
            "Downloaded: 0cef2d72db77ff2660eb1ce8ed48a61291baeee76abc9d3604af785a7298cca3\n",
            "Downloaded: cf17237b42fbef46efd55e92515a0b2d2e4585a3ddf4c77360806f12ccca6b92\n",
            "Downloaded: b3649681304879e866be326aa01936282199e98ea621bdd2ee2a4ef09b006606\n",
            "Downloaded: c54b66566daf3e0b4e5eda9a278ca5d43acf7ed247a8d62be5ca1ac7558937bc\n",
            "Downloaded: 5b089c561ed0a1418f0d260e3ce6a6d30f29fad315c382e8f0549529ed4deade\n",
            "Downloaded: 68a762b82e1659d012cd9d1e3852c94e8a620c698cea9cabd9a40a667e835cc2\n",
            "Downloaded: 2a61c339d9c01af4a9927ad485c193031ee0fcfdf265b9c776fd3d644d72bffd\n",
            "Downloaded: 0ced9922b5b91be30376650d14476c430cd974a203e9301db124ab8ec1cc888c\n",
            "Downloaded: 0c50ae76bc6214509039d25b291b6778355f85a056d02829e288e0e3008ab7d1\n",
            "Downloaded: 7b72bd17fff5800122720308413e9ac7b748ab046609206613d196069bf15537\n",
            "Downloaded: 3b1c690c7dd8719d8651274e2fa3280ebec18316032aa85b5cd261c7f8107b58\n",
            "Downloaded: 28ffb49c2e605cc3b1359ab8e56fd5593279017ee403bc0c6f7561cedc905ec0\n",
            "Downloaded: fd8a6eaf200f82859ef749b79f0ffc1b980104d291784e225395d61694f08fd6\n",
            "Downloaded: b6e06522e7ad1e9d7df5ea42336a319ea4a441f2a36f058d5c21d5d0f95db67a\n",
            "Downloaded: d00d171dc69c05dc52983d945ec79887e670499e553294f606fab800042be3ff\n",
            "Downloaded: 3a1f66e94c5dd69d54396819c658d0bb1adb620c14d4e88e4ef768ab893bd366\n",
            "Downloaded: 44a69dc40bd4d2f5576e2e7a0a1ec5eb8712832adcd4cb776bcfd99721804604\n",
            "Downloaded: 935a84806ac412d4efe35354aee3d463f726902d0c7741aa6df5d43fd5f194de\n",
            "Downloaded: 1fe3763c1131495abd6cd2b313f5b1eeffe02abc4c9c485568a290cf35334568\n",
            "Downloaded: 7c8d440d157208e1b7b9b60de4713ed65ef8e5d5783a2d32290eb829e1979011\n",
            "Downloaded: aece5211f034f09cd25716a59977f815211a396034a5cc5588c48a0ac09f2f41\n",
            "Downloaded: 40074182200eca22770337b979daed9e00e3e7ca12514c66f591e4fd06051c05\n",
            "Downloaded: 6f65168edee73817c40e79c394d79049c60585b3eef44af89235f04543737bc4\n",
            "Downloaded: f37478df5550ddb943cec7b468a59b03e2a56791fbae0bec12e934a5ae6490ae\n",
            "Downloaded: 22caa1c4e1b42396c30fb938568341c16b0e98a6757a88f8f10052a3c44790a2\n",
            "Downloaded: c6dcd2b1e663e8a2349407289c0adedd9c0e1474ea4cfa80f8100b679a2e01bd\n",
            "Downloaded: f575a2bb2c44f7addb126961234378b84956ff84254f523af03f6b2592645623\n",
            "Downloaded: 392bb31543b3a8721bfd70c079b83a4371e254e20d166b14b7c1ee23f28f1cdb\n",
            "Downloaded: 8ec4a617933ff75c2a88b09a4ab7a509c859dc42dc1dface492e988a447cc193\n",
            "Downloaded: 911fc454957e44ace6a26f5700950a1a74aaeeaa8a6f587b116f9127c8abc7b8\n",
            "Downloaded: bdd641da4eb966eccfada3991027f89fe69bf6b1d4bee0610bde37e3ff383e2a\n",
            "Downloaded: 5fe6567c3bf602140aec43f68d94848a038c632b233ff363d36fb9c36ec7c3c9\n",
            "Downloaded: 14aad99a3b4c99738c5c5de4b7de044418ecd0a755308bee956708dd41a24485\n",
            "Downloaded: 4451e0b2f74f3b455cfbda9f8dd4ec097629effc9dd632f86444844d2737ba28\n",
            "Downloaded: 0927ddc2b6070d4fb5ccad72dbf6e627cf3fc7b6b1710c2d77917f6b534b95d9\n",
            "Downloaded: 87fa1224240479f05e165062287410481fd4e9e77b3666685a499289cfb6cec6\n",
            "Downloaded: 851beb7fea3499efc3b2452b485c09e459e1e5de7a0cdb212f93044b8a934b98\n",
            "Downloaded: 7380edff6fd8d83110dac720ec81f2c91a7bb6834efed4d3220c5bbda06eef07\n",
            "Downloaded: 8ea165f1d80332b297f631a6f415ef4618d010b4ca71d545ab2600aa75c7fefa\n",
            "Downloaded: a610ec16d36f836b6a7417e94c77a138e3f8bcf1725cc30b0382ea9ef91eb96a\n",
            "Downloaded: 8f6b4704f8af225513f2d5e58a1ed5ef29e6a3ca0798126bec35ac076304b5f0\n",
            "Downloaded: 59c0bb17740a60841c5ca33cb19f8f0e30c69b6df2b7156179b0999e8b5e0942\n",
            "Downloaded: 38ee3799f110bf1b7cecd8e9a99cc724050e7bd0d1a68c26dfe39a806a1a0550\n",
            "Downloaded: 3fc246e370d7b481f6b7e24a6f9f9bcabb317e0bc6ea57c96c768b77dfc0d198\n",
            "Downloaded: 03264aac24ec06afffa73e6d63ec90866963c4f4475122fbc99646d66a0feabe\n",
            "Downloaded: bc708350255dc2d13fb95b7c103cbde6488502a09efc89aeffcbf87d9f8b64c3\n",
            "Downloaded: fb29d9bc2b64323fc40f12bd696a8d2751fa786fb7664255a06885942e57fece\n",
            "Downloaded: b23bdee027d37af9c2ccf00946dbf2d468a7d65fc3750ea5e605bf32d415461f\n",
            "Downloaded: f623fecb7f63b4c9db7ad55151c7f264d1932603462f0afd971b608baeabd338\n",
            "Downloaded: 36eb282a3856f09eadbb3a4bf7abc24476716a99b12386d91ab98de68633e628\n",
            "Downloaded: cf785dc0e8a4e53d62193c8c0eef92149bf8a8051ef252cae1a209ff6beebe41\n",
            "Downloaded: b02d094e9e5449cf655c1592242afa949b4a46322c85ef6b49b46b5819de1166\n",
            "Downloaded: 4e617ef2896f801d90bfc1e5cb9e1e485c8894a6dad31c416ea3ed7d67b72a61\n",
            "Downloaded: b44dd60061619702e9c8689f71f5dc5c148693fbfa08f85c13c5edbcf7ba64ac\n",
            "Downloaded: 20466febfc5f1a9e35da6ccc91007736ce5007ccf5cb734e89a65b9769245f50\n",
            "Downloaded: 486e8362ac239ed5ff3600e8e0194bfbcaf59af41b0d0cea484327fa0e3b8bb3\n",
            "Downloaded: 8eae162b5af8240a392d56f8f9c8c7fd4e26ed20406751afad64b11975686ee0\n",
            "Downloaded: 1892904f0f8dd0db787957857a9eca8e55834b5007ed71dee1da260987cd79d9\n",
            "Downloaded: 64ec3ffc6d961d42ea5868d5bc82c796a97f7726de78b35f2847eea0a304fc29\n",
            "Downloaded: 6faddc589fb58bd0acf051b40f6f9e19fc23bed13cbee68abd37e58ccdd8bad8\n",
            "Downloaded: 73cfd9d05a277b9e8919005c4a09eec90e58d7ab1321bceb617a6d461d7a3f76\n",
            "Downloaded: 89629f4824e59fa4dc70111b49808e67df5a3abba74f877d63199ce7a4181c74\n",
            "Downloaded: 8094c6bd18758e9bf8ece46dd848abd2b5fc6e15c0b9a5083d293545ea51724b\n",
            "Downloaded: 7160f93ed210d2430ad2bda9f7e3157917e977779e12aac1aa78771e5bfd4fa9\n",
            "Downloaded: 6464325af4435a29c6f2826bcb21d89806bbe269c8a08b0e44c02df951b223a3\n",
            "Downloaded: c0408baae22ef4509a6b086c355b44d3830148830f23cb9a801843d0d86d6f79\n",
            "Downloaded: 6b3bbd582e8792171026800b44a02bea31be970c05604d2194fb1b8efe52e8a3\n",
            "Downloaded: 96a00d13096adf66d3b8c3f793526ccabbf28fe0ba0ce98a2d6481bcddd818df\n",
            "Downloaded: 94c06c8e843662ecaa8217841028c111f56ccd3b13b6d59629e7636558dfc776\n",
            "Downloaded: 97170dbc77a7eec955a0bdc32e1d6a8c99e09e5b28056ecd74e50680aadb39b8\n",
            "Downloaded: d9f832ea72a4f4788b708f2bc0f43f799c155176e69537c50384f59bb215a84a\n",
            "Downloaded: 00de98d22a0164abeb93df3471312583b777663d16b5cfc6e6d3be875a6904b2\n",
            "Downloaded: 3291e0816f5771991f63e77b2848dcb08b27c17cdd24a0de572e130313f68f44\n",
            "Downloaded: 0632f39fa1f35916af19f17d31967f907f5a79a5664a904a9b28c12f5023cae1\n",
            "Downloaded: 9a6c544416b5bb911c3a6d6ef0df8f5f1cbcfe3577aab90a9bc76a8d02bd1684\n",
            "Downloaded: 17a5b3b37aa6a64c3c13bad4894c9c328672077f7169644516eb709ddb028d4e\n",
            "Downloaded: 6197679235dd15be744a26c3ac0a97c557a1353e48b65fe2d8726001c32705b0\n",
            "Downloaded: e2a2ea1df0aa34d0a045e9108bd47488fa766c81c647150353ac516d45288957\n",
            "Downloaded: 7a13f8a317bdc08e370db47af956aeeb8b227f4fba49827694e690c4b53b3191\n",
            "Downloaded: 1d6e0c5388eead3557e5b89a1a81444d12e269122dcc10e6fbcc3705309d86ce\n",
            "Downloaded: 28524fef011cc525d1af690117ed22ffa9b3dca7502b56400e2a1bad0a0be770\n",
            "Downloaded: a042cea4264a6669038c45bdc7b992db4711c2f6b4982eea8ed3fd84b90b8d78\n",
            "Downloaded: 296363f587890ca70e77283b29772bb50f7dfb16a97887544b5cb451b92fff57\n",
            "Downloaded: c3b4da48484cdf7fd8771febce3ceee8db8e43ce878432089ca173b60f153b60\n",
            "Downloaded: 75fdae706d706ceff96bce98ec543127cc13b11445444bf1b71508124275ec23\n",
            "Downloaded: 5fb078bd9b604c2f5aa88b76ff5cb19cefc5e6ec144182191727085d13c27a92\n",
            "Downloaded: 918e51b73af48da79cc04f5149a9c0e5a876ad382b81926f3ea169a02bc43669\n",
            "Downloaded: 29d41ecae2bffde504c3f8f17931943ae162a7b8c4e81fdde25806f90ef36584\n",
            "Downloaded: 9f5a4d295794c65aba01f2cdc0390752b2ff5915dfef73a077e695c15a78fa54\n",
            "Downloaded: 8505308edd3bf809a9ff739394006b79cae858426afe93c254e0f9b371286d6f\n",
            "Downloaded: 400821475ba1a0d98b7189e0bc0d7d5e0729eb86e02b2d6e7551fb1e91f441ee\n",
            "Downloaded: 911db8714428b8b989eeac0be54d8c85680bf76e7b88fb4bd20c1addc5ea9317\n",
            "Downloaded: 0e52249ad6bb1121227d96376c9aae0f65759c03cefe59153f5f50c26b792d03\n",
            "Downloaded: 724e2330203371cd3814a335f448cc5f313d4da45766da8322d469ad205020fc\n",
            "Downloaded: fe9a74c725c737be46fd4a4c6dc22ce90c70575c6ca297920282ceb9817653c4\n",
            "Downloaded: d42272e06c9bfdf9ae9afefb9b26bab612864128c40c1e3f930790310284e853\n",
            "Downloaded: 67d85a810866d5bd60cd99f05f180f53dacd30ccba920821577386aeff47fe3f\n",
            "Downloaded: 7f8f479fee3afb34163d9173757fc5e60cc6d71a81bb8876085a9479ae201845\n",
            "Downloaded: 8588093ccb169c6932bafd40bd878cf1b920c8c80fe569d640866fb158aba487\n",
            "Downloaded: 26de154961dc70a5ce95bd8189ede446e8be3cb28ca51323a54eece3d85b2561\n",
            "Downloaded: 1eae48e256eb1e45248ff46224cde843d965477c25a02000830e956fd676a930\n",
            "Downloaded: ea56c558b257abaf918ac7bbe9b224c6b4496f7c56d24c02a87afdbfb9bc7be7\n",
            "Downloaded: 5089246e7da2b65ae4854f7faa895d2c38f620e4f020308bbac6c6a18bdef8ff\n",
            "Downloaded: 61fe21c247b011dc359dafeed3fb76065fcfbf7260bee79e1cba69556771d8a7\n",
            "Downloaded: 68fa7df3a28554cf3282270542742be7b4ccf4b3821ec9fb3e6cfd008a147e94\n",
            "Downloaded: 2e19883cefdd8196c025eaa2fedf75921326c84e646459def8369c008985860e\n",
            "Downloaded: c683c9941509cf3b6df866a84d1415aa5ee905e2a610c94a39598a83c37144c5\n",
            "Downloaded: 221d31a1afdab118a8a707e7e59526bd85831f607facf75329f25aa3bd813b94\n",
            "Downloaded: d33dfb1c7a21f369504a8aec56f22e52eea5421b88b1cc6afe737af3281e29c2\n",
            "Downloaded: ec69305444e0f6576a55339d6ff341d7a1340aa5043968f061f5589cf4f7fe0a\n",
            "Downloaded: b933d16ad33c5e39ef847be413cbd173df88b584e7cbefd0f23c28754f3c05b7\n",
            "Downloaded: 99e088775e36bbc7db13192d37a732a0fa2d59538f96dd9a1fe127d1de484a06\n",
            "Downloaded: b15ac7a622a8a6f16d28d8c8ab6b8f8d2d63f05e5c95d33987ad93f767290111\n",
            "Downloaded: effd7ca7f784870340de104c8962e5e073ee307af24a30b446351425094beea4\n",
            "Downloaded: cec67578df1ce6ebc907062feca0d4a996aa07eb4b21941536ba0d6112b7fe55\n",
            "Downloaded: 2495d79efd1b96240f59ba42a07cc431f26895f28a086184de0dae49218ad105\n",
            "Downloaded: 7f59667020769d391884c001e91b12b9f519053b8479be3ac0c35e363c44120b\n",
            "Downloaded: 1d3523e472457012f7f67cd04c623b99145c8ff5550aedd456142be9bd6e2cbd\n",
            "Downloaded: f12c04fedfb352c39f74aea26b0c7e913cbbeedf7742819e8c0c9c0f4e409822\n",
            "Downloaded: 534cb73e610342fcb66b2af1221b180caeab626f3d6e938fee4a94f519107c3b\n",
            "Downloaded: b4ef63096de20d35ef268fb83ac3d968138eadecb3c7d43ae30608867d2b75b1\n",
            "Downloaded: c973a246dc570da77191704168c445e4f3429fb40007edbe89bb662bc5770513\n",
            "Downloaded: 190c71bf8d5e0c877deafdabe8090711194ed8fe233507da73363867bc915571\n",
            "Downloaded: ccb1a3620f3e474a3af9dafa2fa43ac842b06ca46dc0d8e88b6d9f2242c1af6a\n",
            "Downloaded: 16b53179fa508980bd8ec1364c3853f5d546fadb75d067863ab3c8009ced9660\n",
            "Downloaded: a451b40258b4879592211543258d0b9b12893d8432d979ee673ce4e64c12077a\n",
            "Downloaded: 83258e84dba3400b3113e8ab6ff3cf20ca6a92031fb06577153c3ffe6f8e78ba\n",
            "Downloaded: 622d3e6ecbf08e4c0894973578a2a734b24a20c460b4a27f2609e5bc0f7c451f\n",
            "Downloaded: 6c51e0ac6e362da960eae980b48bf410ba22eb3c92c70d109e75b476e2d5a61b\n",
            "Downloaded: 90b63635862bf9670a663b578a0be53b9ca7173f0f4cca96508e04f2c1865b84\n",
            "Downloaded: 4e24945c1b79936044866e4aad90d2817da0553b00f0542c515409346f5c9709\n",
            "Downloaded: c294c615c8527336442aa21e4219b5abd4d0bf2d879ba26958068e67d76ff05e\n",
            "Downloaded: 5c64bd30bbabc8f808dc5b53f0d7653eb72a03f9adb77d898b47fff0ba990e89\n",
            "Downloaded: 68ef7147074625efad30ef99d4e56283836db405bd582f144079731d92436101\n",
            "Downloaded: 1253af94bf43c3325a11a00e25e9ce0954c817af58f10f096b590af92ed68861\n",
            "Downloaded: f782506872596f7783748eb112d82cfd64688dc399280c5860951eab04169a49\n",
            "Downloaded: f8350cc8deb9fa47ecdf594bb45ea0f7bb5df41e8f1f561ab26727e1d3302c42\n",
            "Downloaded: 018664966b385cead01d2040a3ee159dcbb1712c621807003d2509176fbb5aba\n",
            "Downloaded: 341493754d84946280dc339da724411e80c6d9623a37710d7d50376540e1f943\n",
            "Downloaded: c73f953027c86916acac2c58b15157a0935daf3c967872bc1d0c93e98354cc1e\n",
            "Downloaded: 58fa7620ae62c20ddacf91f75ea91cc2ab44854414b3e12cdb55d41306079f84\n",
            "Downloaded: 0cdcd96d05aded380badf34328786e0d5575e8d8cb72aebde7b6c77ea23d8641\n",
            "Downloaded: 8e0d400db479eaba6bb7d5e8d22466038d7e2ae02a4a24ddd858906410a2c73c\n",
            "Downloaded: 0d00ac6e055b2df0eed81f463849bf4eeec5caa06e204508b365f9f4c8017881\n",
            "Downloaded: 07a5e3a76585c93d2f6e233c04526da1bf315309a5d0418bcc6f0463721cfa13\n",
            "Downloaded: 017bc92e2dc107fd6b5e07f9667806a03dd10b011543bf010ebbce5fff48bba7\n",
            "Downloaded: 28f007512b355212be018eb455176908b29913dbac1d3cadcc8f04673660875b\n",
            "Downloaded: 75e2011744c3b0b2c8c6016642b914fd8d940424c0eca7c38cf5bdfde9bc8fdf\n",
            "Downloaded: 405bac883734e9d90944f2880f9e962f863a2365fbd2d4bdee90d97e656a7594\n",
            "Downloaded: 1929def5c30e6b0c00e9950b74216114f75a3f16858c0f2338df3acb1e71dea2\n",
            "Downloaded: 81b9c281c88ec166a3b9f5d2802d1c928ef5860ddbe0378e8983b48b5d3d7b86\n",
            "Downloaded: 110fb0f60f90321bb763d42bd5203932ed8b5394ce969288e56a782754aad9a2\n",
            "Downloaded: 9763615184dccce72eb56c63fb823c2db9d733a2ded1e09c3cdd6d27ae4172e3\n",
            "Downloaded: a41ed5095c06844a04f0eb722e3596567f66491c5081d96971fc60f7d44aa251\n",
            "Downloaded: e6c456815c40bf0b252f30d919e3d33b1c9e7198cdce4ffbea1f5fb7f95ac336\n",
            "Downloaded: afc33411fc6d9bc0c74069497c6522ebdd2baf88d492a44453208a32f7ce62d8\n",
            "Downloaded: cd631d1f94a0f658ee4721904d73d934472e95ea99fd12748dccff9bd0c0a7f2\n",
            "Downloaded: 29f27717f0602a30706ae29d8e0ef4f5cf502fd56225eaf7755d33b792c76515\n",
            "Downloaded: 8eccb25d4f525ce68cca399e37b4b26a12588a53fc10075af1ce46ed0013b205\n",
            "Downloaded: d58861ddd6ec60b1a660982c56e68972841a9c76a0ae48028d292dbb2cdbbf8c\n",
            "Downloaded: 6871872534a5c8c4caf297a2bd7d41045576ea389686ff466db9f1a308e85694\n",
            "Downloaded: 43b8f3f7110b7aa2775907f5ddb2317ecc0930053900e812a310a6c541ae9d9b\n",
            "Downloaded: 8d181da7a2b1049f45382a80bd4c3218c1af5bfd9c54556e5e8b7f445b2bd493\n",
            "Downloaded: 0205187ef7720d68092633fa2f26b19600423c9a189167681b4d603971dcbeab\n",
            "Downloaded: faaf93253ca8b67a6a735876ba1f641b7372bc7d410035230695388e5dbaa50b\n",
            "Downloaded: 1c4af0c9308880cf5ecbe41a0f23967284565a391bca181e092a8c6afc79c128\n",
            "Downloaded: e10013d8f820748e389bedbf3af35c9c8262f3af8e8bd40fd3145566ccf11b7c\n",
            "Downloaded: e7f3c6e825dc32c3a85d0376ec05bb4963c1b2817622c7d466d176434ce05061\n",
            "Downloaded: 1e4cb810b4b57df9529e092b8308e4adb0c9f60e9f4df4779ab733aab8681587\n",
            "Downloaded: 3ef07ec1b46a003c1d41ee6ea83d870cb6c3aa1b15c1aa7062d0ebc890582c05\n",
            "Downloaded: bc8fe5e6c7cda70ae5d4b616d75bedeb29b2ad07b853109f99db67f0ccd6304c\n",
            "Downloaded: 7224130c1b4620524110f8d845b154b52f2e7e54fe0f5f1c7b1d04257230a4fe\n",
            "Downloaded: 9d472615a8417ebd0d4119b579fb3a0ef38ce6f5ee3354cbed7ca74165906eb1\n",
            "Downloaded: c00353d797ea679d51afe86b9d51ec7a803f729318881b9e8bc46a8fc1fe35de\n",
            "Downloaded: 611dcf8b58c8e159e96b2650f7bb1e4ae297000969e63ca21b6d1c7f53e73e8b\n",
            "Downloaded: ec39433a13f46fc5a39f7ffc34713e1e616d3fb6d83e9724f54a8e6254f13544\n",
            "Downloaded: 30ffb47b47c982f755405c57541cb27ce0a499cfa9f17eea59cc94193e62b5db\n",
            "Downloaded: 354194d1cd6bd132b3f5dfd76392c929e35fde5d7a3a7ea8a45d42b342c369d3\n",
            "Downloaded: 6e6ed6db1d5f69f0548fcadb1cc21ad2e1240625a5c42e5e01e54a16b6f99236\n",
            "Downloaded: d58910d1ba502439794f312140e6e4427122385ab62292741b0e96979da7365c\n",
            "Downloaded: 7177384d9b8ccb3504b290f7b97c09175d80887305eb52631af5a9362837ca6a\n",
            "Downloaded: a023d3278ea1e4cc00242e1ad2fa2667f02ec8387ee82d871bce5d46b811cc64\n",
            "Downloaded: 052df5c4ecd587e8f816fb77f41485a9a9b12cbd8c8af704c85150691306c730\n",
            "Downloaded: d27e41096bc31ca61271a8cd6bef43ce85c1754673d095371f375971af847daf\n",
            "Downloaded: 476b6d9f836bf30d6c6da1d97fef39de505ee445ff7f4a72fb9b4dfd241f422c\n",
            "Downloaded: 03017e25c4b3045bd476dc3754b78caa21c7c5f30528a7c1bd903044cf6367a7\n",
            "Downloaded: 82b4105e7b274be57085557ef2d0fea71675d0d8fcd73bacdae75acade5fadf5\n",
            "Downloaded: 5ed5ad6db4ce2790aba0bd5c186ab55446726e09c83e537dfeb5c29f3d579414\n",
            "Downloaded: c783916fa58b66545ff4e34d83e47a00fd91a5428114c898578ec25ca9ff95b6\n",
            "Downloaded: ba89a80c15ea83505b1f7a89df174e066a679f34bca32d70dfa0e0bb46a502fe\n",
            "Downloaded: 4b343d0f3ade00178cc5314b3611047f4e0691927add01eae89d0ef30ecae134\n",
            "Downloaded: 8063f0c88cb37604a1a89c86a117397c8f93bffd871d13a81620afbe58990a43\n",
            "Downloaded: 8b098a575df38df6cc83162128a9d12e0f4d6aa878bb7c1b228e0828f8a85745\n",
            "Downloaded: 64ee1fc1cde0fd6f038880472950647f50a7ba845ac1cde04de28ecea2b2f5f0\n",
            "Downloaded: 8e42af92793db5c31febd1fb93c8bef32756e5c801427306d24dd4c82ac069eb\n",
            "Downloaded: 02d27b89d849c7a11bd396e239ca53ed11d347623229a00afbe4f863a8b06a3e\n",
            "Downloaded: 15285441c19048b6cd4eeb09194bad80feaa3847de65a706d918baf15134aa5c\n",
            "Downloaded: 9e5e0818d1f96409816bb4e26c570933f1820d17aa86bd1635041ba152a738ea\n",
            "Downloaded: abb1ec90d719251f4f1fce62fe612a1042809b2c843e07a41575d4b15bdfecf5\n",
            "Downloaded: 395e19d987600da6928c797e149377a05adaf3125ced17dea4614dd8d854dfba\n",
            "Downloaded: 270be9eadc2fec4486f642d7ba81e828d9094fe1e1e67c5172634510cd1f5ef8\n",
            "Downloaded: c884bb0fa692edb71f64f1070bd4257bbc7a14a5387e343d483270da9197351e\n",
            "Downloaded: 8e5c961ff81d85532661ee17391effbae95d5172447be4f890a77a854dd7b334\n",
            "Downloaded: 93c4002e7a98c1f079bf1956a7bb842aedd120a13b20ab9507ace51921aeedd4\n",
            "Downloaded: 574ed0342b508342974846643316f2f2b9bd31094b7f7ca128dac0d8b6eb09e4\n",
            "Downloaded: db470ebf26ba91f34a3332ca620cedaa27f8d611e026679bdb2c01551f5e9558\n",
            "Downloaded: 740f2161e4c48d75f109e8276bc1d8bd4332b28941f71fa5680a138c875a8e6c\n",
            "Downloaded: 87d08f7a1f73aa000e68495647b812f8694e4b33d912eb48e93eb9872306bf84\n",
            "Downloaded: 59d8b300ca29d3cced994cffeed0d737c285a28721732cfd7816d8aff1602e85\n",
            "Downloaded: 413390869a557e671b67c92628db6a91427a8150b208169e099515ed847025f5\n",
            "Downloaded: 9026cbcda6abe20004fd6cbc9344fec54d4da4c015139983e8c9fb373fb5893f\n",
            "Downloaded: f9dd304ae1c03a5e6838e5dd68fef3ca57a087afe5e11d579a3e93325f71c55f\n",
            "Downloaded: 2176a2572d9f662e12340346e1462133ee0a0660b1a6790ba8dc6d0559e9d2f7\n",
            "Downloaded: 57f26076e3f4a54aa70ae87878f3b3df1813bde1797dc3190f9732076f208a31\n",
            "Downloaded: 027aba4324c27cfcc392911e823bc88f8da156bb90b85915928634aca838d725\n",
            "Downloaded: a1fca9506dd03872315b7bf1a6f0fab028449fcc4e3ed7801dd4618814ed142b\n",
            "Downloaded: 142c9ccf7abf34c2bc6c90e52d9cfd59804f164ce606de2ea9d9db644eeefe68\n",
            "Downloaded: 9699aa84f3d4544b63f9df84b9094c658c8ede5a02784e863e5a9eb2de7d9fd1\n",
            "Downloaded: 49a87cd9b04810154c5f98ba6c5d6ce0991532fee700f3b1b8eb8eb9be686615\n",
            "Downloaded: 53c212ddac9eb24f51050ab7eadcd3144d954150e654efbaafe22cc4b938e0ed\n",
            "Downloaded: 1805118b5f6be78d81632314ebeead81c3a87c8484ada929132fc4a3f91145a1\n",
            "Downloaded: 6e49fcfcaff55ba6c80fb676e5aba48fd400c8dd5c4f1ace866c05273ebf394f\n",
            "Downloaded: 658167ca3f75e88fc4f443025a44479c1f588aa2eb80c8ba146d52f85fe4fadb\n",
            "Downloaded: ff0bf6dbb73a98e6f2ec528aa584f6c136bb2c60fc9d208c0c07ede92d406ed1\n",
            "Downloaded: 64bbf09721793085632d515bdff7d99c2e5b6991be322c2a55751f4f70625684\n",
            "Downloaded: f875897a880b13a715ae830e7e2ed24424dfa013b7275f299494727d1380b649\n",
            "Downloaded: 0b57e3208c069b6f0d07e37684142901eb9b4ee97889ab28d2fc27bb4acef754\n",
            "Downloaded: 1c9e00478c80cd6f6a67acd94f29d1036118bed0171cd60351c5cfb1d0c13ea0\n",
            "Downloaded: 12e8e8c0ccbd38b900ff944f84aa99a00dc13014970508bb75aa1cc025c61507\n",
            "Downloaded: c247309092fdaadb5124fa6f66e529fef4c034e74f019709b2cb75f51fcb49af\n",
            "Downloaded: d631dcd2ac6fc6e7b98fd6f3d490dcda24e179bfd7894592a2e0ed1667cfdf90\n",
            "Download process completed.\n"
          ]
        }
      ],
      "source": [
        "# download benign samples\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import concurrent.futures\n",
        "\n",
        "# Replace with your actual API key in androidzoo\n",
        "APIKEY = \"717edc01a24bab5afe87835503feb736540c51352fe02bf2e487146caf0fa192\"\n",
        "\n",
        "# List of SHA256 hashes\n",
        "sha256_list = benign_sha256\n",
        "\n",
        "# Base URL for the download\n",
        "base_url = \"https://androzoo.uni.lu/api/download\"\n",
        "\n",
        "# Destination directory for downloaded APKs\n",
        "download_dir = \"/content/datasets/benign/\"\n",
        "\n",
        "# Create the download directory if it doesn't exist\n",
        "os.makedirs(download_dir, exist_ok=True)\n",
        "\n",
        "# Function to download an APK file\n",
        "def download_apk(sha256):\n",
        "    params = {\"apikey\": APIKEY, \"sha256\": sha256}\n",
        "    response = requests.get(base_url, params=params)\n",
        "    if response.status_code == 200:\n",
        "        filename = sha256\n",
        "        file_path = os.path.join(download_dir, filename)\n",
        "        with open(file_path, \"wb\") as apk_file:\n",
        "            apk_file.write(response.content)\n",
        "        print(f\"Downloaded: {filename}\")\n",
        "    else:\n",
        "        print(f\"Failed to download APK with SHA256: {sha256}\")\n",
        "\n",
        "# Set the maximum number of concurrent downloads (adjust as needed)\n",
        "max_concurrent_downloads = 40\n",
        "\n",
        "# Use ThreadPoolExecutor to run download_apk concurrently\n",
        "with concurrent.futures.ThreadPoolExecutor(max_concurrent_downloads) as executor:\n",
        "    executor.map(download_apk, sha256_list)\n",
        "\n",
        "print(\"Download process completed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the CSV file into a DataFrame\n",
        "df_malicious = pd.read_csv('/content/malware_detection/datasets/malicious_sha256.csv')\n",
        "\n",
        "# Extract the first column as a list\n",
        "malicious_sha256 = df_malicious.iloc[:, 0].tolist()[:350]"
      ],
      "metadata": {
        "id": "SLdVKMWevx1I"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGjZWMvt4Bsu",
        "outputId": "a1fc1a9d-b173-4206-a00b-f5e48682196e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded: f86c0abfe9f95f26d275dd4f0975a037879895451ac6a9c313c4b55b3b9ec5d1\n",
            "Downloaded: 370d03bddc8f3c0475c7ac9c2087b2d2b9ba75784134f86ccdbf3ff3f767da1e\n",
            "Downloaded: 0f69c23273789a1de9e7968418c52dc22b83efa6378b7d2a863dd833dad1684f\n",
            "Downloaded: 3e1d0b46568132eaa5c046a9711c1fc741c22d067400097df8b147ecf6fd70bb\n",
            "Downloaded: c33892fea2f47df861d81a4ae690d8040df2cd3e5753e92e6efa713b82e5a0aa\n",
            "Downloaded: 7f1ed691ef1d8b8e35f168f0f039dc8dc936d945296d66d04c1b4c140a48cddb\n",
            "Downloaded: 0752519e262e470be0c165c3ac5db7cea34a8dc13a15064c4bddac481897ff10\n",
            "Downloaded: 7894a893c7d61102d04ab83f8b57ec821b12f25f5f277bdda5d9c4ffd794e92e\n",
            "Downloaded: e656fc99de56809e7daf86910ce7791e656734a009e702172c0128f9cc4bc82c\n",
            "Downloaded: b5dc305c3a4c81e346c004b1c6590f2683ac727f501658af6e51cbc6ea799091\n",
            "Downloaded: 547141641e2e845d95bb53d74f499dfb7bc9aa5bdc555989fa250bcdff47e10d\n",
            "Downloaded: eb27ec66da5ced43843fffb1d36bb06cf250eec08d0a5f965e09d2ca2d9314c9\n",
            "Downloaded: 05be756cb4c3fc82fbc91cfdc17495b9157ba70a8df9a65e1ba6ccfdc37af56d\n",
            "Downloaded: 76856232bbe0c5fff4ffc67ef07a3628751e27852db210c95d72f9d6ca036acd\n",
            "Downloaded: c590b3a526c8a732bf28629aaa3bd646abf93cb4735edbde605dde429f89e9c0\n",
            "Downloaded: e95ce8e76ca24f7a2b73dd619c0ab90f4f2b438153362966eaa9e69e115d5499\n",
            "Downloaded: 944d4fca6544552dc5987fe6eda76e451a41fe67a9c3570e6114bf5474e7afd5\n",
            "Downloaded: c1b1eb34a2e29eb6610ca78c053e5ee17665162b9aadc0b73d58c591690e8b73\n",
            "Downloaded: 6f7afaaed8e97ac954f7a4b16d52ee6e659199331951e3828b1fe55a3c91f00a\n",
            "Downloaded: 45597da5fb0ff1445537736ab26f18e2f6da04117f06f0a37c5f1e1aaa7ae19d\n",
            "Downloaded: 8ee33563ba3b9470dd1ee60fc75e126758c7ab1449c508b55c970414919da0c2\n",
            "Downloaded: f9d32edd3e84dbf5732a7526d94f3633d150a5a3ff5e172f00ca01716642189a\n",
            "Downloaded: d64c37ae414c5c6b5cdb1599c44b3eea2f002fc934209ffc4485a09833eaa236\n",
            "Downloaded: 0966bd24b579b731907f36d4f7706f34a5be8a91933d120a13cedc7f43ea8439\n",
            "Downloaded: 6a7ffd7e6fdf4e60e0e140558081e7adb5cb3d6e6c506649894d6bf912fa5cba\n",
            "Downloaded: 40ebbdf91ccfb8c07b6869c8ddbfce68f17e79bba12d96bddbe42e4a64f12000\n",
            "Downloaded: 692ebd98c28bc752d8ccce0ccfd182191610a7cc524b6362053e4cf006f3e794\n",
            "Downloaded: 0cf01a62c0b98b661d1b52b0a983a56c6c2db4c0e2008d210e6d221f904b0cf2\n",
            "Downloaded: 22b39f9cf39cddc0cf4660647616c5ddf7bc3f43d1675f7ae120393cb4af19d7\n",
            "Downloaded: b0062fa2e2721e18793e763381fbe186c1df2f0c3a6a87f546436d6f255bdef2\n",
            "Downloaded: d24f233537c909111b62c397d6b8bdc9a2560d76825246f5eddf292060f26563\n",
            "Downloaded: 1520517134a6054fe85298700fbcd73a32e7e4aba4158fc41c33d745de0eb335\n",
            "Downloaded: c16665ac93f2eaedfd1fd9ca713eb45a284a6650e9eead9b2d16677ab62e4f74\n",
            "Downloaded: d18423cf18ac182ffb30ffe1e160520435fa80fbd02ae034bd68aa2708281057\n",
            "Downloaded: 0d2c0a57fb01afbeeec31072fdb751097a1313abe8ef27eeed4fdd75b2323562\n",
            "Downloaded: 33a99ab127bd1614664428950f9251f96ab1c0ed2b9f14cd39a268e09b2d0c88\n",
            "Downloaded: a333978db2ef582f6b63d93aa771313e4ed354f0bd5065b5e6e1747df1927301\n",
            "Downloaded: 75a24a27c4f04627f9762ed98758be0aead9637fcd391f80d4355248ac33dceb\n",
            "Downloaded: 629e1bc6a81d8b717dbcc0a942e60036ea61baf134e013b58bfdd2b2c06eeac7\n",
            "Downloaded: 9d538c385bcdc0f1a8a49e9c0d6ae15242564a0e9d90e2beef63915d9d1feda5\n",
            "Downloaded: 5b11298248c806009500b6e3444fb66a67a360bd33fdbc878ae800f1f35089f1\n",
            "Downloaded: 421538cd0bcf1759823a6b53e8e6f366abc43e68691bcb03e2e8a359dd1a234a\n",
            "Downloaded: 2b1a40b97c00b333085aa7fbff6c62159bbbaa151ecd7cb89cd793e7eaeeff11\n",
            "Downloaded: 424d4c87c18f4048bde9a57a4fbb20a63f784ee43a2c51d69864c7c8ffcd4625\n",
            "Downloaded: 43f2ab127cf83b381014fafa0b9bed49cda6aecfa92c3dbf8f8a808b54f6b1e7\n",
            "Downloaded: cf1259b14723c2265f91941f5f068edebcee6d6d8cd0f77d7cd654eca94f3945\n",
            "Downloaded: c577d1d80afaee6ba70cc8ce280aa30edabd056cf66d8c86d7233fc2f06f48c3\n",
            "Downloaded: cb69b28867579de425ef7459561ea8ac2ae5de02f3073698d3781aa6bb0be74d\n",
            "Downloaded: ef609b3c89e7dbd26f4db7acd98a18f55c3d5f736c66b5cc659745380b8a84a3\n",
            "Downloaded: 876111874bd302794f48f278e734b50d2987be41075b89be9125588212ece4a5\n",
            "Downloaded: 4f76e4fe92c120809f8c9b6a0b11e7c7b487688eee28b0e2f8a1d33d56fe32d3\n",
            "Downloaded: e82672df69ec3527e3687db6a1066ed15fccd6e94a6ea8488f93e07ca7ce293a\n",
            "Downloaded: f7a24b93aff19e73bcc83e8d784736cd1cc06c8cbfaaab0356505ab5a89eeeac\n",
            "Downloaded: e6b163e8a4674b0d4a8bb0278b91a502a3a692d4983145722d3ee9cf2676e2f3\n",
            "Downloaded: 31cc66ede6823e931c23c0d68c9c0ebc7c4b51767ea10700507d8707b043fc74\n",
            "Downloaded: 5b4b74d84311e2fd3b2ed8e88e91d57e3d0b34b81a073f0e8059e6dd706c4484\n",
            "Downloaded: 27a3a8064dba54cf5c7eac3e90b8f30d446c36191f0a26f7d4a4b022d5dd67f2\n",
            "Downloaded: b2810c3756ee8a7f95e2326067c774ef7627c9350dd276da64db5e4b47d2a5be\n",
            "Downloaded: 31cf90be373f9f2f60733f3d164d88cd417625f97f297f214ffe3e7a588442fc\n",
            "Downloaded: e29135d43df99546bb37b59841ac9f72895ff56c54693eefc1a45e609cdff5dd\n",
            "Downloaded: 2e255937e0c9e47b0554470ecc332d627ed00e12766100ff8e2762b41342414c\n",
            "Downloaded: 63120a35311454a5b1dbce5f2781c49c62be3963231ccb7ce44746d789b9fcfd\n",
            "Downloaded: 6cfb869e3dead3b379e08fbc065ec2fe10aac0258fcb3fcc43d82ed81e43ebbb\n",
            "Downloaded: 23beb49169c39a7199049f498951497baf71f2d896d89d2436d1b506092f17d3\n",
            "Downloaded: af4071b55b92f56fd18c3338b10f91b62ccdc49cf2255f0e73390d44b63a3426\n",
            "Downloaded: a9563f2f0cb88930cf49da9051bd054333c8db2f7bfed5b189a3d735a52f3685\n",
            "Downloaded: 73f12c37caccf5c31c30ade3640d69e954cf0532b4de587ae73c1fdaa73b925d\n",
            "Downloaded: 57b7249fa4233c13f03f3694d37a7cbfaffeca7f9d3a62a5a2bb6af8725ca1b0\n",
            "Downloaded: fafed8cfcf24fd40063e4f983c53975056e7b4f2721177b45ba74a9252f1af49\n",
            "Downloaded: b7610078b5181c3cfcaae3c60ec7fb68c409876e765e45752ff263ab3b40b596\n",
            "Downloaded: 83214714e0e24d23bb502e52edae5583d995ee360a55c03ff07216f4b14d9ae4\n",
            "Downloaded: eb4b4f9ced2ddf7133f1149c43075b4edfcbcf1cf4bc60c002721a21f41d08a8\n",
            "Downloaded: 475bc32b36aecb180d6465d9fd2ac65c646fa8da22ef631eb565639297f42a0e\n",
            "Downloaded: e21f2eb43567e12f871f6ffa8ce56531302406174c09966c49dde80357f0a574\n",
            "Downloaded: 768e50768417c4a73d0b267a1be59f978df1e97a4e77d6998a46969e11c5db23\n",
            "Downloaded: 61d534df38137e6d32d2dc9d792a98225191aa2778767ea82b677eaf1c8592d5\n",
            "Downloaded: 9d0669fd0b0fb1d0bf47828765739e49f99f3d150b25f8abb9c929b62b23f234\n",
            "Downloaded: b3f5ed15438782d2a283cd7801167c57f5cc7249d2948464305f76ae6590fdb7\n",
            "Downloaded: f7ca120c8d4c7e8b5f95061e6bbb4870886ebab074b886daa983b05f4316e556\n",
            "Downloaded: 52d1387ff0e0e579dc79d6f8ef80ed80ba3ca88756bb7d55071cd4ede1c25ec1\n",
            "Downloaded: acf9814a6ad1e6f715160bc02b19f36fa56cfe381cbd6f2977f8114816e14c5d\n",
            "Downloaded: 6816f17f59c321f79fac62d93f18b9a47eaa29e5ee8aae0c59815b09ee7fbd34\n",
            "Downloaded: cf40d1f0ca5b3a0bc4db0ea1ddd893d40ba58e39a015fc36e55d36b4ff3c81ac\n",
            "Downloaded: 6990f179d74cd93d0e4ab1bbf48068113ead4ab7e7e9af3f870367ba71958948\n",
            "Downloaded: 03c5c2d8baac404f3ead8a23b991a512d1cfdb7f1b2da25547da1e775396c7c6\n",
            "Downloaded: 17188e5fef5c82ac823a3510012f50146b71b3bf1c977df051ffb7a00a0b7fa2\n",
            "Downloaded: d8e0ca69be7d17159158d9f45d6b51bd07540a537a6b2c614cbdb26e58e4d997\n",
            "Downloaded: 9ba67263f59552e271733ba3bb2e975117ddb2dcb80cde185e2498fa2e998eaf\n",
            "Downloaded: 7098719eb6ec3b873f70b60ff4d17485507d08c4e516f224a7ae725af0f99732\n",
            "Downloaded: cdc4f0b52410f6f96741641bd6d57a08dcbcaf504de9952d6fe1aa55461229e0\n",
            "Downloaded: eca8b1007c85b84c5ddc266c4b93884345678fe1fb1ee1bdc74ea7c43b2add6a\n",
            "Downloaded: 1eba84de83ad7fe8373769087ee37a82ffeb4469461228bbf4758ff33de110c7\n",
            "Downloaded: ffbb456bb96709edda3f15e351c3bd769a061ffcf8cd4be31b1e2c839ad85d4f\n",
            "Downloaded: 508bac5a737ea6bb1e9ef8af0c94bf935d553e167043786e9f70cb3799abc139\n",
            "Downloaded: 6e8065210b610fddfaf452928bb2ad13162c65f3452a34a99b0f926d496490cd\n",
            "Downloaded: 950ab758892d05df0d7dad58a9a65612bdc275e89b080f9ef288a7befd72d459\n",
            "Downloaded: 864f4d8f5053dd87b95b0d84c056229fb7166ecaaf353b4217b136b23abf65f8\n",
            "Downloaded: 84908a5bc5aab590e3d30b1d4e1030c4c086075cf83f13bedaf7e246da578111\n",
            "Downloaded: 2062d91601dd218b102b5e42e53769a5b2f85f5e56bde384321f491569fce4a6\n",
            "Downloaded: a2251d3a692e51e8a443cd8bc908d97b5a8913030461e2139336f75e2e4da53e\n",
            "Downloaded: c7e6ea02d0d51166eac81586508fa520dfe638874c54be4bd27ed066a891b346\n",
            "Downloaded: 9a749a5f7cdd508ea0ead7deb41d3c1c5cb334e8881e8dd04a19474b7040814d\n",
            "Downloaded: 8ecaa5b37d2b8e5c1557cf58cf82046d2418bb37b4c8a111a89bca18574784ed\n",
            "Downloaded: 657fdad7500307bf7c5ed47b2af6bb67d30c9be19585b7fdfa0a488b8a0bd9de\n",
            "Downloaded: 7344dede3c30d3aa12c4610ea83ed369de6598e8abdf44ff24e58adbc653bebf\n",
            "Downloaded: 13954665300ee55df240fbbb4f09bfc3bfdc6e6614b3d46d4aacce536b47d85e\n",
            "Downloaded: b7e6633b9ea652693ed7c04f538e3a8d68e8905daeae95d7d6c013fd7d342883\n",
            "Downloaded: 538f4c0ae2c2f688f01b192ccabc2c86407a36b4f73ee734e2c236d1a7d49eac\n",
            "Downloaded: f37f65907d127d9b057d94844526d5a53dc494304858d6a4f4c6f6eee3cab3e0\n",
            "Downloaded: 459cb6c6be2e511a34722179d14dabbd040f436abdafe77d803e32c47caf631d\n",
            "Downloaded: 1856cf25790fb4c41dc68f70b165bcb565e631a9df133b032dfd7e1631f2cf81\n",
            "Downloaded: 2697f93b0831db1b74847006e92813595f85fa5041ac41fbbb5c26cce0ff55e9\n",
            "Downloaded: 56ee83ec39b3ee2b830decf8e4e5a83e6d53006bc5a02a92e4e115553d0e8b94\n",
            "Downloaded: 079a8a80fd90cd89f1d6cfc4725b4356642fea01ca75ad6c0bf2b9c03b043455\n",
            "Downloaded: ceb75f2f720d5353528df236886defa71bf865112c0e786cfddbc9d7828426a3\n",
            "Downloaded: de59afceb2435a0c5e6e8d48ca7d1fb3636aa7c3672726ba1faf73053e81903d\n",
            "Downloaded: bf19b207b782167a84e0c10fb38c0b439672c969fb511e3edcb96c91da14fcd5\n",
            "Downloaded: cb4e3ed9da47ec0e7117001868335d13b0e00fb853039f23db5a91b8f1631bd3\n",
            "Downloaded: 6861c93c0bf26eea778130bb5a3d12b31cbe6d486971f772008bd533964eb899\n",
            "Downloaded: 10b41e82122a26bab872c6276159d9bf7f251c7b60c7bff2a25fcfe795860ba2\n",
            "Downloaded: 3e60a303dc83d75f540bd3e17b5463b7419e38d43896867e4f001635201ed788\n",
            "Downloaded: c7d9a4bc8d8eb190404768096193fdd76204f85346ba3ff4d6316d4e89f12a88\n",
            "Downloaded: be34113370def6ce47ef7b88c96a9608c0a98ee2e664d1821f7c4a145fb48246\n",
            "Downloaded: 1d55b3f750ff5a848a2510d5539b9a30ab814ad2015d170e2e1386b3a89f806d\n",
            "Downloaded: 3ea781d051714c11172860060f31cd7f60e5c1c0970170efcbf8d87ea42f60bc\n",
            "Downloaded: fafdff1608794cfd0dccffa29a55e678ffec03e9ef440ef4f7f3ff4138be7375\n",
            "Downloaded: 1f019c227223cbf35ed1d6db9c9053a7a41cf321dd58a1e29865eeb470dac722\n",
            "Downloaded: 9890930a1f1075c6cd464cb96585f0f6b8e1298e0ef9306c650ee3ad64eec0b4\n",
            "Downloaded: 5b1804ff100fa03fe42d91bf65aa167458d0090e0a418316d1b804a8990b7dbf\n",
            "Downloaded: 10da7dec99dd3c6bc3a0aab7d47bf73709479e014e6e24ff37d166397694471a\n",
            "Downloaded: 088621f80a039216cd27872315dc99f8f1c352e2d5de65e1dd3f7d11de59839c\n",
            "Downloaded: d5fab44e5f413b2e6d1b858102a6277c7e4ff7b96576c6c3b19891c3ff72ea60\n",
            "Downloaded: 640083bc2b875c52acea355cce87c72e98687495f7e23489eca1b5eee92aea3c\n",
            "Downloaded: 66c02f31f7b3095911dcb4da1b3de24d7c5611675ab8163180440d3f230a47f5\n",
            "Downloaded: 058bec0cf3defdb1403e9dc6368c15b4b38a63d97f44f19b17221bd114898c36\n",
            "Downloaded: f0c1a0ae85b4abe3fdef552a8e2f90947e0353ca6cec87b81364e0e05fd300ad\n",
            "Downloaded: 769d1d63b073500dfa60485a40d1558a4aa002399fa1461bd7804efef2e15f17\n",
            "Downloaded: 3f7c5b76bd171d77e0dd466060f0c89ad9f85d891500efd27001f20711173641\n",
            "Downloaded: 97f74b9831db899827365fc8646fbe6f982270bc2a01f649919c0f10c3e39651\n",
            "Downloaded: 08aa1d7b6c96384a54ada3510cab0b10d2af72aa9fff62fb9c34f669f2abe147\n",
            "Downloaded: d51fce22af221428bbcfb6f155bd87c6de3e24faaf60deb05e75d2dc9ad89b2d\n",
            "Downloaded: 6aed71bfb8be9ac17680b20b49ba978919ab3c8034af41cafa508270e0ff5d91\n",
            "Downloaded: eb76b9354162c747ae7320aa11cd023dcad2bc9693240e48948c4332cfbdafba\n",
            "Downloaded: 6ececf4312d0cf4c6f324ec7d38a5dadb1b38fe08b0bdebfef5c257f83365b32\n",
            "Downloaded: b1bbd3bb482c99e942508d683596696985fc8e5927fb0a094b9b7a867d217fd8\n",
            "Downloaded: b3982633eba2cd32e9e76b2151bbd65347c58e175bb9376659d32af8b1039b41\n",
            "Downloaded: f7f36e664f5165116da57da61af9c7169e6c89721cb64fc3f91da65bc6135ec3\n",
            "Downloaded: 0a59ac59fb5babadeff20fd3f4656d9a74ba2e81982cc22827de676fc8081a25\n",
            "Downloaded: a4d8853cbe9e6d8589d826d314a3b1305333aa3aea2a20b23400c9fb7e4d01fc\n",
            "Downloaded: 59d922f246c9267cc531d25e9990defa96c4e964e7f3cfe525f06dc1d385aefa\n",
            "Downloaded: 5e5ef7a915deb4c9e049f44c2f86e6db85b38f5acc1bb0562bfb878125159ab4\n",
            "Downloaded: 8dc71dfafc5a6611abdea3201f653151e0f3f8cd1eb19d636add69faf3b36b54\n",
            "Downloaded: 921a1ab9021c25d50bd1597aca9e5d006af9034926f23cc390ec50dd70b056d7\n",
            "Downloaded: ff7b482d1bacf53f1e8dd2da5b4c03fdb1e1e209beb663bfb0e24998bcc2eea5\n",
            "Downloaded: d02f7bc16e02efbee66706d82a462e89ee37bfe0672a9e6d7d745b1639d6a001\n",
            "Downloaded: f58a8df2711c23b3a8ea5757a0ec76055c38e4ee98e2c34b6b7367e00deb41cc\n",
            "Downloaded: 28589b704246fe7c02001d314dd14385812b375fa3de93b43fa37f178edf3e49\n",
            "Downloaded: f07f2af179cdd4e937051ecd252d2d81d6a2956b7bd4d2cc51f15dc0a947ebe5\n",
            "Downloaded: 96c1295fad2265b39e52a3ab6f5516db1ebeea573f77e967a2008852de28575c\n",
            "Downloaded: cca7e6de1390873e6d317fa6df04c311e90006301b917b949cd714721a56ce5d\n",
            "Downloaded: 9c28d6b27c9af01c110b7bc4ed73b7a190e7aef1208b5b272080bcc6c8875529\n",
            "Downloaded: afa32c759e3f553c51a3405672a38bf4a7751af0aafac889f2080cf6bf176f46\n",
            "Downloaded: a7078679810cec76410e8d5689c2352b9c220f99cab949f775f38f67cd5196d1\n",
            "Downloaded: 96e5de35a3d153b579d9d228d82320b315fd09c20b036caaa52eef98c8c1ee2d\n",
            "Downloaded: 60f447e0a1e0484bb0d6f2dec702b98d0e7ebacd94e0110f2bc075f599ed6be9\n",
            "Downloaded: 99ecf308277ebc1455d6d3fa23aad08af6b24104afe8d4301e6b6b95ab138883\n",
            "Downloaded: 668ad0ba2c30df8942bcfb866ce877c83dcfddfc692d7006ee896ce39d1b3aa2\n",
            "Downloaded: b492ab56241a75eaee61b9e83df341ec9e80f016f2406d75737f136542f49a3c\n",
            "Downloaded: d17279eab7fbdf94d263e1192b545255ec13e34194afed0b32d66612de734baf\n",
            "Downloaded: a2dd7edb01cb4e6892a53c4d04e2d91f43b30cac7c9621bc59d1de889cc1fb79\n",
            "Downloaded: 7d67e0bd000e94b35f34ba9f5040c76cbcfa2c5d374390d469944e628ba779df\n",
            "Downloaded: 8fd4d1f1186f41f048d4de23c6417d30a36ce1d246bd579f38f497c634fadef7\n",
            "Downloaded: dcaabd004f7e8b643a6f8f039ae5f9bf05489c105fe862ab3f546d39f796d2ff\n",
            "Downloaded: 78e4da9fcde48d7f1c75e7694bf743c65063470ba440a06faf4fdae6c4832277\n",
            "Downloaded: 3b82de7dd8dc0d54aac53e8de87be6c855925649a9f62ef46307cc35fe158e2b\n",
            "Downloaded: 5b78d8b11f4303ca31ff3f3ed69cf9233708030e017e4f105b239236030af7a8\n",
            "Downloaded: 31c07ec57d9385244787d1df958649cc468abb6291037cd254c41a7cd9ad86bb\n",
            "Downloaded: 354467557eef19253c08369c607d85e7be0d148e43b267fce9bbe3a988319db3\n",
            "Downloaded: 1157d4bdb0d20fccb9289d56d96bbb89d764906331d151f06273f4a67a4e552b\n",
            "Downloaded: 29266c9201bf10c70040ce87a53df3f46255069caaa54c4036d4f4aeff738244\n",
            "Downloaded: e37959970e52cbd31174f9336fd63f7657902c3ff4d54e1d11fa10119a4d268f\n",
            "Downloaded: 88c1190b7497df118ca3a080cbf0da2593e806897d3892244b9f10393bf2fa59\n",
            "Downloaded: f08e7f927c95ed84f4bd3c84f4e6c87936c6a7e1452a27be3e9d84b43eaac8e5\n",
            "Downloaded: e34c43fc835d43357f6f2e2e744f81d55f5f67c36bc619fd2983b47d0b2ca021\n",
            "Downloaded: 2bc084c401a0d29b7bdbe7c0aa70735e827e35a980a52705924e77fa7b28fe81\n",
            "Downloaded: 2daf48ed3e6412b580cc22ca9dcbd1bdadce53ca5bc9ba80cec2f18cf350cd80\n",
            "Downloaded: 2ebafcffabab67a1ed496595ebcb3a1ecc81111d80c5c30269d51e06e4fa833b\n",
            "Downloaded: 0a92dafa9b3d4f8578b61dd5b9a04cab1baf3dc2e7137dea86fcc588d76f2aa0\n",
            "Downloaded: 921f857d2f0faa9b327f1f074c5f71af83a11b7a8ad6ffb8107571f55db2bcaa\n",
            "Downloaded: 697753d94c3483af60e31033cf047d6967ad74dee07a14154d32dafdf6029242\n",
            "Downloaded: 5a051784032d8e15b0367c8e2e08e8a870f07d11620383fb0d83379290b36bfd\n",
            "Downloaded: d03a7504a836d7953793ee84a5f15087b46ce93e840d14c2a600ade0174fcecd\n",
            "Downloaded: ee6db6a866079b2a324b31d691069796942310aef9a0b46e5af46bcf787d62c0\n",
            "Downloaded: d8dc2baf6dc76f5ec23d6ebf763099cd25e8b85f52b2b4b375d99a0599eaa02d\n",
            "Downloaded: 3d76bf1982ce100be4175363265c2a84a217120e56afb6294dedb8ebf2106c84\n",
            "Downloaded: 91eb3cc74756c5d2abb41cd6cf002a8d9cf1822ce265de69f7f7fb30b6d87032\n",
            "Downloaded: 2a26b8a0b4fe2ebbd5f99741e7d75dcd0023137bf41309fc05cfc05b4bc29ad6\n",
            "Downloaded: 9a6058dfe0f743b2d3ff9afe5b472922ef570caa3bb9070ff4015a6203848eae\n",
            "Downloaded: 87c94a783b9084bd22d250a497d40d984711d8a892514fa0c982e7ff5a9aaf77\n",
            "Downloaded: 5c0d4d7c7599d8a587cb84b8be7c15f761d9c10cbfd2c9a9c6d085b2381ab0ef\n",
            "Downloaded: 7b62ebf0f4a0c58bf05bfd3a53f58906d36c556866fe0bf26fc0b458a42a4c1c\n",
            "Downloaded: 48c2896a7e38e82450c3f7a9533f659aa19aa76e944dc75adbf4cfccf0d27b75\n",
            "Downloaded: ac043c3da429a6a811ce1c504fe4e799f1ae40b665953c1e47a33446fd0fb758\n",
            "Downloaded: 2529d646a85a790925664b88be7372db454b395099ccfb88e6faca5edf3de509\n",
            "Downloaded: 5e9c100cb52f437592d320ba75024b989c42297e3a3745735489a4489a427827\n",
            "Downloaded: 44d0eed86107ed54a6df2bd97d5470e86bbf880aba624f8bb77691cb1c9e1996\n",
            "Downloaded: fa57bb3e381ca3b375b7f41a7f21d16198dfdb20c619700570b055fc16c2d1ff\n",
            "Downloaded: 1af7798640d56ad5a7c1832b67a11bb1060fb7d6130b5fa0f157a3a024d2d823\n",
            "Downloaded: 7a2ef315c722bb8d446ea33ac1eab776e6c2a52c2dfbdd80153fa4c771de047b\n",
            "Downloaded: 8ff21c8178ce15244a96bb6782239a57daddf220f5faa331cbf5e65cc2849007\n",
            "Downloaded: 2031d80afffe51d16d4a77ea9c49d2f4abcbe5c5709267e56bcaa9a1a460cb1a\n",
            "Downloaded: 94b117aecfa1201da2683be9083b5d1bbc363dab13b282c0b37a732a33b8d6f3\n",
            "Downloaded: ad9b4e52eb2c4c944d0abb0b892e67631f1b254d18267239a6f0364ccb40f389\n",
            "Downloaded: 080c5c12af698d2a0f7016734a97395f62b7c2f4560a916607315fe8ecffb75d\n",
            "Downloaded: b720b23c5fff628f28afeb218a79ad4aec651cdf97e8d6854f0f4e261c98bfa7\n",
            "Downloaded: 88b2690cb87aa04daf27cf2242f7d1455be6d90ad5e2f1230fba78cc1a09bab0\n",
            "Downloaded: da748e8ce183245c3f29c41909e00d4705456704f5a6db542ff4d84e0099b4ae\n",
            "Downloaded: 69d885fcde4941935b5151f43fce7d52aa2586df77117e33118bbcbeb4c9661f\n",
            "Downloaded: f164593df5ab99f47ae942d10bf6d8ea6623e91159d950f078540b652ae114b6\n",
            "Downloaded: b99d2b35d963704edc24c73c92228e76efb4307175b0f2831cace8cc1abc950b\n",
            "Downloaded: b0ed3d799bee97d0d647fcf976953c47bf24c471cfb5d247969cc177e417d563\n",
            "Downloaded: d5f55e8a8988760b7bef925def23f48e0635335437b17eb0c95af362c083a1ee\n",
            "Downloaded: 9995ff60e8bcf3c7aa7dce3f5b3c9c07519312ba09f2420a13178939680c755d\n",
            "Downloaded: d3c984f409ee4dc5e9571862e8e1f5bd294c576b9b98e4f51fa646ecc8d3a02d\n",
            "Downloaded: b6dcfddc9237eddc6cda27df582352ea2428cfd7082084df4430b299b401f8e5\n",
            "Downloaded: 0a6d0e476e4afb2b72f1b34cfb63bcfc6d08232f34407b9f206ef8c66b094756\n",
            "Downloaded: eea555bf579badb832da8e847c95dc88a46d4b2dc7e96e2d4e85e25751c3a606\n",
            "Downloaded: 06e3d922307159039801b1c135192dc148a64a6211f3ed102226107e46a15dc5\n",
            "Downloaded: 45493d3a7d40f298778558b9871fb448402cf9fa71d458efab286c4ca4393b6f\n",
            "Downloaded: 8d499a907ae9f1d372b8134dc43cd49fed281714f3e0702d3e1e023897556280\n",
            "Downloaded: 8c94d2f79d84e5578c55eabd41f918efd4bdcf97235b8a6ab220f2da02ba3eb5\n",
            "Downloaded: 6c4393784a46b16e054b8e63e470883fb7f2b0cb3bf3ed58b0359077d0166ad9\n",
            "Downloaded: 794325ccd4d9effea52c1a3881e1d491bf3b73184049f87b9c84099c954e3f66\n",
            "Downloaded: a4e8b75f3868fc5665d23df0d2bf31a61f5d3e2b2f86b1c6f99f4222c14596f9\n",
            "Downloaded: a0a55b0003922fcd3a2839d9c6db84c9d65f80bb7ea448f67812f6c502aabf54\n",
            "Downloaded: fe81d5d04886f46cc30b446dbe1b9050be8ffd0dde95475c9c88019e05d8f515\n",
            "Downloaded: 2a3799405aafca76ed018e81fb92141a3bf386647b96073df37c47a71b493526\n",
            "Downloaded: b5d32928cfb205758e72700a5b88a2000a6ab9d5483ab227f1cfe6d46fa343c6\n",
            "Downloaded: 0950070565ab7508d0649bb4d2f2af9ab97eb2802d7fd182586c37e075c2e1d6\n",
            "Downloaded: caa768fbbaf6a65d57a600a1ace47dd7a2d7b0dc163586399a5616b2edc19bd8\n",
            "Downloaded: dd755e9f0f642331e0539220c325182c7e65b33215074cc78f59e7a117542496\n",
            "Downloaded: 9bae00f1b3ae6ec3a747762448a79de345283b0ed94c9130451ad12d25cb10e8\n",
            "Downloaded: d4f332132ab578d0ec23fdb2f7eeb2836cd68004badaf2d2d618fb2627d67265\n",
            "Downloaded: 229bca001e030c8b9d442f86b26d8d414cd482d4c88254e51dad31a8f25665f7\n",
            "Downloaded: 8a05c8fd37abfbd0e1b0482fc9362d0957d89cf5b14ecb6ac2a51410e1b29aca\n",
            "Downloaded: 783f105a11aca72368d9d9553146c9498ba4a1f1f0b88d42b87615644a966003\n",
            "Downloaded: b2d2bcf70521bba4b0036df51877f558ccb978cc5537cf70afa4e730aef5a70f\n",
            "Downloaded: 133f167433bb0e01f241ccbe0ecac627f388416490d9d1a2435b4476bd21898b\n",
            "Downloaded: c2a48e5b33a3be3dd0bbc3d00a837184e2d0576e4c0431db34515f70f7b6eedb\n",
            "Downloaded: 3b1be8251a04f22e41ed08ea23e2eec55e2b2b8f57e193fb10bc51c07b148d8e\n",
            "Downloaded: e9f48d03c35351f9880ed0ce27e08a4442c731ab20333fe1e6dcf184e25e8d55\n",
            "Downloaded: 2125c3b3a89486825e37c3ed3c1ae3b6abb5c2c3d25ea4573d400e55e9805c45\n",
            "Downloaded: 8b4c49233e27f7054ca13449b37485f1b2807c104e2e31b59fbbf35ee152731b\n",
            "Downloaded: 586db24884a936918d9424d803a7f179be5133156a8f6823ae45c2b77ae920f7\n",
            "Downloaded: c3d4021d0207ddb352e6131f8903bf96bad2a66a78b7182d77310dd514e29b09\n",
            "Downloaded: f162b9696dfb0f662ffd711ec29e770540a81851296f5d605e30d12d2dc9a8b1\n",
            "Downloaded: 78608ccc34ef4935a1cf49703760b04104045c94f67a66f90e7e350560da48ef\n",
            "Downloaded: 15243a3900f9d631770851edc5b40fb110981bc8df1869c8307fad889a7cd8be\n",
            "Downloaded: 5fce19ffa89d32308cac6ee0b6f1ab0f1d8e8c592c795f50b774f197d8fd143b\n",
            "Downloaded: 2d160e5eaf35b84ae1437f40791b430185304ba3769c7c22b28622502ece0af8\n",
            "Downloaded: 4d45592b2c2382a3620b02cdc21afc9d628072c162fef06d46d97eb3210e42eb\n",
            "Downloaded: 1f8060f69a1a866829664743c402998a85b06f940687dc1b19d88feb7f29896e\n",
            "Downloaded: 3d646a137c6ad440dd79ddf3fe16dbd10a31e602e3889a077c54ef602f3c3882\n",
            "Downloaded: 3463c97a49f9924fce637e14e8897242c199f82695eeca9288253b7e54dfb7f1\n",
            "Downloaded: f708494db86db2de184d90205b695a64f51e46d7d21a7f3e3fcb52449d0bbfb4\n",
            "Downloaded: 8372ce09809a8c9bb0e9b7860f1c22bbc7246189d2da27308fb852e8a6bd3a4b\n",
            "Downloaded: b0f1839158ed983fcd73cb14531edecccff63b2581be3196aecc811b75863529\n",
            "Downloaded: f661e66c975465b0ac4170fef3d652ed317ff44ab06c74028dba022fe41eb311\n",
            "Downloaded: e9e7f879dbe9d7ff2e9c3f2dea011a39acf92c42ce0cd393f89555580de03ebe\n",
            "Downloaded: 6ab71a4879e31508a22b52863672988113a7ea45508f741cca6dd1c855021c87\n",
            "Downloaded: cb2f71b81ddda3cd6319077c9af320f4cb5b91752d87ab44fc95b902f8724d88\n",
            "Downloaded: 4a26ec58293a7a3840afdecbc17a92ee8faf37ee30e6072aa3a9d55ab76ce475\n",
            "Downloaded: bb38024c8667cb7161ec9c2bafb08f7b59f88df4292a705b31e3bf689a00d878\n",
            "Downloaded: e5350db6acf148fd2eeca2436e3b13c11b726624d709ed4ad7b3d10ea1799e67\n",
            "Downloaded: f2fd0fb7ff30b3bb490aa4399e71d2f74c5892d7bbe182bb6cf34354f6de336d\n",
            "Downloaded: 766e5685b347999a5238e798e2fdb63e600c5c4f0157605bc984abf142214c32\n",
            "Downloaded: 5bc37cc7d0911e3c00b006fcca1032b84a500164fc458b67ad5f578984d55acc\n",
            "Downloaded: 130bdcf8746fa8aeee5f9c46f672b078252af7c6e6c35c5bac2b8854a9e1e8ba\n",
            "Downloaded: 0c166120c3194a4ed536e1ea095740e7e8dd978e6ea704cadf15039ed73a9fc6\n",
            "Downloaded: 68fdce3125bd00888aaec02924be40a854c31ceff5b1e633c4e17bd40e9b6601\n",
            "Downloaded: d688e356753a9d52cc802e03fe58bc8f8d480ebeb546db3d84fabd4cde68af0d\n",
            "Download process completed.\n"
          ]
        }
      ],
      "source": [
        "## download malicious samples\n",
        "\n",
        "# List of SHA256 hashes\n",
        "sha256_list = malicious_sha256\n",
        "\n",
        "# Base URL for the download\n",
        "base_url = \"https://androzoo.uni.lu/api/download\"\n",
        "\n",
        "# Destination directory for downloaded APKs\n",
        "download_dir = \"/content/datasets/malicious/\"\n",
        "\n",
        "# Create the download directory if it doesn't exist\n",
        "os.makedirs(download_dir, exist_ok=True)\n",
        "\n",
        "# Function to download an APK file\n",
        "def download_apk(sha256):\n",
        "    params = {\"apikey\": APIKEY, \"sha256\": sha256}\n",
        "    response = requests.get(base_url, params=params)\n",
        "    if response.status_code == 200:\n",
        "        filename = sha256\n",
        "        file_path = os.path.join(download_dir, filename)\n",
        "        with open(file_path, \"wb\") as apk_file:\n",
        "            apk_file.write(response.content)\n",
        "        print(f\"Downloaded: {filename}\")\n",
        "    else:\n",
        "        print(f\"Failed to download APK with SHA256: {sha256}\")\n",
        "\n",
        "# Set the maximum number of concurrent downloads (adjust as needed)\n",
        "max_concurrent_downloads = 40\n",
        "\n",
        "# Use ThreadPoolExecutor to run download_apk concurrently\n",
        "with concurrent.futures.ThreadPoolExecutor(max_concurrent_downloads) as executor:\n",
        "    executor.map(download_apk, sha256_list)\n",
        "\n",
        "print(\"Download process completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/datasets/benign/* /content/malware_detection/datasets/drebin/benign_samples/\n",
        "!mv /content/datasets/malicious/* /content/malware_detection/datasets/drebin/malicious_samples/"
      ],
      "metadata": {
        "id": "nAfcwLqiwQMc"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "folder_path = '/content/malware_detection/datasets/drebin/benign_samples'\n",
        "file_count = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
        "print(f\"Number of files in benign_samples : {file_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdrYNqv2wZdP",
        "outputId": "89fb42d2-6ce2-4f2f-ab59-88afc54b6af7"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files in benign_samples : 286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "folder_path = '/content/malware_detection/datasets/drebin/malicious_samples'\n",
        "file_count = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
        "print(f\"Number of files in malicious_samples : {file_count}\")"
      ],
      "metadata": {
        "id": "v_5Jxz4YOQ_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d21ec87b-1be2-4325-8790-6edc0d6cd265"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files in malicious_samples : 281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzBRqKm_zhKY",
        "outputId": "9fe60f5b-108c-44c8-f3b7-1a8b2c3be129"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasets  drive  malware_detection  model.pth  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Open and load the Pickle file\n",
        "with open('/content/malware_detection/datasets/naive_data/629e1bc6a81d8b717dbcc0a942e60036ea61baf134e013b58bfdd2b2c06eeac7.feat', 'rb') as file:\n",
        "    loaded_data = pickle.load(file)\n",
        "\n",
        "# Access and use the loaded data\n",
        "print(len(loaded_data))  # Example: Print the loaded data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYWQwzfh0vdQ",
        "outputId": "1fef48d2-384a-444f-a75d-65a39aad7bfe"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "# Add the directory to the Python path\n",
        "sys.path.append('/content/malware_detection/core/defense')\n",
        "\n",
        "# Import the module\n",
        "import dataset"
      ],
      "metadata": {
        "id": "I_AvzHRf8UDi"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = Dataset()\n",
        "data.vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gx3TRAv8XIK",
        "outputId": "5a0e8a85-b2a0-47a2-86ab-9f5e5b0799df"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T4kU9GgU-E1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Open the pickled file in binary read mode ('rb')\n",
        "with open('/content/malware_detection/dataset/drebin/data.vocab', 'rb') as file:\n",
        "    # Load the object from the file\n",
        "    loaded_object = pickle.load(file)\n",
        "\n",
        "# Now, 'loaded_object' contains the deserialized data from the pickled file\n",
        "len(loaded_object)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7SNCsE19ryW",
        "outputId": "850ec2cd-3fca-4ec1-d393-2e7243e82038"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Open the pickled file in binary read mode ('rb')\n",
        "with open('/content/malware_detection/dataset/drebin/dataset.idx', 'rb') as file:\n",
        "    # Load the object from the file\n",
        "    loaded_object = pickle.load(file)\n",
        "\n",
        "# Now, 'loaded_object' contains the deserialized data from the pickled file\n",
        "len(loaded_object[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpWvLjBDAVNx",
        "outputId": "63cd8623-bbbf-49c6-e05b-f1263bbe14d6"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_object"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEX37bQLAu6v",
        "outputId": "3ad15dac-8e30-492f-9fc3-3eee32c53023"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array(['/content/malware_detection/datasets/naive_data/689992492bf0914fc74f03314052e925df2425988f5cddcf54f0a1e0ca8692cf.feat',\n",
              "         '/content/malware_detection/datasets/naive_data/cbbc749de2ca1d14d22962c1fcef0978d98007a0f7da0e12263f7fc1d86c0a37.feat',\n",
              "         '/content/malware_detection/datasets/naive_data/e21f2eb43567e12f871f6ffa8ce56531302406174c09966c49dde80357f0a574.feat',\n",
              "         '/content/malware_detection/datasets/naive_data/f86c0abfe9f95f26d275dd4f0975a037879895451ac6a9c313c4b55b3b9ec5d1.feat',\n",
              "         '/content/malware_detection/datasets/naive_data/a5f2fb86a91ba354d0f17bdcd4fbfb15242a2e799f9944765eedbe6a9675e14e.feat',\n",
              "         '/content/malware_detection/datasets/naive_data/bd44570884469185b0dc9c12e04366c37a4df94b45d1235e04e7dac95abccaad.feat'],\n",
              "        dtype='<U116'),\n",
              "  array([0, 0, 1, 1, 0, 0], dtype=int32)),\n",
              " (array(['/content/malware_detection/datasets/naive_data/d64c37ae414c5c6b5cdb1599c44b3eea2f002fc934209ffc4485a09833eaa236.feat',\n",
              "         '/content/malware_detection/datasets/naive_data/fafed8cfcf24fd40063e4f983c53975056e7b4f2721177b45ba74a9252f1af49.feat'],\n",
              "        dtype='<U116'),\n",
              "  array([1, 1], dtype=int32)),\n",
              " (array(['/content/malware_detection/datasets/naive_data/629e1bc6a81d8b717dbcc0a942e60036ea61baf134e013b58bfdd2b2c06eeac7.feat',\n",
              "         '/content/malware_detection/datasets/naive_data/f575a2bb2c44f7addb126961234378b84956ff84254f523af03f6b2592645623.feat'],\n",
              "        dtype='<U116'),\n",
              "  array([1, 0], dtype=int32)))"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from core.defense import Dataset\n",
        "\n",
        "# Dataset is a class\n",
        "data = Dataset()\n",
        "data.vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOix0ER-yofk",
        "outputId": "cdec56bc-615d-47cc-9c44-2900556b0ac8"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/malware_detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xES6Dzx8O4z",
        "outputId": "29217d36-e504-4acf-a9a1-cc9bebb7aae9"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/malware_detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m examples.md_nn_test --cuda --cache --seed 0 --batch_size 128 --proc_number 10 --epochs 50 --max_vocab_size 10000 --dense_hidden_units \"200,200\" --weight_decay 0.0 --lr 0.001 --dropout 0.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLcONMaThGdG",
        "outputId": "118b8174-317d-41fe-bb64-54a5ad909369"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0it [00:00, ?it/s]\r0it [00:00, ?it/s]\n",
            "\r0it [00:00, ?it/s]\r0it [00:00, ?it/s]\n",
            "2023-10-22 15:34:56,390 feature_extraction.py[line:153] INFO: The total number of words: 592-644.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "2023-10-22 15:34:56,408 md_dnn.py[line:85] WARNING: Unknown hyper-parameters {'proc_number': 10, 'number_of_smali_files': 1000000, 'max_vocab_size': 10000, 'update': False, 'cuda': True, 'seed': 0, 'batch_size': 128, 'epochs': 50, 'lr': 0.001, 'weight_decay': 0.0, 'cache': True, 'mode': 'train', 'model_name': 'xxxxxxxx-xxxxxx'}\n",
            "2023-10-22 15:34:56,414 md_dnn.py[line:62] INFO: ========================================dnn model architecture===============================\n",
            "2023-10-22 15:34:56,414 md_dnn.py[line:63] INFO: MalwareDetectionDNN(\n",
            "  (nn_model_layer_0): Linear(in_features=1236, out_features=200, bias=True)\n",
            "  (nn_model_layer_1): Linear(in_features=200, out_features=200, bias=True)\n",
            "  (nn_model_layer_2): Linear(in_features=200, out_features=2, bias=True)\n",
            ")\n",
            "2023-10-22 15:34:56,414 md_dnn.py[line:64] INFO: ===============================================end==========================================\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "2023-10-22 15:34:58,881 md_dnn.py[line:221] INFO: Mini batch: 1/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:34:58,882 md_dnn.py[line:223] INFO: Training loss (batch level): 0.6972 | Train accuracy: 50.00\n",
            "2023-10-22 15:34:58,891 md_dnn.py[line:221] INFO: Mini batch: 2/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:34:58,892 md_dnn.py[line:223] INFO: Training loss (batch level): 0.6688 | Train accuracy: 64.84\n",
            "2023-10-22 15:34:58,900 md_dnn.py[line:221] INFO: Mini batch: 3/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:34:58,900 md_dnn.py[line:223] INFO: Training loss (batch level): 0.6394 | Train accuracy: 75.90\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-153456/model.pth\n",
            "2023-10-22 15:34:59,631 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.6685 | Train accuracy: 63.58\n",
            "2023-10-22 15:34:59,631 md_dnn.py[line:249] INFO: Validation accuracy: 69.30 | The best validation accuracy: 69.30 at epoch: 0\n",
            "2023-10-22 15:34:59,835 md_dnn.py[line:221] INFO: Mini batch: 4/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:34:59,836 md_dnn.py[line:223] INFO: Training loss (batch level): 0.6078 | Train accuracy: 81.25\n",
            "2023-10-22 15:34:59,845 md_dnn.py[line:221] INFO: Mini batch: 5/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:34:59,845 md_dnn.py[line:223] INFO: Training loss (batch level): 0.5601 | Train accuracy: 80.47\n",
            "2023-10-22 15:34:59,854 md_dnn.py[line:221] INFO: Mini batch: 6/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:34:59,854 md_dnn.py[line:223] INFO: Training loss (batch level): 0.5628 | Train accuracy: 74.70\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-153456/model.pth\n",
            "2023-10-22 15:35:00,476 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.5769 | Train accuracy: 78.81\n",
            "2023-10-22 15:35:00,477 md_dnn.py[line:249] INFO: Validation accuracy: 70.18 | The best validation accuracy: 70.18 at epoch: 1\n",
            "2023-10-22 15:35:00,682 md_dnn.py[line:221] INFO: Mini batch: 7/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:00,683 md_dnn.py[line:223] INFO: Training loss (batch level): 0.5177 | Train accuracy: 79.69\n",
            "2023-10-22 15:35:00,693 md_dnn.py[line:221] INFO: Mini batch: 8/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:00,693 md_dnn.py[line:223] INFO: Training loss (batch level): 0.4624 | Train accuracy: 80.47\n",
            "2023-10-22 15:35:00,701 md_dnn.py[line:221] INFO: Mini batch: 9/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:00,702 md_dnn.py[line:223] INFO: Training loss (batch level): 0.4514 | Train accuracy: 74.70\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-153456/model.pth\n",
            "2023-10-22 15:35:01,306 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.4772 | Train accuracy: 78.29\n",
            "2023-10-22 15:35:01,306 md_dnn.py[line:249] INFO: Validation accuracy: 75.44 | The best validation accuracy: 75.44 at epoch: 2\n",
            "2023-10-22 15:35:01,502 md_dnn.py[line:221] INFO: Mini batch: 10/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:01,502 md_dnn.py[line:223] INFO: Training loss (batch level): 0.4252 | Train accuracy: 85.94\n",
            "2023-10-22 15:35:01,512 md_dnn.py[line:221] INFO: Mini batch: 11/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:01,512 md_dnn.py[line:223] INFO: Training loss (batch level): 0.3393 | Train accuracy: 95.31\n",
            "2023-10-22 15:35:01,520 md_dnn.py[line:221] INFO: Mini batch: 12/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:01,521 md_dnn.py[line:223] INFO: Training loss (batch level): 0.3278 | Train accuracy: 91.57\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-153456/model.pth\n",
            "2023-10-22 15:35:02,149 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.3641 | Train accuracy: 90.94\n",
            "2023-10-22 15:35:02,149 md_dnn.py[line:249] INFO: Validation accuracy: 89.47 | The best validation accuracy: 89.47 at epoch: 3\n",
            "2023-10-22 15:35:02,341 md_dnn.py[line:221] INFO: Mini batch: 13/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:02,342 md_dnn.py[line:223] INFO: Training loss (batch level): 0.3421 | Train accuracy: 92.19\n",
            "2023-10-22 15:35:02,351 md_dnn.py[line:221] INFO: Mini batch: 14/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:02,351 md_dnn.py[line:223] INFO: Training loss (batch level): 0.2536 | Train accuracy: 96.09\n",
            "2023-10-22 15:35:02,359 md_dnn.py[line:221] INFO: Mini batch: 15/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:02,359 md_dnn.py[line:223] INFO: Training loss (batch level): 0.2345 | Train accuracy: 92.77\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-153456/model.pth\n",
            "2023-10-22 15:35:02,973 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.2767 | Train accuracy: 93.68\n",
            "2023-10-22 15:35:02,973 md_dnn.py[line:249] INFO: Validation accuracy: 89.47 | The best validation accuracy: 89.47 at epoch: 4\n",
            "2023-10-22 15:35:03,184 md_dnn.py[line:221] INFO: Mini batch: 16/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:03,184 md_dnn.py[line:223] INFO: Training loss (batch level): 0.2727 | Train accuracy: 92.19\n",
            "2023-10-22 15:35:03,193 md_dnn.py[line:221] INFO: Mini batch: 17/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:03,193 md_dnn.py[line:223] INFO: Training loss (batch level): 0.1842 | Train accuracy: 94.53\n",
            "2023-10-22 15:35:03,201 md_dnn.py[line:221] INFO: Mini batch: 18/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:03,201 md_dnn.py[line:223] INFO: Training loss (batch level): 0.1971 | Train accuracy: 93.98\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-153456/model.pth\n",
            "2023-10-22 15:35:03,842 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.2180 | Train accuracy: 93.56\n",
            "2023-10-22 15:35:03,843 md_dnn.py[line:249] INFO: Validation accuracy: 89.47 | The best validation accuracy: 89.47 at epoch: 5\n",
            "2023-10-22 15:35:04,047 md_dnn.py[line:221] INFO: Mini batch: 19/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:04,048 md_dnn.py[line:223] INFO: Training loss (batch level): 0.2126 | Train accuracy: 92.19\n",
            "2023-10-22 15:35:04,057 md_dnn.py[line:221] INFO: Mini batch: 20/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:04,057 md_dnn.py[line:223] INFO: Training loss (batch level): 0.1234 | Train accuracy: 96.88\n",
            "2023-10-22 15:35:04,065 md_dnn.py[line:221] INFO: Mini batch: 21/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:04,065 md_dnn.py[line:223] INFO: Training loss (batch level): 0.1399 | Train accuracy: 95.18\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-153456/model.pth\n",
            "2023-10-22 15:35:04,693 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.1586 | Train accuracy: 94.75\n",
            "2023-10-22 15:35:04,693 md_dnn.py[line:249] INFO: Validation accuracy: 90.35 | The best validation accuracy: 90.35 at epoch: 6\n",
            "2023-10-22 15:35:04,895 md_dnn.py[line:221] INFO: Mini batch: 22/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:04,895 md_dnn.py[line:223] INFO: Training loss (batch level): 0.1861 | Train accuracy: 92.97\n",
            "2023-10-22 15:35:04,903 md_dnn.py[line:221] INFO: Mini batch: 23/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:04,903 md_dnn.py[line:223] INFO: Training loss (batch level): 0.1126 | Train accuracy: 97.66\n",
            "2023-10-22 15:35:04,912 md_dnn.py[line:221] INFO: Mini batch: 24/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:04,912 md_dnn.py[line:223] INFO: Training loss (batch level): 0.1041 | Train accuracy: 96.39\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-153456/model.pth\n",
            "2023-10-22 15:35:05,528 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.1343 | Train accuracy: 95.67\n",
            "2023-10-22 15:35:05,529 md_dnn.py[line:249] INFO: Validation accuracy: 91.23 | The best validation accuracy: 91.23 at epoch: 7\n",
            "2023-10-22 15:35:05,758 md_dnn.py[line:221] INFO: Mini batch: 25/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:05,758 md_dnn.py[line:223] INFO: Training loss (batch level): 0.1798 | Train accuracy: 93.75\n",
            "2023-10-22 15:35:05,766 md_dnn.py[line:221] INFO: Mini batch: 26/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:05,766 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0992 | Train accuracy: 96.09\n",
            "2023-10-22 15:35:05,774 md_dnn.py[line:221] INFO: Mini batch: 27/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:05,774 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0707 | Train accuracy: 97.59\n",
            "2023-10-22 15:35:06,392 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.1166 | Train accuracy: 95.81\n",
            "2023-10-22 15:35:06,392 md_dnn.py[line:249] INFO: Validation accuracy: 90.35 | The best validation accuracy: 91.23 at epoch: 7\n",
            "2023-10-22 15:35:06,596 md_dnn.py[line:221] INFO: Mini batch: 28/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:06,596 md_dnn.py[line:223] INFO: Training loss (batch level): 0.1464 | Train accuracy: 95.31\n",
            "2023-10-22 15:35:06,604 md_dnn.py[line:221] INFO: Mini batch: 29/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:06,604 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0624 | Train accuracy: 99.22\n",
            "2023-10-22 15:35:06,613 md_dnn.py[line:221] INFO: Mini batch: 30/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:06,613 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0497 | Train accuracy: 98.80\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-153456/model.pth\n",
            "2023-10-22 15:35:07,237 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0862 | Train accuracy: 97.78\n",
            "2023-10-22 15:35:07,237 md_dnn.py[line:249] INFO: Validation accuracy: 92.11 | The best validation accuracy: 92.11 at epoch: 9\n",
            "2023-10-22 15:35:07,436 md_dnn.py[line:221] INFO: Mini batch: 31/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:07,436 md_dnn.py[line:223] INFO: Training loss (batch level): 0.1100 | Train accuracy: 96.88\n",
            "2023-10-22 15:35:07,447 md_dnn.py[line:221] INFO: Mini batch: 32/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:07,447 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0413 | Train accuracy: 99.22\n",
            "2023-10-22 15:35:07,457 md_dnn.py[line:221] INFO: Mini batch: 33/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:07,457 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0515 | Train accuracy: 97.59\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-153456/model.pth\n",
            "2023-10-22 15:35:08,086 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0676 | Train accuracy: 97.89\n",
            "2023-10-22 15:35:08,086 md_dnn.py[line:249] INFO: Validation accuracy: 94.74 | The best validation accuracy: 94.74 at epoch: 10\n",
            "2023-10-22 15:35:08,298 md_dnn.py[line:221] INFO: Mini batch: 34/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:08,298 md_dnn.py[line:223] INFO: Training loss (batch level): 0.1089 | Train accuracy: 96.88\n",
            "2023-10-22 15:35:08,308 md_dnn.py[line:221] INFO: Mini batch: 35/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:08,308 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0393 | Train accuracy: 99.22\n",
            "2023-10-22 15:35:08,316 md_dnn.py[line:221] INFO: Mini batch: 36/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:08,316 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0394 | Train accuracy: 98.80\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-153456/model.pth\n",
            "2023-10-22 15:35:09,333 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0625 | Train accuracy: 98.30\n",
            "2023-10-22 15:35:09,333 md_dnn.py[line:249] INFO: Validation accuracy: 94.74 | The best validation accuracy: 94.74 at epoch: 11\n",
            "2023-10-22 15:35:09,630 md_dnn.py[line:221] INFO: Mini batch: 37/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:09,630 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0710 | Train accuracy: 96.88\n",
            "2023-10-22 15:35:09,641 md_dnn.py[line:221] INFO: Mini batch: 38/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:09,642 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0318 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:09,649 md_dnn.py[line:221] INFO: Mini batch: 39/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:09,650 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0437 | Train accuracy: 98.80\n",
            "2023-10-22 15:35:10,758 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0488 | Train accuracy: 98.56\n",
            "2023-10-22 15:35:10,759 md_dnn.py[line:249] INFO: Validation accuracy: 93.86 | The best validation accuracy: 94.74 at epoch: 11\n",
            "2023-10-22 15:35:11,017 md_dnn.py[line:221] INFO: Mini batch: 40/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:11,017 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0833 | Train accuracy: 96.88\n",
            "2023-10-22 15:35:11,067 md_dnn.py[line:221] INFO: Mini batch: 41/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:11,067 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0236 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:11,075 md_dnn.py[line:221] INFO: Mini batch: 42/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:11,075 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0268 | Train accuracy: 98.80\n",
            "2023-10-22 15:35:12,173 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0446 | Train accuracy: 98.56\n",
            "2023-10-22 15:35:12,173 md_dnn.py[line:249] INFO: Validation accuracy: 92.98 | The best validation accuracy: 94.74 at epoch: 11\n",
            "2023-10-22 15:35:12,463 md_dnn.py[line:221] INFO: Mini batch: 43/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:12,466 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0633 | Train accuracy: 97.66\n",
            "2023-10-22 15:35:12,474 md_dnn.py[line:221] INFO: Mini batch: 44/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:12,474 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0171 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:12,483 md_dnn.py[line:221] INFO: Mini batch: 45/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:12,483 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0194 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:13,263 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0333 | Train accuracy: 99.22\n",
            "2023-10-22 15:35:13,263 md_dnn.py[line:249] INFO: Validation accuracy: 92.98 | The best validation accuracy: 94.74 at epoch: 11\n",
            "2023-10-22 15:35:13,463 md_dnn.py[line:221] INFO: Mini batch: 46/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:13,464 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0816 | Train accuracy: 96.88\n",
            "2023-10-22 15:35:13,474 md_dnn.py[line:221] INFO: Mini batch: 47/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:13,474 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0155 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:13,482 md_dnn.py[line:221] INFO: Mini batch: 48/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:13,482 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0132 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:14,113 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0368 | Train accuracy: 98.96\n",
            "2023-10-22 15:35:14,114 md_dnn.py[line:249] INFO: Validation accuracy: 93.86 | The best validation accuracy: 94.74 at epoch: 11\n",
            "2023-10-22 15:35:14,296 md_dnn.py[line:221] INFO: Mini batch: 49/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:14,296 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0483 | Train accuracy: 97.66\n",
            "2023-10-22 15:35:14,305 md_dnn.py[line:221] INFO: Mini batch: 50/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:14,305 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0098 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:14,314 md_dnn.py[line:221] INFO: Mini batch: 51/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:14,314 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0133 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-153456/model.pth\n",
            "2023-10-22 15:35:14,926 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0238 | Train accuracy: 99.22\n",
            "2023-10-22 15:35:14,926 md_dnn.py[line:249] INFO: Validation accuracy: 94.74 | The best validation accuracy: 94.74 at epoch: 16\n",
            "2023-10-22 15:35:15,147 md_dnn.py[line:221] INFO: Mini batch: 52/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:15,148 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0470 | Train accuracy: 96.88\n",
            "2023-10-22 15:35:15,155 md_dnn.py[line:221] INFO: Mini batch: 53/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:15,156 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0143 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:15,163 md_dnn.py[line:221] INFO: Mini batch: 54/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:15,163 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0152 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:15,756 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0255 | Train accuracy: 98.96\n",
            "2023-10-22 15:35:15,756 md_dnn.py[line:249] INFO: Validation accuracy: 93.86 | The best validation accuracy: 94.74 at epoch: 16\n",
            "2023-10-22 15:35:15,993 md_dnn.py[line:221] INFO: Mini batch: 55/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:15,993 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0333 | Train accuracy: 98.44\n",
            "2023-10-22 15:35:16,003 md_dnn.py[line:221] INFO: Mini batch: 56/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:16,004 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0090 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:16,011 md_dnn.py[line:221] INFO: Mini batch: 57/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:16,011 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0128 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:16,680 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0183 | Train accuracy: 99.48\n",
            "2023-10-22 15:35:16,680 md_dnn.py[line:249] INFO: Validation accuracy: 93.86 | The best validation accuracy: 94.74 at epoch: 16\n",
            "2023-10-22 15:35:16,873 md_dnn.py[line:221] INFO: Mini batch: 58/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:16,873 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0299 | Train accuracy: 98.44\n",
            "2023-10-22 15:35:16,882 md_dnn.py[line:221] INFO: Mini batch: 59/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:16,882 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0098 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:16,890 md_dnn.py[line:221] INFO: Mini batch: 60/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:16,890 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0078 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:17,497 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0158 | Train accuracy: 99.48\n",
            "2023-10-22 15:35:17,497 md_dnn.py[line:249] INFO: Validation accuracy: 93.86 | The best validation accuracy: 94.74 at epoch: 16\n",
            "2023-10-22 15:35:17,681 md_dnn.py[line:221] INFO: Mini batch: 61/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:17,681 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0268 | Train accuracy: 98.44\n",
            "2023-10-22 15:35:17,707 md_dnn.py[line:221] INFO: Mini batch: 62/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:17,707 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0078 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:17,714 md_dnn.py[line:221] INFO: Mini batch: 63/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:17,715 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0050 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-153456/model.pth\n",
            "2023-10-22 15:35:18,335 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0132 | Train accuracy: 99.48\n",
            "2023-10-22 15:35:18,335 md_dnn.py[line:249] INFO: Validation accuracy: 95.61 | The best validation accuracy: 95.61 at epoch: 20\n",
            "2023-10-22 15:35:18,549 md_dnn.py[line:221] INFO: Mini batch: 64/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:18,549 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0186 | Train accuracy: 99.22\n",
            "2023-10-22 15:35:18,557 md_dnn.py[line:221] INFO: Mini batch: 65/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:18,557 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0071 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:18,564 md_dnn.py[line:221] INFO: Mini batch: 66/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:18,564 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0079 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-153456/model.pth\n",
            "2023-10-22 15:35:19,217 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0112 | Train accuracy: 99.74\n",
            "2023-10-22 15:35:19,217 md_dnn.py[line:249] INFO: Validation accuracy: 95.61 | The best validation accuracy: 95.61 at epoch: 21\n",
            "2023-10-22 15:35:19,441 md_dnn.py[line:221] INFO: Mini batch: 67/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:19,442 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0189 | Train accuracy: 99.22\n",
            "2023-10-22 15:35:19,449 md_dnn.py[line:221] INFO: Mini batch: 68/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:19,450 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0068 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:19,457 md_dnn.py[line:221] INFO: Mini batch: 69/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:19,457 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0037 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-153456/model.pth\n",
            "2023-10-22 15:35:20,084 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0098 | Train accuracy: 99.74\n",
            "2023-10-22 15:35:20,084 md_dnn.py[line:249] INFO: Validation accuracy: 95.61 | The best validation accuracy: 95.61 at epoch: 22\n",
            "2023-10-22 15:35:20,295 md_dnn.py[line:221] INFO: Mini batch: 70/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:20,296 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0102 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:20,304 md_dnn.py[line:221] INFO: Mini batch: 71/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:20,304 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0055 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:20,313 md_dnn.py[line:221] INFO: Mini batch: 72/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:20,314 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0047 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:20,930 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0068 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:20,931 md_dnn.py[line:249] INFO: Validation accuracy: 94.74 | The best validation accuracy: 95.61 at epoch: 22\n",
            "2023-10-22 15:35:21,121 md_dnn.py[line:221] INFO: Mini batch: 73/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:21,121 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0113 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:21,135 md_dnn.py[line:221] INFO: Mini batch: 74/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:21,135 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0051 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:21,144 md_dnn.py[line:221] INFO: Mini batch: 75/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:21,144 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0097 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:21,772 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0087 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:21,772 md_dnn.py[line:249] INFO: Validation accuracy: 94.74 | The best validation accuracy: 95.61 at epoch: 22\n",
            "2023-10-22 15:35:21,962 md_dnn.py[line:221] INFO: Mini batch: 76/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:21,962 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0118 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:21,971 md_dnn.py[line:221] INFO: Mini batch: 77/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:21,972 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0046 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:21,980 md_dnn.py[line:221] INFO: Mini batch: 78/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:21,980 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0034 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-153456/model.pth\n",
            "2023-10-22 15:35:22,606 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0066 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:22,606 md_dnn.py[line:249] INFO: Validation accuracy: 95.61 | The best validation accuracy: 95.61 at epoch: 25\n",
            "2023-10-22 15:35:22,820 md_dnn.py[line:221] INFO: Mini batch: 79/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:22,820 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0098 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:22,828 md_dnn.py[line:221] INFO: Mini batch: 80/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:22,828 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0049 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:22,837 md_dnn.py[line:221] INFO: Mini batch: 81/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:22,837 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0037 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-153456/model.pth\n",
            "2023-10-22 15:35:23,865 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0061 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:23,865 md_dnn.py[line:249] INFO: Validation accuracy: 95.61 | The best validation accuracy: 95.61 at epoch: 26\n",
            "2023-10-22 15:35:24,194 md_dnn.py[line:221] INFO: Mini batch: 82/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:24,194 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0095 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:24,205 md_dnn.py[line:221] INFO: Mini batch: 83/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:24,205 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0047 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:24,214 md_dnn.py[line:221] INFO: Mini batch: 84/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:24,214 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0025 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:25,305 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0056 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:25,306 md_dnn.py[line:249] INFO: Validation accuracy: 94.74 | The best validation accuracy: 95.61 at epoch: 26\n",
            "2023-10-22 15:35:25,647 md_dnn.py[line:221] INFO: Mini batch: 85/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:25,647 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0059 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:25,655 md_dnn.py[line:221] INFO: Mini batch: 86/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:25,655 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0032 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:25,664 md_dnn.py[line:221] INFO: Mini batch: 87/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:25,664 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0042 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:26,726 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0044 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:26,729 md_dnn.py[line:249] INFO: Validation accuracy: 94.74 | The best validation accuracy: 95.61 at epoch: 26\n",
            "2023-10-22 15:35:27,062 md_dnn.py[line:221] INFO: Mini batch: 88/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:27,063 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0073 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:27,072 md_dnn.py[line:221] INFO: Mini batch: 89/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:27,072 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0020 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:27,081 md_dnn.py[line:221] INFO: Mini batch: 90/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:27,081 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0024 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:27,838 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0039 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:27,838 md_dnn.py[line:249] INFO: Validation accuracy: 94.74 | The best validation accuracy: 95.61 at epoch: 26\n",
            "2023-10-22 15:35:28,039 md_dnn.py[line:221] INFO: Mini batch: 91/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:28,040 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0041 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:28,048 md_dnn.py[line:221] INFO: Mini batch: 92/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:28,048 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0016 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:28,057 md_dnn.py[line:221] INFO: Mini batch: 93/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:28,057 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0011 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:28,653 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0023 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:28,654 md_dnn.py[line:249] INFO: Validation accuracy: 94.74 | The best validation accuracy: 95.61 at epoch: 26\n",
            "2023-10-22 15:35:28,880 md_dnn.py[line:221] INFO: Mini batch: 94/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:28,880 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0029 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:28,888 md_dnn.py[line:221] INFO: Mini batch: 95/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:28,889 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0021 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:28,897 md_dnn.py[line:221] INFO: Mini batch: 96/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:28,897 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0020 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:29,496 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0023 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:29,497 md_dnn.py[line:249] INFO: Validation accuracy: 94.74 | The best validation accuracy: 95.61 at epoch: 26\n",
            "2023-10-22 15:35:29,719 md_dnn.py[line:221] INFO: Mini batch: 97/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:29,720 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0050 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:29,728 md_dnn.py[line:221] INFO: Mini batch: 98/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:29,729 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0016 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:29,737 md_dnn.py[line:221] INFO: Mini batch: 99/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:29,737 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0017 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:30,346 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0028 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:30,346 md_dnn.py[line:249] INFO: Validation accuracy: 94.74 | The best validation accuracy: 95.61 at epoch: 26\n",
            "2023-10-22 15:35:30,546 md_dnn.py[line:221] INFO: Mini batch: 100/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:30,547 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0037 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:30,555 md_dnn.py[line:221] INFO: Mini batch: 101/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:30,556 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0017 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:30,564 md_dnn.py[line:221] INFO: Mini batch: 102/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:30,564 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0030 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:31,189 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0028 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:31,190 md_dnn.py[line:249] INFO: Validation accuracy: 94.74 | The best validation accuracy: 95.61 at epoch: 26\n",
            "2023-10-22 15:35:31,392 md_dnn.py[line:221] INFO: Mini batch: 103/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:31,392 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0031 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:31,400 md_dnn.py[line:221] INFO: Mini batch: 104/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:31,400 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0020 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:31,408 md_dnn.py[line:221] INFO: Mini batch: 105/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:31,408 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0012 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:32,031 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0021 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:32,031 md_dnn.py[line:249] INFO: Validation accuracy: 94.74 | The best validation accuracy: 95.61 at epoch: 26\n",
            "2023-10-22 15:35:32,254 md_dnn.py[line:221] INFO: Mini batch: 106/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:32,254 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0042 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:32,262 md_dnn.py[line:221] INFO: Mini batch: 107/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:32,262 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0016 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:32,270 md_dnn.py[line:221] INFO: Mini batch: 108/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:32,270 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0016 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:32,889 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0025 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:32,889 md_dnn.py[line:249] INFO: Validation accuracy: 94.74 | The best validation accuracy: 95.61 at epoch: 26\n",
            "2023-10-22 15:35:33,082 md_dnn.py[line:221] INFO: Mini batch: 109/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:33,082 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0021 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:33,091 md_dnn.py[line:221] INFO: Mini batch: 110/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:33,091 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0013 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:33,099 md_dnn.py[line:221] INFO: Mini batch: 111/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:33,099 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0013 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:33,710 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0016 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:33,711 md_dnn.py[line:249] INFO: Validation accuracy: 94.74 | The best validation accuracy: 95.61 at epoch: 26\n",
            "2023-10-22 15:35:33,902 md_dnn.py[line:221] INFO: Mini batch: 112/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:33,903 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0034 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:33,911 md_dnn.py[line:221] INFO: Mini batch: 113/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:33,911 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0018 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:33,920 md_dnn.py[line:221] INFO: Mini batch: 114/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:33,920 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0014 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:34,532 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0022 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:34,532 md_dnn.py[line:249] INFO: Validation accuracy: 94.74 | The best validation accuracy: 95.61 at epoch: 26\n",
            "2023-10-22 15:35:34,765 md_dnn.py[line:221] INFO: Mini batch: 115/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:34,766 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0024 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:34,774 md_dnn.py[line:221] INFO: Mini batch: 116/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:34,774 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0015 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:34,782 md_dnn.py[line:221] INFO: Mini batch: 117/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:34,782 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0010 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:35,385 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0016 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:35,386 md_dnn.py[line:249] INFO: Validation accuracy: 94.74 | The best validation accuracy: 95.61 at epoch: 26\n",
            "2023-10-22 15:35:35,571 md_dnn.py[line:221] INFO: Mini batch: 118/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:35,571 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0042 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:35,581 md_dnn.py[line:221] INFO: Mini batch: 119/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:35,581 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0011 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:35,590 md_dnn.py[line:221] INFO: Mini batch: 120/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:35,590 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0008 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:36,205 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0020 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:36,206 md_dnn.py[line:249] INFO: Validation accuracy: 94.74 | The best validation accuracy: 95.61 at epoch: 26\n",
            "2023-10-22 15:35:36,408 md_dnn.py[line:221] INFO: Mini batch: 121/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:36,409 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0050 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:36,416 md_dnn.py[line:221] INFO: Mini batch: 122/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:36,417 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0017 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:36,425 md_dnn.py[line:221] INFO: Mini batch: 123/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:36,425 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0008 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:37,046 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0025 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:37,046 md_dnn.py[line:249] INFO: Validation accuracy: 94.74 | The best validation accuracy: 95.61 at epoch: 26\n",
            "2023-10-22 15:35:37,236 md_dnn.py[line:221] INFO: Mini batch: 124/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:37,236 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0035 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:37,246 md_dnn.py[line:221] INFO: Mini batch: 125/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:37,246 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0011 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:37,255 md_dnn.py[line:221] INFO: Mini batch: 126/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:37,255 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0008 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-153456/model.pth\n",
            "2023-10-22 15:35:38,272 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0018 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:38,272 md_dnn.py[line:249] INFO: Validation accuracy: 95.61 | The best validation accuracy: 95.61 at epoch: 41\n",
            "2023-10-22 15:35:38,579 md_dnn.py[line:221] INFO: Mini batch: 127/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:38,580 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0015 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:38,588 md_dnn.py[line:221] INFO: Mini batch: 128/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:38,588 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0010 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:38,596 md_dnn.py[line:221] INFO: Mini batch: 129/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:38,596 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0015 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-153456/model.pth\n",
            "2023-10-22 15:35:39,749 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0014 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:39,749 md_dnn.py[line:249] INFO: Validation accuracy: 95.61 | The best validation accuracy: 95.61 at epoch: 42\n",
            "2023-10-22 15:35:40,070 md_dnn.py[line:221] INFO: Mini batch: 130/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:40,071 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0013 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:40,079 md_dnn.py[line:221] INFO: Mini batch: 131/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:40,079 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0007 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:40,088 md_dnn.py[line:221] INFO: Mini batch: 132/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:40,088 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0012 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-153456/model.pth\n",
            "2023-10-22 15:35:41,167 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0011 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:41,167 md_dnn.py[line:249] INFO: Validation accuracy: 95.61 | The best validation accuracy: 95.61 at epoch: 43\n",
            "2023-10-22 15:35:41,462 md_dnn.py[line:221] INFO: Mini batch: 133/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:41,462 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0017 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:41,470 md_dnn.py[line:221] INFO: Mini batch: 134/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:41,470 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0010 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:41,479 md_dnn.py[line:221] INFO: Mini batch: 135/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:41,479 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0008 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:42,260 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0012 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:42,260 md_dnn.py[line:249] INFO: Validation accuracy: 94.74 | The best validation accuracy: 95.61 at epoch: 43\n",
            "2023-10-22 15:35:42,470 md_dnn.py[line:221] INFO: Mini batch: 136/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:42,470 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0010 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:42,479 md_dnn.py[line:221] INFO: Mini batch: 137/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:42,479 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0011 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:42,487 md_dnn.py[line:221] INFO: Mini batch: 138/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:42,488 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0007 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:43,098 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0009 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:43,098 md_dnn.py[line:249] INFO: Validation accuracy: 94.74 | The best validation accuracy: 95.61 at epoch: 43\n",
            "2023-10-22 15:35:43,288 md_dnn.py[line:221] INFO: Mini batch: 139/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:43,289 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0027 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:43,303 md_dnn.py[line:221] INFO: Mini batch: 140/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:43,304 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0006 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:43,312 md_dnn.py[line:221] INFO: Mini batch: 141/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:43,312 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:43,917 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0013 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:43,917 md_dnn.py[line:249] INFO: Validation accuracy: 94.74 | The best validation accuracy: 95.61 at epoch: 43\n",
            "2023-10-22 15:35:44,116 md_dnn.py[line:221] INFO: Mini batch: 142/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:44,116 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0011 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:44,135 md_dnn.py[line:221] INFO: Mini batch: 143/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:44,135 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:44,143 md_dnn.py[line:221] INFO: Mini batch: 144/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:44,143 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0006 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:44,753 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0008 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:44,753 md_dnn.py[line:249] INFO: Validation accuracy: 94.74 | The best validation accuracy: 95.61 at epoch: 43\n",
            "2023-10-22 15:35:44,946 md_dnn.py[line:221] INFO: Mini batch: 145/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:44,947 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0014 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:44,959 md_dnn.py[line:221] INFO: Mini batch: 146/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:44,959 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:44,967 md_dnn.py[line:221] INFO: Mini batch: 147/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:44,967 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0006 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:45,629 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0008 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:45,629 md_dnn.py[line:249] INFO: Validation accuracy: 94.74 | The best validation accuracy: 95.61 at epoch: 43\n",
            "2023-10-22 15:35:45,844 md_dnn.py[line:221] INFO: Mini batch: 148/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:45,845 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0009 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:45,852 md_dnn.py[line:221] INFO: Mini batch: 149/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:45,853 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0006 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:45,861 md_dnn.py[line:221] INFO: Mini batch: 150/150 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 15:35:45,861 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0008 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:46,645 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0007 | Train accuracy: 100.00\n",
            "2023-10-22 15:35:46,645 md_dnn.py[line:249] INFO: Validation accuracy: 94.74 | The best validation accuracy: 95.61 at epoch: 43\n",
            "2023-10-22 15:35:47,238 md_dnn.py[line:165] INFO: The accuracy on the test dataset is 92.98246%\n",
            "2023-10-22 15:35:47,238 md_dnn.py[line:167] INFO: The balanced accuracy on the test dataset is 92.97381%\n",
            "Other evaluation metrics we may need:\n",
            "2023-10-22 15:35:47,241 md_dnn.py[line:180] INFO: False Negative Rate (FNR) is 7.27273%, False Positive Rate (FPR) is 6.77966%, F1 score is 92.72727%\n"
          ]
        }
      ]
    }
  ]
}