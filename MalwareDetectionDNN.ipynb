{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1H1KnRs-6oLBOnUpT_3BQ1AoHPcf_q43r",
      "authorship_tag": "ABX9TyO1qHfL9QZb+6+mjzA0uS8U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/a_malware/blob/main/MalwareDetectionDNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os.path as path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIN9uSWILNkN",
        "outputId": "6e2b8fcf-8ab9-42ab-ccdb-9e931862ef1f"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mostafa-ja/malware_detection.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvQzurUxzh7x",
        "outputId": "71327803-87a4-4672-860d-b793151ba85d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'malware_detection'...\n",
            "remote: Enumerating objects: 14653, done.\u001b[K\n",
            "remote: Counting objects: 100% (805/805), done.\u001b[K\n",
            "remote: Compressing objects: 100% (129/129), done.\u001b[K\n",
            "remote: Total 14653 (delta 716), reused 752 (delta 668), pack-reused 13848\u001b[K\n",
            "Receiving objects: 100% (14653/14653), 146.47 MiB | 32.14 MiB/s, done.\n",
            "Resolving deltas: 100% (11646/11646), done.\n",
            "Updating files: 100% (836/836), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "E9woBsXkq7HP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "\n",
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, samples):\n",
        "        self.samples = [(torch.tensor(data, dtype=torch.float32), label) for data, label in samples]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.samples[index]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torch.load('/content/malware_detection/datasets/train_dataset.pt')\n",
        "train_Loader = data.DataLoader(train_dataset, batch_size=128, shuffle=False)\n",
        "validation_dataset = torch.load('/content/malware_detection/datasets/validation_dataset.pt')\n",
        "validation_Loader = data.DataLoader(validation_dataset, batch_size=10000, shuffle=False)\n",
        "test_dataset = torch.load('/content/malware_detection/datasets/test_dataset.pt')\n",
        "test_Loader = data.DataLoader(test_dataset, batch_size=10000, shuffle=False)"
      ],
      "metadata": {
        "id": "B39GkhWXrGy3"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('train_dataset size : ', len(train_dataset))\n",
        "print('validation_dataset size : ', len(validation_dataset))\n",
        "print('test_dataset size : ', len(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqMvr0XR0WmF",
        "outputId": "f1ef9219-d828-4493-f390-90015a786290"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_dataset size :  420\n",
            "validation_dataset size :  140\n",
            "test_dataset size :  140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample,label = next(iter(train_dataset))\n",
        "print(sample.shape)\n",
        "print(label)\n",
        "print(sample)\n",
        "print(sum(sample))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1PexG7s9htv",
        "outputId": "203a5e65-7b12-465d-90d1-ae5d99c132e0"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1368])\n",
            "1\n",
            "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
            "tensor(63.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample,label = next(iter(validation_Loader))\n",
        "print(sample.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMOe0msmYcJl",
        "outputId": "91f79fa2-7903-40b3-87ae-14241e288d69"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([140, 1368])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "class MalwareDetectionDNN(nn.Module):\n",
        "    def __init__(self, input_size, n_classes, device='cpu', name='DNN', dense_hidden_units=[200, 200], dropout=0.6, smooth=False):\n",
        "        \"\"\"\n",
        "        Construct malware detector\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        @param input_size: Integer, the dimentionality number of input vector\n",
        "        @param n_classes: Integer, the number of classes, n=2\n",
        "        @param device: String, 'cpu' or 'cuda'\n",
        "        @param name: String, model name\n",
        "        \"\"\"\n",
        "        super(MalwareDetectionDNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.n_classes = n_classes\n",
        "        self.name = name\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.smooth = smooth\n",
        "        self.dense_hidden_units = dense_hidden_units\n",
        "\n",
        "        self.dense_layers = []\n",
        "        if len(self.dense_hidden_units) >= 1:\n",
        "            self.dense_layers.append(nn.Linear(self.input_size, self.dense_hidden_units[0]))\n",
        "        else:\n",
        "            raise ValueError(\"Expect at least one hidden layer.\")\n",
        "        for i in range(len(self.dense_hidden_units[0:-1])):\n",
        "            self.dense_layers.append(nn.Linear(self.dense_hidden_units[i],  # start from idx=1\n",
        "                                               self.dense_hidden_units[i + 1]))\n",
        "        self.dense_layers.append(nn.Linear(self.dense_hidden_units[-1], self.n_classes))\n",
        "\n",
        "        # registration\n",
        "        for idx_i, dense_layer in enumerate(self.dense_layers):\n",
        "            self.add_module('nn_model_layer_{}'.format(idx_i), dense_layer)\n",
        "\n",
        "        if self.smooth:\n",
        "            self.activation_func = F.selu  # partial(F.elu, alpha=self.alpha_)\n",
        "        else:\n",
        "            self.activation_func = F.relu\n",
        "\n",
        "        self.model_save_path = path.join('/content/malware_detection/save/drebin/md_dnn'+ '_' + self.name,'model.pth')\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Go through the neural network\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        @param x: 2D tensor, feature representation\n",
        "        \"\"\"\n",
        "        for dense_layer in self.dense_layers[:-1]:\n",
        "            x = self.activation_func(dense_layer(x))\n",
        "\n",
        "        latent_representation = F.dropout(x, self.dropout, training=self.training)\n",
        "        logits = self.dense_layers[-1](latent_representation)\n",
        "        return logits\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v0j39fpP-vlt"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MalwareDetectionDNN(1368,2)\n",
        "model = model.to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVPO6jQi_DPE",
        "outputId": "637cf179-64a5-41b3-b0a9-60f68ffe46c2"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MalwareDetectionDNN(\n",
              "  (nn_model_layer_0): Linear(in_features=1368, out_features=200, bias=True)\n",
              "  (nn_model_layer_1): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (nn_model_layer_2): Linear(in_features=200, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(model, input_size=(1368,))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_-ZtrKX-6rW",
        "outputId": "ebd65bda-0628-4133-aa46-639188bb29d9"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 200]         273,800\n",
            "            Linear-2                  [-1, 200]          40,200\n",
            "            Linear-3                    [-1, 2]             402\n",
            "================================================================\n",
            "Total params: 314,402\n",
            "Trainable params: 314,402\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 1.20\n",
            "Estimated Total Size (MB): 1.21\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr =0.005\n",
        "weight_decay = 0.\n",
        "epochs = 50\n",
        "dropout=0.6\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "best_avg_acc = 0.\n",
        "best_epoch = 0\n",
        "total_time = 0.\n",
        "nbatches = len(train_Loader)\n",
        "for i in range(epochs):\n",
        "    model.train()\n",
        "    losses, accuracies = [], []\n",
        "    for idx_batch, (x_train, y_train) in enumerate(train_Loader):\n",
        "        x_train = x_train.to(device)\n",
        "        y_train = y_train.long().to(device)\n",
        "        start_time = time.time()\n",
        "        optimizer.zero_grad()\n",
        "        logits = model.forward(x_train)\n",
        "        loss_train = loss_fn(logits, y_train)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        total_time = total_time + time.time() - start_time\n",
        "        acc_train = (logits.argmax(1) == y_train).sum().item()\n",
        "        acc_train /= x_train.size()[0]\n",
        "        mins, secs = int(total_time / 60), int(total_time % 60)\n",
        "        losses.append(loss_train.item())\n",
        "        accuracies.append(acc_train)\n",
        "\n",
        "        if True:\n",
        "            print(f'Mini batch: {i * nbatches + idx_batch + 1}/{epochs * nbatches} | training time in {mins:.0f} minutes, {secs} seconds.')\n",
        "            print(f'Training loss (batch level): {losses[-1]:.4f} | Train accuracy: {acc_train * 100:.2f}')\n",
        "\n",
        "    model.eval()\n",
        "    avg_acc_val = []\n",
        "    with torch.no_grad():\n",
        "        for x_val, y_val in validation_Loader:\n",
        "            x_val = x_val.to(device)\n",
        "            y_val = y_val.long().to(device)\n",
        "            logits = model.forward(x_val)\n",
        "            acc_val = (logits.argmax(1) == y_val).sum().item()\n",
        "            acc_val /= x_val.size()[0]\n",
        "            avg_acc_val.append(acc_val)\n",
        "        avg_acc_val = np.mean(avg_acc_val)\n",
        "\n",
        "    if avg_acc_val >= best_avg_acc:\n",
        "        best_avg_acc = avg_acc_val\n",
        "        best_epoch = i\n",
        "        torch.save(model.state_dict(), 'model.pth')\n",
        "\n",
        "    if True:\n",
        "        print(f'Training loss (epoch level): {np.mean(losses):.4f} | Train accuracy: {np.mean(accuracies) * 100:.2f}')\n",
        "        print(f'Validation accuracy: {avg_acc_val * 100:.2f} | The best validation accuracy: {best_avg_acc * 100:.2f} at epoch: {best_epoch}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaHrKhisKSMJ",
        "outputId": "920db536-0d74-42e8-c822-85d2719340de"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mini batch: 1/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.6915 | Train accuracy: 56.25\n",
            "Mini batch: 2/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.6138 | Train accuracy: 70.31\n",
            "Mini batch: 3/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.4502 | Train accuracy: 91.41\n",
            "Mini batch: 4/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.3038 | Train accuracy: 91.67\n",
            "Training loss (epoch level): 0.5148 | Train accuracy: 77.41\n",
            "Validation accuracy: 91.43 | The best validation accuracy: 91.43 at epoch: 0\n",
            "Mini batch: 5/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.3305 | Train accuracy: 89.84\n",
            "Mini batch: 6/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.3246 | Train accuracy: 83.59\n",
            "Mini batch: 7/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.1608 | Train accuracy: 91.41\n",
            "Mini batch: 8/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0416 | Train accuracy: 97.22\n",
            "Training loss (epoch level): 0.2144 | Train accuracy: 90.52\n",
            "Validation accuracy: 92.14 | The best validation accuracy: 92.14 at epoch: 1\n",
            "Mini batch: 9/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.2691 | Train accuracy: 92.19\n",
            "Mini batch: 10/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.2720 | Train accuracy: 91.41\n",
            "Mini batch: 11/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0760 | Train accuracy: 96.09\n",
            "Mini batch: 12/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0635 | Train accuracy: 97.22\n",
            "Training loss (epoch level): 0.1701 | Train accuracy: 94.23\n",
            "Validation accuracy: 89.29 | The best validation accuracy: 92.14 at epoch: 1\n",
            "Mini batch: 13/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.1529 | Train accuracy: 92.19\n",
            "Mini batch: 14/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.1218 | Train accuracy: 92.97\n",
            "Mini batch: 15/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0532 | Train accuracy: 97.66\n",
            "Mini batch: 16/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0102 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0845 | Train accuracy: 95.70\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 94.29 at epoch: 3\n",
            "Mini batch: 17/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.1521 | Train accuracy: 95.31\n",
            "Mini batch: 18/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.1060 | Train accuracy: 96.88\n",
            "Mini batch: 19/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0468 | Train accuracy: 97.66\n",
            "Mini batch: 20/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0067 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0779 | Train accuracy: 97.46\n",
            "Validation accuracy: 92.14 | The best validation accuracy: 94.29 at epoch: 3\n",
            "Mini batch: 21/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0381 | Train accuracy: 99.22\n",
            "Mini batch: 22/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0988 | Train accuracy: 95.31\n",
            "Mini batch: 23/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0942 | Train accuracy: 98.44\n",
            "Mini batch: 24/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0131 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0610 | Train accuracy: 98.24\n",
            "Validation accuracy: 93.57 | The best validation accuracy: 94.29 at epoch: 3\n",
            "Mini batch: 25/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0292 | Train accuracy: 98.44\n",
            "Mini batch: 26/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0570 | Train accuracy: 98.44\n",
            "Mini batch: 27/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0267 | Train accuracy: 99.22\n",
            "Mini batch: 28/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0084 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0303 | Train accuracy: 99.02\n",
            "Validation accuracy: 93.57 | The best validation accuracy: 94.29 at epoch: 3\n",
            "Mini batch: 29/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0387 | Train accuracy: 98.44\n",
            "Mini batch: 30/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0444 | Train accuracy: 98.44\n",
            "Mini batch: 31/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0224 | Train accuracy: 99.22\n",
            "Mini batch: 32/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0128 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0296 | Train accuracy: 99.02\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 7\n",
            "Mini batch: 33/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0103 | Train accuracy: 100.00\n",
            "Mini batch: 34/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0272 | Train accuracy: 99.22\n",
            "Mini batch: 35/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0227 | Train accuracy: 99.22\n",
            "Mini batch: 36/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0188 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0198 | Train accuracy: 99.61\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 7\n",
            "Mini batch: 37/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0059 | Train accuracy: 100.00\n",
            "Mini batch: 38/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0179 | Train accuracy: 99.22\n",
            "Mini batch: 39/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0118 | Train accuracy: 99.22\n",
            "Mini batch: 40/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0050 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0101 | Train accuracy: 99.61\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 9\n",
            "Mini batch: 41/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0058 | Train accuracy: 100.00\n",
            "Mini batch: 42/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0235 | Train accuracy: 98.44\n",
            "Mini batch: 43/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0072 | Train accuracy: 99.22\n",
            "Mini batch: 44/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0034 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0099 | Train accuracy: 99.41\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 10\n",
            "Mini batch: 45/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0025 | Train accuracy: 100.00\n",
            "Mini batch: 46/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0102 | Train accuracy: 99.22\n",
            "Mini batch: 47/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0094 | Train accuracy: 99.22\n",
            "Mini batch: 48/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0066 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0072 | Train accuracy: 99.61\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 11\n",
            "Mini batch: 49/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0014 | Train accuracy: 100.00\n",
            "Mini batch: 50/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0075 | Train accuracy: 100.00\n",
            "Mini batch: 51/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0095 | Train accuracy: 99.22\n",
            "Mini batch: 52/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0047 | Train accuracy: 99.80\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 11\n",
            "Mini batch: 53/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0013 | Train accuracy: 100.00\n",
            "Mini batch: 54/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0021 | Train accuracy: 100.00\n",
            "Mini batch: 55/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0096 | Train accuracy: 99.22\n",
            "Mini batch: 56/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0025 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0039 | Train accuracy: 99.80\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 13\n",
            "Mini batch: 57/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0021 | Train accuracy: 100.00\n",
            "Mini batch: 58/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0036 | Train accuracy: 100.00\n",
            "Mini batch: 59/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0016 | Train accuracy: 100.00\n",
            "Mini batch: 60/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0031 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0026 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 14\n",
            "Mini batch: 61/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0021 | Train accuracy: 100.00\n",
            "Mini batch: 62/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0020 | Train accuracy: 100.00\n",
            "Mini batch: 63/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0048 | Train accuracy: 100.00\n",
            "Mini batch: 64/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0022 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 15\n",
            "Mini batch: 65/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 66/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0015 | Train accuracy: 100.00\n",
            "Mini batch: 67/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0075 | Train accuracy: 99.22\n",
            "Mini batch: 68/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0024 | Train accuracy: 99.80\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 16\n",
            "Mini batch: 69/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0014 | Train accuracy: 100.00\n",
            "Mini batch: 70/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00\n",
            "Mini batch: 71/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 72/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0083 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0027 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 17\n",
            "Mini batch: 73/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0013 | Train accuracy: 100.00\n",
            "Mini batch: 74/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00\n",
            "Mini batch: 75/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0014 | Train accuracy: 100.00\n",
            "Mini batch: 76/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0009 | Train accuracy: 100.00\n",
            "Validation accuracy: 93.57 | The best validation accuracy: 95.00 at epoch: 17\n",
            "Mini batch: 77/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 78/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0007 | Train accuracy: 100.00\n",
            "Mini batch: 79/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0023 | Train accuracy: 100.00\n",
            "Mini batch: 80/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0008 | Train accuracy: 100.00\n",
            "Validation accuracy: 93.57 | The best validation accuracy: 95.00 at epoch: 17\n",
            "Mini batch: 81/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 82/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 83/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0055 | Train accuracy: 99.22\n",
            "Mini batch: 84/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0016 | Train accuracy: 99.80\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 17\n",
            "Mini batch: 85/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 86/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0013 | Train accuracy: 100.00\n",
            "Mini batch: 87/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 88/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0044 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0015 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 21\n",
            "Mini batch: 89/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0008 | Train accuracy: 100.00\n",
            "Mini batch: 90/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0009 | Train accuracy: 100.00\n",
            "Mini batch: 91/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 92/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0004 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 21\n",
            "Mini batch: 93/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 94/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 95/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0010 | Train accuracy: 100.00\n",
            "Mini batch: 96/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0003 | Train accuracy: 100.00\n",
            "Validation accuracy: 93.57 | The best validation accuracy: 95.00 at epoch: 21\n",
            "Mini batch: 97/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 98/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 99/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00\n",
            "Mini batch: 100/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0003 | Train accuracy: 100.00\n",
            "Validation accuracy: 93.57 | The best validation accuracy: 95.00 at epoch: 21\n",
            "Mini batch: 101/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 102/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 103/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 104/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0002 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 21\n",
            "Mini batch: 105/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 106/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 107/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 108/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0003 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 26\n",
            "Mini batch: 109/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 110/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 111/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 112/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0002 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 27\n",
            "Mini batch: 113/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 114/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 115/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 116/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 28\n",
            "Mini batch: 117/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 118/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 119/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 120/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 29\n",
            "Mini batch: 121/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 122/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 123/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 124/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0002 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 30\n",
            "Mini batch: 125/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 126/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 127/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 128/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 31\n",
            "Mini batch: 129/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 130/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 131/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 132/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 32\n",
            "Mini batch: 133/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 134/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 135/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 136/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0000 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 33\n",
            "Mini batch: 137/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 138/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 139/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 140/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 34\n",
            "Mini batch: 141/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0004 | Train accuracy: 100.00\n",
            "Mini batch: 142/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 143/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 144/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 34\n",
            "Mini batch: 145/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 146/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 147/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 148/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 34\n",
            "Mini batch: 149/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 150/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 151/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 152/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0000 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 34\n",
            "Mini batch: 153/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 154/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0002 | Train accuracy: 100.00\n",
            "Mini batch: 155/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 156/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 34\n",
            "Mini batch: 157/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 158/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 159/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 160/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 34\n",
            "Mini batch: 161/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 162/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 163/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 164/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0000 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 34\n",
            "Mini batch: 165/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 166/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0003 | Train accuracy: 100.00\n",
            "Mini batch: 167/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 168/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 34\n",
            "Mini batch: 169/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 170/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 171/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 172/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0000 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 34\n",
            "Mini batch: 173/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 174/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 175/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 176/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0000 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 34\n",
            "Mini batch: 177/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 178/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 179/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 180/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 34\n",
            "Mini batch: 181/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 182/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 183/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 184/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0006 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0002 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 34\n",
            "Mini batch: 185/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 186/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 187/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 188/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0000 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 46\n",
            "Mini batch: 189/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 190/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 191/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 192/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0000 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 47\n",
            "Mini batch: 193/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 194/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 195/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 196/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0000 | Train accuracy: 100.00\n",
            "Validation accuracy: 95.00 | The best validation accuracy: 95.00 at epoch: 48\n",
            "Mini batch: 197/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Mini batch: 198/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0005 | Train accuracy: 100.00\n",
            "Mini batch: 199/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0001 | Train accuracy: 100.00\n",
            "Mini batch: 200/200 | training time in 0 minutes, 0 seconds.\n",
            "Training loss (batch level): 0.0000 | Train accuracy: 100.00\n",
            "Training loss (epoch level): 0.0001 | Train accuracy: 100.00\n",
            "Validation accuracy: 94.29 | The best validation accuracy: 95.00 at epoch: 48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sample,test_label = next(iter(test_Loader))\n",
        "test_sample,test_label = test_sample.to(device),test_label.to(device)\n",
        "\n",
        "model.load_state_dict(torch.load('/content/model.pth'))\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for x, y in test_Loader:\n",
        "        x = x.to(device)\n",
        "        logits = model.forward(x)\n",
        "        confidences = F.softmax(logits, dim=-1)\n",
        "\n",
        "\n",
        "y_pred = confidences.argmax(1).cpu().numpy()\n",
        "y_true = y.cpu().numpy()"
      ],
      "metadata": {
        "id": "bexBTwHcmn6L"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, balanced_accuracy_score\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "b_accuracy = balanced_accuracy_score(y_true, y_pred)\n",
        "print(\"The accuracy on the test dataset is {:.5f}%\".format(accuracy * 100))\n",
        "print(\"The balanced accuracy on the test dataset is {:.5f}%\".format(b_accuracy * 100))\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "fpr = fp / float(tn + fp)\n",
        "fnr = fn / float(tp + fn)\n",
        "f1 = f1_score(y_true, y_pred, average='binary')\n",
        "\n",
        "print(\"Other evaluation metrics we may need:\")\n",
        "print(\"False Negative Rate (FNR) is {:.5f}%, False Positive Rate (FPR) is {:.5f}%, F1 score is {:.5f}%\".format(fnr * 100, fpr * 100, f1 * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6GGkhFQdCXJ",
        "outputId": "09c9d5d4-5fb5-40df-9f47-0d3aa716920d"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy on the test dataset is 97.14286%\n",
            "The balanced accuracy on the test dataset is 97.05160%\n",
            "Other evaluation metrics we may need:\n",
            "False Negative Rate (FNR) is 4.54545%, False Positive Rate (FPR) is 1.35135%, F1 score is 96.92308%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test our result with the original code"
      ],
      "metadata": {
        "id": "9xQNS2S1wrwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/malware_detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QNb0HVfg6LF",
        "outputId": "fb500981-0704-43f1-9a31-d2cba0881685"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/malware_detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install androguard\n",
        "!pip install captum\n",
        "\n",
        "import androguard\n",
        "import captum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPz_B5yIhTw2",
        "outputId": "b6a2fd7c-0498-4fbe-e700-f0aac910f407"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting androguard\n",
            "  Downloading androguard-3.3.5-py3-none-any.whl (922 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/922.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m368.6/922.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.4/922.4 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asn1crypto>=0.24.0 (from androguard)\n",
            "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/105.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from androguard) (8.1.7)\n",
            "Collecting colorama (from androguard)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from androguard) (0.18.3)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from androguard) (7.34.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from androguard) (4.9.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from androguard) (3.7.1)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.10/dist-packages (from androguard) (3.1)\n",
            "Requirement already satisfied: pydot>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from androguard) (1.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from androguard) (2.16.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->androguard)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (3.0.39)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (4.8.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot>=1.4.1->androguard) (3.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (2.8.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->androguard) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->androguard) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->androguard) (0.2.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->androguard) (1.16.0)\n",
            "Installing collected packages: asn1crypto, jedi, colorama, androguard\n",
            "Successfully installed androguard-3.3.5 asn1crypto-1.5.1 colorama-0.4.6 jedi-0.19.1\n",
            "Collecting captum\n",
            "  Downloading captum-0.6.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from captum) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from captum) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from captum) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->captum) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->captum) (1.3.0)\n",
            "Installing collected packages: captum\n",
            "Successfully installed captum-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "folder_path = '/content/malware_detection/datasets/naive_data'\n",
        "file_count = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
        "print(f\"Number of files in naive_data : {file_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mE50minvT2x",
        "outputId": "b3e51f37-6302-4c1e-eecc-446760368bee"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files in naive_data : 700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df_benign = pd.read_csv('/content/malware_detection/datasets/benign_sha256.csv')\n",
        "\n",
        "# Extract the first column as a list\n",
        "benign_sha256 = df_benign.iloc[:, 0].tolist()[:350]"
      ],
      "metadata": {
        "id": "Uakws5slviu_"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEQMfH3n3BEA",
        "outputId": "62c8f945-541f-46f8-e1f1-cf2952929a69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded: ef204edf1176051cc9e17a874409118d41cf4c028ba84c316a9a4b0dee72b278\n",
            "Downloaded: 4e2fad79800a24f4d45d2f63335d8c09883d8f93a0b2ee54af394be99aa1fe0b\n",
            "Downloaded: b227e1b32c35fa7ca8dd9facc5404a980d2a3d788de2d86815c7636ab492cd7c\n",
            "Downloaded: f0fdc5d10c01bd3b3294e766d29d4cfecf4a3a725284bc7b670ae042bc560eba\n",
            "Downloaded: f7ab4420fad838ac67ebd681bd35fadf1d42bf76049a8479c59072df455b0d97\n",
            "Downloaded: 5ce062d42fa166af0638186e8509cfd18025ebbfca3b0fdbc59283d0e2a63af0\n",
            "Downloaded: 5f39a782c8230cb446e604f4c35ea4f5e95430aff8d65ae464d55c8a1e1b8fe1\n",
            "Downloaded: 7a3c63d0a9e9a0cc94b7ae880f515c621b9aa496fe8dcec27a60804afad89d0e\n",
            "Downloaded: e32a47354a6b84db80bd4da24b78285b305e9b0957cd6f739818a50ac843b42a\n",
            "Downloaded: 7e82b4c3fe6039a5c166ecbb96bf1dcc59d9902bfae901105eaa067f3c397200\n",
            "Downloaded: 2bfe6ac5d52efa498947a795fce9bd40942640d3caa70c7f1473fdfde2f0b3f9\n",
            "Downloaded: d3adeeb5df196e74ab9f2c578fad61636d5a6fabaccdb1ef31dbf3ad4f4dfc67\n",
            "Downloaded: 689992492bf0914fc74f03314052e925df2425988f5cddcf54f0a1e0ca8692cf\n",
            "Downloaded: bd44570884469185b0dc9c12e04366c37a4df94b45d1235e04e7dac95abccaad\n",
            "Downloaded: 09ba3148d5acc85cc37745d23447a5399d4a8af10511c766939b6fb31dff679d\n",
            "Downloaded: 0ca6d7957e5599361c9e0da293c3276516eb2bed13b3877a27504e92459721bd\n",
            "Downloaded: ff7b0aa25c01aa28a0839d9102d9042df876cb407439fdd4a5b873112a316a82\n",
            "Downloaded: 6e9b28c4339522c26a2dcaeff8525389e456bff148d028c7c95bfa2013d948df\n",
            "Downloaded: f4678982012e5d97adf0b1053d31f5137d5f8796d7291eb348297cb5e948dbb8\n",
            "Downloaded: 2760f1fc8f75091c5a7457b71e56411249d2a62cd2e25e36c7d08d83bd70fcb5\n",
            "Downloaded: fda1903e90e55ba9eda930d8ad33b3289defb8def94565bc7f3e2b9a76f7ba7b\n",
            "Downloaded: 877b8ceecf6926a1223997d475731b44f5f0f2f21cce240085ea1c15944597fc\n",
            "Downloaded: fe0a91973562d4cf63187924ee02907b47fa74dec0957fa099d61165cee1a06e\n",
            "Downloaded: ea5c97e07c804bd8957b86c016ec545850bbee4e3b516bcde59c907cad3d4b2b\n",
            "Downloaded: 0f302b9a6b5141b664c27da3236d166cc0d8dd00a23614ab445ca717e9e1d5fb\n",
            "Downloaded: a02576037cce8ae21354ff37297500b4f6214b1c7344b6440b13d51f2b4cfea3\n",
            "Downloaded: b247a2efd4a9237aa5c9b87b6030018e48401a854003b76f5dd13b7449fadb06\n",
            "Downloaded: c509ac8e68bba5771ec881fd77b578034844663324c0617e87a7cbfdeace6115\n",
            "Downloaded: 4d902e63bb1ebaee9fd091744b095e86db5fab810e3cfb29b33ba8fe6e50bce8\n",
            "Downloaded: ed5dab9e189c7e0c273cfbf0088ac8124617d3a61e4df20464bdde6b33e9fd51\n",
            "Downloaded: d414e4c7de2186f037a469d9398c216be7290b9c2c06c38f1b418aaca237bbd2\n",
            "Downloaded: 35f634617c281c6113318aa03542fc06ec13427440fde4573b7773a37218f22a\n",
            "Downloaded: a5f2fb86a91ba354d0f17bdcd4fbfb15242a2e799f9944765eedbe6a9675e14e\n",
            "Downloaded: 082e529d71e6a847835a954080934f6357e0696996728816a0e079b8bce8eafd\n",
            "Downloaded: da574a347d05c63dc4d6fc001bd3e59f76d51a17c29e60356683856ec473fef7\n",
            "Downloaded: 8c2f578d4a7fffa1655ac7ce58da34dbb5753467d915e9245882b02475f64a49\n",
            "Downloaded: 58f99d57ca8f5ba026ae0f529ad8dcdeb37a1458568b2b9f7f167c33cb88fa1e\n",
            "Downloaded: f41c7dbc627ee1e8b5b04f87421205e7487e509fd1c98232409c3f196d6ceeb1\n",
            "Downloaded: 7087b552e2bfe998ee177374da4ef4bd6f7c3494bc18265ca4e9f7597b8b5554\n",
            "Downloaded: 84e0f36d282bcbe81fca397cbc88f84a4043b70b45aa721d4ef9e584b760e878\n",
            "Downloaded: d9fed5e9d3803fc3cbca3d0b17210004292afb9f2695facaa2826b9782b0d0e7\n",
            "Downloaded: 5be4cb370b5c130ae66d289547197acc8ec2f34cf9ff002529630964dbad8215\n",
            "Downloaded: 362c649f26fa0026763a5a0fc5fbe3a79c1bbb960c891870c908091a80be9dde\n",
            "Downloaded: fc0a686b89ab03b43b4d58e0828c41fdb4acf11ec98c46effeff7fa009aa520e\n",
            "Downloaded: 75a7e03ad0b7c9d1f07315104f2736b9fa84f36eb7e8a4a398906f2451ac958f\n",
            "Downloaded: ecef54b8f8a6fd6805c1e1e226d6861d8274ae7c6851747b6f00648d2bdf4de0\n",
            "Downloaded: 9b7e74ac9e8cf937b00aefd0147ce48b97a49ef68d7208dba7a3b83cc58c301a\n",
            "Downloaded: 5935a43a3b73cd3d301b02d24cf937b167b11f80f5b9260448fe3559872048d6\n",
            "Downloaded: c2944ab5fbfc2add5db84fb8bb569c680efe718f1168ab5c4b272bf35dee0178\n",
            "Downloaded: 79ce8e4f27bea1dda37f96765dc0d7ea1eeef780ec55f6e467b12b011f66d753\n",
            "Downloaded: 3e33d60578419f191252778cb6dc1bec287c63d261b3e761ec8a801b0f461e3c\n",
            "Downloaded: f1ca4fed7a4146e5db842ead0f2af650a1ac6bd40eee8f13c6217605b76733e6\n",
            "Downloaded: 9620d0e141c5c2b440a289d3e7dbfc9d0f7e91c0d19d0b6973802fe3a8f44b86\n",
            "Downloaded: 29d7e78d17319f693f3629eeee131047c3dc693a62947526ab3ae31edba988a3\n",
            "Downloaded: 0cef2d72db77ff2660eb1ce8ed48a61291baeee76abc9d3604af785a7298cca3\n",
            "Downloaded: cf17237b42fbef46efd55e92515a0b2d2e4585a3ddf4c77360806f12ccca6b92\n",
            "Downloaded: b3649681304879e866be326aa01936282199e98ea621bdd2ee2a4ef09b006606\n",
            "Downloaded: c54b66566daf3e0b4e5eda9a278ca5d43acf7ed247a8d62be5ca1ac7558937bc\n",
            "Downloaded: 5b089c561ed0a1418f0d260e3ce6a6d30f29fad315c382e8f0549529ed4deade\n",
            "Downloaded: 68a762b82e1659d012cd9d1e3852c94e8a620c698cea9cabd9a40a667e835cc2\n",
            "Downloaded: 2a61c339d9c01af4a9927ad485c193031ee0fcfdf265b9c776fd3d644d72bffd\n",
            "Downloaded: 0ced9922b5b91be30376650d14476c430cd974a203e9301db124ab8ec1cc888c\n",
            "Downloaded: 0c50ae76bc6214509039d25b291b6778355f85a056d02829e288e0e3008ab7d1\n",
            "Downloaded: 7b72bd17fff5800122720308413e9ac7b748ab046609206613d196069bf15537\n",
            "Downloaded: 3b1c690c7dd8719d8651274e2fa3280ebec18316032aa85b5cd261c7f8107b58\n",
            "Downloaded: 28ffb49c2e605cc3b1359ab8e56fd5593279017ee403bc0c6f7561cedc905ec0\n",
            "Downloaded: fd8a6eaf200f82859ef749b79f0ffc1b980104d291784e225395d61694f08fd6\n",
            "Downloaded: b6e06522e7ad1e9d7df5ea42336a319ea4a441f2a36f058d5c21d5d0f95db67a\n",
            "Downloaded: d00d171dc69c05dc52983d945ec79887e670499e553294f606fab800042be3ff\n",
            "Downloaded: 3a1f66e94c5dd69d54396819c658d0bb1adb620c14d4e88e4ef768ab893bd366\n",
            "Downloaded: 44a69dc40bd4d2f5576e2e7a0a1ec5eb8712832adcd4cb776bcfd99721804604\n",
            "Downloaded: 935a84806ac412d4efe35354aee3d463f726902d0c7741aa6df5d43fd5f194de\n",
            "Downloaded: 1fe3763c1131495abd6cd2b313f5b1eeffe02abc4c9c485568a290cf35334568\n",
            "Downloaded: 7c8d440d157208e1b7b9b60de4713ed65ef8e5d5783a2d32290eb829e1979011\n",
            "Downloaded: aece5211f034f09cd25716a59977f815211a396034a5cc5588c48a0ac09f2f41\n",
            "Downloaded: 40074182200eca22770337b979daed9e00e3e7ca12514c66f591e4fd06051c05\n",
            "Downloaded: 6f65168edee73817c40e79c394d79049c60585b3eef44af89235f04543737bc4\n",
            "Downloaded: f37478df5550ddb943cec7b468a59b03e2a56791fbae0bec12e934a5ae6490ae\n",
            "Downloaded: 22caa1c4e1b42396c30fb938568341c16b0e98a6757a88f8f10052a3c44790a2\n",
            "Downloaded: c6dcd2b1e663e8a2349407289c0adedd9c0e1474ea4cfa80f8100b679a2e01bd\n",
            "Downloaded: f575a2bb2c44f7addb126961234378b84956ff84254f523af03f6b2592645623\n",
            "Downloaded: 392bb31543b3a8721bfd70c079b83a4371e254e20d166b14b7c1ee23f28f1cdb\n",
            "Downloaded: 8ec4a617933ff75c2a88b09a4ab7a509c859dc42dc1dface492e988a447cc193\n",
            "Downloaded: 911fc454957e44ace6a26f5700950a1a74aaeeaa8a6f587b116f9127c8abc7b8\n",
            "Downloaded: bdd641da4eb966eccfada3991027f89fe69bf6b1d4bee0610bde37e3ff383e2a\n",
            "Downloaded: 5fe6567c3bf602140aec43f68d94848a038c632b233ff363d36fb9c36ec7c3c9\n",
            "Downloaded: 14aad99a3b4c99738c5c5de4b7de044418ecd0a755308bee956708dd41a24485\n",
            "Downloaded: 4451e0b2f74f3b455cfbda9f8dd4ec097629effc9dd632f86444844d2737ba28\n",
            "Downloaded: 0927ddc2b6070d4fb5ccad72dbf6e627cf3fc7b6b1710c2d77917f6b534b95d9\n",
            "Downloaded: 87fa1224240479f05e165062287410481fd4e9e77b3666685a499289cfb6cec6\n",
            "Downloaded: 851beb7fea3499efc3b2452b485c09e459e1e5de7a0cdb212f93044b8a934b98\n",
            "Downloaded: 7380edff6fd8d83110dac720ec81f2c91a7bb6834efed4d3220c5bbda06eef07\n",
            "Downloaded: 8ea165f1d80332b297f631a6f415ef4618d010b4ca71d545ab2600aa75c7fefa\n",
            "Downloaded: a610ec16d36f836b6a7417e94c77a138e3f8bcf1725cc30b0382ea9ef91eb96a\n",
            "Downloaded: 8f6b4704f8af225513f2d5e58a1ed5ef29e6a3ca0798126bec35ac076304b5f0\n",
            "Downloaded: 59c0bb17740a60841c5ca33cb19f8f0e30c69b6df2b7156179b0999e8b5e0942\n",
            "Downloaded: 38ee3799f110bf1b7cecd8e9a99cc724050e7bd0d1a68c26dfe39a806a1a0550\n",
            "Downloaded: 3fc246e370d7b481f6b7e24a6f9f9bcabb317e0bc6ea57c96c768b77dfc0d198\n",
            "Downloaded: 03264aac24ec06afffa73e6d63ec90866963c4f4475122fbc99646d66a0feabe\n",
            "Downloaded: bc708350255dc2d13fb95b7c103cbde6488502a09efc89aeffcbf87d9f8b64c3\n",
            "Downloaded: fb29d9bc2b64323fc40f12bd696a8d2751fa786fb7664255a06885942e57fece\n",
            "Downloaded: b23bdee027d37af9c2ccf00946dbf2d468a7d65fc3750ea5e605bf32d415461f\n",
            "Downloaded: f623fecb7f63b4c9db7ad55151c7f264d1932603462f0afd971b608baeabd338\n",
            "Downloaded: 36eb282a3856f09eadbb3a4bf7abc24476716a99b12386d91ab98de68633e628\n",
            "Downloaded: cf785dc0e8a4e53d62193c8c0eef92149bf8a8051ef252cae1a209ff6beebe41\n",
            "Downloaded: b02d094e9e5449cf655c1592242afa949b4a46322c85ef6b49b46b5819de1166\n",
            "Downloaded: 4e617ef2896f801d90bfc1e5cb9e1e485c8894a6dad31c416ea3ed7d67b72a61\n",
            "Downloaded: b44dd60061619702e9c8689f71f5dc5c148693fbfa08f85c13c5edbcf7ba64ac\n",
            "Downloaded: 20466febfc5f1a9e35da6ccc91007736ce5007ccf5cb734e89a65b9769245f50\n",
            "Downloaded: 486e8362ac239ed5ff3600e8e0194bfbcaf59af41b0d0cea484327fa0e3b8bb3\n",
            "Downloaded: 8eae162b5af8240a392d56f8f9c8c7fd4e26ed20406751afad64b11975686ee0\n",
            "Downloaded: 1892904f0f8dd0db787957857a9eca8e55834b5007ed71dee1da260987cd79d9\n",
            "Downloaded: 64ec3ffc6d961d42ea5868d5bc82c796a97f7726de78b35f2847eea0a304fc29\n",
            "Downloaded: 6faddc589fb58bd0acf051b40f6f9e19fc23bed13cbee68abd37e58ccdd8bad8\n",
            "Downloaded: 73cfd9d05a277b9e8919005c4a09eec90e58d7ab1321bceb617a6d461d7a3f76\n",
            "Downloaded: 89629f4824e59fa4dc70111b49808e67df5a3abba74f877d63199ce7a4181c74\n",
            "Downloaded: 8094c6bd18758e9bf8ece46dd848abd2b5fc6e15c0b9a5083d293545ea51724b\n",
            "Downloaded: 7160f93ed210d2430ad2bda9f7e3157917e977779e12aac1aa78771e5bfd4fa9\n",
            "Downloaded: 6464325af4435a29c6f2826bcb21d89806bbe269c8a08b0e44c02df951b223a3\n",
            "Downloaded: c0408baae22ef4509a6b086c355b44d3830148830f23cb9a801843d0d86d6f79\n",
            "Downloaded: 6b3bbd582e8792171026800b44a02bea31be970c05604d2194fb1b8efe52e8a3\n",
            "Downloaded: 96a00d13096adf66d3b8c3f793526ccabbf28fe0ba0ce98a2d6481bcddd818df\n",
            "Downloaded: 94c06c8e843662ecaa8217841028c111f56ccd3b13b6d59629e7636558dfc776\n",
            "Downloaded: 97170dbc77a7eec955a0bdc32e1d6a8c99e09e5b28056ecd74e50680aadb39b8\n",
            "Downloaded: d9f832ea72a4f4788b708f2bc0f43f799c155176e69537c50384f59bb215a84a\n",
            "Downloaded: 00de98d22a0164abeb93df3471312583b777663d16b5cfc6e6d3be875a6904b2\n",
            "Downloaded: 3291e0816f5771991f63e77b2848dcb08b27c17cdd24a0de572e130313f68f44\n",
            "Downloaded: 0632f39fa1f35916af19f17d31967f907f5a79a5664a904a9b28c12f5023cae1\n",
            "Downloaded: 9a6c544416b5bb911c3a6d6ef0df8f5f1cbcfe3577aab90a9bc76a8d02bd1684\n",
            "Downloaded: 17a5b3b37aa6a64c3c13bad4894c9c328672077f7169644516eb709ddb028d4e\n",
            "Downloaded: 6197679235dd15be744a26c3ac0a97c557a1353e48b65fe2d8726001c32705b0\n",
            "Downloaded: e2a2ea1df0aa34d0a045e9108bd47488fa766c81c647150353ac516d45288957\n",
            "Downloaded: 7a13f8a317bdc08e370db47af956aeeb8b227f4fba49827694e690c4b53b3191\n",
            "Downloaded: 1d6e0c5388eead3557e5b89a1a81444d12e269122dcc10e6fbcc3705309d86ce\n",
            "Downloaded: 28524fef011cc525d1af690117ed22ffa9b3dca7502b56400e2a1bad0a0be770\n",
            "Downloaded: a042cea4264a6669038c45bdc7b992db4711c2f6b4982eea8ed3fd84b90b8d78\n",
            "Downloaded: 296363f587890ca70e77283b29772bb50f7dfb16a97887544b5cb451b92fff57\n",
            "Downloaded: c3b4da48484cdf7fd8771febce3ceee8db8e43ce878432089ca173b60f153b60\n",
            "Downloaded: 75fdae706d706ceff96bce98ec543127cc13b11445444bf1b71508124275ec23\n",
            "Downloaded: 5fb078bd9b604c2f5aa88b76ff5cb19cefc5e6ec144182191727085d13c27a92\n",
            "Downloaded: 918e51b73af48da79cc04f5149a9c0e5a876ad382b81926f3ea169a02bc43669\n",
            "Downloaded: 29d41ecae2bffde504c3f8f17931943ae162a7b8c4e81fdde25806f90ef36584\n",
            "Downloaded: 9f5a4d295794c65aba01f2cdc0390752b2ff5915dfef73a077e695c15a78fa54\n",
            "Downloaded: 8505308edd3bf809a9ff739394006b79cae858426afe93c254e0f9b371286d6f\n",
            "Downloaded: 400821475ba1a0d98b7189e0bc0d7d5e0729eb86e02b2d6e7551fb1e91f441ee\n",
            "Downloaded: 911db8714428b8b989eeac0be54d8c85680bf76e7b88fb4bd20c1addc5ea9317\n",
            "Downloaded: 0e52249ad6bb1121227d96376c9aae0f65759c03cefe59153f5f50c26b792d03\n",
            "Downloaded: 724e2330203371cd3814a335f448cc5f313d4da45766da8322d469ad205020fc\n",
            "Downloaded: fe9a74c725c737be46fd4a4c6dc22ce90c70575c6ca297920282ceb9817653c4\n",
            "Downloaded: d42272e06c9bfdf9ae9afefb9b26bab612864128c40c1e3f930790310284e853\n",
            "Downloaded: 67d85a810866d5bd60cd99f05f180f53dacd30ccba920821577386aeff47fe3f\n",
            "Downloaded: 7f8f479fee3afb34163d9173757fc5e60cc6d71a81bb8876085a9479ae201845\n",
            "Downloaded: 8588093ccb169c6932bafd40bd878cf1b920c8c80fe569d640866fb158aba487\n",
            "Downloaded: 26de154961dc70a5ce95bd8189ede446e8be3cb28ca51323a54eece3d85b2561\n",
            "Downloaded: 1eae48e256eb1e45248ff46224cde843d965477c25a02000830e956fd676a930\n",
            "Downloaded: ea56c558b257abaf918ac7bbe9b224c6b4496f7c56d24c02a87afdbfb9bc7be7\n",
            "Downloaded: 5089246e7da2b65ae4854f7faa895d2c38f620e4f020308bbac6c6a18bdef8ff\n",
            "Downloaded: 61fe21c247b011dc359dafeed3fb76065fcfbf7260bee79e1cba69556771d8a7\n",
            "Downloaded: 68fa7df3a28554cf3282270542742be7b4ccf4b3821ec9fb3e6cfd008a147e94\n",
            "Downloaded: 2e19883cefdd8196c025eaa2fedf75921326c84e646459def8369c008985860e\n",
            "Downloaded: c683c9941509cf3b6df866a84d1415aa5ee905e2a610c94a39598a83c37144c5\n",
            "Downloaded: 221d31a1afdab118a8a707e7e59526bd85831f607facf75329f25aa3bd813b94\n",
            "Downloaded: d33dfb1c7a21f369504a8aec56f22e52eea5421b88b1cc6afe737af3281e29c2\n",
            "Downloaded: ec69305444e0f6576a55339d6ff341d7a1340aa5043968f061f5589cf4f7fe0a\n",
            "Downloaded: b933d16ad33c5e39ef847be413cbd173df88b584e7cbefd0f23c28754f3c05b7\n",
            "Downloaded: 99e088775e36bbc7db13192d37a732a0fa2d59538f96dd9a1fe127d1de484a06\n",
            "Downloaded: b15ac7a622a8a6f16d28d8c8ab6b8f8d2d63f05e5c95d33987ad93f767290111\n",
            "Downloaded: effd7ca7f784870340de104c8962e5e073ee307af24a30b446351425094beea4\n",
            "Downloaded: cec67578df1ce6ebc907062feca0d4a996aa07eb4b21941536ba0d6112b7fe55\n",
            "Downloaded: 2495d79efd1b96240f59ba42a07cc431f26895f28a086184de0dae49218ad105\n",
            "Downloaded: 7f59667020769d391884c001e91b12b9f519053b8479be3ac0c35e363c44120b\n",
            "Downloaded: 1d3523e472457012f7f67cd04c623b99145c8ff5550aedd456142be9bd6e2cbd\n",
            "Downloaded: f12c04fedfb352c39f74aea26b0c7e913cbbeedf7742819e8c0c9c0f4e409822\n",
            "Downloaded: 534cb73e610342fcb66b2af1221b180caeab626f3d6e938fee4a94f519107c3b\n",
            "Downloaded: b4ef63096de20d35ef268fb83ac3d968138eadecb3c7d43ae30608867d2b75b1\n",
            "Downloaded: c973a246dc570da77191704168c445e4f3429fb40007edbe89bb662bc5770513\n",
            "Downloaded: 190c71bf8d5e0c877deafdabe8090711194ed8fe233507da73363867bc915571\n",
            "Downloaded: ccb1a3620f3e474a3af9dafa2fa43ac842b06ca46dc0d8e88b6d9f2242c1af6a\n",
            "Downloaded: 16b53179fa508980bd8ec1364c3853f5d546fadb75d067863ab3c8009ced9660\n",
            "Downloaded: a451b40258b4879592211543258d0b9b12893d8432d979ee673ce4e64c12077a\n",
            "Downloaded: 83258e84dba3400b3113e8ab6ff3cf20ca6a92031fb06577153c3ffe6f8e78ba\n",
            "Downloaded: 622d3e6ecbf08e4c0894973578a2a734b24a20c460b4a27f2609e5bc0f7c451f\n",
            "Downloaded: 6c51e0ac6e362da960eae980b48bf410ba22eb3c92c70d109e75b476e2d5a61b\n",
            "Downloaded: 90b63635862bf9670a663b578a0be53b9ca7173f0f4cca96508e04f2c1865b84\n",
            "Downloaded: 4e24945c1b79936044866e4aad90d2817da0553b00f0542c515409346f5c9709\n",
            "Downloaded: c294c615c8527336442aa21e4219b5abd4d0bf2d879ba26958068e67d76ff05e\n",
            "Downloaded: 5c64bd30bbabc8f808dc5b53f0d7653eb72a03f9adb77d898b47fff0ba990e89\n",
            "Downloaded: 68ef7147074625efad30ef99d4e56283836db405bd582f144079731d92436101\n",
            "Downloaded: 1253af94bf43c3325a11a00e25e9ce0954c817af58f10f096b590af92ed68861\n",
            "Downloaded: f782506872596f7783748eb112d82cfd64688dc399280c5860951eab04169a49\n",
            "Downloaded: f8350cc8deb9fa47ecdf594bb45ea0f7bb5df41e8f1f561ab26727e1d3302c42\n",
            "Downloaded: 018664966b385cead01d2040a3ee159dcbb1712c621807003d2509176fbb5aba\n",
            "Downloaded: 341493754d84946280dc339da724411e80c6d9623a37710d7d50376540e1f943\n",
            "Downloaded: c73f953027c86916acac2c58b15157a0935daf3c967872bc1d0c93e98354cc1e\n",
            "Downloaded: 58fa7620ae62c20ddacf91f75ea91cc2ab44854414b3e12cdb55d41306079f84\n",
            "Downloaded: 0cdcd96d05aded380badf34328786e0d5575e8d8cb72aebde7b6c77ea23d8641\n",
            "Downloaded: 8e0d400db479eaba6bb7d5e8d22466038d7e2ae02a4a24ddd858906410a2c73c\n",
            "Downloaded: 0d00ac6e055b2df0eed81f463849bf4eeec5caa06e204508b365f9f4c8017881\n",
            "Downloaded: 07a5e3a76585c93d2f6e233c04526da1bf315309a5d0418bcc6f0463721cfa13\n",
            "Downloaded: 017bc92e2dc107fd6b5e07f9667806a03dd10b011543bf010ebbce5fff48bba7\n",
            "Downloaded: 28f007512b355212be018eb455176908b29913dbac1d3cadcc8f04673660875b\n",
            "Downloaded: 75e2011744c3b0b2c8c6016642b914fd8d940424c0eca7c38cf5bdfde9bc8fdf\n",
            "Downloaded: 405bac883734e9d90944f2880f9e962f863a2365fbd2d4bdee90d97e656a7594\n",
            "Downloaded: 1929def5c30e6b0c00e9950b74216114f75a3f16858c0f2338df3acb1e71dea2\n",
            "Downloaded: 81b9c281c88ec166a3b9f5d2802d1c928ef5860ddbe0378e8983b48b5d3d7b86\n",
            "Downloaded: 110fb0f60f90321bb763d42bd5203932ed8b5394ce969288e56a782754aad9a2\n",
            "Downloaded: 9763615184dccce72eb56c63fb823c2db9d733a2ded1e09c3cdd6d27ae4172e3\n",
            "Downloaded: a41ed5095c06844a04f0eb722e3596567f66491c5081d96971fc60f7d44aa251\n",
            "Downloaded: e6c456815c40bf0b252f30d919e3d33b1c9e7198cdce4ffbea1f5fb7f95ac336\n",
            "Downloaded: afc33411fc6d9bc0c74069497c6522ebdd2baf88d492a44453208a32f7ce62d8\n",
            "Downloaded: cd631d1f94a0f658ee4721904d73d934472e95ea99fd12748dccff9bd0c0a7f2\n",
            "Downloaded: 29f27717f0602a30706ae29d8e0ef4f5cf502fd56225eaf7755d33b792c76515\n",
            "Downloaded: 8eccb25d4f525ce68cca399e37b4b26a12588a53fc10075af1ce46ed0013b205\n",
            "Downloaded: d58861ddd6ec60b1a660982c56e68972841a9c76a0ae48028d292dbb2cdbbf8c\n",
            "Downloaded: 6871872534a5c8c4caf297a2bd7d41045576ea389686ff466db9f1a308e85694\n",
            "Downloaded: 43b8f3f7110b7aa2775907f5ddb2317ecc0930053900e812a310a6c541ae9d9b\n",
            "Downloaded: 8d181da7a2b1049f45382a80bd4c3218c1af5bfd9c54556e5e8b7f445b2bd493\n",
            "Downloaded: 0205187ef7720d68092633fa2f26b19600423c9a189167681b4d603971dcbeab\n",
            "Downloaded: faaf93253ca8b67a6a735876ba1f641b7372bc7d410035230695388e5dbaa50b\n",
            "Downloaded: 1c4af0c9308880cf5ecbe41a0f23967284565a391bca181e092a8c6afc79c128\n",
            "Downloaded: e10013d8f820748e389bedbf3af35c9c8262f3af8e8bd40fd3145566ccf11b7c\n",
            "Downloaded: e7f3c6e825dc32c3a85d0376ec05bb4963c1b2817622c7d466d176434ce05061\n",
            "Downloaded: 1e4cb810b4b57df9529e092b8308e4adb0c9f60e9f4df4779ab733aab8681587\n",
            "Downloaded: 3ef07ec1b46a003c1d41ee6ea83d870cb6c3aa1b15c1aa7062d0ebc890582c05\n",
            "Downloaded: bc8fe5e6c7cda70ae5d4b616d75bedeb29b2ad07b853109f99db67f0ccd6304c\n",
            "Downloaded: 7224130c1b4620524110f8d845b154b52f2e7e54fe0f5f1c7b1d04257230a4fe\n",
            "Downloaded: 9d472615a8417ebd0d4119b579fb3a0ef38ce6f5ee3354cbed7ca74165906eb1\n",
            "Downloaded: c00353d797ea679d51afe86b9d51ec7a803f729318881b9e8bc46a8fc1fe35de\n",
            "Downloaded: 611dcf8b58c8e159e96b2650f7bb1e4ae297000969e63ca21b6d1c7f53e73e8b\n",
            "Downloaded: ec39433a13f46fc5a39f7ffc34713e1e616d3fb6d83e9724f54a8e6254f13544\n",
            "Downloaded: 30ffb47b47c982f755405c57541cb27ce0a499cfa9f17eea59cc94193e62b5db\n",
            "Downloaded: 354194d1cd6bd132b3f5dfd76392c929e35fde5d7a3a7ea8a45d42b342c369d3\n",
            "Downloaded: 6e6ed6db1d5f69f0548fcadb1cc21ad2e1240625a5c42e5e01e54a16b6f99236\n",
            "Downloaded: d58910d1ba502439794f312140e6e4427122385ab62292741b0e96979da7365c\n",
            "Downloaded: 7177384d9b8ccb3504b290f7b97c09175d80887305eb52631af5a9362837ca6a\n",
            "Downloaded: a023d3278ea1e4cc00242e1ad2fa2667f02ec8387ee82d871bce5d46b811cc64\n",
            "Downloaded: 052df5c4ecd587e8f816fb77f41485a9a9b12cbd8c8af704c85150691306c730\n",
            "Downloaded: d27e41096bc31ca61271a8cd6bef43ce85c1754673d095371f375971af847daf\n",
            "Downloaded: 476b6d9f836bf30d6c6da1d97fef39de505ee445ff7f4a72fb9b4dfd241f422c\n",
            "Downloaded: 03017e25c4b3045bd476dc3754b78caa21c7c5f30528a7c1bd903044cf6367a7\n",
            "Downloaded: 82b4105e7b274be57085557ef2d0fea71675d0d8fcd73bacdae75acade5fadf5\n",
            "Downloaded: 5ed5ad6db4ce2790aba0bd5c186ab55446726e09c83e537dfeb5c29f3d579414\n",
            "Downloaded: c783916fa58b66545ff4e34d83e47a00fd91a5428114c898578ec25ca9ff95b6\n",
            "Downloaded: ba89a80c15ea83505b1f7a89df174e066a679f34bca32d70dfa0e0bb46a502fe\n",
            "Downloaded: 4b343d0f3ade00178cc5314b3611047f4e0691927add01eae89d0ef30ecae134\n",
            "Downloaded: 8063f0c88cb37604a1a89c86a117397c8f93bffd871d13a81620afbe58990a43\n",
            "Downloaded: 8b098a575df38df6cc83162128a9d12e0f4d6aa878bb7c1b228e0828f8a85745\n",
            "Downloaded: 64ee1fc1cde0fd6f038880472950647f50a7ba845ac1cde04de28ecea2b2f5f0\n",
            "Downloaded: 8e42af92793db5c31febd1fb93c8bef32756e5c801427306d24dd4c82ac069eb\n",
            "Downloaded: 02d27b89d849c7a11bd396e239ca53ed11d347623229a00afbe4f863a8b06a3e\n",
            "Downloaded: 15285441c19048b6cd4eeb09194bad80feaa3847de65a706d918baf15134aa5c\n",
            "Downloaded: 9e5e0818d1f96409816bb4e26c570933f1820d17aa86bd1635041ba152a738ea\n",
            "Downloaded: abb1ec90d719251f4f1fce62fe612a1042809b2c843e07a41575d4b15bdfecf5\n",
            "Downloaded: 395e19d987600da6928c797e149377a05adaf3125ced17dea4614dd8d854dfba\n",
            "Downloaded: 270be9eadc2fec4486f642d7ba81e828d9094fe1e1e67c5172634510cd1f5ef8\n",
            "Downloaded: c884bb0fa692edb71f64f1070bd4257bbc7a14a5387e343d483270da9197351e\n",
            "Downloaded: 8e5c961ff81d85532661ee17391effbae95d5172447be4f890a77a854dd7b334\n",
            "Downloaded: 93c4002e7a98c1f079bf1956a7bb842aedd120a13b20ab9507ace51921aeedd4\n",
            "Downloaded: 574ed0342b508342974846643316f2f2b9bd31094b7f7ca128dac0d8b6eb09e4\n",
            "Downloaded: db470ebf26ba91f34a3332ca620cedaa27f8d611e026679bdb2c01551f5e9558\n",
            "Downloaded: 740f2161e4c48d75f109e8276bc1d8bd4332b28941f71fa5680a138c875a8e6c\n",
            "Downloaded: 87d08f7a1f73aa000e68495647b812f8694e4b33d912eb48e93eb9872306bf84\n",
            "Downloaded: 59d8b300ca29d3cced994cffeed0d737c285a28721732cfd7816d8aff1602e85\n",
            "Downloaded: 413390869a557e671b67c92628db6a91427a8150b208169e099515ed847025f5\n",
            "Downloaded: 9026cbcda6abe20004fd6cbc9344fec54d4da4c015139983e8c9fb373fb5893f\n",
            "Downloaded: f9dd304ae1c03a5e6838e5dd68fef3ca57a087afe5e11d579a3e93325f71c55f\n",
            "Downloaded: 2176a2572d9f662e12340346e1462133ee0a0660b1a6790ba8dc6d0559e9d2f7\n",
            "Downloaded: 57f26076e3f4a54aa70ae87878f3b3df1813bde1797dc3190f9732076f208a31\n",
            "Downloaded: 027aba4324c27cfcc392911e823bc88f8da156bb90b85915928634aca838d725\n",
            "Downloaded: a1fca9506dd03872315b7bf1a6f0fab028449fcc4e3ed7801dd4618814ed142b\n",
            "Downloaded: 142c9ccf7abf34c2bc6c90e52d9cfd59804f164ce606de2ea9d9db644eeefe68\n",
            "Downloaded: 9699aa84f3d4544b63f9df84b9094c658c8ede5a02784e863e5a9eb2de7d9fd1\n",
            "Downloaded: 49a87cd9b04810154c5f98ba6c5d6ce0991532fee700f3b1b8eb8eb9be686615\n",
            "Downloaded: 53c212ddac9eb24f51050ab7eadcd3144d954150e654efbaafe22cc4b938e0ed\n",
            "Downloaded: 1805118b5f6be78d81632314ebeead81c3a87c8484ada929132fc4a3f91145a1\n",
            "Downloaded: 6e49fcfcaff55ba6c80fb676e5aba48fd400c8dd5c4f1ace866c05273ebf394f\n",
            "Downloaded: 658167ca3f75e88fc4f443025a44479c1f588aa2eb80c8ba146d52f85fe4fadb\n",
            "Downloaded: ff0bf6dbb73a98e6f2ec528aa584f6c136bb2c60fc9d208c0c07ede92d406ed1\n",
            "Downloaded: 64bbf09721793085632d515bdff7d99c2e5b6991be322c2a55751f4f70625684\n",
            "Downloaded: f875897a880b13a715ae830e7e2ed24424dfa013b7275f299494727d1380b649\n",
            "Downloaded: 0b57e3208c069b6f0d07e37684142901eb9b4ee97889ab28d2fc27bb4acef754\n",
            "Downloaded: 1c9e00478c80cd6f6a67acd94f29d1036118bed0171cd60351c5cfb1d0c13ea0\n",
            "Downloaded: 12e8e8c0ccbd38b900ff944f84aa99a00dc13014970508bb75aa1cc025c61507\n",
            "Downloaded: c247309092fdaadb5124fa6f66e529fef4c034e74f019709b2cb75f51fcb49af\n",
            "Downloaded: d631dcd2ac6fc6e7b98fd6f3d490dcda24e179bfd7894592a2e0ed1667cfdf90\n",
            "Download process completed.\n"
          ]
        }
      ],
      "source": [
        "# download benign samples\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import concurrent.futures\n",
        "\n",
        "# Replace with your actual API key in androidzoo\n",
        "APIKEY = \"717edc01a24bab5afe87835503feb736540c51352fe02bf2e487146caf0fa192\"\n",
        "\n",
        "# List of SHA256 hashes\n",
        "sha256_list = benign_sha256\n",
        "\n",
        "# Base URL for the download\n",
        "base_url = \"https://androzoo.uni.lu/api/download\"\n",
        "\n",
        "# Destination directory for downloaded APKs\n",
        "download_dir = \"/content/datasets/benign/\"\n",
        "\n",
        "# Create the download directory if it doesn't exist\n",
        "os.makedirs(download_dir, exist_ok=True)\n",
        "\n",
        "# Function to download an APK file\n",
        "def download_apk(sha256):\n",
        "    params = {\"apikey\": APIKEY, \"sha256\": sha256}\n",
        "    response = requests.get(base_url, params=params)\n",
        "    if response.status_code == 200:\n",
        "        filename = sha256\n",
        "        file_path = os.path.join(download_dir, filename)\n",
        "        with open(file_path, \"wb\") as apk_file:\n",
        "            apk_file.write(response.content)\n",
        "        print(f\"Downloaded: {filename}\")\n",
        "    else:\n",
        "        print(f\"Failed to download APK with SHA256: {sha256}\")\n",
        "\n",
        "# Set the maximum number of concurrent downloads (adjust as needed)\n",
        "max_concurrent_downloads = 40\n",
        "\n",
        "# Use ThreadPoolExecutor to run download_apk concurrently\n",
        "with concurrent.futures.ThreadPoolExecutor(max_concurrent_downloads) as executor:\n",
        "    executor.map(download_apk, sha256_list)\n",
        "\n",
        "print(\"Download process completed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the CSV file into a DataFrame\n",
        "df_malicious = pd.read_csv('/content/malware_detection/datasets/malicious_sha256.csv')\n",
        "\n",
        "# Extract the first column as a list\n",
        "malicious_sha256 = df_malicious.iloc[:, 0].tolist()[:350]"
      ],
      "metadata": {
        "id": "SLdVKMWevx1I"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGjZWMvt4Bsu",
        "outputId": "a1fc1a9d-b173-4206-a00b-f5e48682196e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded: f86c0abfe9f95f26d275dd4f0975a037879895451ac6a9c313c4b55b3b9ec5d1\n",
            "Downloaded: 370d03bddc8f3c0475c7ac9c2087b2d2b9ba75784134f86ccdbf3ff3f767da1e\n",
            "Downloaded: 0f69c23273789a1de9e7968418c52dc22b83efa6378b7d2a863dd833dad1684f\n",
            "Downloaded: 3e1d0b46568132eaa5c046a9711c1fc741c22d067400097df8b147ecf6fd70bb\n",
            "Downloaded: c33892fea2f47df861d81a4ae690d8040df2cd3e5753e92e6efa713b82e5a0aa\n",
            "Downloaded: 7f1ed691ef1d8b8e35f168f0f039dc8dc936d945296d66d04c1b4c140a48cddb\n",
            "Downloaded: 0752519e262e470be0c165c3ac5db7cea34a8dc13a15064c4bddac481897ff10\n",
            "Downloaded: 7894a893c7d61102d04ab83f8b57ec821b12f25f5f277bdda5d9c4ffd794e92e\n",
            "Downloaded: e656fc99de56809e7daf86910ce7791e656734a009e702172c0128f9cc4bc82c\n",
            "Downloaded: b5dc305c3a4c81e346c004b1c6590f2683ac727f501658af6e51cbc6ea799091\n",
            "Downloaded: 547141641e2e845d95bb53d74f499dfb7bc9aa5bdc555989fa250bcdff47e10d\n",
            "Downloaded: eb27ec66da5ced43843fffb1d36bb06cf250eec08d0a5f965e09d2ca2d9314c9\n"
          ]
        }
      ],
      "source": [
        "## download malicious samples\n",
        "\n",
        "# List of SHA256 hashes\n",
        "sha256_list = malicious_sha256\n",
        "\n",
        "# Base URL for the download\n",
        "base_url = \"https://androzoo.uni.lu/api/download\"\n",
        "\n",
        "# Destination directory for downloaded APKs\n",
        "download_dir = \"/content/datasets/malicious/\"\n",
        "\n",
        "# Create the download directory if it doesn't exist\n",
        "os.makedirs(download_dir, exist_ok=True)\n",
        "\n",
        "# Function to download an APK file\n",
        "def download_apk(sha256):\n",
        "    params = {\"apikey\": APIKEY, \"sha256\": sha256}\n",
        "    response = requests.get(base_url, params=params)\n",
        "    if response.status_code == 200:\n",
        "        filename = sha256\n",
        "        file_path = os.path.join(download_dir, filename)\n",
        "        with open(file_path, \"wb\") as apk_file:\n",
        "            apk_file.write(response.content)\n",
        "        print(f\"Downloaded: {filename}\")\n",
        "    else:\n",
        "        print(f\"Failed to download APK with SHA256: {sha256}\")\n",
        "\n",
        "# Set the maximum number of concurrent downloads (adjust as needed)\n",
        "max_concurrent_downloads = 40\n",
        "\n",
        "# Use ThreadPoolExecutor to run download_apk concurrently\n",
        "with concurrent.futures.ThreadPoolExecutor(max_concurrent_downloads) as executor:\n",
        "    executor.map(download_apk, sha256_list)\n",
        "\n",
        "print(\"Download process completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/datasets/benign/* /content/malware_detection/datasets/drebin/benign_samples/\n",
        "!mv /content/datasets/malicious/* /content/malware_detection/datasets/drebin/malicious_samples/"
      ],
      "metadata": {
        "id": "nAfcwLqiwQMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "folder_path = '/content/malware_detection/datasets/drebin/benign_samples'\n",
        "file_count = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
        "print(f\"Number of files in benign_samples : {file_count}\")"
      ],
      "metadata": {
        "id": "zdrYNqv2wZdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "folder_path = '/content/malware_detection/datasets/drebin/malicious_samples'\n",
        "file_count = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
        "print(f\"Number of files in malicious_samples : {file_count}\")"
      ],
      "metadata": {
        "id": "v_5Jxz4YOQ_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m examples.md_nn_test --cuda --cache --seed 0 --batch_size 128 --proc_number 10 --epochs 50 --max_vocab_size 10000 --dense_hidden_units \"200,200\" --weight_decay 0.0 --lr 0.001 --dropout 0.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLcONMaThGdG",
        "outputId": "f18bcf4b-1296-471c-a47a-7715a4bc46b9"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "2023-10-22 14:05:46,207 md_dnn.py[line:85] WARNING: Unknown hyper-parameters {'proc_number': 10, 'number_of_smali_files': 1000000, 'max_vocab_size': 10000, 'update': False, 'cuda': True, 'seed': 0, 'batch_size': 128, 'epochs': 50, 'lr': 0.001, 'weight_decay': 0.0, 'cache': True, 'mode': 'train', 'model_name': 'xxxxxxxx-xxxxxx'}\n",
            "2023-10-22 14:05:46,210 md_dnn.py[line:62] INFO: ========================================dnn model architecture===============================\n",
            "2023-10-22 14:05:46,210 md_dnn.py[line:63] INFO: MalwareDetectionDNN(\n",
            "  (nn_model_layer_0): Linear(in_features=235, out_features=200, bias=True)\n",
            "  (nn_model_layer_1): Linear(in_features=200, out_features=200, bias=True)\n",
            "  (nn_model_layer_2): Linear(in_features=200, out_features=2, bias=True)\n",
            ")\n",
            "2023-10-22 14:05:46,210 md_dnn.py[line:64] INFO: ===============================================end==========================================\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "2023-10-22 14:05:46,996 md_dnn.py[line:221] INFO: Mini batch: 1/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:46,997 md_dnn.py[line:223] INFO: Training loss (batch level): 0.7374 | Train accuracy: 33.33\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:47,257 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.7374 | Train accuracy: 33.33\n",
            "2023-10-22 14:05:47,257 md_dnn.py[line:249] INFO: Validation accuracy: 0.00 | The best validation accuracy: 0.00 at epoch: 0\n",
            "2023-10-22 14:05:47,394 md_dnn.py[line:221] INFO: Mini batch: 2/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:47,394 md_dnn.py[line:223] INFO: Training loss (batch level): 0.6418 | Train accuracy: 83.33\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:47,644 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.6418 | Train accuracy: 83.33\n",
            "2023-10-22 14:05:47,645 md_dnn.py[line:249] INFO: Validation accuracy: 0.00 | The best validation accuracy: 0.00 at epoch: 1\n",
            "2023-10-22 14:05:47,765 md_dnn.py[line:221] INFO: Mini batch: 3/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:47,765 md_dnn.py[line:223] INFO: Training loss (batch level): 0.6036 | Train accuracy: 66.67\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:48,012 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.6036 | Train accuracy: 66.67\n",
            "2023-10-22 14:05:48,013 md_dnn.py[line:249] INFO: Validation accuracy: 0.00 | The best validation accuracy: 0.00 at epoch: 2\n",
            "2023-10-22 14:05:48,145 md_dnn.py[line:221] INFO: Mini batch: 4/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:48,146 md_dnn.py[line:223] INFO: Training loss (batch level): 0.5207 | Train accuracy: 66.67\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:48,407 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.5207 | Train accuracy: 66.67\n",
            "2023-10-22 14:05:48,407 md_dnn.py[line:249] INFO: Validation accuracy: 0.00 | The best validation accuracy: 0.00 at epoch: 3\n",
            "2023-10-22 14:05:48,540 md_dnn.py[line:221] INFO: Mini batch: 5/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:48,541 md_dnn.py[line:223] INFO: Training loss (batch level): 0.4956 | Train accuracy: 66.67\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:48,789 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.4956 | Train accuracy: 66.67\n",
            "2023-10-22 14:05:48,789 md_dnn.py[line:249] INFO: Validation accuracy: 0.00 | The best validation accuracy: 0.00 at epoch: 4\n",
            "2023-10-22 14:05:48,915 md_dnn.py[line:221] INFO: Mini batch: 6/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:48,916 md_dnn.py[line:223] INFO: Training loss (batch level): 0.4950 | Train accuracy: 66.67\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:49,178 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.4950 | Train accuracy: 66.67\n",
            "2023-10-22 14:05:49,178 md_dnn.py[line:249] INFO: Validation accuracy: 0.00 | The best validation accuracy: 0.00 at epoch: 5\n",
            "2023-10-22 14:05:49,295 md_dnn.py[line:221] INFO: Mini batch: 7/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:49,295 md_dnn.py[line:223] INFO: Training loss (batch level): 0.4655 | Train accuracy: 66.67\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:49,550 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.4655 | Train accuracy: 66.67\n",
            "2023-10-22 14:05:49,551 md_dnn.py[line:249] INFO: Validation accuracy: 0.00 | The best validation accuracy: 0.00 at epoch: 6\n",
            "2023-10-22 14:05:49,685 md_dnn.py[line:221] INFO: Mini batch: 8/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:49,686 md_dnn.py[line:223] INFO: Training loss (batch level): 0.4511 | Train accuracy: 66.67\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:49,926 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.4511 | Train accuracy: 66.67\n",
            "2023-10-22 14:05:49,927 md_dnn.py[line:249] INFO: Validation accuracy: 0.00 | The best validation accuracy: 0.00 at epoch: 7\n",
            "2023-10-22 14:05:50,064 md_dnn.py[line:221] INFO: Mini batch: 9/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:50,065 md_dnn.py[line:223] INFO: Training loss (batch level): 0.4082 | Train accuracy: 66.67\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:50,334 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.4082 | Train accuracy: 66.67\n",
            "2023-10-22 14:05:50,334 md_dnn.py[line:249] INFO: Validation accuracy: 0.00 | The best validation accuracy: 0.00 at epoch: 8\n",
            "2023-10-22 14:05:50,456 md_dnn.py[line:221] INFO: Mini batch: 10/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:50,456 md_dnn.py[line:223] INFO: Training loss (batch level): 0.4015 | Train accuracy: 66.67\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:50,710 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.4015 | Train accuracy: 66.67\n",
            "2023-10-22 14:05:50,711 md_dnn.py[line:249] INFO: Validation accuracy: 0.00 | The best validation accuracy: 0.00 at epoch: 9\n",
            "2023-10-22 14:05:50,839 md_dnn.py[line:221] INFO: Mini batch: 11/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:50,840 md_dnn.py[line:223] INFO: Training loss (batch level): 0.3266 | Train accuracy: 83.33\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:51,097 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.3266 | Train accuracy: 83.33\n",
            "2023-10-22 14:05:51,097 md_dnn.py[line:249] INFO: Validation accuracy: 0.00 | The best validation accuracy: 0.00 at epoch: 10\n",
            "2023-10-22 14:05:51,242 md_dnn.py[line:221] INFO: Mini batch: 12/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:51,242 md_dnn.py[line:223] INFO: Training loss (batch level): 0.3333 | Train accuracy: 83.33\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:51,504 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.3333 | Train accuracy: 83.33\n",
            "2023-10-22 14:05:51,504 md_dnn.py[line:249] INFO: Validation accuracy: 0.00 | The best validation accuracy: 0.00 at epoch: 11\n",
            "2023-10-22 14:05:51,625 md_dnn.py[line:221] INFO: Mini batch: 13/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:51,626 md_dnn.py[line:223] INFO: Training loss (batch level): 0.3280 | Train accuracy: 83.33\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:51,874 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.3280 | Train accuracy: 83.33\n",
            "2023-10-22 14:05:51,874 md_dnn.py[line:249] INFO: Validation accuracy: 0.00 | The best validation accuracy: 0.00 at epoch: 12\n",
            "2023-10-22 14:05:51,999 md_dnn.py[line:221] INFO: Mini batch: 14/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:51,999 md_dnn.py[line:223] INFO: Training loss (batch level): 0.3165 | Train accuracy: 66.67\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:52,271 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.3165 | Train accuracy: 66.67\n",
            "2023-10-22 14:05:52,271 md_dnn.py[line:249] INFO: Validation accuracy: 0.00 | The best validation accuracy: 0.00 at epoch: 13\n",
            "2023-10-22 14:05:52,399 md_dnn.py[line:221] INFO: Mini batch: 15/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:52,399 md_dnn.py[line:223] INFO: Training loss (batch level): 0.3033 | Train accuracy: 83.33\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:52,753 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.3033 | Train accuracy: 83.33\n",
            "2023-10-22 14:05:52,753 md_dnn.py[line:249] INFO: Validation accuracy: 0.00 | The best validation accuracy: 0.00 at epoch: 14\n",
            "2023-10-22 14:05:52,975 md_dnn.py[line:221] INFO: Mini batch: 16/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:52,975 md_dnn.py[line:223] INFO: Training loss (batch level): 0.2057 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:53,415 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.2057 | Train accuracy: 100.00\n",
            "2023-10-22 14:05:53,415 md_dnn.py[line:249] INFO: Validation accuracy: 0.00 | The best validation accuracy: 0.00 at epoch: 15\n",
            "2023-10-22 14:05:53,626 md_dnn.py[line:221] INFO: Mini batch: 17/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:53,627 md_dnn.py[line:223] INFO: Training loss (batch level): 0.2395 | Train accuracy: 83.33\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:54,062 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.2395 | Train accuracy: 83.33\n",
            "2023-10-22 14:05:54,062 md_dnn.py[line:249] INFO: Validation accuracy: 0.00 | The best validation accuracy: 0.00 at epoch: 16\n",
            "2023-10-22 14:05:54,248 md_dnn.py[line:221] INFO: Mini batch: 18/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:54,248 md_dnn.py[line:223] INFO: Training loss (batch level): 0.1855 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:54,671 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.1855 | Train accuracy: 100.00\n",
            "2023-10-22 14:05:54,671 md_dnn.py[line:249] INFO: Validation accuracy: 0.00 | The best validation accuracy: 0.00 at epoch: 17\n",
            "2023-10-22 14:05:54,863 md_dnn.py[line:221] INFO: Mini batch: 19/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:54,864 md_dnn.py[line:223] INFO: Training loss (batch level): 0.1709 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:55,325 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.1709 | Train accuracy: 100.00\n",
            "2023-10-22 14:05:55,326 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 18\n",
            "2023-10-22 14:05:55,544 md_dnn.py[line:221] INFO: Mini batch: 20/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:55,545 md_dnn.py[line:223] INFO: Training loss (batch level): 0.1553 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:55,997 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.1553 | Train accuracy: 100.00\n",
            "2023-10-22 14:05:55,997 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 19\n",
            "2023-10-22 14:05:56,227 md_dnn.py[line:221] INFO: Mini batch: 21/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:56,227 md_dnn.py[line:223] INFO: Training loss (batch level): 0.1403 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:56,595 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.1403 | Train accuracy: 100.00\n",
            "2023-10-22 14:05:56,595 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 20\n",
            "2023-10-22 14:05:56,780 md_dnn.py[line:221] INFO: Mini batch: 22/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:56,781 md_dnn.py[line:223] INFO: Training loss (batch level): 0.1571 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:57,059 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.1571 | Train accuracy: 100.00\n",
            "2023-10-22 14:05:57,059 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 21\n",
            "2023-10-22 14:05:57,196 md_dnn.py[line:221] INFO: Mini batch: 23/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:57,196 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0871 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:57,518 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0871 | Train accuracy: 100.00\n",
            "2023-10-22 14:05:57,518 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 22\n",
            "2023-10-22 14:05:57,665 md_dnn.py[line:221] INFO: Mini batch: 24/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:57,665 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0906 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:57,940 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0906 | Train accuracy: 100.00\n",
            "2023-10-22 14:05:57,940 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 23\n",
            "2023-10-22 14:05:58,071 md_dnn.py[line:221] INFO: Mini batch: 25/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:58,071 md_dnn.py[line:223] INFO: Training loss (batch level): 0.1196 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:58,321 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.1196 | Train accuracy: 100.00\n",
            "2023-10-22 14:05:58,321 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 24\n",
            "2023-10-22 14:05:58,434 md_dnn.py[line:221] INFO: Mini batch: 26/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:58,434 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0993 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:58,703 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0993 | Train accuracy: 100.00\n",
            "2023-10-22 14:05:58,704 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 25\n",
            "2023-10-22 14:05:58,829 md_dnn.py[line:221] INFO: Mini batch: 27/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:58,829 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0523 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:59,090 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0523 | Train accuracy: 100.00\n",
            "2023-10-22 14:05:59,090 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 26\n",
            "2023-10-22 14:05:59,226 md_dnn.py[line:221] INFO: Mini batch: 28/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:59,226 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0334 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:59,496 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0334 | Train accuracy: 100.00\n",
            "2023-10-22 14:05:59,497 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 27\n",
            "2023-10-22 14:05:59,613 md_dnn.py[line:221] INFO: Mini batch: 29/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:59,613 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0292 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:05:59,867 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0292 | Train accuracy: 100.00\n",
            "2023-10-22 14:05:59,867 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 28\n",
            "2023-10-22 14:05:59,983 md_dnn.py[line:221] INFO: Mini batch: 30/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:05:59,983 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0533 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:06:00,229 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0533 | Train accuracy: 100.00\n",
            "2023-10-22 14:06:00,230 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 29\n",
            "2023-10-22 14:06:00,357 md_dnn.py[line:221] INFO: Mini batch: 31/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:06:00,357 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0301 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:06:00,611 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0301 | Train accuracy: 100.00\n",
            "2023-10-22 14:06:00,612 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 30\n",
            "2023-10-22 14:06:00,729 md_dnn.py[line:221] INFO: Mini batch: 32/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:06:00,730 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0460 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:06:00,985 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0460 | Train accuracy: 100.00\n",
            "2023-10-22 14:06:00,986 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 31\n",
            "2023-10-22 14:06:01,106 md_dnn.py[line:221] INFO: Mini batch: 33/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:06:01,106 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0058 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:06:01,365 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0058 | Train accuracy: 100.00\n",
            "2023-10-22 14:06:01,365 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 32\n",
            "2023-10-22 14:06:01,507 md_dnn.py[line:221] INFO: Mini batch: 34/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:06:01,507 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0302 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:06:01,771 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0302 | Train accuracy: 100.00\n",
            "2023-10-22 14:06:01,772 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 33\n",
            "2023-10-22 14:06:01,904 md_dnn.py[line:221] INFO: Mini batch: 35/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:06:01,904 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0108 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:06:02,156 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0108 | Train accuracy: 100.00\n",
            "2023-10-22 14:06:02,156 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 34\n",
            "2023-10-22 14:06:02,285 md_dnn.py[line:221] INFO: Mini batch: 36/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:06:02,285 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0117 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:06:02,526 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0117 | Train accuracy: 100.00\n",
            "2023-10-22 14:06:02,526 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 35\n",
            "2023-10-22 14:06:02,673 md_dnn.py[line:221] INFO: Mini batch: 37/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:06:02,674 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0069 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:06:02,918 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0069 | Train accuracy: 100.00\n",
            "2023-10-22 14:06:02,918 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 36\n",
            "2023-10-22 14:06:03,041 md_dnn.py[line:221] INFO: Mini batch: 38/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:06:03,041 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0120 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:06:03,293 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0120 | Train accuracy: 100.00\n",
            "2023-10-22 14:06:03,293 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 37\n",
            "2023-10-22 14:06:03,431 md_dnn.py[line:221] INFO: Mini batch: 39/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:06:03,432 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0092 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:06:03,692 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0092 | Train accuracy: 100.00\n",
            "2023-10-22 14:06:03,692 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 38\n",
            "2023-10-22 14:06:03,817 md_dnn.py[line:221] INFO: Mini batch: 40/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:06:03,818 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0044 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:06:04,082 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0044 | Train accuracy: 100.00\n",
            "2023-10-22 14:06:04,083 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 39\n",
            "2023-10-22 14:06:04,212 md_dnn.py[line:221] INFO: Mini batch: 41/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:06:04,212 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0016 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:06:04,474 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0016 | Train accuracy: 100.00\n",
            "2023-10-22 14:06:04,475 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 40\n",
            "2023-10-22 14:06:04,597 md_dnn.py[line:221] INFO: Mini batch: 42/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:06:04,598 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0128 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:06:04,872 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0128 | Train accuracy: 100.00\n",
            "2023-10-22 14:06:04,872 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 41\n",
            "2023-10-22 14:06:05,004 md_dnn.py[line:221] INFO: Mini batch: 43/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:06:05,004 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0026 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:06:05,247 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0026 | Train accuracy: 100.00\n",
            "2023-10-22 14:06:05,248 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 42\n",
            "2023-10-22 14:06:05,377 md_dnn.py[line:221] INFO: Mini batch: 44/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:06:05,377 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0082 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:06:05,633 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0082 | Train accuracy: 100.00\n",
            "2023-10-22 14:06:05,634 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 43\n",
            "2023-10-22 14:06:05,771 md_dnn.py[line:221] INFO: Mini batch: 45/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:06:05,771 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0072 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:06:06,019 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0072 | Train accuracy: 100.00\n",
            "2023-10-22 14:06:06,020 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 44\n",
            "2023-10-22 14:06:06,151 md_dnn.py[line:221] INFO: Mini batch: 46/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:06:06,151 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0041 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:06:06,399 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0041 | Train accuracy: 100.00\n",
            "2023-10-22 14:06:06,400 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 45\n",
            "2023-10-22 14:06:06,523 md_dnn.py[line:221] INFO: Mini batch: 47/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:06:06,523 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0027 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:06:06,792 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0027 | Train accuracy: 100.00\n",
            "2023-10-22 14:06:06,792 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 46\n",
            "2023-10-22 14:06:06,945 md_dnn.py[line:221] INFO: Mini batch: 48/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:06:06,947 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0024 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:06:07,401 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0024 | Train accuracy: 100.00\n",
            "2023-10-22 14:06:07,402 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 47\n",
            "2023-10-22 14:06:07,619 md_dnn.py[line:221] INFO: Mini batch: 49/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:06:07,620 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0026 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:06:08,042 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0026 | Train accuracy: 100.00\n",
            "2023-10-22 14:06:08,042 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 48\n",
            "2023-10-22 14:06:08,275 md_dnn.py[line:221] INFO: Mini batch: 50/50 | training time in 0 minutes, 0 seconds.\n",
            "2023-10-22 14:06:08,275 md_dnn.py[line:223] INFO: Training loss (batch level): 0.0021 | Train accuracy: 100.00\n",
            "Model saved at path: /content/malware_detection/save/drebin/md_dnn_20231022-140546/model.pth\n",
            "2023-10-22 14:06:08,728 md_dnn.py[line:247] INFO: Training loss (epoch level): 0.0021 | Train accuracy: 100.00\n",
            "2023-10-22 14:06:08,729 md_dnn.py[line:249] INFO: Validation accuracy: 100.00 | The best validation accuracy: 100.00 at epoch: 49\n",
            "2023-10-22 14:06:09,078 md_dnn.py[line:165] INFO: The accuracy on the test dataset is 100.00000%\n",
            "2023-10-22 14:06:09,078 md_dnn.py[line:167] INFO: The balanced accuracy on the test dataset is 100.00000%\n",
            "Other evaluation metrics we may need:\n",
            "2023-10-22 14:06:09,082 md_dnn.py[line:180] INFO: False Negative Rate (FNR) is 0.00000%, False Positive Rate (FPR) is 0.00000%, F1 score is 100.00000%\n"
          ]
        }
      ]
    }
  ]
}