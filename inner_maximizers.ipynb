{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1H1KnRs-6oLBOnUpT_3BQ1AoHPcf_q43r",
      "authorship_tag": "ABX9TyNv8IfJOZgh2l8wZ2XDL1MM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/a_malware/blob/main/inner_maximizers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def or_float_tensors(x_1, x_2):\n",
        "    \"\"\"\n",
        "    ORs two float tensors by converting them to byte and back\n",
        "    Note that byte() takes the first 8 bit after the decimal point of the float\n",
        "    e.g., 0.0 ==> 0\n",
        "          0.1 ==> 0\n",
        "          1.1 ==> 1\n",
        "        255.1 ==> 255\n",
        "        256.1 ==> 0\n",
        "    Subsequently the purpose of this function is to map 1s float tensors to 1\n",
        "    and those of 0s to 0. I.e., it is meant to be used on tensors of 0s and 1s.\n",
        "\n",
        "    :param x_1: tensor one\n",
        "    :param x_2: tensor two\n",
        "    :return: float tensor of 0s and 1s.\n",
        "    \"\"\"\n",
        "    return (x_1.byte() | x_2.byte()).float()\n",
        "\n",
        "\n",
        "def xor_float_tensors(x_1, x_2):\n",
        "    \"\"\"\n",
        "    XORs two float tensors by converting them to byte and back\n",
        "    Note that byte() takes the first 8 bit after the decimal point of the float\n",
        "    e.g., 0.0 ==> 0\n",
        "          0.1 ==> 0\n",
        "          1.1 ==> 1\n",
        "        255.1 ==> 255\n",
        "        256.1 ==> 0\n",
        "    Subsequently the purpose of this function is to map 1s float tensors to 1\n",
        "    and those of 0s to 0. I.e., it is meant to be used on tensors of 0s and 1s.\n",
        "\n",
        "    :param x_1: tensor one\n",
        "    :param x_2: tensor two\n",
        "    :return: float tensor of 0s and 1s.\n",
        "    \"\"\"\n",
        "    return (x_1.byte() ^ x_2.byte()).float()\n",
        "\n",
        "\n",
        "def clip_tensor(x, lb=0., ub=1.):\n",
        "    \"\"\"\n",
        "    Clip a tensor to be within lb and ub\n",
        "    :param x:\n",
        "    :param lb: lower bound (scalar)\n",
        "    :param ub: upper bound (scalar)\n",
        "    :return: clipped version of x\n",
        "    \"\"\"\n",
        "    return torch.clamp(x, min=lb, max=ub)\n",
        "\n",
        "def round_x(x, alpha=0.99):\n",
        "    \"\"\"\n",
        "    rounds x by thresholding it according to alpha which can be a scalar or vector\n",
        "    :param x:\n",
        "    :param alpha: threshold parameter\n",
        "    :return: a float tensor of 0s and 1s.\n",
        "    \"\"\"\n",
        "    return (x > alpha).float()\n",
        "\n",
        "\n",
        "def get_x0(x, is_sample=False):\n",
        "    \"\"\"\n",
        "    Helper function to randomly initialize the the inner maximizer algos\n",
        "    randomize such that the functionality is preserved.\n",
        "    Functionality is preserved by maintaining the features present in x\n",
        "    :param x: training sample\n",
        "    :param is_sample: flag to sample randomly from feasible area or return just x\n",
        "    :return: randomly sampled feasible version of x\n",
        "    \"\"\"\n",
        "    if is_sample:\n",
        "        rand_x = round_x(torch.rand(x.size()))\n",
        "        if x.is_cuda:\n",
        "            rand_x = rand_x.cuda()\n",
        "        return or_float_tensors(x, rand_x)\n",
        "    else:\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "rcpYyhRhmhwS"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os.path as path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIN9uSWILNkN",
        "outputId": "dbb6468e-f7c2-4c78-f2d8-e77d4d871352"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mostafa-ja/malware_detection.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvQzurUxzh7x",
        "outputId": "674f7810-bbd3-47b5-e543-268808023f53"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'malware_detection'...\n",
            "remote: Enumerating objects: 15943, done.\u001b[K\n",
            "remote: Counting objects: 100% (2095/2095), done.\u001b[K\n",
            "remote: Compressing objects: 100% (250/250), done.\u001b[K\n",
            "remote: Total 15943 (delta 1948), reused 1980 (delta 1835), pack-reused 13848\u001b[K\n",
            "Receiving objects: 100% (15943/15943), 179.53 MiB | 28.27 MiB/s, done.\n",
            "Resolving deltas: 100% (12878/12878), done.\n",
            "Updating files: 100% (142/142), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "E9woBsXkq7HP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "\n",
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, samples):\n",
        "        self.samples = [(torch.tensor(data, dtype=torch.float32), label) for data, label in samples]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.samples[index]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torch.load('/content/malware_detection/datasets/train_dataset.pt')\n",
        "train_Loader = data.DataLoader(train_dataset, batch_size=128, shuffle=False)\n",
        "validation_dataset = torch.load('/content/malware_detection/datasets/validation_dataset.pt')\n",
        "validation_Loader = data.DataLoader(validation_dataset, batch_size=10000, shuffle=False)\n",
        "test_dataset = torch.load('/content/malware_detection/datasets/test_dataset.pt')\n",
        "test_Loader = data.DataLoader(test_dataset, batch_size=10000, shuffle=False)"
      ],
      "metadata": {
        "id": "B39GkhWXrGy3"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('train_dataset size : ', len(train_dataset))\n",
        "print('validation_dataset size : ', len(validation_dataset))\n",
        "print('test_dataset size : ', len(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqMvr0XR0WmF",
        "outputId": "00f0d5ae-ebe2-496f-9f6b-ecff25d3d851"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_dataset size :  1199\n",
            "validation_dataset size :  400\n",
            "test_dataset size :  400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "class MalwareDetectionDNN(nn.Module):\n",
        "    def __init__(self, input_size, n_classes, device='cpu', name='DNN', dense_hidden_units=[200, 200], dropout=0.6, smooth=False):\n",
        "        \"\"\"\n",
        "        Construct malware detector\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        @param input_size: Integer, the dimentionality number of input vector\n",
        "        @param n_classes: Integer, the number of classes, n=2\n",
        "        @param device: String, 'cpu' or 'cuda'\n",
        "        @param name: String, model name\n",
        "        \"\"\"\n",
        "        super(MalwareDetectionDNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.n_classes = n_classes\n",
        "        self.name = name\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.smooth = smooth\n",
        "        self.dense_hidden_units = dense_hidden_units\n",
        "\n",
        "        self.dense_layers = []\n",
        "        if len(self.dense_hidden_units) >= 1:\n",
        "            self.dense_layers.append(nn.Linear(self.input_size, self.dense_hidden_units[0]))\n",
        "        else:\n",
        "            raise ValueError(\"Expect at least one hidden layer.\")\n",
        "        for i in range(len(self.dense_hidden_units[0:-1])):\n",
        "            self.dense_layers.append(nn.Linear(self.dense_hidden_units[i],  # start from idx=1\n",
        "                                               self.dense_hidden_units[i + 1]))\n",
        "        self.dense_layers.append(nn.Linear(self.dense_hidden_units[-1], self.n_classes))\n",
        "\n",
        "        # registration\n",
        "        for idx_i, dense_layer in enumerate(self.dense_layers):\n",
        "            self.add_module('nn_model_layer_{}'.format(idx_i), dense_layer)\n",
        "\n",
        "        if self.smooth:\n",
        "            self.activation_func = F.selu  # partial(F.elu, alpha=self.alpha_)\n",
        "        else:\n",
        "            self.activation_func = F.relu\n",
        "\n",
        "        self.model_save_path = path.join('/content/malware_detection/save/drebin/md_dnn'+ '_' + self.name,'model.pth')\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Go through the neural network\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        @param x: 2D tensor, feature representation\n",
        "        \"\"\"\n",
        "        for dense_layer in self.dense_layers[:-1]:\n",
        "            x = self.activation_func(dense_layer(x))\n",
        "\n",
        "        latent_representation = F.dropout(x, self.dropout, training=self.training)\n",
        "        logits = self.dense_layers[-1](latent_representation)\n",
        "        return logits\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v0j39fpP-vlt"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MalwareDetectionDNN(3070,2)\n",
        "model = model.to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVPO6jQi_DPE",
        "outputId": "c8900888-ab84-43b3-9fb3-5a3e8f89f3d7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MalwareDetectionDNN(\n",
              "  (nn_model_layer_0): Linear(in_features=3070, out_features=200, bias=True)\n",
              "  (nn_model_layer_1): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (nn_model_layer_2): Linear(in_features=200, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(model, input_size=(3070,))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_-ZtrKX-6rW",
        "outputId": "7e2c100d-1e87-4825-b0b8-b46445029c03"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 200]         614,200\n",
            "            Linear-2                  [-1, 200]          40,200\n",
            "            Linear-3                    [-1, 2]             402\n",
            "================================================================\n",
            "Total params: 654,802\n",
            "Trainable params: 654,802\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 2.50\n",
            "Estimated Total Size (MB): 2.51\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('/content/MalwareDetectionDNN.pth'))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gMh8_eMlT9V",
        "outputId": "0b6fc4f6-8317-40f3-d2d9-f164b9a905c6"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MalwareDetectionDNN(\n",
              "  (nn_model_layer_0): Linear(in_features=3070, out_features=200, bias=True)\n",
              "  (nn_model_layer_1): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (nn_model_layer_2): Linear(in_features=200, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples,labels = next(iter(test_Loader))\n",
        "x,y = samples[0:1],labels[0:1]\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0v_nGozlhmm",
        "outputId": "96b7a14f-205a-4299-80e9-f23428b228d6"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3070])\n",
            "torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert samples and labels to PyTorch tensors and specify dtype as torch.float\n",
        "# Convert samples and labels to a floating-point data type\n",
        "x = x.clone().to(torch.float).requires_grad_(True)\n",
        "y = y.clone().to(torch.long)"
      ],
      "metadata": {
        "id": "7usfs8rxr1ug"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fct = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# compute natural loss\n",
        "loss_natural = loss_fct(model(x), y).data\n",
        "loss_natural\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWazL9e5mOFw",
        "outputId": "65f2041b-3081-466d-880a-686d961c6d0a"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_next = get_x0(x, is_sample=True)\n",
        "print(torch.sum(x))\n",
        "print(torch.sum(x_next))\n",
        "# having alpha big number alpha(here 0.99) to decrease the diffrence between x and x_next"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84UdIi-qnCbb",
        "outputId": "b4b380b9-c937-4164-e3c5-13b973ca5153"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(30., grad_fn=<SumBackward0>)\n",
            "tensor(56.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multi-step with gradients\n",
        "k=10\n",
        "epsilon = 0.02\n",
        "for t in range(k):\n",
        "    # forward pass\n",
        "    x_var = x_next.requires_grad_()\n",
        "    y_model = model(x_var)\n",
        "    loss = loss_fct(y_model, y)\n",
        "    print(loss)\n",
        "    # compute gradient\n",
        "    #grad_vars gives us the list of gradients of variables which are requires_grad compare to loss\n",
        "    # here we just have one variable so in grad_vars there is just one element\n",
        "    grad_vars = torch.autograd.grad(loss.mean(), x_var)\n",
        "\n",
        "\n",
        "    # find the next sample\n",
        "    x_next = x_next + epsilon * torch.sign(grad_vars[0].data)\n",
        "\n",
        "    # projection\n",
        "    x_next = clip_tensor(x_next)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hrfa3fpuuhm",
        "outputId": "8c5f6e98-b1b1-4899-cd1b-0fbd395aa65e"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(29.2442, grad_fn=<NllLossBackward0>)\n",
            "tensor(45.1557, grad_fn=<NllLossBackward0>)\n",
            "tensor(60.8567, grad_fn=<NllLossBackward0>)\n",
            "tensor(76.3368, grad_fn=<NllLossBackward0>)\n",
            "tensor(91.7155, grad_fn=<NllLossBackward0>)\n",
            "tensor(107.0838, grad_fn=<NllLossBackward0>)\n",
            "tensor(122.4927, grad_fn=<NllLossBackward0>)\n",
            "tensor(137.8887, grad_fn=<NllLossBackward0>)\n",
            "tensor(153.2570, grad_fn=<NllLossBackward0>)\n",
            "tensor(168.5825, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grad_vars[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9m0dxMHvpr5",
        "outputId": "f217eef9-d8ca-4bd3-fc70-110800a904b7"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3070])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zeBf2mvyvwrB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}