{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPO4v+l1IjwvlVTBX/IAAky",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/a_malware/blob/main/genetic_algorithm3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install androguard\n",
        "!pip install captum\n",
        "\n",
        "import androguard\n",
        "import captum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GmGwtcRElwZ",
        "outputId": "49e812f5-9f10-4447-e390-1fe27220b3bb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting androguard\n",
            "  Downloading androguard-3.3.5-py3-none-any.whl (922 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.4/922.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asn1crypto>=0.24.0 (from androguard)\n",
            "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from androguard) (8.1.7)\n",
            "Collecting colorama (from androguard)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from androguard) (0.18.3)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from androguard) (7.34.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from androguard) (4.9.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from androguard) (3.7.1)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.10/dist-packages (from androguard) (3.2.1)\n",
            "Requirement already satisfied: pydot>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from androguard) (1.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from androguard) (2.16.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->androguard)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (3.0.41)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->androguard) (4.8.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot>=1.4.1->androguard) (3.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->androguard) (2.8.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->androguard) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->androguard) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->androguard) (0.2.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->androguard) (1.16.0)\n",
            "Installing collected packages: asn1crypto, jedi, colorama, androguard\n",
            "Successfully installed androguard-3.3.5 asn1crypto-1.5.1 colorama-0.4.6 jedi-0.19.1\n",
            "Collecting captum\n",
            "  Downloading captum-0.6.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from captum) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from captum) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from captum) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->captum) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->captum) (1.3.0)\n",
            "Installing collected packages: captum\n",
            "Successfully installed captum-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eRx10YoAiFg",
        "outputId": "4ab59c1b-ac97-462b-c7b6-e0805fff2870"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "Cloning into 'malware_detection'...\n",
            "remote: Enumerating objects: 16033, done.\u001b[K\n",
            "remote: Counting objects: 100% (2185/2185), done.\u001b[K\n",
            "remote: Compressing objects: 100% (168/168), done.\u001b[K\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import os.path as path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "!git clone https://github.com/mostafa-ja/malware_detection.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "# our sharable address : https://drive.google.com/file/d/1-MPYbRTFn_zH3rybfAYihHuIjq2XSiI5/view?usp=sharing\n",
        "download_link = 'https://drive.google.com/uc?id=1-MPYbRTFn_zH3rybfAYihHuIjq2XSiI5'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "id": "nBAlbafmmMfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://drive.google.com/uc?id=1--gjFTkAJUW74RXWE4anJ5wssV7K_VAo'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "id": "LWrVkcPVjjzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://drive.google.com/uc?id=1-2NnBk3YKauGTGK8DfQHBxrLrYyTxNsp'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "id": "P3KZMz42m4c1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://drive.google.com/uc?id=1-4PhQGYHpMXrCcxcgMadgPPA4S-9yluX'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "id": "9vo-g1RHm46G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_link = 'https://drive.google.com/uc?id=1JmP8VxTUU3Yi7dle247PKlgrS6WS91x8'\n",
        "output_filepath = '/content/'\n",
        "gdown.download(download_link, output_filepath)"
      ],
      "metadata": {
        "id": "YAEZPxxKPPa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/train_dataset.pt /content/malware_detection/datasets\n",
        "!cp /content/validation_dataset.pt /content/malware_detection/datasets\n",
        "!cp /content/test_dataset.pt /content/malware_detection/datasets"
      ],
      "metadata": {
        "id": "ml8RC85unN-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "\n",
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, samples):\n",
        "        self.samples = [(torch.tensor(data, dtype=torch.float32), label) for data, label in samples]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.samples[index]"
      ],
      "metadata": {
        "id": "a4E-Kgs2AoJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MalwareDetectionDNN(nn.Module):\n",
        "    def __init__(self, input_size, n_classes, device='cpu', name='DNN', dense_hidden_units=[200, 200], dropout=0.6, smooth=False):\n",
        "        \"\"\"\n",
        "        Construct malware detector\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        @param input_size: Integer, the dimentionality number of input vector\n",
        "        @param n_classes: Integer, the number of classes, n=2\n",
        "        @param device: String, 'cpu' or 'cuda'\n",
        "        @param name: String, model name\n",
        "        \"\"\"\n",
        "        super(MalwareDetectionDNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.n_classes = n_classes\n",
        "        self.name = name\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.smooth = smooth\n",
        "        self.dense_hidden_units = dense_hidden_units\n",
        "\n",
        "        self.dense_layers = []\n",
        "        if len(self.dense_hidden_units) >= 1:\n",
        "            self.dense_layers.append(nn.Linear(self.input_size, self.dense_hidden_units[0]))\n",
        "        else:\n",
        "            raise ValueError(\"Expect at least one hidden layer.\")\n",
        "        for i in range(len(self.dense_hidden_units[0:-1])):\n",
        "            self.dense_layers.append(nn.Linear(self.dense_hidden_units[i],  # start from idx=1\n",
        "                                               self.dense_hidden_units[i + 1]))\n",
        "        self.dense_layers.append(nn.Linear(self.dense_hidden_units[-1], self.n_classes))\n",
        "\n",
        "        # registration\n",
        "        for idx_i, dense_layer in enumerate(self.dense_layers):\n",
        "            self.add_module('nn_model_layer_{}'.format(idx_i), dense_layer)\n",
        "\n",
        "        if self.smooth:\n",
        "            self.activation_func = F.selu  # partial(F.elu, alpha=self.alpha_)\n",
        "        else:\n",
        "            self.activation_func = F.relu\n",
        "\n",
        "        self.model_save_path = path.join('/content/malware_detection/save/drebin/md_dnn'+ '_' + self.name,'model.pth')\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Go through the neural network\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        @param x: 2D tensor, feature representation\n",
        "        \"\"\"\n",
        "        for dense_layer in self.dense_layers[:-1]:\n",
        "            x = self.activation_func(dense_layer(x))\n",
        "\n",
        "        latent_representation = F.dropout(x, self.dropout, training=self.training)\n",
        "        logits = self.dense_layers[-1](latent_representation)\n",
        "        return logits\n",
        "\n",
        "    def customize_loss(self, logits, gt_labels, representation = None, mini_batch_idx=None):\n",
        "        return F.cross_entropy(logits, gt_labels)\n",
        "\n",
        "    # for predict pertubed malicious and create a y_true same size for theam\n",
        "    def inference_batch_wise(self, x):\n",
        "        \"\"\"\n",
        "        support malware samples solely\n",
        "        \"\"\"\n",
        "        assert isinstance(x, torch.Tensor)\n",
        "        logit = self.forward(x)\n",
        "        return torch.softmax(logit, dim=-1).detach().cpu().numpy(), np.ones((logit.size()[0],))\n",
        "\n",
        "    def inference(self, test_data_producer):\n",
        "        confidences = []\n",
        "        gt_labels = []\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            for x, y in test_data_producer: # for large dataset we have to consider test dataset with batches\n",
        "                x, y = x.double().to(device), y.long().to(device)\n",
        "                logits = self.forward(x)\n",
        "                confidences.append(F.softmax(logits, dim=-1))\n",
        "                gt_labels.append(y)\n",
        "        confidences = torch.vstack(confidences) #[[1,2,3],[4,5,6]] > below each other\n",
        "        gt_labels = torch.cat(gt_labels, dim=0) #[[1,2,3],[4,5,6]] > [1,2,3,4,5,6]\n",
        "        return confidences, gt_labels"
      ],
      "metadata": {
        "id": "IBNqn_OEAuV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/malware_detection"
      ],
      "metadata": {
        "id": "MRRx7oWaDnGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torch.load('/content/malware_detection/datasets/train_dataset.pt')\n",
        "train_Loader = data.DataLoader(train_dataset, batch_size=128, shuffle=False)\n",
        "validation_dataset = torch.load('/content/malware_detection/datasets/validation_dataset.pt')\n",
        "validation_Loader = data.DataLoader(validation_dataset, batch_size=10000, shuffle=False)\n",
        "test_dataset = torch.load('/content/malware_detection/datasets/test_dataset.pt')\n",
        "test_Loader = data.DataLoader(test_dataset, batch_size=10000, shuffle=False)"
      ],
      "metadata": {
        "id": "MRAX7j_qywXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from core.droidfeature import InverseDroidFeature\n",
        "\n",
        "inverse_feature = InverseDroidFeature()\n",
        "\n",
        "# manipulation_x : removable features\n",
        "manipulation_x = inverse_feature.get_manipulation()\n",
        "manipulation_x = torch.LongTensor(manipulation_x).to(device)\n",
        "\n",
        "# index of vocab which are interdependent\n",
        "omega = inverse_feature.get_interdependent_apis()\n",
        "omega = torch.sum(F.one_hot(torch.tensor(omega), num_classes=len(inverse_feature.vocab)),dim=0).to(device)\n",
        "\n",
        "# a list of vocab length : if the type of feature is api , index of that feature will be true\n",
        "api_flag = inverse_feature.get_api_flag()"
      ],
      "metadata": {
        "id": "sY7SRwnGYixM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#mimicry"
      ],
      "metadata": {
        "id": "vi7BQWN3Woz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def changable(adv_features,manipulation_x):\n",
        "  pos_insertion = (adv_features <= 0.5) * 1\n",
        "  pos_removal = (adv_features > 0.5)& (manipulation_x) * 1\n",
        "  mask = pos_insertion - pos_removal\n",
        "  return mask\n",
        "\n",
        "# Initialization Function\n",
        "def initialization(original_example, ben_x, manipulation_x, num_individuals):\n",
        "    indices = torch.randperm(len(ben_x))[:num_individuals]\n",
        "    trial_vectors = ben_x[indices]\n",
        "    x_fixed_one = ((1. - manipulation_x).float() * original_example)\n",
        "    modified_x = torch.clamp(x_fixed_one + trial_vectors, min=0., max=1.)\n",
        "    modified_x = modified_x.double()\n",
        "    return modified_x\n",
        "\n",
        "\n",
        "def fitness_function(individual,delta, alpha):\n",
        "  pertubation = torch.sum(abs(delta))\n",
        "  pertubed_x = individual + delta\n",
        "  if model.inference_batch_wise(pertubed_x.double())[0][0].argmax() == 1 :\n",
        "      fitness = 80 * (model.inference_batch_wise(pertubed_x.double())[0][0][1])\n",
        "  else :\n",
        "      fitness = model.inference_batch_wise(pertubed_x.double())[0][0][1] + alpha * pertubation\n",
        "\n",
        "  return fitness\n",
        "\n",
        "def selection(population, fitness_values):\n",
        "    selected_parents = []\n",
        "    s = sum(fitness_values)\n",
        "    fitness_values = [s / x for x in fitness_values]\n",
        "    total_fitness = torch.sum(torch.tensor(fitness_values))\n",
        "\n",
        "    # Calculate selection probabilities\n",
        "    selection_probabilities = torch.tensor(fitness_values) / total_fitness\n",
        "\n",
        "    # Perform roulette wheel selection to choose parents\n",
        "    for _ in range(len(population)):\n",
        "        rand_val = random.random()\n",
        "        cumulative_prob = 0.0\n",
        "        for i, prob in enumerate(selection_probabilities):\n",
        "            cumulative_prob += prob.item()\n",
        "            if rand_val <= cumulative_prob:\n",
        "                selected_parents.append(population[i])\n",
        "                break\n",
        "\n",
        "    return selected_parents\n",
        "\n",
        "\n",
        "\n",
        "def crossover(parent_1, parent_2, crossover_prob):\n",
        "\n",
        "    # Create a matrix B of the same size as the parents filled with random 0s and 1s\n",
        "    B = torch.randint(0, 2, size=parent_1.size()).float()\n",
        "    if random.random() < crossover_prob :\n",
        "      child_1 = parent_1 * B  + parent_2 * (1 - B)\n",
        "      child_2 = parent_1 * (1 - B)  + parent_2 * B\n",
        "    else :\n",
        "      child_1 = parent_1\n",
        "      child_2 = parent_2\n",
        "\n",
        "    return child_1, child_2\n",
        "\n",
        "\n",
        "\n",
        "def mutation(individual, A_cross, mutation_prob,manipulation_x):\n",
        "    prob = torch.rand(A_cross.size()) > mutation_prob\n",
        "    mutated_A = A_cross * prob\n",
        "    return mutated_A\n",
        "\n",
        "\n",
        "# Main Genetic Algorithm\n",
        "def genetic_algorithm(original_example, ben_x, manipulation_x, num_individuals, max_generation, alpha, crossover_prob, mutation_prob):\n",
        "    population = initialization(original_example, ben_x, manipulation_x, num_individuals)\n",
        "    fitness = []\n",
        "    fit_min = 100\n",
        "    for t in range(max_generation):\n",
        "        # Calculate fitness values for the current population\n",
        "        fitness_values = [fitness_function(original_example, delta, alpha) for delta in population]\n",
        "        fitness.append(torch.min(torch.tensor(fitness_values)))\n",
        "        if torch.min(torch.tensor(fitness_values)) < fit_min :\n",
        "            fit_min = torch.min(torch.tensor(fitness_values))\n",
        "            best_adversarial_example = population[torch.argmin(torch.tensor(fitness_values))]\n",
        "            print(torch.sum(abs(best_adversarial_example)))\n",
        "            print(fit_min)\n",
        "        # Check termination condition\n",
        "        #if max(fitness_values) < gamma:\n",
        "            #break\n",
        "\n",
        "        # Selection\n",
        "        selected_parents = selection(population, fitness_values)\n",
        "\n",
        "        # Create new population using crossover and mutation\n",
        "        new_population = []\n",
        "        for i in range(0, num_individuals, 2):\n",
        "            parent_1 = selected_parents[i]\n",
        "            parent_2 = selected_parents[i + 1]\n",
        "\n",
        "            child_1, child_2 = crossover(parent_1, parent_2, crossover_prob)\n",
        "            child_1 = mutation(original_example, child_1, mutation_prob, manipulation_x)\n",
        "            child_2 = mutation(original_example, child_2, mutation_prob, manipulation_x)\n",
        "\n",
        "            new_population.extend([child_1, child_2])\n",
        "\n",
        "        population = new_population\n",
        "\n",
        "    # Return the best adversarial example after termination\n",
        "\n",
        "    return best_adversarial_example, fitness"
      ],
      "metadata": {
        "id": "Q2aSysMTbgD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MalwareDetectionDNN(6693,2)\n",
        "model = model.double().to(device)\n",
        "ckpt = torch.load('/content/md_at_pgd.pth')\n",
        "model.load_state_dict(ckpt['model'])"
      ],
      "metadata": {
        "id": "38k87O4JPh_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MalwareDetectionDNN(6693,2)\n",
        "model = model.double().to(device)\n",
        "model.load_state_dict(torch.load('/content/malware_detection/model.pth'))"
      ],
      "metadata": {
        "id": "moyA8-soZc21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SO IMPORTANT\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "G21DF7LTULft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "original_example = x\n",
        "num_individuals = 100\n",
        "max_generation = 500\n",
        "gamma = 0.5\n",
        "alpha = 0.01\n",
        "initial_prob = 20\n",
        "crossover_prob = 0.5\n",
        "mutation_prob = 0.01\n",
        "\n",
        "best_adversarial_example, fitness = genetic_algorithm(x, manipulation_x, num_individuals, max_generation, gamma, alpha, crossover_prob, mutation_prob)\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Mkzk-ZAw8ccz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = next(iter(test_Loader))\n",
        "mal_x = X[y==1]\n",
        "ben_x = X[y==0]"
      ],
      "metadata": {
        "id": "RAetCI2UEahv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genetic_algorithm(original_example,ben_xو manipulation_x, num_individuals, max_generation, alpha, crossover_prob, mutation_prob)"
      ],
      "metadata": {
        "id": "djUtUEi1TBJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_example = mal_x[2:3]\n",
        "num_individuals = 100\n",
        "max_generation = 300\n",
        "gamma = 0.5\n",
        "alpha = 0.01\n",
        "crossover_prob = 0.5\n",
        "mutation_prob = 0.01\n",
        "\n",
        "best_adversarial_example, fitness = genetic_algorithm(x, ben_x, manipulation_x, num_individuals, max_generation, gamma, alpha, crossover_prob, mutation_prob)\n"
      ],
      "metadata": {
        "id": "V5GbhlzWQCUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(fitness)"
      ],
      "metadata": {
        "id": "PvRAw1PMS3u7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.inference_batch_wise((x+best_adversarial_example).double())[0]"
      ],
      "metadata": {
        "id": "Zz30AtjZQj43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(best_adversarial_example)"
      ],
      "metadata": {
        "id": "ygza3a_t-4b5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(x)"
      ],
      "metadata": {
        "id": "SZf_UlIn_J9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(x+best_adversarial_example)"
      ],
      "metadata": {
        "id": "ZKSa7m0y_QlR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}